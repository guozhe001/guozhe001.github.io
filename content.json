{"meta":{"title":"滴水成涓","subtitle":"每天进步一点点","description":"","author":"guozhe","url":"https://guozhe001.github.io"},"pages":[{"title":"分类","date":"2020-12-31T03:08:07.000Z","updated":"2024-11-22T06:32:06.497Z","comments":true,"path":"categories/index.html","permalink":"https://guozhe001.github.io/categories/index.html","excerpt":"","text":"","raw":null,"content":null},{"title":"about","date":"2020-12-30T11:07:14.000Z","updated":"2024-11-22T06:32:06.497Z","comments":true,"path":"about/index.html","permalink":"https://guozhe001.github.io/about/index.html","excerpt":"","text":"","raw":null,"content":null},{"title":"search","date":"2020-12-30T11:21:06.000Z","updated":"2024-11-22T06:32:06.498Z","comments":true,"path":"search/index.html","permalink":"https://guozhe001.github.io/search/index.html","excerpt":"","text":"","raw":null,"content":null},{"title":"标签","date":"2020-12-31T03:13:42.000Z","updated":"2024-11-22T06:32:06.498Z","comments":true,"path":"tags/index.html","permalink":"https://guozhe001.github.io/tags/index.html","excerpt":"","text":"","raw":null,"content":null}],"posts":[{"title":"","slug":"others/follow_renzheng","date":"2024-11-23T15:55:05.568Z","updated":"2024-11-23T15:55:14.189Z","comments":true,"path":"2024/11/23/others/follow_renzheng/","link":"","permalink":"https://guozhe001.github.io/2024/11/23/others/follow_renzheng/","excerpt":"","text":"This message is used to verify that this feed (feedId:83175506817005568) belongs to me (userId:82619195380144128). Join me in enjoying the next generation information browser https://follow.is.","raw":null,"content":null,"categories":[],"tags":[]},{"title":"","slug":"language/一些好的项目跟踪","date":"2024-11-22T06:32:06.497Z","updated":"2024-11-22T06:32:06.497Z","comments":true,"path":"2024/11/22/language/一些好的项目跟踪/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/language/%E4%B8%80%E4%BA%9B%E5%A5%BD%E7%9A%84%E9%A1%B9%E7%9B%AE%E8%B7%9F%E8%B8%AA/","excerpt":"","text":"一些好的但是还没有上线（或发币）的项目跟踪 项目名称 项目描述 项目地址 个人备注 optimism layer 2解决方案 https://optimism.io/ uniswap等defi项目支持 ZK Rollup layer 2解决方案 https://zksync.io/ 2021值得关注的l2","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Docker常用命令记录","slug":"others/Docker常用命令记录","date":"2024-11-22T06:32:06.497Z","updated":"2024-11-22T06:32:06.497Z","comments":true,"path":"2024/11/22/others/Docker常用命令记录/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/others/Docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E8%AE%B0%E5%BD%95/","excerpt":"","text":"docker命令 删除本地所有没有被使用的卷： 1docker volume prune WARNING! This will remove all local volumes not used by at least one container. 查看本地的所有卷： 1docker volume ls 删除某个volume卷 1docker volume rm docker_orderer.supply.com 查看所有的容器，包括没有运行中的 1docker ps -a 查看某个容器的日志 1docker logs ead00b30e8ec 停止容器 1docker stop 46bc78ee1f8a e8df5432a918 be15203b7835 删除容器 1docker rm ead00b30e8ec 46bc78ee1f8a e8df5432a918 be15203b7835 进入docker容器 1docker exec -it f37c61b09023 /bin/sh 修改容器的环境变量 在配置docker-compose某个容器的环境变量时出现了错误，但是容器已经运行了，如果重新运行则数据会丢失。所以需要修正此环境变量 1234567891011121314151617181920212223 peer0.s1.supply.com:​ container_name: peer0.s1.supply.com​ image: hyperledger/fabric-peer:2.2.0​ environment:​ *#Generic peer variables*​ \\- CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock​ *# the following setting starts chaincode containers on the same*​ *# bridge network as the peers*​ *# https://docs.docker.com/compose/networking/*​ \\- CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=_test​ \\- FABRIC_LOGGING_SPEC=INFO​ *#- FABRIC_LOGGING_SPEC=DEBUG* 如要修改CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE为docker_test: 12345# 1、进入容器docker exec -it f37c61b09023 /bin/sh# 2、修改环境变量echo &quot;export CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=docker_test&quot; &gt;&gt; /etc/profile# 3、重新启动容器即可 查看docker启动的网络 1docker network ls docker-compose命令 使用docker-compose启动docker镜像 12# --f 指定文件, -d指定后台运行docker-compose --f docker-compose.yml up -d 使用docker-compose启动指定的名称的容器 在一个docker-compose.yaml配置文件下可能有多个serevice，可以指定名称来启动其中的一个，命令如下: 1docker-compose up ca-tls","raw":null,"content":null,"categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://guozhe001.github.io/categories/Cloud/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://guozhe001.github.io/tags/Docker/"},{"name":"docker-compose","slug":"docker-compose","permalink":"https://guozhe001.github.io/tags/docker-compose/"}]},{"title":"Homebrew配置为国内镜像","slug":"others/Homebrew配置为国内镜像","date":"2024-11-22T06:32:06.497Z","updated":"2024-11-22T06:32:06.497Z","comments":true,"path":"2024/11/22/others/Homebrew配置为国内镜像/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/others/Homebrew%E9%85%8D%E7%BD%AE%E4%B8%BA%E5%9B%BD%E5%86%85%E9%95%9C%E5%83%8F/","excerpt":"","text":"本人的Mac电脑按照清华大学开源软件镜像站的设置时报错如下： 12git -C &quot;$(brew --repo homebrew/cask)&quot; remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask.gitfatal: cannot change to &#x27;/usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask&#x27;: No such file or directory 解决方案是先change到对应的目录下，在执行替换脚本，操作如下： 12345cd &quot;$(brew --repo)&quot;git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.gitcd $(brew --repo homebrew/core)git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git 卸载homebrew 执行卸载脚本： 1sudo /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/uninstall)&quot; 如果报错如下： 1curl: (7) Failed to connect to raw.githubusercontent.com port 443: Connection refused 需要配置一下host；去往https://www.ipaddress.com/，输入raw.githubusercontent.com查看ip地址，然后配置host之后重试。 安装bash_completion 卸载homebrew后发现自动补全的功能也没有了，报错如下： 1vi awk: can&#x27;t open file /usr/local/etc/bash_completion 解决方法是重新安装homebrew后，安装bash-completion： 1brew install bash-completion","raw":null,"content":null,"categories":[{"name":"Mac","slug":"Mac","permalink":"https://guozhe001.github.io/categories/Mac/"}],"tags":[{"name":"Mac","slug":"Mac","permalink":"https://guozhe001.github.io/tags/Mac/"},{"name":"Homebrew","slug":"Homebrew","permalink":"https://guozhe001.github.io/tags/Homebrew/"}]},{"title":"Gradle常用命令记录","slug":"others/Gradle常用命令","date":"2024-11-22T06:32:06.497Z","updated":"2024-11-22T06:32:06.497Z","comments":true,"path":"2024/11/22/others/Gradle常用命令/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/others/Gradle%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"Gradle常用命令记录: 运行gradle help --task someTask来显示帮助，如： 1./gradlew help --task test clean 1./gradlew clean build 1./gradlew build test 1./gradlew test 排除指定的task--exclude-task 1./gradlew clean build --exclude-task test 多模块指定模块运行task 12./gradlew :my-subproject:taskName./gradlew my-subproject:taskName 测试失败继续执行 1./gradlew test --continue 检查，会执行test和linting 1./gradlew check 显示当前的项目层次 1./gradlew project 列出所有的task 1./gradlew tasks 列出项目所有的依赖： 1./gradlew dependencies 去官网查看更多","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://guozhe001.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://guozhe001.github.io/tags/Java/"},{"name":"Gradle","slug":"Gradle","permalink":"https://guozhe001.github.io/tags/Gradle/"}]},{"title":"Linux常用命令记录","slug":"others/Linux Shell命令记录","date":"2024-11-22T06:32:06.497Z","updated":"2024-11-22T06:32:06.497Z","comments":true,"path":"2024/11/22/others/Linux Shell命令记录/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/others/Linux%20Shell%E5%91%BD%E4%BB%A4%E8%AE%B0%E5%BD%95/","excerpt":"","text":"tar(解压，压缩，帮助：tar -h) 解压，-C标签指定解压到哪个目录 1tar -xf -C ./test 压缩 1tar -cf &lt;archive-filename&gt; [filenames...] shasum（hash，帮助shasum -h） 生成hash，-a标签指定使用哪个算法 1shasum -a 256 README.md 修改终端显示，不显示用户名和电脑名称 修改/etc/bashrc：PS1='\\w $ ’ 123456789101112$ more /etc/bashrc# System-wide .bashrc file for interactive bash(1) shells.if [ -z &quot;$PS1&quot; ]; then returnfi#PS1=&#x27;\\h:\\W \\u\\$ &#x27;PS1=&#x27;\\w \\$ &#x27;# Make bash check its window size after a process completesshopt -s checkwinsize[ -r &quot;/etc/bashrc_$TERM_PROGRAM&quot; ] &amp;&amp; . &quot;/etc/bashrc_$TERM_PROGRAM&quot; 其他参数： \\d ：代表日期，格式为weekday month date，例如：“Mon Aug 1” \\H ：完整的主机名称。例如：我的机器名称为：fc4.linux，则这个名称就是fc4.linux \\h ：仅取主机的第一个名字，如上例，则为fc4，.linux则被省略 \\t ：显示时间为24小时格式，如：HH：MM：SS \\T ：显示时间为12小时格式\\A ：显示时间为24小时格式：HH：MM \\u ：当前用户的账号名称\\v ：BASH的版本信息 \\w ：完整的工作目录名称。家目录会以 ~代替 \\W ：利用basename取得工作目录名称，所以只会列出最后一个目录 # ：下达的第几个命令 $ ：提示字符，如果是root时，提示符为：# ，普通用户则为：$ crontab（定时任务,man crontab） 查看：crontab -l 编辑：crontab -e crontab配置举例如下： 123# 每天十点30分执行hello.sh# 分 时 日 月 星期 command30 10 * * * ～/hello.sh grep 屏蔽grep命令本身 1ps -ef|grep python |grep -v grep","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://guozhe001.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://guozhe001.github.io/tags/Linux/"},{"name":"shell","slug":"shell","permalink":"https://guozhe001.github.io/tags/shell/"}]},{"title":"MySQL主从复制切换","slug":"others/MYSQL主从同步切换","date":"2024-11-22T06:32:06.497Z","updated":"2024-11-22T06:32:06.497Z","comments":true,"path":"2024/11/22/others/MYSQL主从同步切换/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/others/MYSQL%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E5%88%87%E6%8D%A2/","excerpt":"","text":"背景 由于公司iaas人员在操作虚拟ip时手误，导致应该指向mysql主库的虚拟ip指向了从库。因为业务app使用的是虚拟ip链接的数据库，因此导致所有的业务数据都写入了从库，而主库的数据从此没有任何变化。 为了解决此问题，需要把原来的主库变成从库，从而继续保持mysql数据库的高可用。 基本信息 旧主库ip：172.99.0.32 旧从库ip：172.99.0.31 具体操作如下 验证当前的主从复制状态 旧的主库数据是否全部同步到从库，在原主库执行主从同步状态： 1234567sys@172.99.0.32:(none) 17:54:52&gt;show processlist;+-------+------------+-------------------+------+-------------+--------+-----------------------------------------------------------------------+------------------+----------+| Id | User | Host | db | Command | Time | State | Info | Progress |+-------+------------+-------------------+------+-------------+--------+-----------------------------------------------------------------------+------------------+----------+| 11679 | rep | 172.99.0.31:8609 | NULL | Binlog Dump | 279575 | Master has sent all binlog to slave; waiting for binlog to be updated | NULL | 0.000 |+-------+------------+-------------------+------+-------------+--------+-----------------------------------------------------------------------+------------------+----------+3 rows in set (0.00 sec) 查看从库是否可以做主库 主要是查看bin-log是否打开，结论：31服务器可以作为主库 1234567sys@172.99.0.31:(none) 17:57:01&gt;show master status;+------------------+----------+--------------+------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+------------------+----------+--------------+------------------+| mysql-bin.000153 | 2786181 | | |+------------------+----------+--------------+------------------+1 row in set (0.00 sec) 查看从哪里进行主从复制 查看旧主库最后一条bin-log位置 因为重新启动过，并且重新启动之后主库没有执行过sql，所以最新的bin-log并没有sql，因此查看上一个bin-log的最后的位置。 把二进制的bin-log转换成人类语言 1mysqlbinlog --base64-output=decode-rows -v mysql-bin.000706 &gt; mysql-bin.000706.txt 查看bin-log最后的位置如下： tail -200 mysql-bin.000706.txt 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647BEGIN&#x2F;*!*&#x2F;;# at 32438411# at 32438848# at 32438939#220317 15:00:00 server id 533307 end_log_pos 32438848 Annotate_rows:#Q&gt; update job_log set#Q&gt; job_name&#x3D;&#39;detail_NoticeJob&#39;,#Q&gt; job_cron_expression&#x3D;&#39;0 0 1,10,15,21 * * ?&#39;,#Q&gt; create_time&#x3D;&#39;2022-03-17 15:00:00&#39;,#Q&gt; job_class_name&#x3D;&#39;com.hello.lease.job.NoticeJob&#39;,#Q&gt; staff_name&#x3D;&#39;系统操作&#39;,#Q&gt; update_time&#x3D;&#39;2022-03-17 15:00:00&#39;,#Q&gt; staff_id&#x3D;0,#Q&gt; job_msg&#x3D;&#39;通知-每日1、10、15、21点&#39;,#Q&gt; status&#x3D;&#39;end&#39;#Q&gt; wher#220317 15:00:00 server id 533307 end_log_pos 32438939 Table_map: &#96;db&#96;.&#96;job_log&#96; mapped to number 3857#220317 15:00:00 server id 533307 end_log_pos 32439375 Update_rows: table id 3857 flags: STMT_END_F### UPDATE &#96;db&#96;.&#96;job_log&#96;### WHERE### @1&#x3D;14424### @2&#x3D;&#39;detail_NoticeJob&#39;### @3&#x3D;&#39;0 0 1,10,15,21 * * ?&#39;### @4&#x3D;&#39;com.hello.lease.job.NoticeJob&#39;### @5&#x3D;&#39;通知-每日1、10、15、21点&#39;### @6&#x3D;&#39;start&#39;### @7&#x3D;0### @8&#x3D;&#39;系统操作&#39;### @9&#x3D;2022-03-17 15:00:00### @10&#x3D;1647500400### SET### @1&#x3D;14424### @2&#x3D;&#39;detail_NoticeJob&#39;### @3&#x3D;&#39;0 0 1,10,15,21 * * ?&#39;### @4&#x3D;&#39;com.hello.lease.job.NoticeJob&#39;### @5&#x3D;&#39;通知-每日1、10、15、21点&#39;### @6&#x3D;&#39;end&#39;### @7&#x3D;0### @8&#x3D;&#39;系统操作&#39;### @9&#x3D;2022-03-17 15:00:00### @10&#x3D;1647500400# at 32439375#220317 15:00:00 server id 533307 end_log_pos 32439402 Xid &#x3D; 825866165COMMIT&#x2F;*!*&#x2F;;DELIMITER ;# End of log file 旧从库同步最后一条数据时的bin-log位置 根据主库的最后一条bin-log信息找到从库对应的bin-log位置如下： mysql-bin.000703 123456789101112131415161718192021222324252627282930313233BEGIN&#x2F;*!*&#x2F;;# at 132131716# at 132131807#220317 15:00:00 server id 533307 end_log_pos 132131807 Table_map: &#96;db&#96;.&#96;job_log&#96; mapped to number 54116#220317 15:00:00 server id 533307 end_log_pos 132132243 Update_rows: table id 54116 flags: STMT_END_F### UPDATE &#96;db&#96;.&#96;job_log&#96;### WHERE### @1&#x3D;14424### @2&#x3D;&#39;detail_NoticeJob&#39;### @3&#x3D;&#39;0 0 1,10,15,21 * * ?&#39;### @4&#x3D;&#39;com.hello.lease.job.NoticeJob&#39;### @5&#x3D;&#39;通知-每日1、10、15、21点&#39;### @6&#x3D;&#39;start&#39;### @7&#x3D;0### @8&#x3D;&#39;系统操作&#39;### @9&#x3D;2022-03-17 15:00:00### @10&#x3D;1647500400### SET### @1&#x3D;14424### @2&#x3D;&#39;detail_NoticeJob&#39;### @3&#x3D;&#39;0 0 1,10,15,21 * * ?&#39;### @4&#x3D;&#39;com.hello.lease.job.NoticeJob&#39;### @5&#x3D;&#39;通知-每日1、10、15、21点&#39;### @6&#x3D;&#39;end&#39;### @7&#x3D;0### @8&#x3D;&#39;系统操作&#39;### @9&#x3D;2022-03-17 15:00:00### @10&#x3D;1647500400# at 132132243#220317 15:00:00 server id 533307 end_log_pos 132132270 Xid &#x3D; 49158632COMMIT&#x2F;*!*&#x2F;;# at 132132270 进行主从切换 验证31上是否有主从复制的用户 如果没有需要新建 1234567sys@172.99.0.31:mysql 16:07:25&gt;select user,host from user where user&#x3D;&#39;rep&#39;;+----------+------+| user | host |+----------+------+| rep | % |+----------+------+1 row in set (0.00 sec) 停掉31的主从复制 123456# 停止同步stop slave;# 重置同步：https://mariadb.com/kb/en/reset-replica/RESET SLAVE;# 验证同步状态show slave status \\G 启动32的主从复制 MASTER_LOG_FILE和MASTER_LOG_POS的值是从上面的旧从库的bin-log中获取的。位置是旧主库的最后一条bin-log执行的sql的位置。 12345678910111213141516# 添加主从同步配置CHANGE MASTER TO MASTER_HOST=&#x27;172.99.0.31&#x27;, MASTER_USER=&#x27;rep&#x27;, MASTER_PASSWORD=&#x27;123456&#x27;, MASTER_PORT=3308, MASTER_LOG_FILE=&#x27;mysql-bin.000703&#x27;, MASTER_LOG_POS=132132270, MASTER_CONNECT_RETRY=10;# 启动主从同步start slave;# 验证同步状态show slave status \\G","raw":null,"content":null,"categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://guozhe001.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://guozhe001.github.io/tags/MySQL/"},{"name":"主从复制","slug":"主从复制","permalink":"https://guozhe001.github.io/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"}]},{"title":"Mac安装多版本golang","slug":"others/Mac安装多版本golang","date":"2024-11-22T06:32:06.497Z","updated":"2024-11-22T06:32:06.497Z","comments":true,"path":"2024/11/22/others/Mac安装多版本golang/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/others/Mac%E5%AE%89%E8%A3%85%E5%A4%9A%E7%89%88%E6%9C%ACgolang/","excerpt":"","text":"起因 最近在运行一些源软件时，因为golang的版本问题而报错： 12345compile: version &quot;go1.15.7&quot; does not match go tool version &quot;go1.16&quot;# golang.org/x/net/html/atomcompile: version &quot;go1.15.7&quot; does not match go tool version &quot;go1.16&quot;# golang.org/x/text/internal/utf8internalcompile: version &quot;go1.15.7&quot; does not match go tool version &quot;go1.16&quot; 安装不同版本的golang 首先安装gvm 1bash &lt; &lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer) 安装完成之后重启终端。 查看当前已经安装了哪些版本的go 1brew install go@1.15 注意：指定版本时可以先运行brew search go来查看有哪些版本，如果直接指定go1.15.7小版本可能报错。","raw":null,"content":null,"categories":[{"name":"Mac","slug":"Mac","permalink":"https://guozhe001.github.io/categories/Mac/"}],"tags":[{"name":"Mac","slug":"Mac","permalink":"https://guozhe001.github.io/tags/Mac/"},{"name":"golang","slug":"golang","permalink":"https://guozhe001.github.io/tags/golang/"}]},{"title":"Gradle学习踩坑记录","slug":"others/gradle学习踩坑记录","date":"2024-11-22T06:32:06.497Z","updated":"2024-11-22T06:32:06.497Z","comments":true,"path":"2024/11/22/others/gradle学习踩坑记录/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/others/gradle%E5%AD%A6%E4%B9%A0%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/","excerpt":"","text":"gradle学习踩坑记录 最近想学习一下Java11，使用gradle搭建了一个项目，但是在执行打包命令./gradlew clean build时报错如下： 1Could not target platform: &#x27;Java SE 11&#x27; using tool chain: &#x27;JDK 8 (1.8)&#x27; 原因是因为我本地的JAVA_HOME配置的JDK版本是1.8，但是项目中指定的编译版本为Java11： 12sourceCompatibility = JavaVersion.VERSION_11targetCompatibility = JavaVersion.VERSION_11 解决方式是在项目的根目录下新建gradle.properties文件，并写入以下配置，问题解决 1org.gradle.java.home = /Library/Java/JavaVirtualMachines/jdk-11.0.9.jdk/Contents/Home gradle的官方文档解释如下： Resolve the Gradle JVM version for the existing project IntelliJ IDEA checks the gradle.properties file for the appropriate Gradle JVM specified in org.gradle.java.home and uses it for the project. Then it checks the JAVA_HOME environment variable. Then it checks the closest appropriate JDK version for the existing Gradle version.","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://guozhe001.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://guozhe001.github.io/tags/Java/"},{"name":"Gradle","slug":"Gradle","permalink":"https://guozhe001.github.io/tags/Gradle/"}]},{"title":"ubuntu20.04设置静态ip","slug":"others/ubuntu20.04设置静态ip","date":"2024-11-22T06:32:06.497Z","updated":"2024-11-22T06:32:06.497Z","comments":true,"path":"2024/11/22/others/ubuntu20.04设置静态ip/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/others/ubuntu20.04%E8%AE%BE%E7%BD%AE%E9%9D%99%E6%80%81ip/","excerpt":"","text":"设置静态IP 修改/etc/netplan/01-network-manager-all.yaml文件如下： 123456789101112# Let NetworkManager manage all devices on this systemnetwork: version: 2 renderer: NetworkManager ethernets: wlp7s0: addresses: [192.168.0.107/24, ] dhcp4: no dhcp6: no gateway4: 192.168.0.1 nameservers: addresses: [8.8.8.8, 9.9.9.9] 其中的wlp7s0是网卡信息，可以通过ifconfig获得。 设置生效： 1sudo netplan apply 启动ssh 1apt install openssh-service","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://guozhe001.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://guozhe001.github.io/tags/Linux/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://guozhe001.github.io/tags/ubuntu/"}]},{"title":"ubuntu如何挂载硬盘","slug":"others/ubuntu如何挂载硬盘","date":"2024-11-22T06:32:06.497Z","updated":"2024-11-22T06:32:06.497Z","comments":true,"path":"2024/11/22/others/ubuntu如何挂载硬盘/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/others/ubuntu%E5%A6%82%E4%BD%95%E6%8C%82%E8%BD%BD%E7%A1%AC%E7%9B%98/","excerpt":"","text":"查看已经挂载了哪些 123456789101112131415161718192021$ df -l文件系统 1K-块 已用 可用 已用% 挂载点udev 16362980 0 16362980 0% /devtmpfs 3285100 2364 3282736 1% /run/dev/nvme0n1p7 200537360 18016188 172264740 10% /tmpfs 16425488 408624 16016864 3% /dev/shmtmpfs 5120 4 5116 1% /run/locktmpfs 16425488 0 16425488 0% /sys/fs/cgroup/dev/loop0 56832 56832 0 100% /snap/core18/1988/dev/loop1 66432 66432 0 100% /snap/gtk-common-themes/1514/dev/loop2 33152 33152 0 100% /snap/snapd/11402/dev/loop3 52352 52352 0 100% /snap/snap-store/518/dev/loop4 31872 31872 0 100% /snap/snapd/11036/dev/loop5 224256 224256 0 100% /snap/gnome-3-34-1804/66/dev/nvme0n1p1 98304 33555 64749 35% /boot/efitmpfs 3285096 20 3285076 1% /run/user/125tmpfs 3285096 92 3285004 1% /run/user/1000/dev/loop6 101632 101632 0 100% /snap/core/10908/dev/loop7 435968 435968 0 100% /snap/pycharm-community/233/dev/loop8 680192 680192 0 100% /snap/intellij-idea-community/289 查看有哪些 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889$ sudo fdisk -lDisk /dev/loop0：55.48 MiB，58159104 字节，113592 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节Disk /dev/loop1：64.79 MiB，67915776 字节，132648 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节Disk /dev/loop2：32.28 MiB，33841152 字节，66096 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节Disk /dev/loop3：51.4 MiB，53522432 字节，104536 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节Disk /dev/loop4：31.9 MiB，32595968 字节，63664 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节Disk /dev/loop5：218.102 MiB，229629952 字节，448496 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节Disk /dev/loop6：99.22 MiB，104030208 字节，203184 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节Disk /dev/loop7：425.67 MiB，446328832 字节，871736 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节Disk /dev/nvme0n1：931.53 GiB，1000204886016 字节，1953525168 个扇区Disk model: WDC WDS100T2B0C-00PXH0 单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：gpt磁盘标识符：C12B6754-9D12-4F54-92FA-086CE249C548设备 起点 末尾 扇区 大小 类型/dev/nvme0n1p1 2048 206847 204800 100M EFI 系统/dev/nvme0n1p2 206848 239615 32768 16M Microsoft 保留/dev/nvme0n1p3 239616 408449302 408209687 194.7G Microsoft 基本数据/dev/nvme0n1p4 408451072 409597951 1146880 560M Windows 恢复环境/dev/nvme0n1p5 409597952 1134321663 724723712 345.6G Microsoft 基本数据/dev/nvme0n1p6 1134321664 1543921663 409600000 195.3G Microsoft 基本数据/dev/nvme0n1p7 1543921664 1953523711 409602048 195.3G Linux 文件系统Disk /dev/sda：7.28 TiB，8001563222016 字节，15628053168 个扇区Disk model: HGST HUS728T8TAL单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 4096 字节I/O 大小(最小/最佳)：4096 字节 / 4096 字节磁盘标签类型：gpt磁盘标识符：F654D976-A27E-49D1-B0FD-5DCB3914D51D设备 起点 末尾 扇区 大小 类型/dev/sda1 34 32767 32734 16M Microsoft 保留/dev/sda2 32768 4096032767 4096000000 1.9T Microsoft 基本数据/dev/sda3 4096032768 8192032767 4096000000 1.9T Microsoft 基本数据/dev/sda4 8192032768 15628050431 7436017664 3.5T Microsoft 基本数据分区 1 未起始于物理扇区边界。Disk /dev/loop8：664.17 MiB，696426496 字节，1360208 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节 查看想要挂载的硬盘的uuid 1234567891011121314151617181920212223242526$ lsblk -fNAME FSTYPE LABEL UUID FSAVAIL FSUSE% MOUNTPOINTloop0 squashfs 0 100% /snap/core18/1988loop1 squashfs 0 100% /snap/gtk-common-themes/1514loop2 squashfs 0 100% /snap/snapd/11402loop3 squashfs 0 100% /snap/snap-store/518loop4 squashfs 0 100% /snap/snapd/11036loop5 squashfs 0 100% /snap/gnome-3-34-1804/66loop6 squashfs 0 100% /snap/core/10908loop7 squashfs 0 100% /snap/pycharm-community/233loop8 squashfs 0 100% /snap/intellij-idea-community/289sda ├─sda1 ├─sda2 ntfs 数据 38C09128C090ECFE ├─sda3 ntfs 新加卷 2A9E99709E993573 └─sda4 ntfs 新加卷 C25E9EB25E9E9F2B nvme0n1 ├─nvme0n1p1 vfat 2E15-C03F 63.2M 34% /boot/efi├─nvme0n1p2 ├─nvme0n1p3 ntfs A4AA2056AA2026F0 ├─nvme0n1p4 ntfs FE347AD2347A8D81 ├─nvme0n1p5 ntfs 娱乐 E848526348523114 ├─nvme0n1p6 ntfs 学习工作 EA1E592A1E58F155 └─nvme0n1p7 ext4 12354a11-9bf9-4882-a202-3e3e675b3158 164.3G 9% / 比如我想要挂载/dev/sda4的uuid为C25E9EB25E9E9F2B 修改/etc/fstab进行挂载 参考：https://blog.51cto.com/13570193/2070157 比如我的添加了一行：UUID=C25E9EB25E9E9F2B /data ntfs defaults 0 0 重启 验证 12345678910111213141516171819202122$ df -h文件系统 容量 已用 可用 已用% 挂载点udev 16G 0 16G 0% /devtmpfs 3.2G 2.3M 3.2G 1% /run/dev/nvme0n1p7 192G 18G 165G 10% /tmpfs 16G 0 16G 0% /dev/shmtmpfs 5.0M 4.0K 5.0M 1% /run/locktmpfs 16G 0 16G 0% /sys/fs/cgroup/dev/loop0 56M 56M 0 100% /snap/core18/1988/dev/loop1 100M 100M 0 100% /snap/core/10908/dev/loop2 33M 33M 0 100% /snap/snapd/11402/dev/loop4 52M 52M 0 100% /snap/snap-store/518/dev/loop3 426M 426M 0 100% /snap/pycharm-community/233/dev/loop5 32M 32M 0 100% /snap/snapd/11036/dev/loop6 65M 65M 0 100% /snap/gtk-common-themes/1514/dev/loop7 219M 219M 0 100% /snap/gnome-3-34-1804/66/dev/loop8 665M 665M 0 100% /snap/intellij-idea-community/289/dev/nvme0n1p1 96M 33M 64M 35% /boot/efi/dev/sda4 3.5T 211M 3.5T 1% /datatmpfs 3.2G 16K 3.2G 1% /run/user/125tmpfs 3.2G 24K 3.2G 1% /run/user/1000 1234567UUID=80A467CBA467C270 /chia/temp1 ntfs defaults 0 0UUID=A4186E0A186DDBB4 /chia/temp2 ntfs defaults 0 0UUID=089E5CA89E5C8FD4 /chia/temp3 ntfs defaults 0 0UUID=38C09128C090ECFE /chia/data1 ntfs defaults 0 0UUID=2A9E99709E993573 /chia/data2 ntfs defaults 0 0UUID=C25E9EB25E9E9F2B /chia/data3 ntfs defaults 0","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://guozhe001.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://guozhe001.github.io/tags/Linux/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://guozhe001.github.io/tags/ubuntu/"}]},{"title":"ubuntu系统下nvidia显卡超频设置","slug":"others/ubuntu系统下nvidia显卡超频设置","date":"2024-11-22T06:32:06.497Z","updated":"2024-11-22T06:32:06.497Z","comments":true,"path":"2024/11/22/others/ubuntu系统下nvidia显卡超频设置/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/others/ubuntu%E7%B3%BB%E7%BB%9F%E4%B8%8Bnvidia%E6%98%BE%E5%8D%A1%E8%B6%85%E9%A2%91%E8%AE%BE%E7%BD%AE/","excerpt":"","text":"必要条件是先安装nvidia的官方驱动 卸载全部nvidia驱动 https://az764295.vo.msecnd.net/stable/379476f0e13988d90fab105c5c19e7abc8b1dea8/VSCode-darwin-universal.zip 报错解决1： 错误信息： ERROR: The Nouveau kernel driver is currently in use by your system. This driver is incompatible with the NVIDIA driver…… 解决方法： 12345# 创建文件sudo vim /etc/modprobe.d/blacklist-nouveau.conf# 添加内容blacklist nouveauoptions nouveau modeset=0 更新使其生效 1sudo update-initramfs -u 重启机器 1sudo reboot 报错解决2： 错误信息： Unable to find the development tool cc in your path; please make sure that you have the 或： Unable to find the development tool make in your path; please make sure that you have t 解决方法： 12sudo apt install gccsudo apt install make 报错解决3: 错误信息： 1234An NVIDIA kernel module &#x27;nvidia-drm&#x27; appears to already be loaded in your kernel. This may be because it is in use (for example, by an X server, a CUDA program, or the NVIDIA Persistence Daemon), but this may also happen if your kernel was configured without support for module unloading. Please be sure to exit any programs that may be using the GPU(s) before attempting to upgrade your driver. If no GPU-based programs are running, you know that your kernel supports module unloading, and you still receive this message, then an error may have occurred that has corrupted an NVIDIA kernel module&#x27;s usage count, for which the simplest remedy is to reboot your computer. 解决方法： 卸载驱动 1sudo /usr/bin/nvidia-uninstall 安装完毕之后检查 1nvidia-smi 注意事项 在开始之前先打开ssh，并且设置静态ip否则可能无法进入桌面；如果无法进入桌面使用ssh链接然后把/etc/X11/xorg.conf文件删除之后重启即可。 参考： https://www.youtube.com/watch?v=5XaWVQ1GDVY https://bitcointalk.org/index.php?topic=2848723.0 https://blog.csdn.net/liufunan/article/details/52090382 https://askubuntu.com/questions/1251920/overclock-nvidia-gpu-to-achieve-undervolting 查看显卡信息： 1nvidia-smi 设置显卡功率 12# 设置第一个显卡的功率为125wsudo nvidia-smi -i 0 -pl 125 开启超频 生成xorg.conf文件 查看有没有/etc/X11/xorg.conf文件，如果没有则生成，命令如下 1234# 如果只有一张显卡，可以执行下面这一行。sudo nvidia-xconfig# 如果是多个显卡，但是有一个显卡是用来视频输出的，则不要执行下面这一行。# sudo nvidia-xconfig --enable-all-gpus 设置--cool-bits=28 12sudo nvidia-xconfig --cool-bits&#x3D;28# sudo nvidia-xconfig -a --cool-bits&#x3D;28 具体的cool-bits的意思如下： 1234567cool-bits的值的每一位都代表不同的含义，可以根据自己的需要组合，具体含义摘抄如下。Coolbits的值是所有位的组合成的二进制数对应的10进制数值：- 1 (bit0) 允许老的（Fermi核心）之前的显卡超频- 2 (bit1) 当使用不同显存的GPU需要设置成SLI时，可以设置这一位- 4 (bit2) 允许手动设置显卡风扇的转速- 8 (bit3) 允许超频，驱动版本要比337.12新，架构要比Fermi新- 16 (bit4) 允许超电压，驱动版本要比346.16新，架构要比Fermi新 设置完成之后查看/etc/X11/xorg.conf文件，我的Device和Screen如下： 123456789101112131415Section &quot;Device&quot; Identifier &quot;Device0&quot; Driver &quot;nvidia&quot; VendorName &quot;NVIDIA Corporation&quot;EndSectionSection &quot;Screen&quot; Identifier &quot;Screen0&quot; Device &quot;Device0&quot; Monitor &quot;Monitor0&quot; DefaultDepth 24 Option &quot;Coolbits&quot; &quot;28&quot; SubSection &quot;Display&quot; Depth 24 EndSubSection 需要把Section &quot;Screen&quot;下的Option &quot;Coolbits&quot; &quot;28&quot;这一行移动到Section Device下面，如果不移动我的会导致显示器黑屏。移动之后如下: 12345678910111213141516Section &quot;Device&quot; Identifier &quot;Device0&quot; Driver &quot;nvidia&quot; Option &quot;Coolbits&quot; &quot;28&quot; VendorName &quot;NVIDIA Corporation&quot;EndSectionSection &quot;Screen&quot; Identifier &quot;Screen0&quot; Device &quot;Device0&quot; Monitor &quot;Monitor0&quot; DefaultDepth 24 SubSection &quot;Display&quot; Depth 24 EndSubSectionEndSection 重启 1sudo reboot 超频 3070超频设置： 12nvidia-settings -c :0 -a &quot;[gpu:0]/GPUMemoryTransferRateOffset[4]=2500&quot;nvidia-settings -c :0 -a &quot;[gpu:0]/GPUGraphicsClockOffset[4]=-350&quot; 1660超频 1234567891011121314nvidia-settings -c :0 -a &quot;[gpu:0]/GPUMemoryTransferRateOffset[4]=1200&quot;nvidia-settings -c :0 -a &quot;[gpu:0]/GPUGraphicsClockOffset[4]=-80&quot;nvidia-settings -c :0 -a &quot;[gpu:1]/GPUMemoryTransferRateOffset[4]=1400&quot;nvidia-settings -c :0 -a &quot;[gpu:1]/GPUGraphicsClockOffset[4]=-100&quot;nvidia-settings -c :0 -a &quot;[gpu:2]/GPUMemoryTransferRateOffset[4]=1200&quot;nvidia-settings -c :0 -a &quot;[gpu:2]/GPUGraphicsClockOffset[4]=-80&quot;nvidia-settings -c :0 -a &quot;[gpu:3]/GPUMemoryTransferRateOffset[4]=1200&quot;nvidia-settings -c :0 -a &quot;[gpu:3]/GPUGraphicsClockOffset[4]=-80&quot;nvidia-settings -c :0 -a &quot;[gpu:4]/GPUMemoryTransferRateOffset[4]=1200&quot;nvidia-settings -c :0 -a &quot;[gpu:4]/GPUGraphicsClockOffset[4]=-80&quot;nvidia-settings -c :0 -a &quot;[gpu:5]/GPUMemoryTransferRateOffset[4]=1200&quot;nvidia-settings -c :0 -a &quot;[gpu:5]/GPUGraphicsClockOffset[4]=-80&quot;nvidia-settings -c :0 -a &quot;[gpu:6]/GPUMemoryTransferRateOffset[4]=1200&quot;nvidia-settings -c :0 -a &quot;[gpu:6]/GPUGraphicsClockOffset[4]=-80&quot; ubuntu安装.deb软件 123456# 指定安装包安装sudo dpkg -i teamviewer_15.16.8_amd64.deb# 如果上面的命令报错说缺少依赖，则执行：sudo apt -f -y install# 安装依赖之后，重新安装sudo dpkg -i teamviewer_15.16.8_amd64.deb ubuntu更新已经安装的软件 123456# 检查更新sudo apt update# 列出可更新软件apt list --upgradable# 更新sudo apt upgrade","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"https://guozhe001.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://guozhe001.github.io/tags/Linux/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://guozhe001.github.io/tags/ubuntu/"},{"name":"nvidia","slug":"nvidia","permalink":"https://guozhe001.github.io/tags/nvidia/"}]},{"title":"MySQL数据库备份并添加主从复制","slug":"others/数据库备份并添加主从复制","date":"2024-11-22T06:32:06.497Z","updated":"2024-11-22T06:32:06.497Z","comments":true,"path":"2024/11/22/others/数据库备份并添加主从复制/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/others/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E5%B9%B6%E6%B7%BB%E5%8A%A0%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","excerpt":"","text":"背景 由于公司iaas人员在操作虚拟ip时手误，导致应该指向mysql主库的虚拟ip指向了从库。因为业务app使用的是虚拟ip链接的数据库，因此导致所有的业务数据都写入了从库，而主库的数据从此没有任何变化。 为了解决此问题，需要把原来的主库变成从库，从而继续保持mysql数据库的高可用；但是在处理的时候发现由于旧从库配置的bin-log超时时间为：expire-logs-days = 3，这导致了3天前的bin-log已经因为过期而被清除。所以如果直接把旧的主库当作从库来进行主从复制，会导数据不一致。 因此最终需要把旧主库的数据全部清除，然后从旧从库导出所有数据再导入旧主库，最后再添加主从复制来达到此目的。 基本信息 旧主库ip：172.99.0.32 旧从库ip：172.99.0.31 具体操作如下 因为一共有三个数据库，查看数据库的data目录共200G以上的数据量，因此不能使用mysqldump来进行导入和导出备份。最终确定使用Percona XtraBackup工具进行备份和恢复数据。 安装Percona XtraBackup 参考官方文档： 123456789101112# 1.Install the percona-release configuration toolyum install https://repo.percona.com/yum/percona-release-latest.noarch.rpm# 2.Testing the repositoryyum list | grep percona# 3.Enable the repository:percona-release enable-only tools release# 4.Install Percona XtraBackupyum install percona-xtrabackup-24 错误处理 1234567891011$ yum install https://repo.percona.com/yum/percona-release-latest.noarch.rpmLoaded plugins: fastestmirrorSetting up Install Processpercona-release-latest.noarch.rpm | 20 kB 00:00Examining /var/tmp/yum-root-3a5UYo/percona-release-latest.noarch.rpm: percona-release-1.0-27.noarchMarking /var/tmp/yum-root-3a5UYo/percona-release-latest.noarch.rpm to be installedDetermining fastest mirrorsYumRepo Error: All mirror URLs are not using ftp, http[s] or file. Eg. Invalid release/repo/arch combination/removing mirrorlist with no valid mirrors: /var/cache/yum/x86_64/6/base/mirrorlist.txtError: Cannot find a valid baseurl for repo: base 解决方案： 把源替换为清华大学源，参考文档 查看当前系统的版本：more /etc/issue 如果sudo yum makecache报错，先执行yum clean all 如果sudo yum makecache依旧报错（[Errno 14] Peer cert cannot be verified or peer cert invalid），追加sslverify=false导/etc/yum.conf文件 1234567891011121314$ sudo yum makecacheLoaded plugins: fastestmirrorDetermining fastest mirrorsepel/metalink | 4.4 kB 00:00 * epel: ftp.iij.ad.jphttps://mirrors.tuna.tsinghua.edu.cn/centos-vault/6.8/os/x86_64/repodata/repomd.xml: [Errno 14] Peer cert cannot be verified or peer cert invalidTrying other mirror.It was impossible to connect to the Red Hat servers.This could mean a connectivity issue in your environment, such as the requirement to configure a proxy,or a transparent proxy that tampers with TLS security, or an incorrect system clock.Please collect information about the specific failure that occurs in your environment,using the instructions in: https://access.redhat.com/solutions/1527033 and open a ticket with Red Hat Support.Error: Cannot retrieve repository metadata (repomd.xml) for repository: base. Please verify its path and try again 使用Percona XtraBackup 参考官方文档 备份master 1innobackupex --defaults-file=/data/mysql/mysql_3306/my_3306.cnf --host=127.0.0.1 --port=3306 --user=root --password=123456 /data/backup 查看备份文件： 1234567891011121314151617181920$ lltotal 8drwxr-x--- 5 root root 4096 Mar 25 11:34 2022-03-25_10-56-55drwxr-x--- 7 root root 4096 Mar 25 15:10 2022-03-25_14-49-59$ ll 2022-03-25_14-49-59total 2108548-rw-r----- 1 root root 437 Mar 25 15:10 backup-my.cnfdrwxr-x--- 2 root root 16384 Mar 25 15:10 db1drwxr-x--- 2 root root 176128 Mar 25 15:10 db2drwxr-x--- 2 root root 8192 Mar 25 15:10 db3-rw-r----- 1 root root 10656571 Mar 25 15:10 ib_buffer_pool-rw-r----- 1 root root 2147483648 Mar 25 14:50 ibdata1drwxr-x--- 2 root root 4096 Mar 25 15:10 mysqldrwxr-x--- 2 root root 4096 Mar 25 15:10 performance_schema-rw-r----- 1 root root 46 Mar 25 15:10 xtrabackup_binlog_info-rw-r----- 1 root root 150 Mar 25 15:10 xtrabackup_checkpoints-rw-r----- 1 root root 630 Mar 25 15:10 xtrabackup_info-rw-r----- 1 root root 731648 Mar 25 15:10 xtrabackup_logfile 数据文件一致性 1innobackupex --apply-log /data/backup/2022-03-25_14-49-59 数据恢复 把备份数据copy导32服务器 1scp -r /data/backup/2022-03-25_14-49-59/ iaas@172.99.0.32:/data/backup_20220325 停止mysql 123sudo sumysqladmin --port=3306 -uroot -p12345 -h127.0.0.1 shutdown 备份和删除历史数据 1mv /data/mysql/mysql_3306 /data/mysql/mysql_3306_backup_20220325 创建新的数据文件夹 1mkdir /data/mysql/mysql_3306 数据恢复 1innobackupex --defaults-file=/data/mysql/mysql_3306/my_3306.cnf --host=127.0.0.1 --port=3306 --user=root --password=123456 --copy-back /data/backup_20220325/2022-03-25_14-49-59 授权数据文件夹给mysql用户 123cd /data/mysqlchown -R mysql:mysql mysql_3306 启动数据库 12cd /data/mysql/mysql_3306sh start.sh 添加主从复制配置 查看data/xtrabackup_binlog_pos_innodb获取主从同步的位置。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# 添加主从配置CHANGE MASTER TO MASTER_HOST=&#x27;172.99.0.31&#x27;, MASTER_USER=&#x27;rep&#x27;, MASTER_PASSWORD=&#x27;123456&#x27;, MASTER_PORT=3306, MASTER_LOG_FILE=&#x27;mysql-bin.003637&#x27;, MASTER_LOG_POS=103905709, MASTER_CONNECT_RETRY=10;# 查看主从同步配置show slave status \\G# 启动主从同步start slave;# 验证show slave status \\Gmysql&gt; show slave status \\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.99.0.31 Master_User: rep Master_Port: 3306 Connect_Retry: 10 Master_Log_File: mysql-bin.003637 Read_Master_Log_Pos: 108431943 Relay_Log_File: relay-log.000002 Relay_Log_Pos: 749241 Relay_Master_Log_File: mysql-bin.003637 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: mysql,test,information_schema Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 105389363 Relay_Log_Space: 2847004 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 3177Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 523306 Master_SSL_Crl: Master_SSL_Crlpath: Using_Gtid: No Gtid_IO_Pos:1 row in set (0.02 sec) 错误记录 xtrabackup: Can’t change dir to ‘/var/lib/mysql’ (Errcode: 2 - No such file or directory) 错误场景 在运行备份命令innobackupex --defaults-file=/root/master/config-file.cnf --host=127.0.0.1 --port=3306 --user=root --password=123456 /root/backup时报错 12345678910111213141516171819[root@localhost master]# innobackupex --defaults-file=/root/master/config-file.cnf --host=127.0.0.1 --port=3306 --user=root --password=123456 /root/backupxtrabackup: recognized server arguments: --log_bin --server-id=2481903306xtrabackup: recognized client arguments:220324 18:36:59 innobackupex: Starting the backup operationIMPORTANT: Please check that the backup run completes successfully. At the end of a successful backup run innobackupex prints &quot;completed OK!&quot;.220324 18:36:59 version_check Connecting to MySQL server with DSN &#x27;dbi:mysql:;mysql_read_default_group=xtrabackup;host=127.0.0.1;port=3306&#x27; as &#x27;root&#x27; (using password: YES).220324 18:36:59 version_check Connected to MySQL server220324 18:36:59 version_check Executing a version check against the server...220324 18:36:59 version_check Done.220324 18:36:59 Connecting to MySQL server host: 127.0.0.1, user: root, password: set, port: 3306, socket: not setUsing server version 10.1.32-MariaDB-1~jessieinnobackupex version 2.4.24 based on MySQL server 5.7.35 Linux (x86_64) (revision id: b4ee263)xtrabackup: uses posix_fadvise().innobackupex: Can&#x27;t change dir to &#x27;/var/lib/mysql/&#x27; (Errcode: 2 - No such file or directory)xtrabackup: cannot my_setwd /var/lib/mysql/ 解决方案 不可以在其他服务器上运行innobackupex命令对mysql进行备份 参考：https://serverfault.com/questions/685279/can-i-run-percona-xtrabackup-on-my-desktop [ERROR] Can’t start server: Bind on TCP/IP port. Got error: 98: Address already in use 第一次启动数据库报错： 12345678910111213141516171819202122232425262728293031220325 16:16:17 mysqld_safe Starting mysqld daemon with databases from &#x2F;data&#x2F;mysql&#x2F;mysql_3306&#x2F;data220325 16:16:17 [Note] &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysqld (mysqld 10.0.28-MariaDB-enterprise) starting as process 19969 ...220325 16:16:17 [Note] InnoDB: Using mutexes to ref count buffer pool pages220325 16:16:17 [Note] InnoDB: The InnoDB memory heap is disabled220325 16:16:17 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins220325 16:16:17 [Note] InnoDB: GCC builtin __sync_synchronize() is used for memory barrier220325 16:16:17 [Note] InnoDB: Compressed tables use zlib 1.2.3220325 16:16:17 [Note] InnoDB: Using Linux native AIO220325 16:16:17 [Note] InnoDB: Using CPU crc32 instructions220325 16:16:17 [Note] InnoDB: Initializing buffer pool, size &#x3D; 50.0G220325 16:16:19 [Note] InnoDB: Completed initialization of buffer pool220325 16:16:19 [Note] InnoDB: Highest supported file format is Barracuda.220325 16:16:20 [Note] InnoDB: 128 rollback segment(s) are active.220325 16:16:20 [Note] InnoDB: Percona XtraDB (http:&#x2F;&#x2F;www.percona.com) 5.6.32-79.0 started; log sequence number 8360233886962022-03-25 16:16:20 7f6e1bfe8700 InnoDB: Loading buffer pool(s) from .&#x2F;&#x2F;ib_buffer_pool220325 16:16:20 [Note] Server socket created on IP: &#39;::&#39;.220325 16:16:20 [ERROR] Can&#39;t start server: Bind on TCP&#x2F;IP port. Got error: 98: Address already in use220325 16:16:20 [ERROR] Do you already have another mysqld server running on port: 3306 ?220325 16:16:20 [ERROR] Aborting220325 16:16:20 [Note] unregister_replicator OK220325 16:16:20 [Note] InnoDB: FTS optimize thread exiting.220325 16:16:20 [Note] InnoDB: Starting shutdown...2022-03-25 16:16:20 7f6e1bfe8700 InnoDB: Buffer pool(s) load completed at 220325 16:16:202022-03-25 16:16:20 7f6e1bfe8700 InnoDB: Dumping buffer pool(s) to .&#x2F;&#x2F;ib_buffer_pool2022-03-25 16:16:20 7f6e1bfe8700 InnoDB: Buffer pool(s) dump completed at 220325 16:16:20220325 16:16:21 [Note] InnoDB: Waiting for page_cleaner to finish flushing of buffer pool220325 16:16:23 [Note] InnoDB: Shutdown completed; log sequence number 836023391393220325 16:16:23 [Note] &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysqld: Shutdown complete220325 16:16:23 mysqld_safe mysqld from pid file &#x2F;data&#x2F;mysql&#x2F;mysql_3306&#x2F;data&#x2F;172-22-0-32.pid ended 解决方案 查看占用3306端口的进程（lsof -i TCP:3306)，杀掉此进程之后再重新启动。","raw":null,"content":null,"categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://guozhe001.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://guozhe001.github.io/tags/MySQL/"},{"name":"主从复制","slug":"主从复制","permalink":"https://guozhe001.github.io/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"name":"MySQL备份","slug":"MySQL备份","permalink":"https://guozhe001.github.io/tags/MySQL%E5%A4%87%E4%BB%BD/"}]},{"title":"读书笔记-《你的第一本保险指南》","slug":"others/读书笔记-《你的第一本保险指南》","date":"2024-11-22T06:32:06.497Z","updated":"2024-11-22T06:32:06.497Z","comments":true,"path":"2024/11/22/others/读书笔记-《你的第一本保险指南》/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/others/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E3%80%8A%E4%BD%A0%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E4%BF%9D%E9%99%A9%E6%8C%87%E5%8D%97%E3%80%8B/","excerpt":"","text":"1、破除误会，我们真的了解保险吗 我们对保险的认识：理赔似乎特别难 发生的事故不在保险范围，不能赔付 客户未如实告知自身情况，不能赔付 条款过于严苛，不能赔付 什么是核保师与健康告知 健康告知 健康告知问询 健康问询：是否有疾病或住院记录等 职业问询：是否从事高危行业 生活问询：是否吸烟、酗酒（酒精依赖），是否有极限运动等危险性高的业余爱好等 核保结论 结论一：标准体。恭喜，你完美地符合健康告知中的所有要求，可以直接投保，无须做补充告知 结论二：次标准体。可能有少数几条不符合健康告知，但考虑到基本在可接受范围内，保险公司就“勉为其难”地允许你投保了 接受除外责任：保险公司考虑到投保人当前的健康状况，将特定疾病排除在责任范围之外 增加保费 结论三：延期。保险公司考虑到你的某个健康问题，暂不接受你的本次投保申请，建议过一段时间再来试试 结论四：拒保 到底怎么健康告知？ 说实话，当保险公司把重疾险、医疗险这类保障型产品放到网上销售的时候，其实只是想卖给标准体客户。 至于次标准体和非标准体客户，对不起，这类产品不是为他们准备的。 买保险一定要返本吗？ 当你想要返还的时候，你到底想要什么 第一，拿回保费。如果没有发生保险事故，请把我交的保费还给我 第二，获得赔偿。既然我购买了保险，总归是希望能派上用场。 追求保费返还，切莫因小失大 反本保险一般会比不反本（消费型）保险更贵 在追求保费返还时，想一下自己购买保险的初心：当初你说要买保险的时候，到底是用来做什么的？保费和保额，哪个才是你的初心？ 非要拿到保费，不妨这样选择 提前给付型重疾险：身患重疾或不幸身故，哪个提前发生，都可给付赔偿，但是代价依然是支付更多保费 保障终身只是保险产品的一个功能设置，而不应被视为一个优点，因为你为此支付了更多的保费 保险公司会不会破产 保险公司会破产，却不会完蛋 保险公司破产时，人寿保险合同及责任准备金，必须转让给其他经营有人寿保险业务的保险公司 保险保障基金：来源是81家财险公司和88家寿险公司，保险公司每年需向其缴纳一定数额的资金，这也是被写进《保险法》的强制性要求。 政府在做的，是拼命预防保险公司破产 一家保险公司从计划成立之初，就不得不接受一系列监管。这些监管措施和规定就像一道道防火墙，确保公司在正确轨道上运转。 第一道防火墙是极高的公司设立标准 第二道防火墙是全面科学的偿付能力监管 所谓偿付能力，指的是当保险公司遭遇极端情况时，是否仍有能力履行赔付责任。每个年度和季度，保险公司的精算、财务等专业人士都会编制公司偿付能力报告，涉及一系列数学模型和压力测试 根据偿付能力情况，保险公司会得到从优到差的评级，包括A、B、C、D4个等级。评级可以在保险公司官网的“公开信息查询”栏目查到，我们将它视为判断保险公司是否“靠谱”的一个重要标志。长期来看，只要评级稳定在A和B的公司，我们都可以放心购买其产品 第三道防火墙是频率高、强度大的现场检查 监管部门会随时进驻保险公司总公司和分公司，通过调取档案、查询系统等方式实施现场检查 当然，上述的防火墙虽好，如果因为贪污腐败而让保险公司蒙混过关，这是我们无法改变的事情，暂时只能接受 如何选择一家保险公司？ 对比不同保险公司的投诉情况 监管部门每年都会对各家保险公司的投诉情况进行通报、评分，并发布在官网上（比如保监会官网） 销售人员口碑如何，信息技术实力如何（比如官网和手机软件的使用体验），客服电话能否快速接通，诸如此类 最重要的是保险产品的性价比 2、购前指南：买保险的正确方法 买保险和吃麦当劳是一样的，保险产品一般都是很多保险组成的。 一份保险计划通常由一款主险和若干款附加险构成，主险就像一位大哥，带着一帮作为附加险的小弟。 这种充分利用和客户接触的机会推销尽可能多的产品，是一种普遍的保险销售模式 但是有时候，单点比套餐更好，毕竟保险公司定的产品并非根据我们的需求定，附加险可能并非我们需要的。 责任的多少、保额的高低、期限的长短，这三大因素直接决定了保险产品的价格。 保额：真到用时方恨少 期限：从一天到一辈子 短期产品 保险期限不超过一年 以一年为一期计，产品的定价就要参考当下被保险人的年龄来计算了。30岁时购买，价格可能是100元；5年后，价格可能就会涨到400元。这种随年龄增加而上涨的定价策略，叫作自然费率。客户每年交的钱，只负责承担当年的风险。 长期产品 10年、20年甚至终身 定价方法遵循两个原则：一是均衡费率原则，二是保证费率原则 均衡费率，指的是保险公司将被保险人未来很长一段时间的风险，归并到一起进行定价，而不只是一年的风险 比如，保到70岁或保终身，投保人未来几十年的疾病发生率或者死亡率被累计后算出保费，再按照20年或30年交费的方式进行均摊，价格就确定了 在这样一种模式下，长期产品的停售只意味着不接受新客户的购买，但并不影响已经投保的客户 保证费率：指的是在你投保的一瞬间，价格便已确定，后期不会增加。对于长期重疾险来说，即使投保人未来的发病率上升，保险公司也不会涨价 长期产品和短期产品费用比较 整体来看，购买短期险费用要比长期险费用高 人到中年，就有可能无法购买短期险 人到老年，则根本不能购买短期险 对于已经有长期险庇护的人来说，额外购买一份一年期产品，可以在一定时间内增加保额 短期险在年轻时比较便宜 保险产品的价格由谁决定 我们有哪些需求需要保险解决？ 得了重疾，有钱治病 得了重疾，弥补治疗期间的收入 不幸身故，给爸妈留一笔养老费 意外受伤，解决医保不包含的费用 保险这种产品不是一次性的，它是陪伴你度过漫长人生的一种风险规划 如何与保险业务员打交道 保险公司会不遗余力地增加产品的“人情味”，比如将保险塑造成爱与责任的象征，让你把对子女、父母的爱寄托于保险产品之上，让购买行为更加顺理成章 保险销售人员到底指的是谁 第一，保险代理人。全国约800万，他们代表各自所在的保险公司，只销售某一家保险公司的产品。 第二，保险经纪人。和代理人最大的不同是，经纪人代表的不是某一家保险公司，而是保险中介公司，他们可以销售多家保险公司产品 第三，银行理财经理 第四，互联网第三方平台 和业务员打交道，要遵循两个原则 想一下我们有时候会不会因为下面的情况而买保险 第一，卖保险的人是亲戚，抹不开面子，买吧。 第二，邻居都给孩子买的这个，我也买一个吧 第三，他答应我把佣金返还给我，省了不少钱，买吧。 第四，小伙子口才好，人也帅，卖的保险不会差。 第五，就算被骗一年才损失1000多块钱，买吧 好面子、从众心理、贪图小便宜、忽略产品的本质，这类问题经常发生，也间接催生了一批不靠谱的保险业务员 第一个原则：互相尊重，学会提问。 条款能给我看一下吗？ 为什么我需要这款产品？ 为什么这类产品你们家的最好？ 能比较一下不同产品吗？ 为什么要保终身？ 为什么这个附加险值得购买？ 如果你发现这位保险业务员面对你提出的一个个问题，要么答不出来，要么逻辑混乱，要么不分青红皂白地敌视及贬损其他保险公司，最好立即更换业务员 第二个原则：充分信任，要有主见 卖保险简单吗 产品贵不贵（同类产品的定价和费率对比）？ 到底有哪些保障（保险责任的解读）？ 退保能拿到多少保费（保单现金价值的解读）？ 买完后哪些信息可以修改（对保单保全功能的讲解）？ 这个产品能实现多高收益（如何计算分红险、万能险、年金等产品的投资收益）？ 缴费期限怎么选择（现金流贴现原理）？ 保险条款里有没有所谓的坑（除外责任做重点说明）？ 遇到纠纷的时候如何处理？ 如果他真的做了产品对比，但如果他推销的产品价格没有竞争力，该怎么办？他真的算清楚了产品收益，但客户觉得收益率不如想象的那么高，该怎么办？他真的一条一条地解释清楚除外责任，客户却产生“保险公司推卸责任”的情绪化误解，该怎么办？他因为客户的健康问题而拒绝其投保，之前的工作不就白忙活了吗？ 这些假设似乎暗示了保险销售人员“能力越强越卖不出去产品”的观点，但我想表达的绝不是“知识无用论”，它们只是在一定程度上反映了当前保险销售领域存在的弊病。而这些极端的例子恰恰凸显了“你”的重要性。 你的公司给你买保险了吗 企业团体保险 团险通常由4个保险产品组成： 定期寿险 重大疾病险 意外险 医疗险 团险计划可以涵盖以下责任： 罹患重大疾病：保额50万元（重大疾病险的重疾责任50万元）。 疾病导致身故：保额50万元（定期寿险身故责任50万元）。 意外导致身故：保额150万元（定期寿险身故责任50万元+意外险身故责任100万元）。 门诊责任：保额2万元（医疗险包含的门急诊医疗责任2万元）。 住院责任：保额30万元（医疗险包含的住院医疗责任30万元）。 团险价格之所以“亲民”，主要原因如下： 第一，团险可以简单类比为团购，买的人数多，节省了一部分管理成本，自然就能获得一定的优惠 第二，团险的主要销售对象是企业人力资源部，只要负责人拍板，100个员工就直接购买了，不用一个一个地宣传、介绍，间接降低了产品的销售费用，最终的实惠落在了每一位参保员工身上 第三，以企业名义投保，参保人员的工作环境和性质相对一致，外部风险可控，何况不少企业还有入职体检，可以很好解决客户的逆选择和健康问题 团险带来的“保险幻觉” 一般公司团险的保险产品的保障期限都是一年，如果完全依赖公司保险，我们一旦离职就会面临保险“裸奔”的情况 所以，建议大家用客观的态度看待公司为员工购买的团险。它是一种极好的员工福利，它应该是员工自身已购保险的有力补充，却不能被当作全部。 了解公司的团险政策 这份团险计划里有涵盖身故责任的产品吗？ 如果有，保额是多少？ 如果员工获得晋升，保额会随之提高吗？ 03 重点关注：中产必备的“四大保险金刚” 重大疾病险：为了不被改变的人生 重疾险的诞生，本质上是为了解决收入中断的风险，站在患者及其家人的角度，为已在重病深渊的家庭提供雪中送炭般的经济补偿 重疾险究竟保什么 什么叫“重大疾病”？ 保监会安排中国保险行业协会和中国医师协会，在2007年拿出了一版25种重疾标准，囊括所有高发重疾类型（其实，只要是重疾险就都包括这25种） 保监会设定的这25种重大疾病，其发生概率超过95%的疾病种类。 所以如果一个保险说他包含更多的重疾，然后让我们多花钱买它，其实没有太必要。 什么叫“罹患”？ 第一，病情达到某个标准，相当于确诊即赔，比如恶性肿瘤 第二，投保人为治疗某种疾病而接受了某种治疗方法。比如心脏瓣膜手术 第三，某种状态持续了一段时间。比如脑中风后遗症 除了重大疾病，重疾险还保这些 当重疾险的责任只有重大疾病时，消费者理所当然地提出了一个振聋发聩的问题：如果我一辈子没得重疾，这保费岂不是白交了？ 好，为了不让你白交，保险公司索性增加了很多其他责任，“顺便”提升了保费。买卖双方都高兴，这种商业模式堪称完美。 在新增的责任里，第一类是“身故责任”。这种包含身故责任的重疾险，基本上都可以“提前给付”。 这里的提前指的是重疾、身故二者中哪个先发生，就给付哪个。 提前给付不过是一种产品设计罢了，千万别觉得它是一项独特的优势。 第二类新增责任是轻症和中症责任 第三类新增责任是针对重大疾病的花样赔付方式。比如重疾和轻症可以赔付多次，又比如挑出某几个病种额外赔付50%的保额，再比如投保后前10年享受保额额外增加50%。 上面说的这些都是在增加保费的基础上增加了更多的责任，所以当保险公司说我们保的多的时候除非和别人价格一样，否则只是在骗我们花更多钱而已。 重疾险的保额及其他 如何确定保额 患重疾后，患者普遍面临的是3~5年的治疗康复期 与此同时，重疾导致收入中断将为家庭带来更大的压力 因此，重疾险的保额应至少覆盖投保人3~5年的收入 如年收入20万元的保额应该在60万以上 而且只要确保这款重疾险能提供60万元的重疾保额，有没有身故责任、多次赔付、投保人豁免，都无关紧要 重疾险应该保障多久和交多少年保费。 讨论这个问题有一个前提：我们选择的是长期产品。 对于重疾险、定期寿险，可以保终身或者保到70岁左右的长期产品，是我们的首选——不仅价格更划算，也不会出现保险中断的情况。 长期重疾险的缴费期往往有多种选择： 趸交（一次性交完） 10年交 20年交 少数产品甚至还设计了30年交 保障期限： 保障期限的延长，会带来保费的升高；没办法，一个人年龄越大，罹患重疾的概率就越高。如果预算充足，保终身当然是最好的选择。 在确保保额充足的情况下，我们可以把保额拆成两个产品来实现，一个保到退休，另一个保终身 如：对于需要60万元重疾险保额的小王来说，可以选择买一份保终身的30万元保额的重疾险，再买一份保到70岁的30万元保额的重疾险。这比直接购买一份保终身的60万元保额的重疾险，花费更少 定期寿险：解决人生中最大的风险 谁适合买寿险 如果说重疾险的赌注是病，寿险的赌注就是命。定期寿险赌的则是一段时间的命。比如投保人于30年内身故，受益人即可获得理赔款。 一般的定期寿险，除了保障身故，还会把全残也视作与身故等同的责任。 单身的人理应关心父母的养老问题 新婚的人会增加对另一半的考虑 有了孩子后，责任更重 意外险和寿险对比 这里需要额外强调一点。谈到身故风险，很多人会联想到意外险，因为它不是也有身故保障吗？ “疾病”和“意外”为占比最大的两类死亡原因，分别为79.3%和18.9%。 所以，单纯购买意外险，是无法解决身故的风险的。 如何选购定期寿险？ 确定保额是关键性的第一步 保额的高低，决定了投保人身故后他的妻子、父母或者孩子能拿到多少补偿。定期寿险的保额，主要取决于三个因素。 一是个人和家庭的债务额度，比如房贷、车贷等，确保一方身故后，债务不转嫁到另一方或父母身上 二是家庭成员的基本生活成本。如果家庭每年的开销为20万元，那么身故理赔金至少应为100万元，以负担家庭未来5—10年的基本生活开销。 三是父母的养老支出，这笔费用的计算逻辑和上一个类似。 定期寿险还要考虑的问题是保障期限 到底要保到多大年龄呢？我个人建议，以退休年龄为标准，60岁或70岁皆可。 至于缴费年限的选择，我建议尽可能拉长，20年交或30年交皆可。缴费年限越长，年均保费越低，从而做到用尽可能少的钱去撬动尽可能高的保额。 保额、保障期限和缴费年限都确定后，我们在选购具体产品时，还要格外关注三个方面： 第一，核保是否宽松。这是最重要的，因为如果健康告知非常严格，想买也买不了，何谈其他？比如，有的定期寿险不接受乙肝小三阳患者，有的不接受高危职业从业者。所以我们一定要弄清楚投保要求再买，尽量避免理赔时的潜在纠纷，才能真正做到安心。 第二，除外责任多不多。前文在分析如何阅读保险条款的时候，专门强调要关注除外责任。比如，有的定期寿险明确指出，因为战争、军事暴乱导致的死亡，它们概不负责。那么，对于去中东、非洲等地区旅游或工作的中国人来说，这种定期寿险就得慎重考虑购买了。 第三，价格低不低。如果上面几条标准比较起来都差不多，问题就变简单了：哪个产品便宜就选择哪个。 商业医疗险：让高额医疗开支不再可怕 社会医疗保险 在用医保卡看病的过程中，我们都接触过一些陌生的名词，比如起付线、药品目录、自费药、报销额度等。 起付线：的意思是，每年只有花到一定金额，才能开始报销，否则就都是自费 药品目录：指的是在医保系统中，对于医疗机构开具的药品做了不同分类，不同类型的药品报销额度也不一样，有的可全部报销，有的则只可报销一部分，还有的药全部要自费购买 销额度很好理解，即使药品、治疗等都在报销范围内，医保也不是无限制的报销，整体来看，每年的报销额度范围为20万~30万元；对于罹患重大疾病的患者来说，这一额度根本无法满足他们长期、昂贵的治疗需求。 医保不管的，让商业医疗保险来管 医疗险其实只包括两种产品 第一种是包含门诊责任的商业医疗保险，可暂且称之为门诊医疗保险 这种产品保额不高，一般是几千元。有的门诊医疗保险会设置一个免赔额，比如单次100元或者累计500元。免赔额和政府医保起付线是同一个概念，都是为了减少理赔支出，实际上也起到了降低保费的作用。 第二种是包含住院责任的商业医疗保险，我们称之为住院医疗保险。 这类产品的保额就高多了，几十万元甚至上百万元都很常见。和门诊医疗保险相比，住院医疗保险是下文要重点介绍的产品。 能被称作风险的，必然意味着财务上的巨大影响。所以和几十万甚至上百万元的医疗支出相比，几千元的门诊、住院费用，真的称不上风险。 买了重疾险，还要买医疗险吗 重疾险和商业医疗最重要的区别，是保险公司的理赔方式不一样 重疾险有点儿像一锤子买卖，只要符合条款规定，保险公司就会把理赔款一次性打给你，无论是几万元还是几十万元。 商业医保就不一样了，花多少才能赔多少，保额仅代表可报销额度的上限，而你不一定能花掉这么多钱 如果一个人罹患影响正常生活的重大疾病，那他主要面临的问题有两个：一是治疗费用太高，掏空家底；二是无法继续工作，失去收入。前者可以靠商业医疗保险解决，后者则只能靠重疾险解决，两类保险的功能不一样。 重疾险和商业医疗保险在定价方面的区别 长期重疾险每年的保费是恒定的，商业医疗保险的保费则会随着被保险人年龄的增加而上调 重疾险和商业医疗保险在续保方面的区别 目前市场上大多数医疗险都是一年期产品，如果第二年你想继续投保，得先看看保险条款是怎么规定的，通常有以下两种情况： 第一种是，卖不卖给你，我说了算。投保人的续保申请须经保险人审核同意，投保人申请续保时，保险人有权对费率进行调整。 第二种规定是，只要这个产品还在销售，保险公司就肯定会卖给你。连续投保时，保险人不会因为某一被保险人的健康状况变化或历史理赔情况而单独调整该被保险人的连续投保费率。 意外险：不容忽视的“小”保险 意外险保什么、不保什么 遭受外来的、突发的、非本意的、非疾病的使身体受到伤害的客观事件。自然死亡、疾病身故、猝死、自杀及自伤均不属于意外伤害。 在每份意外险的保险条款里，你都能看到这样的描述。这段话表达了两层意思： 第一，外来的、突发的、非本意的、非疾病的使身体受到伤害的客观事件，属于意外； 第二，自然死亡、疾病身故、猝死、自杀及自伤，不属于意外。 除了猝死，意外险还有一些“不保”： 意外险通常不保高危职业从业者 除了特定人群“不保”，还有某类地区“不保”。关于意外医疗责任，保险条款中往往会有一个补充描述：只承担中华人民共和国国境内（不包括港澳台地区）医院产生的医疗费用和支出。 最后一个“不保”，是某些行为不保。被保险人从事潜水、跳伞、攀岩运动、探险活动、武术比赛、摔跤比赛、特技表演、赛马、赛车等高风险活动期间发生的意外，不在意外险的责任范围内 配置意外险的几条原则 原则一：必须涵盖意外医疗责任。 意外导致的结果无非两种：伤残和死亡。因此，意外险保障的责任有三个必选项：身故、伤残、医疗。 意外受伤后，我们最大的需求就是医疗费用补偿。考虑到很多意外产生的医疗费用医保都无法报销，意外险的医疗责任就更重要了。 至于意外医疗的保额，一两万就足够了。如果是一两万元都治不好的意外受伤，一定已经严重到需要做手术或者长期住院治疗了，这时理赔的责任就可以交给上文提到的住院医疗保险了。 另外，你可能听说过住院津贴或住院保险金，它的作用是，投保人每住一天院，保险公司就会支付给他几百元钱，主要是为了弥补住院期间的收入损失，颇为贴心，本质上也属于意外医疗的责任范围。住院津贴属于锦上添花型保险，而且要花钱购买，所以有没有都无所谓。 原则二：一般意外身故的保额应足够高。 在这里我要提醒大家注意某些保险公司的“套路”。当你看到一个类似于“百万身价意外险”的打折产品时，请一定弄清楚它所说的百万身价到底是什么意思。举个例子，有个产品页面是这么描述该产品的： 一般意外身故：10万元 航空意外身故：100万元 我更喜欢以下这类保险： 一般意外身故：100万元 航空意外身故：200万元 原则三：不同人群的意外险，侧重点不一样。 对于职场白领来说，意外险既要有足够的身故补偿（用于弥补家庭经济损失），也要保证受伤后有钱治疗； 但对于孩子和老人来说，身故补偿就没有医疗费用补偿重要，毕竟他们不是家里的顶梁柱。 因此，孩子和老人的意外险，应侧重于考虑提升意外医疗的保额，而没有必要追求意外身故的高保额。 原则四：保障时间一年就够了。 之前在介绍一年期产品特征的时候我提过，意外险和医疗险大多会设计成短期险，这样一来，就可以随时按照意外发生率和医疗成本的波动进行价格调整。因此，每年各家公司的意外险层出不穷，可能去年买的产品，到了明年就没什么竞争力了，这时直接换一家公司购买就好。由于意外险的几个基本责任都没有等待期这一说，所以可以做到无缝衔接。 04 优化配置：给保险升个级 像有钱人一样看病 高端医疗，高端在哪里？ 第一，保额更高。几十万元甚至几百万元的保额都是小菜一碟，从几千万元到不设限，高端医疗的保额完全超乎你的想象。 第二，医院更多、更高端。从三甲医院的特需部、国际部，到私立医院、国际医院，而且不限中国地区，从亚太地区到全球，基本覆盖所有类型的医疗机构。 第三，保障更全面。除了传统的门诊、住院两大块之外，高端医疗险还包含分娩、牙科、眼科、体检等责任，要知道，这些治疗通常都在常规医疗险的除外项目里，一般医疗险都不管。 第四，增值服务更多。 第五，理赔体验更好。 保险能为我的养老做什么？ 该不该买养老保险？ 可不可以把保险当作投资方式 要回答上面两个问题，需要使用excel中的IRR公式计算内部收益率，如果内部收益率能够达到预期并且现在手头有钱就可以买。 比如年复利6%以上就能达到预期，否则不如买债券基金或者指数型基金。 该去香港买保险吗？ 略 05 个性化定制：保险方案，你自己说了算 如何给孩子买保险 先别着急买商业保险 和大人一样，孩子也是可以参加政府医保的。在配置商业保险之前，父母一定要参考当地的医保政策为孩子办理少儿医保。 少儿医保本质上是针对儿童罹患重大疾病提供的风险保障。 有没有医保也会影响孩子投保商业保险的价格。尤其是医疗险，被保险人有医保的医疗险价格更低。 孩子会面临哪些风险 风险一：身患危重疾病 孩子一旦患危重疾病，除了需要长期投入高额治疗费用，父母也可能为了照顾孩子而辞掉工作。 因此，重疾险和高保额住院医疗险是应该首先为孩子配置的保险。 重疾险的价值在于，罹患重疾后一次性获得定额赔偿，可作为自费治疗费用和家庭收入中断的补偿。 高额住院医疗险的价值在于应对高额的医疗费用，尤其是许多医保范围外的自费项目 风险二：发生意外受伤 风险三：身患一般疾病 配置儿童商业保险 孩子不该买哪些保险 包含身故责任的意外险不在我们的讨论范围内 定期寿险、终身寿险也无需购买 除意义不大的身故责任外，为孩子购买教育金、养老金，优先级也不高 孩子真正需要的商业保险其实只有三款：重大疾病险、意外险、高额住院医疗险。 关于孩子的重疾险 请记住一个事实：少儿罹患重大疾病的概率非常低。这直接决定了儿童重疾险的价格十分便宜。因此，为孩子配置重疾险，一定要抓住价格优势，尽可能提高保额，拉长期限。都是100万元的终身重疾险保额，30多岁男性的购买价格，可以达到小孩子的两倍多。 孩子的重疾险应该买保终身或者70岁的，不要买保障30年，三十年之后孩子才三、四十岁，那时断保再新买保险会更贵。 孩子最好的保险是父母 父母自身的健康以及稳定、持续的赚钱能力，是孩子最重要的保险。 总结一下为孩子配置保险的几个关键点。 作为父母，先把自己的保险配置好，因为你才是孩子最大的“保险”； 在购买任何商业保险之前，先为孩子办理好当地的少儿医保，这是政府给予的福利，一定要充分利用； 结合自身预算，首先配置高保额的重大疾病险和住院医疗险，其他的保险则量力购买。 如何给父母买保险 一个不断妥协退让的过程 其实父母面临的风险非常简单，就是疾病引发的财务风险。 这样看来，给父母配置保险，主要考虑的应该是重疾险、医疗险和意外险。 年龄超过60岁的人想要投保重疾险和医疗险会有很多限制： 第一，年龄限制。 几乎所有重疾险和医疗险的投保年龄都在0~60岁。对重疾险而言，55岁的投保年龄上限是普遍规则。 第二，保额限制。 同样一份保险，30岁的人和50岁的人可享受的保额上限是不一样的。 以重疾险为例，如果在网上直接投保，30岁的被保险人的保额上限基本为50万~60万元，而50岁的被保险人的保额上限只有10万元。 第三，保费倒挂。 一位55岁的男性购买保额为10万元的重疾险，每年需要交3500元左右，交20年，总计7万元的支出和10万元的保额相比，差别不大。 第四，健康告知不符。 患有高血压、心脏病、糖尿病的老年人，可以直接和重大疾病险、住院医疗险说再见了 保险公司也意识到了这个问题，于是想了一个办法：双方各退一步。保险公司把保障范围缩小，限制也随之减少。但这个保障范围不能太小，得有存在的意义。 于是，防癌类保险应运而生。重疾险涵盖的几十种疾病，只保留第一项，即恶性肿瘤；住院医疗险涵盖的所有疾病的住院责任，也只保留一项，即癌症住院责任。 这种做法最大的好处，就是健康告知的内容大幅减少。只要不是易引发癌症的症状（肝部疾病、器官或组织的结节等），保险公司都不介意，高血压、糖尿病患者也可以投保。毕竟，高血压导致的急性心梗和糖尿病导致的终末期肾病或截肢，都不在防癌类保险的责任范围内。 六分靠规划，四分靠心态 哪怕有那么多的限制，我们还是可以购买意外险、防癌险、防癌医疗险和糖尿病特定疾病重疾险。 如果你想简明扼要地掌握给父母买保险的技巧，请记住以下几点。 第一，确保父母双方都有社会医疗保险。不管是城市的居民医保，还是农村的“新农合”，没有的话，赶紧先把社会医保办好。 第二，遇到疑难杂症，不少人会选择带父母来北上广等大城市就诊。所以，请提前研究好医保的异地结算流程，确保不让医保“白交”，这一点非常有必要。 第三，详细了解爸妈的身体健康情况，对症下药买保险。 如何给自己买保险 18岁保险清单 学生团体保险：包含意外身故/伤残责任，意外医疗责任，住院医疗责任；预算为200元。 或自己投保： 意外险：包含意外身故/伤残责任，意外医疗责任；预算为200元（保额为50万元）。 医疗险：包含疾病导致的住院医疗责任，预算为200元。 18岁保障速览 身故补偿（仅限意外原因）：50万元。 意外医疗补偿：1万元（上限）。 住院医疗补偿：100万元（上限）。 22岁新增保险情况 定期寿险A：受益人为父母，保额大约相当于父母5年的退休金；预算为每年500元（保额50万元，保障期30年，缴费期30年）。 保障速览 身故补偿（不限死亡原因）：50万元。 额外身故补偿（仅限意外原因）：50万元。 意外医疗补偿：1万元（上限）。 住院医疗补偿：100万元（上限）。 28岁新增保险情况 定期寿险B：受益人为法定受益人，保额约等于5倍年薪； 预算为每年1000元（保额80万元，保到60岁，缴费期30年）。 重大疾病险A：保额约等于购买时的3倍年薪；预算为每年5000元（保额50万元，保到70岁，缴费期30年）。 28岁保障速览 身故补偿（不限死亡原因）：130万元。 额外身故补偿（仅限意外原因）：50万元。 意外医疗补偿：1万元（上限）。 住院医疗补偿：100万元（上限）。 重大疾病补偿：50万元。 32岁新增保险情况 意外险：包含意外身故/伤残责任；预算为每年400元（保额100万元）。 减额定期寿险C：受益人为法定受益人，保额等于房贷总额；预算为每年2000元（保额150万元，保障期30年，缴费期20年）。（有房贷才买） 重大疾病险B：提升重疾保额；预算为每年5000元（保额30万元，保终身，缴费期30年）。 32岁保障速览 身故补偿（不限死亡原因）：130万元。 额外身故补偿（仅限意外原因）：150万元。 意外医疗补偿：1万元（上限）。 住院医疗补偿：100万元（上限）。 重大疾病补偿：80万元。 34岁 意外险：包含意外身故/伤残责任，意外医疗责任；预算为每年200元（保额50万元）。 意外险：包含意外身故/伤残责任；预算为每年400元（保额100万元）。 医疗险：包含疾病导致的住院医疗责任；预算为每年200元。定期寿险A：受益人为父母，保额相当于父母5年的退休金；预算为每年500元（保额50万元，保障期30年，缴费期30年）。 定期寿险B：受益人为法定受益人，保额相当于自己5倍的年薪。预算为每年1000元（保额80万元，保到60岁，缴费期30年）。 减额定期寿险C：受益人为法定受益人，保额等于房贷总额；预算为每年2000元（保额150万元，保障期30年，缴费期20年）。 定期寿险D：受益人为子女，保额相当于孩子5年的生活费；预算为每年4000元（保额100万元，保到60岁，缴费期20年）。 重大疾病险A：保额相当于自己当时的3倍年薪；预算为每年5000元（保额50万元，保到70岁，缴费期30年）。重大疾病险B：提升重疾险保额；预算为每年5000元（保额30万元，保终身，缴费期30年）。 养老保险（60岁领取）：预算为每年60000元（每月5000元）。 给自己买保险，不能一蹴而就，应随着人生进入不同阶段而分步实施。在这个过程中，我们需要对自己的情感进行再分配，说到底就是，回答“为谁买保险”的问题。比如，涉及医疗补偿的保险（如住院医疗险、重大疾病险），是为了让自己不至于被疾病掏空腰包；再比如，涉及身故补偿的保险（如定期寿险、意外险），是为了让家人能够继续维持原来的生活水准。","raw":null,"content":null,"categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://guozhe001.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://guozhe001.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"保险","slug":"保险","permalink":"https://guozhe001.github.io/tags/%E4%BF%9D%E9%99%A9/"}]},{"title":"Python总结","slug":"language/Python总结","date":"2024-11-22T06:32:06.496Z","updated":"2024-11-22T06:32:06.496Z","comments":true,"path":"2024/11/22/language/Python总结/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/language/Python%E6%80%BB%E7%BB%93/","excerpt":"","text":"Jupyter 启动 1jupyter notebook ModuleNotFoundError: No module named ‘okex’ 在导入本地文件夹的文件时报错如上，可以在import这个模块之前添加以下代码，然后再import 1234module_path = os.path.abspath(os.path.join(&#x27;..&#x27;))print(&quot;module_path=&quot;, module_path)if module_path not in sys.path: sys.path.append(module_path) AttributeError: module ‘util.file_util’ has no attribute ‘exists’ 如果本地的python代码已经修改，如果不重启（刷新）jupyter会报错如上，刷新一下即可。 Pydoc 本地启动 1python3 -m pydoc -p 6789 pip install报错 错误信息如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778$ pip3.9 install cytoolzLooking in indexes: http://mirrors.cloud.aliyuncs.com/pypi/simple/Collecting cytoolz Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/58/67/1c60da8ba831bfefedb64c78b9f6820bdf58972797c95644ee3191daf27a/cytoolz-0.11.0.tar.gz (477 kB) |████████████████████████████████| 477 kB 2.6 MB/sRequirement already satisfied: toolz&gt;=0.8.0 in /usr/local/lib/python3.9/site-packages (from cytoolz) (0.11.1)Using legacy &#x27;setup.py install&#x27; for cytoolz, since package &#x27;wheel&#x27; is not installed.Installing collected packages: cytoolz Running setup.py install for cytoolz ... error ERROR: Command errored out with exit status 1: command: /usr/bin/python3.9 -u -c &#x27;import io, os, sys, setuptools, tokenize; sys.argv[0] = &#x27;&quot;&#x27;&quot;&#x27;/tmp/pip-install-x0b5qh9y/cytoolz_939a8fed01cc43dc979d68c8072b3af1/setup.py&#x27;&quot;&#x27;&quot;&#x27;; __file__=&#x27;&quot;&#x27;&quot;&#x27;/tmp/pip-install-x0b5qh9y/cytoolz_939a8fed01cc43dc979d68c8072b3af1/setup.py&#x27;&quot;&#x27;&quot;&#x27;;f = getattr(tokenize, &#x27;&quot;&#x27;&quot;&#x27;open&#x27;&quot;&#x27;&quot;&#x27;, open)(__file__) if os.path.exists(__file__) else io.StringIO(&#x27;&quot;&#x27;&quot;&#x27;from setuptools import setup; setup()&#x27;&quot;&#x27;&quot;&#x27;);code = f.read().replace(&#x27;&quot;&#x27;&quot;&#x27;\\r\\n&#x27;&quot;&#x27;&quot;&#x27;, &#x27;&quot;&#x27;&quot;&#x27;\\n&#x27;&quot;&#x27;&quot;&#x27;);f.close();exec(compile(code, __file__, &#x27;&quot;&#x27;&quot;&#x27;exec&#x27;&quot;&#x27;&quot;&#x27;))&#x27; install --record /tmp/pip-record-sp17_zhm/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.9/cytoolz cwd: /tmp/pip-install-x0b5qh9y/cytoolz_939a8fed01cc43dc979d68c8072b3af1/ Complete output (63 lines): [1/5] Cythonizing cytoolz/dicttoolz.pyx [2/5] Cythonizing cytoolz/functoolz.pyx [3/5] Cythonizing cytoolz/itertoolz.pyx [4/5] Cythonizing cytoolz/recipes.pyx [5/5] Cythonizing cytoolz/utils.pyx /usr/local/lib/python3.9/site-packages/setuptools/dist.py:691: UserWarning: Usage of dash-separated &#x27;index-url&#x27; will not be supported in future versions. Please use the underscore name &#x27;index_url&#x27; instead warnings.warn( running install running build running build_py creating build creating build/lib.linux-x86_64-3.9 creating build/lib.linux-x86_64-3.9/cytoolz copying cytoolz/__init__.py -&gt; build/lib.linux-x86_64-3.9/cytoolz copying cytoolz/_signatures.py -&gt; build/lib.linux-x86_64-3.9/cytoolz copying cytoolz/_version.py -&gt; build/lib.linux-x86_64-3.9/cytoolz copying cytoolz/compatibility.py -&gt; build/lib.linux-x86_64-3.9/cytoolz copying cytoolz/utils_test.py -&gt; build/lib.linux-x86_64-3.9/cytoolz creating build/lib.linux-x86_64-3.9/cytoolz/curried copying cytoolz/curried/__init__.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/curried copying cytoolz/curried/exceptions.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/curried copying cytoolz/curried/operator.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/curried copying cytoolz/dicttoolz.pyx -&gt; build/lib.linux-x86_64-3.9/cytoolz copying cytoolz/functoolz.pyx -&gt; build/lib.linux-x86_64-3.9/cytoolz copying cytoolz/itertoolz.pyx -&gt; build/lib.linux-x86_64-3.9/cytoolz copying cytoolz/recipes.pyx -&gt; build/lib.linux-x86_64-3.9/cytoolz copying cytoolz/utils.pyx -&gt; build/lib.linux-x86_64-3.9/cytoolz copying cytoolz/__init__.pxd -&gt; build/lib.linux-x86_64-3.9/cytoolz copying cytoolz/cpython.pxd -&gt; build/lib.linux-x86_64-3.9/cytoolz copying cytoolz/dicttoolz.pxd -&gt; build/lib.linux-x86_64-3.9/cytoolz copying cytoolz/functoolz.pxd -&gt; build/lib.linux-x86_64-3.9/cytoolz copying cytoolz/itertoolz.pxd -&gt; build/lib.linux-x86_64-3.9/cytoolz copying cytoolz/recipes.pxd -&gt; build/lib.linux-x86_64-3.9/cytoolz copying cytoolz/utils.pxd -&gt; build/lib.linux-x86_64-3.9/cytoolz creating build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/dev_skip_test.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/test_compatibility.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/test_curried.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/test_curried_toolzlike.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/test_dev_skip_test.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/test_dicttoolz.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/test_docstrings.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/test_doctests.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/test_embedded_sigs.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/test_functoolz.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/test_inspect_args.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/test_itertoolz.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/test_none_safe.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/test_recipes.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/test_serialization.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/test_signatures.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/test_tlz.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests copying cytoolz/tests/test_utils.py -&gt; build/lib.linux-x86_64-3.9/cytoolz/tests running build_ext building &#x27;cytoolz.dicttoolz&#x27; extension creating build/temp.linux-x86_64-3.9 creating build/temp.linux-x86_64-3.9/cytoolz gcc -pthread -Wno-unused-result -Wsign-compare -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong -grecord-gcc-switches -m64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong -grecord-gcc-switches -m64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong -grecord-gcc-switches -m64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -D_GNU_SOURCE -fPIC -fwrapv -fPIC -I/usr/include/python3.9 -c cytoolz/dicttoolz.c -o build/temp.linux-x86_64-3.9/cytoolz/dicttoolz.o cytoolz/dicttoolz.c:19:10: fatal error: Python.h: No such file or directory #include &quot;Python.h&quot; ^~~~~~~~~~ compilation terminated. error: command &#x27;/usr/bin/gcc&#x27; failed with exit code 1 ----------------------------------------ERROR: Command errored out with exit status 1: /usr/bin/python3.9 -u -c &#x27;import io, os, sys, setuptools, tokenize; sys.argv[0] = &#x27;&quot;&#x27;&quot;&#x27;/tmp/pip-install-x0b5qh9y/cytoolz_939a8fed01cc43dc979d68c8072b3af1/setup.py&#x27;&quot;&#x27;&quot;&#x27;; __file__=&#x27;&quot;&#x27;&quot;&#x27;/tmp/pip-install-x0b5qh9y/cytoolz_939a8fed01cc43dc979d68c8072b3af1/setup.py&#x27;&quot;&#x27;&quot;&#x27;;f = getattr(tokenize, &#x27;&quot;&#x27;&quot;&#x27;open&#x27;&quot;&#x27;&quot;&#x27;, open)(__file__) if os.path.exists(__file__) else io.StringIO(&#x27;&quot;&#x27;&quot;&#x27;from setuptools import setup; setup()&#x27;&quot;&#x27;&quot;&#x27;);code = f.read().replace(&#x27;&quot;&#x27;&quot;&#x27;\\r\\n&#x27;&quot;&#x27;&quot;&#x27;, &#x27;&quot;&#x27;&quot;&#x27;\\n&#x27;&quot;&#x27;&quot;&#x27;);f.close();exec(compile(code, __file__, &#x27;&quot;&#x27;&quot;&#x27;exec&#x27;&quot;&#x27;&quot;&#x27;))&#x27; install --record /tmp/pip-record-sp17_zhm/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.9/cytoolz Check the logs for full command output. 解决方法： 1sudo yum install python39-devel redhat","raw":null,"content":null,"categories":[{"name":"language","slug":"language","permalink":"https://guozhe001.github.io/categories/language/"},{"name":"Python","slug":"language/Python","permalink":"https://guozhe001.github.io/categories/language/Python/"}],"tags":[{"name":"language","slug":"language","permalink":"https://guozhe001.github.io/tags/language/"},{"name":"Python","slug":"Python","permalink":"https://guozhe001.github.io/tags/Python/"}]},{"title":"","slug":"language/d ","date":"2024-11-22T06:32:06.496Z","updated":"2024-11-22T06:32:06.496Z","comments":true,"path":"2024/11/22/language/d /","link":"","permalink":"https://guozhe001.github.io/2024/11/22/language/d%20/","excerpt":"","text":"runtime/cgo xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun 1xcode-select --install","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Java实现Redis分布式锁","slug":"language/java/Java实现redis分布式锁","date":"2024-11-22T06:32:06.496Z","updated":"2024-11-22T06:32:06.496Z","comments":true,"path":"2024/11/22/language/java/Java实现redis分布式锁/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/language/java/Java%E5%AE%9E%E7%8E%B0redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"","text":"背景 在实际的业务中遇到用户账户充值、提现等业务，需要防止并发来达到账户余额变动的正确性。 旧的实现是通过mysql悲观锁来完成的，在充值和提现等账户余额会变化的功能操作之前，先使用用户账户ID做for update，来锁定用户账户。但是这种实现方式把所有的压力都放在数据库上面，随着业务的不断发展，数据库压力也越来越大，因此我对分布式锁进行了改造，使用redis来实现。 具体实现 分布式锁主逻辑 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290package com.guozhe.core.service.impl;import com.github.rholder.retry.*;import com.google.common.base.Joiner;import com.guozhe.core.exception.AssetCommonException;import com.guozhe.core.utils.CommonPreconditions;import com.guozhe.core.utils.CommonUtil;import com.guozhe.core.utils.UUIDUtils;import lombok.extern.slf4j.Slf4j;import org.springframework.data.redis.core.RedisCallback;import org.springframework.data.redis.core.RedisTemplate;import java.util.Arrays;import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.TimeUnit;/** * redis分布式锁 * * @author guozhe * @date 2019-09-11 */@Slf4jpublic class RedisLock &#123; /** * redis锁key的前缀 */ static final String REDIS_LOCK_PREFIX = &quot;CORE_LOCK&quot;; /** * redis默认的分割字符串 */ static final String REDIS_DEFAULT_SPLIT = &quot;:&quot;; /** * redis的ttl命令如果有key没有失效时间的返回结果 */ private static final int TTL_NO_EXPIRE_RESPONSE = -1; /** * 加锁尝试retryer */ private final Retryer&lt;Boolean&gt; retryer; /** * redis锁的超时时长，单位秒 */ private final int redisLockExpireSeconds; private final RedisTemplate&lt;String, String&gt; redisTemplate; RedisLock(RedisTemplate&lt;String, String&gt; redisTemplate, int redisLockExpireSeconds) &#123; this.redisTemplate = redisTemplate; this.redisLockExpireSeconds = redisLockExpireSeconds; this.retryer = getRetryer((this.redisLockExpireSeconds * 1000) / 100, 100L); &#125; /** * 通用分布式redis锁 * 默认每隔200毫秒尝试一次枷锁，一共尝试10次 * * @param beforeLock 可以为null，加锁之前处理的逻辑，如果有返回值则直接返回，如果得到的是null则继续执行业务逻辑 * @param beforeBizCalled 可以为null，业务处理之前处理的逻辑，如果有返回值则直接返回，如果得到的是null则继续执行业务逻辑 * @param bizCallable 业务处理逻辑 * @param businessName 当前业务名称 * @param key redis加锁的key * @return 业务处理结果 * @throws AssetCommonException 有两种情况会抛此异常： * 0、如果一直获取不到锁会抛此异常 * 1、如果业务处理包括beforeLock、beforeBizCalled、bizCallable时有异常，则直接转成此异常抛出 */ public &lt;T&gt; T lockAndCall(Callable&lt;T&gt; beforeLock, Callable&lt;T&gt; beforeBizCalled, Callable&lt;T&gt; bizCallable, String businessName, String key) &#123; if (CommonUtil.isNotNull(beforeLock)) &#123; T result = call(beforeLock); if (CommonUtil.isNotNull(result)) &#123; return result; &#125; &#125; final String uuid = UUIDUtils.getUUID(); // 此方法会阻塞线程往下运行，除非已经获得锁才会继续执行，否则一直尝试获取锁或者最终获取锁失败抛异常 retryLock(businessName, key, uuid); return lockSuccessDoBiz(beforeBizCalled, bizCallable, businessName, key, uuid); &#125; /** * 通用分布式redis锁，只尝试加锁一次， * 需要自定义Retryer实例 * * @param beforeLock 可以为null，加锁之前处理的逻辑，如果有返回值则直接返回，如果得到的是null则继续执行业务逻辑 * @param beforeBizCalled 可以为null，业务处理之前处理的逻辑，如果有返回值则直接返回，如果得到的是null则继续执行业务逻辑 * @param bizCallable 业务处理逻辑 * @param businessName 当前业务名称 * @param key redis加锁的key * @return 业务处理结果 * @throws AssetCommonException 有两种情况会抛此异常： * 0、如果一直获取不到锁会抛此异常 * 1、如果业务处理包括beforeLock、beforeBizCalled、bizCallable时有异常，则直接转成此异常抛出 */ &lt;T&gt; T lockAndCallNoRetry(Callable&lt;T&gt; beforeLock, Callable&lt;T&gt; beforeBizCalled, Callable&lt;T&gt; bizCallable, String businessName, String key) &#123; if (CommonUtil.isNotNull(beforeLock)) &#123; T result = call(beforeLock); if (CommonUtil.isNotNull(result)) &#123; return result; &#125; &#125; final String uuid = UUIDUtils.getUUID(); // 此方法不会阻塞线程，如果加锁成功则处理业务，否则直接返回null if (tryLock(businessName, key, uuid)) &#123; return lockSuccessDoBiz(beforeBizCalled, bizCallable, businessName, key, uuid); &#125; return null; &#125; /** * 加锁成功之后的业务处理 * * @param beforeBizCalled 可以为null，业务处理之前处理的逻辑，如果有返回值则直接返回，如果得到的是null则继续执行业务逻辑 * @param bizCallable 业务处理逻辑 * @param businessName 当前业务名称 * @param key redis加锁的key * @param value redis锁的value值，为了解锁 * @param &lt;T&gt; 自定义返回值 * @return 业务处理结果 */ private &lt;T&gt; T lockSuccessDoBiz(Callable&lt;T&gt; beforeBizCalled, Callable&lt;T&gt; bizCallable, String businessName, String key, String value) &#123; try &#123; if (CommonUtil.isNotNull(beforeBizCalled)) &#123; T call = beforeBizCalled.call(); if (CommonUtil.isNotNull(call)) &#123; return call; &#125; &#125; CommonPreconditions.checkArgument(CommonUtil.isNotNull(bizCallable), &quot;businessName=%s,key=%s业务处理逻辑为null&quot;, businessName, key); return bizCallable.call(); &#125; catch (Exception e) &#123; throw new AssetCommonException(e); &#125; finally &#123; log.info(&quot;&#123;&#125;业务处理完成，解锁key=&#123;&#125;,value=&#123;&#125;&quot;, businessName, key, value); unlocked(key, value); &#125; &#125; /** * 执行，如果成功则返回结果；如果有异常则抛出AssetCommonException * * @param callable callable * @param &lt;T&gt; 自定义返回值 * @return 业务处理结果 */ private &lt;T&gt; T call(Callable&lt;T&gt; callable) &#123; try &#123; return callable.call(); &#125; catch (Exception e) &#123; throw new AssetCommonException(e); &#125; &#125; /** * 获取加锁的redis的key * * @param key 需要加锁的原始key * @return 最终处理后的key字节数组 */ static byte[] getRedisKey(String key) &#123; return getRedisKeyString(key).getBytes(); &#125; /** * 获取加锁的redis的key字符串,使用:把传入的字符串拼接起来 * * @param first 第一个字符串 * @param rest 其他的字符串 * @return 最终处理后的key字节数组 */ static String getRedisKeyString(String first, String... rest) &#123; return Joiner.on(REDIS_DEFAULT_SPLIT).join(REDIS_LOCK_PREFIX, first, rest); &#125; /** * 解锁，删除redis中的key如果value的值和此实例的值一样的话 * * @param key redis锁的key * @param value 锁的值 */ private void unlocked(String key, String value) &#123; final byte[] redisKey = getRedisKey(key); redisTemplate.execute((RedisCallback&lt;Boolean&gt;) connection -&gt; &#123; byte[] bytes = connection.get(redisKey); if (Arrays.equals(value.getBytes(), bytes)) &#123; connection.del(redisKey); &#125; return null; &#125;); &#125; /** * 重试的多次尝试加锁,如果获取到锁则继续往下执行，否则会阻断线程直到获得锁或者抛异常 * * @param businessName 业务名称 * @param key redis锁的key * @param value 锁的值 * @throws AssetCommonException 如果加锁失败或者重复次数达到最大的尝试次数，则抛此异常 */ private void retryLock(String businessName, String key, String value) &#123; try &#123; retryer.call(() -&gt; tryLock(businessName, key, value)); &#125; catch (RetryException e) &#123; // 重试失败说明没有获取到锁，所以直接抛异常不再往下执行 throw new AssetCommonException(String.format(&quot;业务%s,key=%s正在处理中，请稍后重试&quot;, businessName, key)); &#125; catch (ExecutionException e) &#123; // 执行加锁时失败，有些未知原因，如redis连不上之类的，此时为了不影响业务接着往下执行 log.error(&quot;businessName=&#123;&#125;,key=&#123;&#125;执行redis加锁异常 errorMsg=&#123;&#125;&quot;, businessName, key, e.getMessage(), e); &#125; &#125; /** * 单次尝试加锁 * * @param businessName 业务名称 * @param key redis锁的key * @param value 锁的值 * @return 如果加锁成功返回true，否则返回false */ private boolean tryLock(String businessName, String key, String value) &#123; return tryLock(businessName, key, value, this.redisTemplate, this.redisLockExpireSeconds); &#125; /** * 单次尝试加锁 * * @param businessName 业务名称 * @param key redis锁的key * @param value 锁的值 * @return 如果加锁成功返回true，否则返回false */ private static boolean tryLock(String businessName, String key, String value, RedisTemplate&lt;String, String&gt; redisTemplate, long redisLockExpireSeconds) &#123; final byte[] redisKey = getRedisKey(key); return redisTemplate.execute((RedisCallback&lt;Boolean&gt;) connection -&gt; &#123; // 加锁，只有在key不存在的情况下才能加锁成功 boolean result = connection.setNX(redisKey, value.getBytes()); if (result) &#123; log.info(&quot;businessName=&#123;&#125; key=&#123;&#125; value=&#123;&#125;,设置锁的失效时间=&#123;&#125;s&quot;, businessName, key, value, redisLockExpireSeconds); // 如果加锁成功设置锁的超时时间 connection.expire(redisKey, redisLockExpireSeconds); &#125; else &#123; /* 如果没有加锁成功，检查这个key是否有超时时间，如果没有超时时间则设置超时时间 ttl的官方文档如下： Returns the remaining time to live of a key that has a timeout. In Redis 2.6 or older the command returns -1 if the key does not exist or if the key exist but has no associated expire. Starting with Redis 2.8 the return value in case of error changed: The command returns -2 if the key does not exist. The command returns -1 if the key exists but has no associated expire. 测试环境redis_version:4.0.1 生产环境redis_version:4.0.13 @2019-09-20 */ if (TTL_NO_EXPIRE_RESPONSE == connection.ttl(redisKey)) &#123; connection.expire(redisKey, redisLockExpireSeconds); &#125; &#125; return result; &#125;); &#125; /** * 有些业务不需要一直等待重试，如果第一次获取锁不成功则马上不处理即可； * 所以本方法即是 * * @param retryTimes 尝试枷锁次数 必须大于0 * @param fixedWaitTime 固定等待时长,单位MILLISECONDS * @return Retryer实例 */ public Retryer&lt;Boolean&gt; getRetryer(int retryTimes, long fixedWaitTime) &#123; /* * 加锁尝试retryer * 最多尝试10次，每次不成功等待100ms，所以最多等待一秒钟如果获取不到锁就不再尝试 * 2019-09-11查询生产环境日志，放款接口处理时间几乎没有超过500ms，所以时间是够用的 */ return RetryerBuilder.&lt;Boolean&gt;newBuilder() // 每次尝试加锁失败后等待100ms .withWaitStrategy(WaitStrategies.fixedWait(fixedWaitTime, TimeUnit.MILLISECONDS)) // 最多尝试10次 .withStopStrategy(StopStrategies.stopAfterAttempt(retryTimes)) // 如果返回false则继续重试 .retryIfResult(aBoolean -&gt; aBoolean == null || !aBoolean).build(); &#125;&#125; 构建分布式锁 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.guozhe.core.service.impl;import com.guozhe.core.utils.CommonPreconditions;import com.guozhe.core.utils.CommonUtil;import org.springframework.data.redis.core.RedisTemplate;/** * 通用的redis分布式锁构建器 * 必须设置RedisTemplate * * @author guozhe */public class RedisLockBuilder &#123; private RedisTemplate&lt;String, String&gt; redisTemplate; /** * redis锁的超时时长，单位秒;默认1s，客户端可以根据自身业务自己设置 */ private int redisLockExpireSeconds = 1; private RedisLockBuilder() &#123; &#125; public static RedisLockBuilder newBuilder() &#123; return new RedisLockBuilder(); &#125; public RedisLockBuilder redisTemplate(RedisTemplate&lt;String, String&gt; redisTemplate) &#123; this.redisTemplate = redisTemplate; return this; &#125; /** * 设置加锁时长，默认1s，客户端可以根据自身业务自己设置 * * @param seconds 超时时间，单位秒 * @return 当前RedisLockBuilder */ public RedisLockBuilder redisLockExpireSeconds(int seconds) &#123; this.redisLockExpireSeconds = seconds; return this; &#125; public RedisLock build() &#123; CommonPreconditions.checkArgument(CommonUtil.isNotNull(redisTemplate), &quot;构建redis分布式锁时，redisTemplate不允许为null&quot;); CommonPreconditions.checkArgument(redisLockExpireSeconds &gt; 0, &quot;构建redis分布式锁时，超时时间必须大于0seconds=%s&quot;, this.redisLockExpireSeconds); return new RedisLock(redisTemplate, redisLockExpireSeconds); &#125;&#125; 如何使用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package com.guozhe.core.service.impl;import com.google.common.collect.Sets;import com.guozhe.core.manager.CoreCommonApiNotifyRecordManagerService;import com.guozhe.core.model.CoreCommonApiNotifyRecord;import com.guozhe.core.remote.BaseRemoteApiNotifyService;import com.guozhe.core.service.CommonApiNotifyService;import com.guozhe.core.service.ServiceLocator;import com.guozhe.core.utils.CommonPreconditions;import com.guozhe.core.utils.CommonUtil;import lombok.extern.slf4j.Slf4j;import org.apache.commons.collections4.CollectionUtils;import org.apache.commons.lang3.BooleanUtils;import org.apache.commons.lang3.StringUtils;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.stereotype.Service;import java.util.Set;import java.util.concurrent.TimeUnit;import java.util.stream.Collectors;/** * @author guozhe * @date 2019-12-06 */@Slf4j@Servicepublic class CommonApiNotifyServiceImpl implements CommonApiNotifyService &#123; /** * redis加锁时key标示的业务名称 */ static final String REDIS_LOCK_BUSINESS_NAME = &quot;COMMON_API_NOTIFY&quot;; /** * redis加锁时的超时时长，为了防止业务方的接口处理时间过长导致并发，此处设置的时间比较长 */ private static final int REDIS_LOCK_EXPIRE_SECONDS = 20; /** * redis分布式锁 */ private final RedisLock redisLockService; private final CoreCommonApiNotifyRecordManagerService coreCommonApiNotifyRecordManagerService; private final RedisTemplate&lt;String, String&gt; redisTemplate; public CommonApiNotifyServiceImpl(RedisTemplate&lt;String, String&gt; redisTemplate, CoreCommonApiNotifyRecordManagerService coreCommonApiNotifyRecordManagerService) &#123; this.coreCommonApiNotifyRecordManagerService = coreCommonApiNotifyRecordManagerService; this.redisTemplate = redisTemplate; this.redisLockService = RedisLockBuilder.newBuilder().redisTemplate(redisTemplate).redisLockExpireSeconds(REDIS_LOCK_EXPIRE_SECONDS).build(); &#125; @Override public void notifyWithLock(CoreCommonApiNotifyRecord record) &#123; BaseRemoteApiNotifyService remoteApiNotifyService = getBaseRemoteApiNotifyService(record); // 此处是为了防止并发，如果本次通知成功或已经通知成功result是true;如果本次通知失败则返回false;如果正在处理则返回null // 此处不只是为了防并发，此处也有如果已经通知过了就不再通知的逻辑，因此在加锁之前和加锁之后业务处理之前都做检查 Boolean result = redisLockService.lockAndCallNoRetry( () -&gt; checkIfNotified(record), () -&gt; checkIfNotified(record), () -&gt; remoteApiNotifyService.bizNotify(record), REDIS_LOCK_BUSINESS_NAME, String.valueOf(record.getId())); if (CommonUtil.isNull(result)) &#123; log.info(&quot;API通知recordId=&#123;&#125;, coreLendRequestId=&#123;&#125;, businessType=&#123;&#125; 正在通知无需重复&quot;, record.getId(), record.getCoreLendRequestId(), record.getBusinessType()); &#125; executeResult(record, result); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://guozhe001.github.io/categories/Java/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://guozhe001.github.io/tags/Redis/"},{"name":"分布式锁","slug":"分布式锁","permalink":"https://guozhe001.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"}]},{"title":"为什么我们在使用Spring的时候应该使用构造方法注入bean","slug":"language/java/为什么建议使用构造器注入而不是@Autoware","date":"2024-11-22T06:32:06.496Z","updated":"2024-11-22T06:32:06.496Z","comments":true,"path":"2024/11/22/language/java/为什么建议使用构造器注入而不是@Autoware/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/language/java/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BB%BA%E8%AE%AE%E4%BD%BF%E7%94%A8%E6%9E%84%E9%80%A0%E5%99%A8%E6%B3%A8%E5%85%A5%E8%80%8C%E4%B8%8D%E6%98%AF@Autoware/","excerpt":"","text":"问题 对于使用Spring框架的java开发人员对下面的代码应该很熟悉： 12@Autowiredprivate HelloService helloService; 但是对于上面的代码，Sonar会提示：Remove this annotation and use constructor injection instead. 翻译成中文即：移除@Autowired注解使用构造器注入方式替代。 IntelliJ IDEA也会提示Field injection is not recommended 翻译成中文即：不推荐使用字段注入 那么他们为什么这么建议呢？ 首先我们先看一下Spring有哪些注入bean的方式 构造方法注入 set方法注入 字段注入，即@Autowired注解 如何使用这些方式 构造方法注入 在Spring4.3版本之前，我们必须要在构造方法上加@Autowired注解；在新版本中如果当前类只有一个构造方法@Autowired注解就是可选的。 只有一个构造方法示例： 123456789@Controllerpublic class ValidationController &#123; private final HelloService helloService; public ValidationController(HelloService helloService) &#123; this.helloService = helloService; &#125;&#125; 多个构造方法示例： 1234567891011121314@Controllerpublic class ValidationController &#123; private HelloService helloService; @Autowired public ValidationController(HelloService helloService) &#123; this.helloService = helloService; &#125; public ValidationController() &#123; &#125;&#125; set方法注入 这种方式Spring会找到 @Autowired 注解并且调用set方法来注入所需的依赖。 1234567891011121314@Controllerpublic class ValidationController &#123; private HelloService helloService; public HelloService getHelloService() &#123; return helloService; &#125; @Autowired public void setHelloService(HelloService helloService) &#123; this.helloService = helloService; &#125;&#125; 字段注入 通过基于字段的注入，Spring在使用@Autowired注释进行注释时，直接将所需的依赖项分配给字段。 123456@Controllerpublic class ValidationController &#123; @Autowired private HelloService helloService;&#125; 这些方式有什么优缺点 既然要移除@Autowired注解使用构造器注入方式替代，那么我们主要讨一下这些方式的优缺点。 字段注入方式的优点 相比较另外两种方式，字段注入方式的代码量更少、更整齐、更简洁 构造方法注入的优点 容易发现代码的坏味道 set方法注入和字段注入会间接违反单一职责原则。 因为在一个类依赖很多其他类的时候，如果使用构造方法注入就会发现构造方法的参数太多，这会让开发人员反思这个类真的需要这么多依赖吗？当前类是不是职责过多？ 而使用字段注入时，就会把一些例如sonar的提示屏蔽掉，让开发人员误以为这样做没有问题 可以创建不可变类 在使用构造方法注入时因为构造方法是创建依赖对象的唯一方式，这非常有助于让我们创建不可变的对象。 想象一下创建一个bean之后你可以通过set方法随意修改此类的依赖，在出现问题时是很难定位的。 @Autowired的源码有一段注释如下：Fields are injected right after construction of a bean, before any config methods are invoked. Such a config field does not have to be public. 大意是使用@Autowired注解时，bean是在构造当前的bean之后，并且在任何的其他方法调用之前注入，因此无法设置成final类型的字段。 更明显的声明所有的依赖 使用构造方法注入，在使用这个类时就会暴露给使用者说我要依赖构造方法中的类。 但是使用字段注入时，使用者其实并不知道这个类依赖了哪些类，除非我到此类中查看这个类有多少个字段是有@Autowired注解。 不方便迁移 spring实现了DI（控制反转），但并非是DI本身； 使用构造方法注入时，除了在类上面有@Service、@Component等的注解，没有其他的Spring相关的更多的注解。 使用字段注入时，除了在类上面有@Service、@Component等的注解之外又使用了Spring的@Autowired注解，如果把此类迁移到其他没有spring的环境时是完成不了注入的。 不方便测试 在使用构造方法注入时，单元测试时开发人员可以直接传入一个mock的类或者其他的任何被测试类依赖的子类； 当然我们也可以使用set方式注入一个mock的类，但是如果代码修改了新增了一个依赖，那么我们很容易忘掉在测试代码中set新增的依赖，直到运行的时候我们才会看到可能有NPE异常爆出；但是构造方法就不必有这种烦恼，因为如果新增了一个依赖，测试方法会马上编译不通过。 使用字段注入，必须依赖Spring去帮助注入依赖的类 总结 通过构造方法注入bean是我们更容易创建不可变类，代码更健壮、更具有可测试性、更容易避免NPE。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://guozhe001.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://guozhe001.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://guozhe001.github.io/tags/Spring/"}]},{"title":"使用Redis自增特性创建唯一id生成器","slug":"language/java/使用redis自增特性创建唯一id生成器","date":"2024-11-22T06:32:06.496Z","updated":"2024-11-22T06:32:06.496Z","comments":true,"path":"2024/11/22/language/java/使用redis自增特性创建唯一id生成器/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/language/java/%E4%BD%BF%E7%94%A8redis%E8%87%AA%E5%A2%9E%E7%89%B9%E6%80%A7%E5%88%9B%E5%BB%BA%E5%94%AF%E4%B8%80id%E7%94%9F%E6%88%90%E5%99%A8/","excerpt":"","text":"需求说明 产品要求实现一个订单编号，此编号规则如下 订单编号规则： “字母” + “日期” + “自增ID” 订单编号举例 比如业务A，在2020-08-04日有三个订单，那么订单编号如下： A202008040001 A202008040002 A202008040003 比如业务A，在2020-08-05日有4个订单，那么订单编号如下： A202008050001 A202008050002 A202008050003 A202008050003 通过上面的例子可以看到，后面的“自增ID”每天都会从1开始增加，在一个分布式系统中，要做到每天从1开始不重复并且自增的效果；想到的第一个实现方案就是redis的Incr命令（Redis Incr 命令将 key 中储存的数字值增一）。 需求实现 配置redis 依赖redis相关jar包 因为此模块继承了spring-boot-starter-parent，所以不需要指定版本 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;/dependency&gt; 编写配置redis的config 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.nicai.config;import org.springframework.boot.autoconfigure.data.redis.RedisProperties;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisClusterConfiguration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;import org.springframework.data.redis.core.StringRedisTemplate;/** * redis集群配置 * * @author guozhe * @date 2020/08/04 */@Configuration@EnableConfigurationProperties(RedisProperties.class)public class RedisClusterConfig &#123; private final RedisProperties redisProperties; public RedisClusterConfig(RedisProperties redisProperties) &#123; this.redisProperties = redisProperties; &#125; /** * Thread-safe factory of Redis connections配置 * * @return factory of Redis */ @Bean public RedisConnectionFactory redisConnectionFactory() &#123; RedisClusterConfiguration redisClusterConfiguration = new RedisClusterConfiguration(redisProperties.getCluster().getNodes()); redisClusterConfiguration.setPassword(redisProperties.getPassword()); return new JedisConnectionFactory(redisClusterConfiguration); &#125; /** * 创建String类型的redis模板 * * @param redisConnectionFactory factory of Redis * @return String-focused extension of RedisTemplate */ @Bean public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; StringRedisTemplate template = new StringRedisTemplate(redisConnectionFactory); template.afterPropertiesSet(); return template; &#125;&#125; 如果是配置范型的RedisTemplate，需要设置值的序列化规则为：StringRedisSerializer，原因可以参考此文章：Spring Boot中使用RedisTemplate优雅的操作Redis，并且解决RedisTemplate泛型注入失败的问题 测试redis的config代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.nicai.config;import com.yuanfeng.accounting.BaseAdminSpringTest;import com.yuanfeng.accounting.Constants;import lombok.extern.slf4j.Slf4j;import org.junit.Assert;import org.junit.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.data.redis.core.ValueOperations;import java.util.concurrent.TimeUnit;/** * @author guozhe * @date 2020/08/04 */@Slf4j@RunWith(SpringRunner.class)@SpringBootTest(classes = AdminApplication.class)public class RedisClusterConfigTest &#123; private static final String TEST_KEY = Constants.REDIS_KEY_PREFIX + &quot;test:hello&quot;; private static final String TEST_VALUE = &quot;world&quot;; @Autowired private StringRedisTemplate stringRedisTemplate; @Test public void testStringRedisTemplateGetAndSet() &#123; stringRedisTemplate.opsForValue().set(TEST_KEY, TEST_VALUE); String value = stringRedisTemplate.opsForValue().get(TEST_KEY); Assert.assertEquals(TEST_VALUE, value); stringRedisTemplate.delete(TEST_KEY); Assert.assertNull(stringRedisTemplate.opsForValue().get(TEST_KEY)); &#125; @Test public void testIncr() &#123; String key = TEST_KEY; ValueOperations&lt;String, String&gt; valueOperations = stringRedisTemplate.opsForValue(); valueOperations.set(key, &quot;1&quot;, 24, TimeUnit.HOURS); String initValue = valueOperations.get(key); log.info(&quot;key=&#123;&#125;, init value=&#123;&#125;&quot;, key, initValue); Assert.assertEquals(&quot;1&quot;, initValue); Long increment = valueOperations.increment(key); log.info(&quot;key=&#123;&#125;, after increment=&#123;&#125;&quot;, key, increment); Assert.assertEquals(Long.valueOf(2), increment); stringRedisTemplate.delete(key); Assert.assertNull(valueOperations.get(key)); &#125;&#125; 基于redis编写唯一ID生成服务 添加抽象的唯一id生成服务 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197package com.nicai.service;import cn.hutool.core.util.BooleanUtil;import com.alibaba.fastjson.JSON;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import lombok.extern.slf4j.Slf4j;import org.springframework.data.redis.core.StringRedisTemplate;import java.util.Objects;import java.util.Optional;import java.util.concurrent.TimeUnit;/** * 分布式ID生成服务 * * @author guozhe * @date 2020/08/04 */@Slf4jpublic abstract class AbstractRedisDistributedIDGenerateService&lt;T extends AbstractRedisDistributedIDGenerateService.Context&gt; &#123; /** * 初始化key时的默认值 */ private static final long DEFAULT_VALUE = 0; protected final StringRedisTemplate redisTemplate; public AbstractRedisDistributedIDGenerateService(StringRedisTemplate redisTemplate) &#123; this.redisTemplate = redisTemplate; &#125; /** * 获取下一个ID，直接从redis中获取自增后的值； * * @return 下一个ID, 如果redis出现异常则返回null，请使用者自行处理 */ public final Optional&lt;Long&gt; nextId() &#123; // 从redis中获取自增id Long id = incr(getKey()); return Objects.isNull(id) ? Optional.empty() : Optional.of(id); &#125; /** * 获取下一个ID，根据传入的上下文和redis中自增后的值最终组装成下一个ID； * 获取之后会交给子类检查此ID是否重复，如果重复会从子类中获取最新的ID，然后更新redis中的值 * * @param context 拼装id时需要的上下文 * @return 下一个ID */ public final String nextId(T context) &#123; Optional&lt;Long&gt; id = nextId(); // 如果可以从redis中获取值，则说明redis服务正常，需要判重；否则直接从数据库中获取下一个id String nextId = id.isPresent() ? ifDuplicatedThenUpdate(context, assemblyNextId(context, id.get())) : getNewIdFromDbAndUpdateRedis(context, null); if (log.isDebugEnabled()) &#123; log.debug(&quot;context=&#123;&#125;,redisIncrId=&#123;&#125; nextId=&#123;&#125;&quot;, JSON.toJSONString(context), id, nextId); &#125; return nextId; &#125; /** * 检查获取到的ID是否重复 * 如果重复则说明由于redis的一些原因导致的重复，返回最新的redis中应该存在的值 * * @param nextId 下一个ID * @return 如果当前ID没有重复，则返回null，否则如果重复了则返回redis中应该有的值 */ protected abstract boolean checkIfDuplicated(String nextId); /** * 从数据库获取下一个id * * @param duplicatedId 重复的id，此入参可能为null，子类需要自己处理 * @return 数据库获取下一个id */ protected abstract Long maxIdFromDatabase(String duplicatedId); /** * 子类根据redis当前的值自行组装最终的ID * * @param context 上下文 * @param redisValue redis当前的值 * @return 最终的ID */ protected abstract String assemblyNextId(T context, Long redisValue); /** * 获取redis自增的key * * @return redis自增的key */ protected abstract String getKey(); /** * 调用redis的自增方法 * 如果key不存在则先设置key，再调用自增方法 * * @param key 需要自增的key * @return 自增之后的值，如果redis出现异常则返回null */ Long incr(String key) &#123; Long increment = null; try &#123; // 先检查redis中是否有key,如果没有,先设置key并且设置过期时间 if (BooleanUtil.isFalse(redisTemplate.hasKey(key))) &#123; initOrUpdateValue(key, getKeyInitValue()); &#125; increment = redisTemplate.opsForValue().increment(key); &#125; catch (Exception e) &#123; log.error(&quot;调用redis的自增方法异常，error_message=&#123;&#125;&quot;, e.getMessage(), e); &#125; log.debug(&quot;key = &#123;&#125;, increment=&#123;&#125;&quot;, key, increment); return increment; &#125; /** * 获取初始化key时的value值，默认是0，自增之后id从1开始； * 如果子类想从其他数字开始则自己覆盖此方法即可 * * @return 初始化key时的value值 */ protected long getKeyInitValue() &#123; return DEFAULT_VALUE; &#125; /** * 获取key的超时时间，单位是小时，由子类设置 * * @return 超时时间，单位小时 */ protected abstract long getTimeOutHours(); /** * 判断是否重复，如果重复则从别的渠道（由子类自己决定从哪个渠道）更新 * * @param context 拼装id时需要的上下文 * @param nextId 下一个id * @return 如果重复则返回新的nextId，否则返回入参传入的nextId */ private String ifDuplicatedThenUpdate(T context, String nextId) &#123; // 判断是否重复，如果重复则从数据库中获取，否则直接返回当前值 return checkIfDuplicated(nextId) ? getNewIdFromDbAndUpdateRedis(context, nextId) : nextId; &#125; /** * 从数据库获取新id并更新redis中的值 * * @param context 拼装id时需要的上下文 * @param nextId 下一个id * @return 根据数据库的id获得的新id */ private String getNewIdFromDbAndUpdateRedis(T context, String nextId) &#123; Long maxIdFromDatabase = maxIdFromDatabase(nextId); String newId = assemblyNextId(context, maxIdFromDatabase); log.warn(&quot;nextId=&#123;&#125; 在数据库中已经存在，maxIdFromDatabase=&#123;&#125; 重新获取新的newId=&#123;&#125;&quot;, nextId, maxIdFromDatabase, newId); initOrUpdateValue(getKey(), maxIdFromDatabase); return newId; &#125; /** * 初始化或者更新redis中的自增的值 * * @param key redis中的key * @param value 需要设置的值 */ private void initOrUpdateValue(String key, Long value) &#123; try &#123; redisTemplate.opsForValue().set(key, String.valueOf(value), getTimeOutHours(), TimeUnit.HOURS); &#125; catch (Exception e) &#123; log.error(&quot;设置redis值异常，value=&#123;&#125; error_message=&#123;&#125;&quot;, value, e.getMessage(), e); &#125; &#125; /** * 上下文；子类自己定义上下文，然后根据上下文的数据来最终组装ID */ public interface Context &#123; &#125; /** * 凭证编号上下文 */ @Data @NoArgsConstructor @AllArgsConstructor public static class AContext implements Context &#123; /** * 业务类型 */ private String businessType; &#125;&#125; 添加一个A服务的唯一id生成服务实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package com.nicai.service.impl;import cn.hutool.core.date.DatePattern;import cn.hutool.core.date.DateUtil;import cn.hutool.core.util.StrUtil;import com.yuanfeng.accounting.Constants;import com.yuanfeng.accounting.dao.ManualVoucherDAO;import com.yuanfeng.accounting.entity.ManualVoucherEntity;import com.yuanfeng.accounting.exception.AccountingException;import com.yuanfeng.accounting.service.AbstractRedisDistributedIDGenerateService;import lombok.extern.slf4j.Slf4j;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.stereotype.Service;import java.util.List;import java.util.Objects;import java.util.Optional;/** * 分布式唯一ID生成-A实现类 * 编号规则：用途+日期+自增ID，如：A202007310001；A202007310002；A202008070001； * * @author guozhe * @date 2020/08/04 */@Slf4j@Servicepublic class DistributedIDGenerateServiceAImpl extends AbstractRedisDistributedIDGenerateService&lt;AbstractRedisDistributedIDGenerateService.AContext&gt; &#123; /** * 业务类型 */ private static final String BUSINESS_TYPE = &quot;A:&quot;; /** * ID长度不足4位时在前面填充的字符 */ private static final char FILLED_CHAR = &#x27;0&#x27;; /** * 最后的自增ID的长度 */ private static final int INCREMENT_LENGTH = 4; /** * 过期小时数，即在24小时候过期 */ private static final int EXPIRATION_HOURS = 24; public DistributedIDGenerateServiceAImpl(StringRedisTemplate redisTemplate) &#123; super(redisTemplate); &#125; @Override protected boolean checkIfDuplicated(String nextId) &#123; return false; &#125; @Override protected Long maxIdFromDatabase(String duplicatedId) &#123; return 1L; &#125; @Override protected String assemblyNextId(VoucherNumberContext context, Long redisValue) &#123; return String.join(Constants.BLANK, context.getBusinessType(), getDatePeriod(), StrUtil.fillBefore(String.valueOf(redisValue), FILLED_CHAR, INCREMENT_LENGTH)); &#125; @Override protected String getKey() &#123; return String.join(Constants.REDIS_KEY_DELIMITER, Constants.REDIS_KEY_PREFIX, BUSINESS_TYPE, getDatePeriod()); &#125; @Override protected long getTimeOutHours() &#123; return EXPIRATION_HOURS; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://guozhe001.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://guozhe001.github.io/tags/Java/"},{"name":"Redis","slug":"Redis","permalink":"https://guozhe001.github.io/tags/Redis/"}]},{"title":"线程池无法捕获线程的异常踩坑复盘","slug":"language/java/线程池无法捕获线程的异常踩坑复盘","date":"2024-11-22T06:32:06.496Z","updated":"2024-11-22T06:32:06.497Z","comments":true,"path":"2024/11/22/language/java/线程池无法捕获线程的异常踩坑复盘/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/language/java/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%97%A0%E6%B3%95%E6%8D%95%E8%8E%B7%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%BC%82%E5%B8%B8%E8%B8%A9%E5%9D%91%E5%A4%8D%E7%9B%98/","excerpt":"","text":"问题描述 需求信息 最近在工作中有个需求，先在A服务页面增加一条数据，然后去B服务查询此数据的详细信息 解决方案 为了使A服务的新增数据接口快速响应，在查询B服务数据详情的地方使用了线程池异步查询与更新。 问题现象 在验证时发现数据库中的数据字段不全，经分析缺少的都是需要从B服务查询并更新的字段 初步定位 猜测应该是查询B服务时出了一些异常，而由于不规范使用线程池导致异常没有抛出，直接打到了控制台，故A服务的日志系统并看不到错误日志。 问题解决 查询B服务数据详情时暂时去掉使用线程池，改为同步调用 增加容错定时任务，定时查询需要从B服务获取缺失字段的数据进行更新 上线后观察，新增的数据不再有部分字段缺失的情况；问题解决。 问题复盘 A服务线程池的使用 线程池定义 12345/** * 查询B服务数据详情的线程池 */private static final ExecutorService executorService = new ThreadPoolExecutor(2, 2, 0L, TimeUnit.MICROSECONDS, new LinkedBlockingDeque&lt;&gt;(), new ThreadFactoryBuilder().setNameFormat(&quot;queryDataDetail-%d&quot;).build()); 线程池使用 12345678910@Override@Transactional(rollbackFor = Exception.class)public void add(String contract) &#123; // 0、检查合同必须不存在 checkIfExist(contract); // 1、保存合同数据 Entity entity = saveData(contract); // 2、从B服务查询缺失信息 executorService.execute(() -&gt; queryDataDetail(entity));&#125; 如此使用有何问题 我重新写了一个测试方法如下： 1、定义一个会一直抛异常的方法 1234567891011121314/** * 引入SystemOutRule，监听程序日志输出 */@Rulepublic SystemOutRule systemOutRule = new SystemOutRule().enableLog();/** * 引入SystemOutRule，监听程序日志输出 */private String runWithException() &#123; Thread thread = Thread.currentThread(); log.info(&quot;thread is &#123;&#125;&quot;, thread); log.info(&quot;eh=&#123;&#125;&quot;, thread.getUncaughtExceptionHandler()); throw new NicaiException(&quot;出错啦！&quot;);&#125; 2、使用线程池调用上面的方法 12345678@Testpublic void run() throws InterruptedException &#123; ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(this::runWithException); TimeUnit.MILLISECONDS.sleep(100L); // 断言程序打印的日志不包含“出错啦！” Assert.assertFalse(systemOutRule.getLog().contains(&quot;出错啦！&quot;));&#125; 3、上面的单测断言是成功的，那么异常跑哪里去了？上面的单测在控制台的输出如下： 4、可以看出上面的异常信息是直接输出到了控制台，而不是由程序输出到控制台，主要原因是主程序没有捕获到此异常导致的。（具体原因还没有深入） 如何解决线程池的异常捕获问题 上面的测试可以说明到为什么日志里面查不到错误日志，那么如何捕获线程里的异常呢？ 方法1:使用UncaughtExceptionHandler 1、在创建线程池的时候，设置传入的ThreadFactory的UncaughtExceptionHandler属性，此UncaughtExceptionHandler会处理线程中的异常；下面的例子我直接打印了出来异常原因和异常栈。 12345678910@Testpublic void runWithUncaughtExceptionHandler() throws InterruptedException &#123; ExecutorService executorService = Executors.newCachedThreadPool( new ThreadFactoryBuilder() .setUncaughtExceptionHandler((t, e) -&gt; log.info(&quot;UncaughtExceptionHandler caught, error_message=&#123;&#125;&quot;, e.getMessage(), e)) .build()); executorService.execute(this::runWithException); TimeUnit.MILLISECONDS.sleep(100L); Assert.assertTrue(systemOutRule.getLog().contains(&quot;出错啦！&quot;));&#125; 2、上面的单测运行结果如下：（可以和上面的运行结果进行比对） 3、从上面的运行结果可以看出异常信息是由程序捕获后再输出出来，这样就不会导致查不到异常日志了。 方法2:使用guava扩展的FutureCallback 1、guava对jdk的线程做了一些扩展，其中一个就是FutureCallback，使用方法如下： 123456789101112131415161718@Testpublic void runWithGuavaThreadPool() throws InterruptedException &#123; ListeningExecutorService executorService = MoreExecutors.listeningDecorator(Executors.newCachedThreadPool()); ListenableFuture&lt;String&gt; listenableFuture = executorService.submit(this::runWithException); Futures.addCallback(listenableFuture, new FutureCallback&lt;String&gt;() &#123; @Override public void onSuccess(String result) &#123; log.info(&quot;success! result = &#123;&#125;&quot;, result); &#125; @Override public void onFailure(Throwable t) &#123; log.error(&quot;guava FutureCallback caught, error_message=&#123;&#125;&quot;, t.getMessage(), t); &#125; &#125;, executorService); TimeUnit.MILLISECONDS.sleep(100L); Assert.assertTrue(systemOutRule.getLog().contains(&quot;出错啦！&quot;));&#125; 2、上面的单测运行结果如下： 问题总结 1、通过上面的测试，优化A服务的线程池定义，使之在遇到异常时能够正常被捕获，能输出，方便问题定位；补偿定时任务也能对第一次查询异常进行容错，保证数据能够同步过来。 1234567/** * 查询B服务数据详情的线程池 */private static final ExecutorService executorService = new ThreadPoolExecutor(2, 2, 0L, TimeUnit.MICROSECONDS, new LinkedBlockingDeque&lt;&gt;(), new ThreadFactoryBuilder() .setUncaughtExceptionHandler((t, e) -&gt; log.error(&quot;查询数据详情的线程池异常,error_message=&#123;&#125;&quot;, e.getMessage(), e)) .setNameFormat(&quot;queryDataDetail-%d&quot;).build()); 2、当然此问题更深层的问题还没有完全解答 为什么线程里的异常不会被捕获？ UncaughtExceptionHandler的运行原理是什么？ Guava的FutureCallback是如何运行的？ 3、测试代码源码地址","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"https://guozhe001.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://guozhe001.github.io/tags/Java/"},{"name":"线程池","slug":"线程池","permalink":"https://guozhe001.github.io/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"}]},{"title":"SUMMARY-供应链金融","slug":"blockchain/fabric/通过供应链金融练习Fabric/summary","date":"2024-11-22T06:32:06.496Z","updated":"2024-11-22T06:32:06.496Z","comments":true,"path":"2024/11/22/blockchain/fabric/通过供应链金融练习Fabric/summary/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E9%80%9A%E8%BF%87%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D%E7%BB%83%E4%B9%A0Fabric/summary/","excerpt":"","text":"项目背景 为了学习Fabric，模拟搭建一个供应链金融的区块链项目。 为了简单起见，此项目有以下四个组织： 核心企业 一级供应商 二级供应商1 二级供应商2 操作步骤： 设置环境变量 创建网络 创建channel 开发智能合约 部署智能合约到channel并进行交易 [交易与验证](file://部署智能合约到channel.md)：查看“部署supply-v8到alljoinchannel通道”部分 隐秘交易 源码地址 总结： 本项目成功的在测试环境自己部署网络，自己写智能合约并进行调用；完成了入门练习。 存在的问题： 问题1 目前此程序把所有的组织都加入了同一个渠道，所以账本是对所有组织都是公开的；现实生活中每个企业之间的交易应该都是私密的，不能被其他企业所见。 解决方案1： 使用通道隔离，每两个需要交易的组织之间都创建一个通道。 可行性： 初步判断此方法不可行，因为不同通道之间无法交易资产？如果可以交易需要从原来的channel销毁此资产，然后在新channel创建一个新的可被信任的新资产 解决方案2： 使用私密资产交易的方式解决,参考文档Secured asset transfer in Fabric 可行性： 可以，查看[隐秘交易](file://隐秘交易.md) 问题2: 同一个智能合约如何限制只能由指定的人调用？如本例中，发行方法应该只能由核心企业调用。 解决方案 同一个智能合约可以由部署智能合约的成员调用，所以无法限制，除非智能合约里面写死。 在应收账款供应链金融的demo中，我们写的智能合约可以由任何人发行应收账款，但是这只是生成了私有的数据，别人认不认可是否跟发行应收账款的组织交易是链下解决的问题。 问题3： 使用安全的方式交易资产之后，除了资产的拥有者之外其他任何人都无法知道资产的金额等私有信息。但是现实中的供应链金融应该是允许凭证资产的发行人知道资产归属是谁、资产的金额是多少；只有这样发行人才能够在凭证资产到期时进行还款。 解决方案 修改智能合约，待完成。","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"项目实践-供应链金融","slug":"区块链/Hyperledger-Fabric/项目实践-供应链金融","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5-%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"供应链金融","slug":"供应链金融","permalink":"https://guozhe001.github.io/tags/%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D/"}]},{"title":"创建网络","slug":"blockchain/fabric/通过供应链金融练习Fabric/创建网络","date":"2024-11-22T06:32:06.496Z","updated":"2024-11-22T06:32:06.496Z","comments":true,"path":"2024/11/22/blockchain/fabric/通过供应链金融练习Fabric/创建网络/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E9%80%9A%E8%BF%87%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D%E7%BB%83%E4%B9%A0Fabric/%E5%88%9B%E5%BB%BA%E7%BD%91%E7%BB%9C/","excerpt":"","text":"创建网络 一个生产的fabric网络应该由各个组织自己保存自己的加密材料，测试环境为了演示在本地生成所有组织的加密材料。 生成加密材料 创建配置文件 创建supply-finance文件夹，配置config/crypto-config.yaml文件： 123456789101112131415161718192021222324252627282930OrdererOrgs: - Name: Orderer Domain: supply.com Specs: - Hostname: ordererPeerOrgs: - Name: gyl_core_org1 Domain: core.supply.com Template: Count: 1 Users: Count: 2 - Name: gyl_f_org1 Domain: f1.supply.com Template: Count: 1 Users: Count: 2 - Name: gyl_s_org1 Domain: s1.supply.com Template: Count: 1 Users: Count: 2 - Name: gyl_s_org2 Domain: s2.supply.com Template: Count: 1 Users: Count: 2 使用配置文件生成加密材料 使用下面的命令生成加密材料： 1cryptogen generate --config=config/crypto-config.yaml --output=&quot;./organizations&quot; 使用加密材料生成创世纪区块 使用下面的命令生成系统创世纪区块： 1configtxgen -profile TestOrgsOrdererGenesis -channelID system-channel -outputBlock ./system-genesis-block/genesis.block 输出结果： 12345678esis.block2020-12-24 15:41:52.702 CST [common.tools.configtxgen] main -&gt; INFO 001 Loading configuration2020-12-24 15:41:52.716 CST [common.tools.configtxgen.localconfig] completeInitialization -&gt; INFO 002 orderer type: etcdraft2020-12-24 15:41:52.716 CST [common.tools.configtxgen.localconfig] completeInitialization -&gt; INFO 003 Orderer.EtcdRaft.Options unset, setting to tick_interval:&quot;500ms&quot; election_tick:10 heartbeat_tick:1 max_inflight_blocks:5 snapshot_interval_size:167772162020-12-24 15:41:52.716 CST [common.tools.configtxgen.localconfig] Load -&gt; INFO 004 Loaded configuration: /Users/apple/code/open-source/blockchain/hyperledger/supply-finance/config/configtx.yaml2020-12-24 15:41:52.723 CST [common.tools.configtxgen] doOutputBlock -&gt; INFO 005 Generating genesis block2020-12-24 15:41:52.723 CST [common.tools.configtxgen] doOutputBlock -&gt; INFO 006 Creating system channel genesis block2020-12-24 15:41:52.724 CST [common.tools.configtxgen] doOutputBlock -&gt; INFO 007 Writing genesis block 遇到的错误信息： 12020-12-24 15:39:28.696 CST [common.tools.configtxgen] main -&gt; FATA 005 Error on outputBlock: could not create bootstrapper: could not create channel group: could not create orderer group: cannot marshal metadata for orderer type etcdraft: cannot load client cert for consenter orderer.supply.com:8050: open /Users/apple/code/open-source/blockchain/hyperledger/supply-finance/cryptogen/crypto-config/ordererOrganizations/supply.com/orderers/orderer.supply.com/tls/server.crt: no such file or directory 错误原因：$FABRIC_CFG_PATH/configtx.yaml配置的加密文件地址不正确 启动网络 各个组织的加密材料生成之后，在本地docker环境启动这些组织的peer节点。 配置docker-compose.yml文件 在supply-finance目录下添加docker/docker-compose.yml文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: &#x27;2&#x27;volumes: orderer.supply.com: peer0.core.supply.com: peer0.f1.supply.com: peer0.s1.supply.com: peer0.s2.supply.com:networks: test:services: orderer.supply.com: container_name: orderer.supply.com image: hyperledger/fabric-orderer:2.2.0 environment: - FABRIC_LOGGING_SPEC=INFO - ORDERER_GENERAL_LISTENADDRESS=0.0.0.0 - ORDERER_GENERAL_LISTENPORT=8050 - ORDERER_GENERAL_GENESISMETHOD=file - ORDERER_GENERAL_BOOTSTRAPFILE=/etc/hyperledger/orderer/orderer.genesis.block - ORDERER_GENERAL_LOCALMSPID=OrdererMSP - ORDERER_GENERAL_LOCALMSPDIR=/etc/hyperledger/fabric/msp - ORDERER_GENERAL_LEDGERTYPE=file - ORDERER_OPERATIONS_LISTENADDRESS=0.0.0.0:8443 # enabled TLS - ORDERER_GENERAL_TLS_ENABLED=true - ORDERER_GENERAL_TLS_PRIVATEKEY=/etc/hyperledger/fabric/tls/server.key - ORDERER_GENERAL_TLS_CERTIFICATE=/etc/hyperledger/fabric/tls/server.crt - ORDERER_GENERAL_TLS_ROOTCAS=[/etc/hyperledger/fabric/tls/ca.crt] - ORDERER_GENERAL_CLUSTER_CLIENTCERTIFICATE=/etc/hyperledger/fabric/tls/server.crt - ORDERER_GENERAL_CLUSTER_CLIENTPRIVATEKEY=/etc/hyperledger/fabric/tls/server.key - ORDERER_GENERAL_CLUSTER_ROOTCAS=[/etc/hyperledger/fabric/tls/ca.crt] working_dir: /opt/gopath/src/github.com/hyperledger/fabric command: orderer volumes: - ../system-genesis-block/genesis.block:/etc/hyperledger/orderer/orderer.genesis.block - ../organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp:/etc/hyperledger/fabric/msp - ../organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/tls:/etc/hyperledger/fabric/tls - orderer.supply.com:/var/hyperledger/production/orderer - ../organizations:/tmp ports: - 8050:8050 networks: - test peer0.core.supply.com: container_name: peer0.core.supply.com image: hyperledger/fabric-peer:2.2.0 environment: #Generic peer variables - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock # the following setting starts chaincode containers on the same # bridge network as the peers # https://docs.docker.com/compose/networking/ - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=docker_test - FABRIC_LOGGING_SPEC=INFO #- FABRIC_LOGGING_SPEC=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt # Peer specific variabes - CORE_PEER_ID=peer0.core.supply.com - CORE_PEER_ADDRESS=peer0.core.supply.com:8051 - CORE_PEER_LISTENADDRESS=0.0.0.0:8051 - CORE_PEER_CHAINCODEADDRESS=peer0.core.supply.com:8052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:8052 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.core.supply.com:8051 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.core.supply.com:8051 - CORE_PEER_LOCALMSPID=GylCoreOrg1MSP volumes: - /var/run/:/host/var/run/ - ../organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/msp:/etc/hyperledger/fabric/msp - ../organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls:/etc/hyperledger/fabric/tls - peer0.core.supply.com:/var/hyperledger/production - ../organizations:/tmp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start ports: - 8051:8051 networks: - test peer0.f1.supply.com: container_name: peer0.f1.supply.com image: hyperledger/fabric-peer:2.2.0 environment: #Generic peer variables - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock # the following setting starts chaincode containers on the same # bridge network as the peers # https://docs.docker.com/compose/networking/ - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=docker_test - FABRIC_LOGGING_SPEC=INFO #- FABRIC_LOGGING_SPEC=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt # Peer specific variabes - CORE_PEER_ID=peer0.f1.supply.com - CORE_PEER_ADDRESS=peer0.f1.supply.com:8053 - CORE_PEER_LISTENADDRESS=0.0.0.0:8053 - CORE_PEER_CHAINCODEADDRESS=peer0.f1.supply.com:8054 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:8054 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.f1.supply.com:8053 - CORE_PEER_LOCALMSPID=GylFOrg1MSP volumes: - /var/run/:/host/var/run/ - ../organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/msp:/etc/hyperledger/fabric/msp - ../organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls:/etc/hyperledger/fabric/tls - peer0.f1.supply.com:/var/hyperledger/production - ../organizations:/tmp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start ports: - 8053:8053 networks: - test peer0.s1.supply.com: container_name: peer0.s1.supply.com image: hyperledger/fabric-peer:2.2.0 environment: #Generic peer variables - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock # the following setting starts chaincode containers on the same # bridge network as the peers # https://docs.docker.com/compose/networking/ - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=docker_test - FABRIC_LOGGING_SPEC=INFO #- FABRIC_LOGGING_SPEC=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt # Peer specific variabes - CORE_PEER_ID=peer0.s1.supply.com - CORE_PEER_ADDRESS=peer0.s1.supply.com:8055 - CORE_PEER_LISTENADDRESS=0.0.0.0:8055 - CORE_PEER_CHAINCODEADDRESS=peer0.s1.supply.com:8056 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:8056 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.s1.supply.com:8055 - CORE_PEER_LOCALMSPID=GylSOrg1MSP volumes: - /var/run/:/host/var/run/ - ../organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/msp:/etc/hyperledger/fabric/msp - ../organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls:/etc/hyperledger/fabric/tls - peer0.s1.supply.com:/var/hyperledger/production - ../organizations:/tmp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start ports: - 8055:8055 networks: - test peer0.s2.supply.com: container_name: peer0.s2.supply.com image: hyperledger/fabric-peer:2.2.0 environment: #Generic peer variables - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock # the following setting starts chaincode containers on the same # bridge network as the peers # https://docs.docker.com/compose/networking/ - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=docker_test - FABRIC_LOGGING_SPEC=INFO #- FABRIC_LOGGING_SPEC=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt # Peer specific variabes - CORE_PEER_ID=peer0.s2.supply.com - CORE_PEER_ADDRESS=peer0.s2.supply.com:8151 - CORE_PEER_LISTENADDRESS=0.0.0.0:8151 - CORE_PEER_CHAINCODEADDRESS=peer0.s2.supply.com:8152 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:8152 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.s2.supply.com:8151 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.s2.supply.com:8151 - CORE_PEER_LOCALMSPID=GylSOrg2MSP volumes: - /var/run/:/host/var/run/ - ../organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/msp:/etc/hyperledger/fabric/msp - ../organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls:/etc/hyperledger/fabric/tls - ../organizations:/tmp - peer0.s2.supply.com:/var/hyperledger/production working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start ports: - 8151:8151 networks: - test 使用docker-compose.yml配置文件启动各组织的服务 命令如下： 1docker-compose -f ./docker/docker-compose.yml up -d 启动之后会在docker启动下面这些容器： orderer.supply.com:排序节点 peer0.core.supply.com:核心企业节点 peer0.f1.supply.com:一级供应商节点 peer0.s1.supply.com:二级供应商1节点 peer0.s2.supply.com:二级供应商2节点","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"项目实践-供应链金融","slug":"区块链/Hyperledger-Fabric/项目实践-供应链金融","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5-%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"供应链金融","slug":"供应链金融","permalink":"https://guozhe001.github.io/tags/%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D/"}]},{"title":"环境变量设置","slug":"blockchain/fabric/通过供应链金融练习Fabric/设置环境变量","date":"2024-11-22T06:32:06.496Z","updated":"2024-11-22T06:32:06.496Z","comments":true,"path":"2024/11/22/blockchain/fabric/通过供应链金融练习Fabric/设置环境变量/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E9%80%9A%E8%BF%87%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D%E7%BB%83%E4%B9%A0Fabric/%E8%AE%BE%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/","excerpt":"","text":"以下所有的命令均在supply-finance目录下执行 环境变量设置： 123export PATH=$&#123;PWD&#125;/bin:$PATHexport FABRIC_CFG_PATH=$&#123;PWD&#125;/configconfigtxgen --help 核心企业GylCoreOrg1MSP,Admin： 12345export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;GylCoreOrg1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/users/Admin@core.supply.com/mspexport CORE_PEER_ADDRESS=localhost:8051 一级供应商GylFOrg1MSP,Admin： 12345export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;GylFOrg1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/users/Admin@f1.supply.com/mspexport CORE_PEER_ADDRESS=localhost:8053 二级供应商1GylSOrg1MSP,Admin： 12345export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;GylSOrg1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/users/Admin@s1.supply.com/mspexport CORE_PEER_ADDRESS=localhost:8055 二级供应商2GylSOrg2MSP,Admin： 12345export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;GylSOrg2MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/users/Admin@s2.supply.com/mspexport CORE_PEER_ADDRESS=localhost:8151","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"项目实践-供应链金融","slug":"区块链/Hyperledger-Fabric/项目实践-供应链金融","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5-%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"peer","slug":"peer","permalink":"https://guozhe001.github.io/tags/peer/"},{"name":"供应链金融","slug":"供应链金融","permalink":"https://guozhe001.github.io/tags/%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D/"}]},{"title":"开发智能合约","slug":"blockchain/fabric/通过供应链金融练习Fabric/开发智能合约","date":"2024-11-22T06:32:06.496Z","updated":"2024-11-22T06:32:06.496Z","comments":true,"path":"2024/11/22/blockchain/fabric/通过供应链金融练习Fabric/开发智能合约/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E9%80%9A%E8%BF%87%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D%E7%BB%83%E4%B9%A0Fabric/%E5%BC%80%E5%8F%91%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/","excerpt":"","text":"开发智能合约 本次的智能合约从fabric-samples的asset-transfer-basic/chaincode-go拷贝然后进行了修改。 智能合约代码smartcontract.go如下：本文档更新不及时，可到源码地址查看。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181package chaincodeimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;time&quot; &quot;github.com/golang/protobuf/ptypes&quot; &quot;github.com/hyperledger/fabric-contract-api-go/contractapi&quot;)// SmartContract provides functions for managing an Assettype SmartContract struct &#123; contractapi.Contract&#125;// Asset describes basic details of what makes up a simple assettype Asset struct &#123; ID string `json:&quot;ID&quot;` Issuer string `json:&quot;issuer&quot;` Owner string `json:&quot;owner&quot;` Amount int64 `json:&quot;amount&quot;` CreateDate time.Time `json:&quot;createDate&quot;` EndDate time.Time `json:&quot;endDate&quot;` ContractHash string `json:&quot;contractHash&quot;` InvoiceHash string `json:&quot;invoiceHash&quot;`&#125;// IssueVoucher 发行凭证func (s *SmartContract) IssueVoucher(ctx contractapi.TransactionContextInterface, assetID string, amount int64, owner string, contractHash string, invoiceHash string) error &#123; // 创建资产 return s.CreateAssetAndSave(ctx, assetID, amount, &quot;核心企业&quot;, owner, contractHash, invoiceHash)&#125;// CreateAssetAndSave 创建资产并保存func (s *SmartContract) CreateAssetAndSave(ctx contractapi.TransactionContextInterface, id string, amount int64, issuerName string, owner string, contractHash string, invoiceHash string) error &#123; asset, err := s.createAsset(ctx, id, amount, issuerName, owner, contractHash, invoiceHash) if err != nil &#123; return err &#125; return s.PutState(ctx, asset)&#125;// createAsset issues a new asset to the world state with given details.func (s *SmartContract) createAsset(ctx contractapi.TransactionContextInterface, id string, amount int64, issuerName string, owner string, contractHash string, invoiceHash string) (*Asset, error) &#123; exists, err := s.AssetExists(ctx, id) if err != nil &#123; return nil, err &#125; if exists &#123; return nil, fmt.Errorf(&quot;the asset %s already exists&quot;, id) &#125; now, err := getNow(ctx) if err != nil &#123; return nil, err &#125; asset := Asset&#123;ID: id, Issuer: issuerName, Amount: amount, Owner: owner, CreateDate: now, EndDate: now.AddDate(0, 6, 0), ContractHash: contractHash, InvoiceHash: invoiceHash&#125; return &amp;asset, nil&#125;// 获取当前时间func getNow(ctx contractapi.TransactionContextInterface) (time.Time, error) &#123; now, err := ctx.GetStub().GetTxTimestamp() if err != nil &#123; return time.Now(), err &#125; return ptypes.Timestamp(now)&#125;// ReadAsset returns the asset stored in the world state with given id.func (s *SmartContract) ReadAsset(ctx contractapi.TransactionContextInterface, id string) (*Asset, error) &#123; assetJSON, err := ctx.GetStub().GetState(id) if err != nil &#123; return nil, fmt.Errorf(&quot;failed to read from world state: %v&quot;, err) &#125; if assetJSON == nil &#123; return nil, fmt.Errorf(&quot;the asset %s does not exist&quot;, id) &#125; var asset Asset err = json.Unmarshal(assetJSON, &amp;asset) if err != nil &#123; return nil, err &#125; return &amp;asset, nil&#125;// AssetExists returns true when asset with given ID exists in world statefunc (s *SmartContract) AssetExists(ctx contractapi.TransactionContextInterface, id string) (bool, error) &#123; assetJSON, err := ctx.GetStub().GetState(id) if err != nil &#123; return false, fmt.Errorf(&quot;failed to read from world state: %v&quot;, err) &#125; return assetJSON != nil, nil&#125;// TransferAssetByID 根据资产ID转账func (s *SmartContract) TransferAssetByID(ctx contractapi.TransactionContextInterface, id string, newID string, newOwner string, amount int64, contractHash string, invoiceHash string) error &#123; asset, err := s.ReadAsset(ctx, id) if err != nil &#123; return err &#125; return s.TransferAsset(ctx, asset, newID, newOwner, amount, contractHash, invoiceHash)&#125;// TransferAsset updates the owner field of asset with given id in world state.func (s *SmartContract) TransferAsset(ctx contractapi.TransactionContextInterface, asset *Asset, newID string, newOwner string, amount int64, contractHash string, invoiceHash string) error &#123; // 如果金额刚好等于凭证资产的金额，直接更新凭证资产的拥有者 if asset.Amount == amount &#123; asset.Owner = newOwner return s.PutState(ctx, asset) &#125; else if asset.Amount &gt; amount &#123; // 如果凭证资产的金额大于转账的金额，则创建一个新的资产 if newID == &quot;&quot; &#123; return fmt.Errorf(&quot;转账金额小于资产的金额时，newID必须不能为空&quot;) &#125; // 创建新的资产并保存 err := s.CreateAssetAndSave(ctx, newID, amount, asset.Issuer, newOwner, contractHash, invoiceHash) if err != nil &#123; return err &#125; // 更新旧资产的金额 asset.Amount = asset.Amount - amount return s.PutState(ctx, asset) &#125; else if asset.Amount &lt; amount &#123; // 如果资产的额度小于要转账的金额，则直接报错 return fmt.Errorf(&quot;转账金额=%d,不能超过资产的金额=%d&quot;, amount, asset.Amount) &#125; return nil&#125;// PutState 更新资产func (s *SmartContract) PutState(ctx contractapi.TransactionContextInterface, asset *Asset) error &#123; assetJSON, err := json.Marshal(asset) if err != nil &#123; return err &#125; return ctx.GetStub().PutState(asset.ID, assetJSON)&#125;// DelState 删除资产func (s *SmartContract) DelState(ctx contractapi.TransactionContextInterface, assetID string) error &#123; exists, err := s.AssetExists(ctx, assetID) if err != nil &#123; return nil &#125; if !exists &#123; return fmt.Errorf(&quot;assetID=%s的资产不存在&quot;, assetID) &#125; return ctx.GetStub().DelState(assetID)&#125;// GetAllAssets returns all assets found in world statefunc (s *SmartContract) GetAllAssets(ctx contractapi.TransactionContextInterface) ([]*Asset, error) &#123; // range query with empty string for startKey and endKey does an // open-ended query of all assets in the chaincode namespace. resultsIterator, err := ctx.GetStub().GetStateByRange(&quot;&quot;, &quot;&quot;) if err != nil &#123; return nil, err &#125; defer resultsIterator.Close() var assets []*Asset for resultsIterator.HasNext() &#123; queryResponse, err := resultsIterator.Next() if err != nil &#123; return nil, err &#125; var asset Asset err = json.Unmarshal(queryResponse.Value, &amp;asset) if err != nil &#123; return nil, err &#125; assets = append(assets, &amp;asset) &#125; return assets, nil&#125;","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"项目实践-供应链金融","slug":"区块链/Hyperledger-Fabric/项目实践-供应链金融","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5-%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"供应链金融","slug":"供应链金融","permalink":"https://guozhe001.github.io/tags/%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D/"}]},{"title":"创建channel","slug":"blockchain/fabric/通过供应链金融练习Fabric/创建channel","date":"2024-11-22T06:32:06.496Z","updated":"2024-11-22T06:32:06.496Z","comments":true,"path":"2024/11/22/blockchain/fabric/通过供应链金融练习Fabric/创建channel/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E9%80%9A%E8%BF%87%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D%E7%BB%83%E4%B9%A0Fabric/%E5%88%9B%E5%BB%BAchannel/","excerpt":"","text":"2. 创建Channel 参考：创建一个新的channel 创建通道： 运行下面的程序来为coreandfirstchannel通道创建一个“创建通道的交易” 1configtxgen -profile CoreAndFirstChannel -outputCreateChannelTx ./channel-artifacts/coreandfirstchannel.tx -channelID coreandfirstchannel 执行结果如下： 12342020-12-24 14:29:40.728 CST [common.tools.configtxgen] main -&gt; INFO 001 Loading configuration2020-12-24 14:29:40.739 CST [common.tools.configtxgen.localconfig] Load -&gt; INFO 002 Loaded configuration: /Users/apple/code/open-source/blockchain/hyperledger/supply-finance/configtx/configtx.yaml2020-12-24 14:29:40.739 CST [common.tools.configtxgen] doOutputChannelCreateTx -&gt; INFO 003 Generating new channel configtx2020-12-24 14:29:40.750 CST [common.tools.configtxgen] doOutputChannelCreateTx -&gt; INFO 004 Writing new channel tx 设置环境变量，以核心企业(core.supply.com)管理员身份操作peerCLI;然后使用下面的命令把交易发给order服务创建通道： 1peer channel create -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com -c coreandfirstchannel -f ./channel-artifacts/coreandfirstchannel.tx --outputBlock ./channel-artifacts/coreandfirstchannel.block --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 正确执行之后的日志： 1234567891011122020-12-24 15:59:28.470 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-12-24 15:59:28.490 CST [cli.common] readBlock -&gt; INFO 002 Expect block, but got status: &amp;&#123;NOT_FOUND&#125;2020-12-24 15:59:28.497 CST [channelCmd] InitCmdFactory -&gt; INFO 003 Endorser and orderer connections initialized2020-12-24 15:59:28.701 CST [cli.common] readBlock -&gt; INFO 004 Expect block, but got status: &amp;&#123;SERVICE_UNAVAILABLE&#125;2020-12-24 15:59:28.708 CST [channelCmd] InitCmdFactory -&gt; INFO 005 Endorser and orderer connections initialized2020-12-24 15:59:28.917 CST [cli.common] readBlock -&gt; INFO 006 Expect block, but got status: &amp;&#123;SERVICE_UNAVAILABLE&#125;2020-12-24 15:59:28.924 CST [channelCmd] InitCmdFactory -&gt; INFO 007 Endorser and orderer connections initialized2020-12-24 15:59:29.134 CST [cli.common] readBlock -&gt; INFO 008 Expect block, but got status: &amp;&#123;SERVICE_UNAVAILABLE&#125;2020-12-24 15:59:29.141 CST [channelCmd] InitCmdFactory -&gt; INFO 009 Endorser and orderer connections initialized2020-12-24 15:59:29.349 CST [cli.common] readBlock -&gt; INFO 00a Expect block, but got status: &amp;&#123;SERVICE_UNAVAILABLE&#125;2020-12-24 15:59:29.357 CST [channelCmd] InitCmdFactory -&gt; INFO 00b Endorser and orderer connections initialized2020-12-24 15:59:29.566 CST [cli.common] readBlock -&gt; INFO 00c Received block: 0 报错信息记录： 12345(base) apple@WHOAMIdeMacBook-Pro:~/code/open-source/blockchain/hyperledger/supply-finance$ peer channel create -o localhost:8051 --ordererTLSHostnameOverride orderer.supply.com -c coreandfirstchannel -f ./channel-artifacts/coreandfirstchannel.tx --outputBlock ./channel-artifacts/coreandfirstchannel.block --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem2020-12-24 15:56:56.602 CST [comm.tls] ClientHandshake -&gt; ERRO 001 Client TLS handshake failed after 5.225381ms with error: x509: certificate is valid for peer0.core.supply.com, peer0, not orderer.supply.com remoteaddress=[::1]:80512020-12-24 15:56:57.611 CST [comm.tls] ClientHandshake -&gt; ERRO 002 Client TLS handshake failed after 3.907471ms with error: x509: certificate is valid for peer0.core.supply.com, peer0, not orderer.supply.com remoteaddress=[::1]:80512020-12-24 15:56:59.315 CST [comm.tls] ClientHandshake -&gt; ERRO 003 Client TLS handshake failed after 4.52302ms with error: x509: certificate is valid for peer0.core.supply.com, peer0, not orderer.supply.com remoteaddress=[::1]:8051Error: failed to create deliver client for orderer: orderer client failed to connect to localhost:8051: failed to create new connection: context deadline exceeded 错误原因：peer channel create -o localhost:8051 命令-o应该传入order服务的地址和端口。 把核心企业和一级供应商的peer加入通道 核心企业的peer加入通道 使用下面的命令将核心企业的peer加入通道（确认已经设置了核心企业的环境变量）： 1peer channel join -b ./channel-artifacts/coreandfirstchannel.block 成功信息如下： 122020-12-24 16:46:40.206 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-12-24 16:46:40.235 CST [channelCmd] executeJoin -&gt; INFO 002 Successfully submitted proposal to join channel 报错信息记录: 12345(base) apple@WHOAMIdeMacBook-Pro:~/code/open-source/blockchain/hyperledger/supply-finance$ peer channel join -b ./channel-artifacts/coreandfirstchannel.block2020-12-24 16:18:23.258 CST [comm.tls] ClientHandshake -&gt; ERRO 001 Client TLS handshake failed after 2.895228ms with error: x509: certificate is valid for peer0.core.supply.com, peer0, not localhost remoteaddress=[::1]:80512020-12-24 16:18:24.266 CST [comm.tls] ClientHandshake -&gt; ERRO 002 Client TLS handshake failed after 4.537447ms with error: x509: certificate is valid for peer0.core.supply.com, peer0, not localhost remoteaddress=[::1]:80512020-12-24 16:18:25.659 CST [comm.tls] ClientHandshake -&gt; ERRO 003 Client TLS handshake failed after 4.16728ms with error: x509: certificate is valid for peer0.core.supply.com, peer0, not localhost remoteaddress=[::1]:8051Error: error getting endorser client for channel: endorser client failed to connect to localhost:8051: failed to create new connection: context deadline exceeded **错误原因：**未知。 **解决方式：**把Profiles里面的Organizations信息统一修改，与环境变量保持一致 123456Organizations: - *GylCoreOrg1MSP - *GylFOrg1MSP - *GylSOrg1MSP - *GylSOrg2MSP 然后把上面步骤中生成的加密材料信息、区块信息都删除，容器和volume全部删除；重新执行一遍。 通过获取通道信息确认加入成功 获取通道信息 1peer channel getinfo -c coreandfirstchannel 可以看到如下信息： 122020-12-24 16:53:01.633 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initializedBlockchain info: &#123;&quot;height&quot;:1,&quot;currentBlockHash&quot;:&quot;kXOOwW8prt0XPvgEGMDrzdt1nNH8T7qlObL9eT8FZ7c=&quot;&#125; 一级供应商加入通道 设置环境变量，然后拉取通道的创世纪区块(因为是测试本次忽略)： 1peer channel fetch 0 ./channel-artifacts/coreandfirstchannel.block -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com -c coreandfirstchannel --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 加入通道： 1peer channel join -b ./channel-artifacts/coreandfirstchannel.block 成功信息如下： 122020-12-24 17:06:30.499 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-12-24 17:06:30.527 CST [channelCmd] executeJoin -&gt; INFO 002 Successfully submitted proposal to join channel 报错信息如下： 12(base) apple@WHOAMIdeMacBook-Pro:~/code/open-source/blockchain/hyperledger/supply-finance$ peer channel join -b ./channel-artifacts/coreandfirstchannel.block2020-12-24 17:01:05.904 CST [main] InitCmd -&gt; ERRO 001 Cannot run peer because cannot init crypto, specified path &quot;/Users/apple/code/open-source/blockchain/hyperledger/supply-finance/organizations/peerOrganizations/f1.supply.com/users/Admin@f1.supply.com/msp/organizations/peerOrganizations/f1.supply.com/users/Admin@f1.supply.com/msp&quot; does not exist or cannot be accessed: stat /Users/apple/code/open-source/blockchain/hyperledger/supply-finance/organizations/peerOrganizations/f1.supply.com/users/Admin@f1.supply.com/msp/organizations/peerOrganizations/f1.supply.com/users/Admin@f1.supply.com/msp: no such file or directory **错误原因：**因为在设置环境变量时不是在supply-finance目录下设置的，所以设置的环境变量有问题，重新设置一下。 设置锚节点 为GylFOrg1MSP设置锚节点 因为上面已经设置了一级供应商（GylFOrg1MSP）的环境变量，所以先设置GylFOrg1MSP的锚节点： 拉取最新的channel配置区块 1peer channel fetch config channel-artifacts/coreandfirstchannel_config_block.pb -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com -c coreandfirstchannel --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 成功信息如下： 12342020-12-24 17:56:48.435 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-12-24 17:56:48.439 CST [cli.common] readBlock -&gt; INFO 002 Received block: 02020-12-24 17:56:48.439 CST [channelCmd] fetch -&gt; INFO 003 Retrieving last config block: 02020-12-24 17:56:48.442 CST [cli.common] readBlock -&gt; INFO 004 Received block: 0 修改通道配置区块 切换到channel-artifacts然后把区块内容转换成json格式： 12345cd channel-artifactsconfigtxlator proto_decode --input coreandfirstchannel_config_block.pb --type common.Block --output coreandfirstchannel_config_block.jsonjq .data.data[0].payload.data.config coreandfirstchannel_config_block.json &gt; coreandfirstchannel_config.json# copy一份cp coreandfirstchannel_config.json coreandfirstchannel_config_copy.json 使用jq 工具来添加GylFOrg1MSP组织的锚节点到通道配置。 1jq &#x27;.channel_group.groups.Application.groups.GylFOrg1MSP.values += &#123;&quot;AnchorPeers&quot;:&#123;&quot;mod_policy&quot;: &quot;Admins&quot;,&quot;value&quot;:&#123;&quot;anchor_peers&quot;: [&#123;&quot;host&quot;: &quot;peer0.f1.supply.com&quot;,&quot;port&quot;: 8053&#125;]&#125;,&quot;version&quot;: &quot;0&quot;&#125;&#125;&#x27; coreandfirstchannel_config_copy.json &gt; modified_coreandfirstchannel_config.json 将原始的和修改后的通道配置都转换回protobuf格式，并计算它们之间的差异。 123configtxlator proto_encode --input coreandfirstchannel_config.json --type common.Config --output coreandfirstchannel_config.pbconfigtxlator proto_encode --input modified_coreandfirstchannel_config.json --type common.Config --output modified_coreandfirstchannel_config.pbconfigtxlator compute_update --channel_id coreandfirstchannel --original coreandfirstchannel_config.pb --updated modified_coreandfirstchannel_config.pb --output coreandfirstchannel_config_update.pb 把更新后的交易打包成一个更新通道配置的交易： 123configtxlator proto_decode --input coreandfirstchannel_config_update.pb --type common.ConfigUpdate --output coreandfirstchannel_config_update.jsonecho &#x27;&#123;&quot;payload&quot;:&#123;&quot;header&quot;:&#123;&quot;channel_header&quot;:&#123;&quot;channel_id&quot;:&quot;coreandfirstchannel&quot;, &quot;type&quot;:2&#125;&#125;,&quot;data&quot;:&#123;&quot;config_update&quot;:&#x27;$(cat coreandfirstchannel_config_update.json)&#x27;&#125;&#125;&#125;&#x27; | jq . &gt; coreandfirstchannel_config_update_in_envelope.jsonconfigtxlator proto_encode --input coreandfirstchannel_config_update_in_envelope.json --type common.Envelope --output coreandfirstchannel_config_update_in_envelope.pb 提交“更新通道配置的交易” 进到上一级目录cd ..，之后运行命令将交易提交给排序服务进行通道配置的更新： 12cd ..peer channel update -f channel-artifacts/coreandfirstchannel_config_update_in_envelope.pb -c coreandfirstchannel -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 执行成功的结果： 122020-12-24 18:13:59.246 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-12-24 18:13:59.265 CST [channelCmd] update -&gt; INFO 002 Successfully submitted channel update 错误信息记录： 122020-12-24 18:12:49.469 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initializedError: got unexpected status: BAD_REQUEST -- error applying config update to existing channel &#x27;coreandfirstchannel&#x27;: error authorizing update: ConfigUpdate for channel &#x27;channel1&#x27; but envelope for channel &#x27;coreandfirstchannel&#x27; **错误原因：**在修改配置的时候指定channel名称错误，修正重新执行一遍。 验证，获取通道信息:peer channel getinfo -c coreandfirstchannel 123supply-finance$ peer channel getinfo -c coreandfirstchannel2020-12-24 18:19:31.275 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initializedBlockchain info: &#123;&quot;height&quot;:2,&quot;currentBlockHash&quot;:&quot;h5CY6RfVNNg8kYWPZ+tZqdMIrGoXeoDSQFd0YfiBhRk=&quot;,&quot;previousBlockHash&quot;:&quot;kXOOwW8prt0XPvgEGMDrzdt1nNH8T7qlObL9eT8FZ7c=&quot;&#125; 为核心企业GylCoreOrg1MSP设置锚节点 修改环境变量，然后拉取最新的channel配置区块 1peer channel fetch config channel-artifacts/coreandfirstchannel_config_block.pb -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com -c coreandfirstchannel --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 修改通道配置区块 切换到channel-artifacts然后把区块内容转换成json格式： 12345cd channel-artifactsconfigtxlator proto_decode --input coreandfirstchannel_config_block.pb --type common.Block --output coreandfirstchannel_config_block.jsonjq .data.data[0].payload.data.config coreandfirstchannel_config_block.json &gt; coreandfirstchannel_config.json# copy一份cp coreandfirstchannel_config.json coreandfirstchannel_config_copy.json 使用jq 工具来添加GylCoreOrg1MSP组织的锚节点到通道配置。 1jq &#x27;.channel_group.groups.Application.groups.GylCoreOrg1MSP.values += &#123;&quot;AnchorPeers&quot;:&#123;&quot;mod_policy&quot;: &quot;Admins&quot;,&quot;value&quot;:&#123;&quot;anchor_peers&quot;: [&#123;&quot;host&quot;: &quot;peer0.core.supply.com&quot;,&quot;port&quot;: 8051&#125;]&#125;,&quot;version&quot;: &quot;0&quot;&#125;&#125;&#x27; coreandfirstchannel_config_copy.json &gt; modified_coreandfirstchannel_config.json 将原始的和修改后的通道配置都转换回protobuf格式，并计算它们之间的差异。 123configtxlator proto_encode --input coreandfirstchannel_config.json --type common.Config --output coreandfirstchannel_config.pbconfigtxlator proto_encode --input modified_coreandfirstchannel_config.json --type common.Config --output modified_coreandfirstchannel_config.pbconfigtxlator compute_update --channel_id coreandfirstchannel --original coreandfirstchannel_config.pb --updated modified_coreandfirstchannel_config.pb --output coreandfirstchannel_config_update.pb 把更新后的交易打包成一个更新通道配置的交易： 123configtxlator proto_decode --input coreandfirstchannel_config_update.pb --type common.ConfigUpdate --output coreandfirstchannel_config_update.jsonecho &#x27;&#123;&quot;payload&quot;:&#123;&quot;header&quot;:&#123;&quot;channel_header&quot;:&#123;&quot;channel_id&quot;:&quot;coreandfirstchannel&quot;, &quot;type&quot;:2&#125;&#125;,&quot;data&quot;:&#123;&quot;config_update&quot;:&#x27;$(cat coreandfirstchannel_config_update.json)&#x27;&#125;&#125;&#125;&#x27; | jq . &gt; coreandfirstchannel_config_update_in_envelope.jsonconfigtxlator proto_encode --input coreandfirstchannel_config_update_in_envelope.json --type common.Envelope --output coreandfirstchannel_config_update_in_envelope.pb 提交“更新通道配置的交易” 进到上一级目录cd ..，之后运行命令将交易提交给排序服务进行通道配置的更新： 12cd ..peer channel update -f channel-artifacts/coreandfirstchannel_config_update_in_envelope.pb -c coreandfirstchannel -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 执行成功的结果： 122020-12-24 18:13:59.246 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-12-24 18:13:59.265 CST [channelCmd] update -&gt; INFO 002 Successfully submitted channel update 验证，获取通道信息 123$ peer channel getinfo -c coreandfirstchannel2020-12-24 18:24:51.015 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initializedBlockchain info: &#123;&quot;height&quot;:3,&quot;currentBlockHash&quot;:&quot;e52oT2HAiTxyeh4a30kTx32xLJAKIWa7rm6PVOn8eoA=&quot;,&quot;previousBlockHash&quot;:&quot;h5CY6RfVNNg8kYWPZ+tZqdMIrGoXeoDSQFd0YfiBhRk=&quot;&#125; 部署测试chaincode来确认 打包 1peer lifecycle chaincode package basic.tar.gz --path /Users/apple/code/open-source/blockchain/hyperledger/fabric-samples/asset-transfer-basic/chaincode-go/ --lang golang --label basic_1.0 运行完上面的命令，查看当前目录会发现多了basic.tar.gz包，说明打包成功。 安装链码包 一级供应商和核心企业都要安装： 核心企业： 1peer lifecycle chaincode install basic.tar.gz --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt 一级供应商： 1peer lifecycle chaincode install basic.tar.gz --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt 安装成功输出结果如下： 122020-12-24 18:51:45.793 CST [cli.lifecycle.chaincode] submitInstallProposal -&gt; INFO 001 Installed remotely: response:&lt;status:200 payload:&quot;\\nJbasic_1.0:4ec191e793b27e953ff2ede5a8bcc63152cecb1e4c3f301a26e22692c61967ad\\022\\tbasic_1.0&quot; &gt;2020-12-24 18:51:45.793 CST [cli.lifecycle.chaincode] submitInstallProposal -&gt; INFO 002 Chaincode code package identifier: basic_1.0:4ec191e793b27e953ff2ede5a8bcc63152cecb1e4c3f301a26e22692c61967ad 批准链码定义 查看已经安装的chaincode 1peer lifecycle chaincode queryinstalled 成功结果如下： 12Installed chaincodes on peer:Package ID: basic_1.0:4ec191e793b27e953ff2ede5a8bcc63152cecb1e4c3f301a26e22692c61967ad, Label: basic_1.0 将链码的信息保存为一个变量 1export CC_PACKAGE_ID=basic_1.0:4ec191e793b27e953ff2ede5a8bcc63152cecb1e4c3f301a26e22692c61967ad 批准链码定义 核心企业和一级供应商都需要执行此命令： 1peer lifecycle chaincode approveformyorg -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID coreandfirstchannel --name basic --version 1.0 --package-id $CC_PACKAGE_ID --sequence 1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 成功结果如下： 12020-12-24 19:02:47.351 CST [chaincodeCmd] ClientWait -&gt; INFO 001 txid [d7e2224f63a1516ffeeed26ec5c8f69872141f5864b3602a1409679472692840] committed with status (VALID) at localhost:8051 将链码定义提交到通道 检查channel上的成员是否已经批准了链码定义： 1peer lifecycle chaincode checkcommitreadiness --channelID coreandfirstchannel --name basic --version 1.0 --sequence 1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --output json 成功结果如下： 123456&#123; &quot;approvals&quot;: &#123; &quot;GylCoreOrg1MSP&quot;: true, &quot;GylFOrg1MSP&quot;: true &#125;&#125; 在两个组织都批准之后，执行下面的命令将链码定义提交到通道： 1peer lifecycle chaincode commit -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID coreandfirstchannel --name basic --version 1.0 --sequence 1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt 成功结果如下： 122020-12-24 19:10:18.071 CST [chaincodeCmd] ClientWait -&gt; INFO 001 txid [5b363e2e419dbb1307726fe44428e23ae1b0e5feaf86cb577383b6e8a68464d6] committed with status (VALID) at localhost:80532020-12-24 19:10:18.094 CST [chaincodeCmd] ClientWait -&gt; INFO 002 txid [5b363e2e419dbb1307726fe44428e23ae1b0e5feaf86cb577383b6e8a68464d6] committed with status (VALID) at localhost:8051 使用 peer lifecycle chaincode querycommitted 命令来确认链码定义已经提交到通道。 1peer lifecycle chaincode querycommitted --channelID coreandfirstchannel --name basic --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 成功结果如下： 12Committed chaincode definition for chaincode &#x27;basic&#x27; on channel &#x27;coreandfirstchannel&#x27;:Version: 1.0, Sequence: 1, Endorsement Plugin: escc, Validation Plugin: vscc, Approvals: [GylCoreOrg1MSP: true, GylFOrg1MSP: true] 调用链码 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C coreandfirstchannel -n basic --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;InitLedger&quot;,&quot;Args&quot;:[]&#125;&#x27; 成功信息： 12020-12-25 17:26:22.583 CST [chaincodeCmd] chaincodeInvokeOrQuery -&gt; INFO 001 Chaincode invoke successful. result: status:200 查询调用后的结果 1peer chaincode query -C coreandfirstchannel -n basic -c &#x27;&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;&#x27; 成功结果如下,说明channel部署成功： 1[&#123;&quot;ID&quot;:&quot;asset1&quot;,&quot;color&quot;:&quot;blue&quot;,&quot;size&quot;:5,&quot;owner&quot;:&quot;Tomoko&quot;,&quot;appraisedValue&quot;:300&#125;,&#123;&quot;ID&quot;:&quot;asset2&quot;,&quot;color&quot;:&quot;red&quot;,&quot;size&quot;:5,&quot;owner&quot;:&quot;Brad&quot;,&quot;appraisedValue&quot;:400&#125;,&#123;&quot;ID&quot;:&quot;asset3&quot;,&quot;color&quot;:&quot;green&quot;,&quot;size&quot;:10,&quot;owner&quot;:&quot;Jin Soo&quot;,&quot;appraisedValue&quot;:500&#125;,&#123;&quot;ID&quot;:&quot;asset4&quot;,&quot;color&quot;:&quot;yellow&quot;,&quot;size&quot;:10,&quot;owner&quot;:&quot;Max&quot;,&quot;appraisedValue&quot;:600&#125;,&#123;&quot;ID&quot;:&quot;asset5&quot;,&quot;color&quot;:&quot;black&quot;,&quot;size&quot;:15,&quot;owner&quot;:&quot;Adriana&quot;,&quot;appraisedValue&quot;:700&#125;,&#123;&quot;ID&quot;:&quot;asset6&quot;,&quot;color&quot;:&quot;white&quot;,&quot;size&quot;:15,&quot;owner&quot;:&quot;Michel&quot;,&quot;appraisedValue&quot;:800&#125;] 错误信息如下： 1Error: endorsement failure during invoke. response: status:500 message:&quot;error in simulation: failed to execute transaction 207cf99d289ffe9deca6a320aba59cc155fae02d19d51c9cfebc9943ffc7794d: could not launch chaincode basic_1.0:4ec191e793b27e953ff2ede5a8bcc63152cecb1e4c3f301a26e22692c61967ad: error starting container: error starting container: API error (404): network _test not found&quot; **错误原因：**因为chaincode的容器没有启动成功,直接指定容器启动报错如下： 123/supply-finance$ docker start bc47970e58a5Error response from daemon: network _test not foundError: failed to start containers: bc47970e58a5 问题解决： 因为在docker-compose.yml文件中配置了下面的环境变量，在启动chaincode容器时会链接到这个网络。 之前的配置是： 1- CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=$&#123;COMPOSE_PROJECT_NAME&#125;_test 修改后重新启动，问题解决。 1- CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE&#x3D;docker_test 为什么修改成docker_test呢，可以查看使用docker-compose命令启动容器时的日志： 1Creating network &quot;docker_test&quot; with the default driver 核心企业、一级和二级供应商加入同一个channel 创建通道： 运行下面的程序来为alljoinchannel通道创建一个“创建通道的交易” 123configtxgen -profile AllPlayChannel -outputCreateChannelTx ./channel-artifacts/alljoinchannel.tx -channelID alljoinchannel# 使用下面的命令把交易发给order服务创建通道：peer channel create -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com -c alljoinchannel -f ./channel-artifacts/alljoinchannel.tx --outputBlock ./channel-artifacts/alljoinchannel.block --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 加入通道 使用下面的命令将peer加入通道,所有节点都需要执行： 123peer channel join -b ./channel-artifacts/alljoinchannel.block# 通过获取通道信息确认加入成功peer channel getinfo -c alljoinchannel 为各个组织设置锚节点 GylCoreOrg1MSP 12345678peer channel fetch config channel-artifacts/alljoinchannel_config_block.pb -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com -c alljoinchannel --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem# 切换到`channel-artifacts`然后把区块内容转换成json格式：cd channel-artifactsconfigtxlator proto_decode --input alljoinchannel_config_block.pb --type common.Block --output alljoinchannel_config_block.jsonjq .data.data[0].payload.data.config alljoinchannel_config_block.json &gt; alljoinchannel_config.jsoncp alljoinchannel_config.json alljoinchannel_config_copy.json# 使用`jq`工具添加各个组织的锚节点配置jq &#x27;.channel_group.groups.Application.groups.GylCoreOrg1MSP.values += &#123;&quot;AnchorPeers&quot;:&#123;&quot;mod_policy&quot;: &quot;Admins&quot;,&quot;value&quot;:&#123;&quot;anchor_peers&quot;: [&#123;&quot;host&quot;: &quot;peer0.core.supply.com&quot;,&quot;port&quot;: 8051&#125;]&#125;,&quot;version&quot;: &quot;0&quot;&#125;&#125;&#x27; alljoinchannel_config_copy.json &gt; modified_alljoinchannel_config.json 12345678# 将原始的和修改后的通道配置都转换回protobuf格式，并计算它们之间的差异。configtxlator proto_encode --input alljoinchannel_config.json --type common.Config --output alljoinchannel_config.pbconfigtxlator proto_encode --input modified_alljoinchannel_config.json --type common.Config --output modified_alljoinchannel_config.pbconfigtxlator compute_update --channel_id alljoinchannel --original alljoinchannel_config.pb --updated modified_alljoinchannel_config.pb --output alljoinchannel_config_update.pb# 把更新后的交易打包成一个更新通道配置的交易：configtxlator proto_decode --input alljoinchannel_config_update.pb --type common.ConfigUpdate --output alljoinchannel_config_update.jsonecho &#x27;&#123;&quot;payload&quot;:&#123;&quot;header&quot;:&#123;&quot;channel_header&quot;:&#123;&quot;channel_id&quot;:&quot;alljoinchannel&quot;, &quot;type&quot;:2&#125;&#125;,&quot;data&quot;:&#123;&quot;config_update&quot;:&#x27;$(cat alljoinchannel_config_update.json)&#x27;&#125;&#125;&#125;&#x27; | jq . &gt; alljoinchannel_config_update_in_envelope.jsonconfigtxlator proto_encode --input alljoinchannel_config_update_in_envelope.json --type common.Envelope --output alljoinchannel_config_update_in_envelope.pb 12345# 进到上一级目录`cd ..`，之后运行命令将交易提交给排序服务进行通道配置的更新：cd ..peer channel update -f channel-artifacts/alljoinchannel_config_update_in_envelope.pb -c alljoinchannel -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem# 验证，获取通道信息:peer channel getinfo -c alljoinchannel GylFOrg1MSP 12345678peer channel fetch config channel-artifacts/alljoinchannel_config_block.pb -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com -c alljoinchannel --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem# 切换到`channel-artifacts`然后把区块内容转换成json格式：cd channel-artifactsconfigtxlator proto_decode --input alljoinchannel_config_block.pb --type common.Block --output alljoinchannel_config_block.jsonjq .data.data[0].payload.data.config alljoinchannel_config_block.json &gt; alljoinchannel_config.jsoncp alljoinchannel_config.json alljoinchannel_config_copy.json# 使用`jq`工具添加各个组织的锚节点配置jq &#x27;.channel_group.groups.Application.groups.GylFOrg1MSP.values += &#123;&quot;AnchorPeers&quot;:&#123;&quot;mod_policy&quot;: &quot;Admins&quot;,&quot;value&quot;:&#123;&quot;anchor_peers&quot;: [&#123;&quot;host&quot;: &quot;peer0.f1.supply.com&quot;,&quot;port&quot;: 8053&#125;]&#125;,&quot;version&quot;: &quot;0&quot;&#125;&#125;&#x27; alljoinchannel_config_copy.json &gt; modified_alljoinchannel_config.json 12345678# 将原始的和修改后的通道配置都转换回protobuf格式，并计算它们之间的差异。configtxlator proto_encode --input alljoinchannel_config.json --type common.Config --output alljoinchannel_config.pbconfigtxlator proto_encode --input modified_alljoinchannel_config.json --type common.Config --output modified_alljoinchannel_config.pbconfigtxlator compute_update --channel_id alljoinchannel --original alljoinchannel_config.pb --updated modified_alljoinchannel_config.pb --output alljoinchannel_config_update.pb# 把更新后的交易打包成一个更新通道配置的交易：configtxlator proto_decode --input alljoinchannel_config_update.pb --type common.ConfigUpdate --output alljoinchannel_config_update.jsonecho &#x27;&#123;&quot;payload&quot;:&#123;&quot;header&quot;:&#123;&quot;channel_header&quot;:&#123;&quot;channel_id&quot;:&quot;alljoinchannel&quot;, &quot;type&quot;:2&#125;&#125;,&quot;data&quot;:&#123;&quot;config_update&quot;:&#x27;$(cat alljoinchannel_config_update.json)&#x27;&#125;&#125;&#125;&#x27; | jq . &gt; alljoinchannel_config_update_in_envelope.jsonconfigtxlator proto_encode --input alljoinchannel_config_update_in_envelope.json --type common.Envelope --output alljoinchannel_config_update_in_envelope.pb 12345# 进到上一级目录`cd ..`，之后运行命令将交易提交给排序服务进行通道配置的更新：cd ..peer channel update -f channel-artifacts/alljoinchannel_config_update_in_envelope.pb -c alljoinchannel -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem# 验证，获取通道信息:peer channel getinfo -c alljoinchannel GylSOrg1MSP 12345678peer channel fetch config channel-artifacts/alljoinchannel_config_block.pb -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com -c alljoinchannel --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem# 切换到`channel-artifacts`然后把区块内容转换成json格式：cd channel-artifactsconfigtxlator proto_decode --input alljoinchannel_config_block.pb --type common.Block --output alljoinchannel_config_block.jsonjq .data.data[0].payload.data.config alljoinchannel_config_block.json &gt; alljoinchannel_config.jsoncp alljoinchannel_config.json alljoinchannel_config_copy.json# 使用`jq`工具添加各个组织的锚节点配置jq &#x27;.channel_group.groups.Application.groups.GylSOrg1MSP.values += &#123;&quot;AnchorPeers&quot;:&#123;&quot;mod_policy&quot;: &quot;Admins&quot;,&quot;value&quot;:&#123;&quot;anchor_peers&quot;: [&#123;&quot;host&quot;: &quot;peer0.s1.supply.com&quot;,&quot;port&quot;: 8055&#125;]&#125;,&quot;version&quot;: &quot;0&quot;&#125;&#125;&#x27; alljoinchannel_config_copy.json &gt; modified_alljoinchannel_config.json 12345678# 将原始的和修改后的通道配置都转换回protobuf格式，并计算它们之间的差异。configtxlator proto_encode --input alljoinchannel_config.json --type common.Config --output alljoinchannel_config.pbconfigtxlator proto_encode --input modified_alljoinchannel_config.json --type common.Config --output modified_alljoinchannel_config.pbconfigtxlator compute_update --channel_id alljoinchannel --original alljoinchannel_config.pb --updated modified_alljoinchannel_config.pb --output alljoinchannel_config_update.pb# 把更新后的交易打包成一个更新通道配置的交易：configtxlator proto_decode --input alljoinchannel_config_update.pb --type common.ConfigUpdate --output alljoinchannel_config_update.jsonecho &#x27;&#123;&quot;payload&quot;:&#123;&quot;header&quot;:&#123;&quot;channel_header&quot;:&#123;&quot;channel_id&quot;:&quot;alljoinchannel&quot;, &quot;type&quot;:2&#125;&#125;,&quot;data&quot;:&#123;&quot;config_update&quot;:&#x27;$(cat alljoinchannel_config_update.json)&#x27;&#125;&#125;&#125;&#x27; | jq . &gt; alljoinchannel_config_update_in_envelope.jsonconfigtxlator proto_encode --input alljoinchannel_config_update_in_envelope.json --type common.Envelope --output alljoinchannel_config_update_in_envelope.pb 12345# 进到上一级目录`cd ..`，之后运行命令将交易提交给排序服务进行通道配置的更新：cd ..peer channel update -f channel-artifacts/alljoinchannel_config_update_in_envelope.pb -c alljoinchannel -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem# 验证，获取通道信息:peer channel getinfo -c alljoinchannel GylSOrg1MSP 12345678peer channel fetch config channel-artifacts/alljoinchannel_config_block.pb -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com -c alljoinchannel --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem# 切换到`channel-artifacts`然后把区块内容转换成json格式：cd channel-artifactsconfigtxlator proto_decode --input alljoinchannel_config_block.pb --type common.Block --output alljoinchannel_config_block.jsonjq .data.data[0].payload.data.config alljoinchannel_config_block.json &gt; alljoinchannel_config.jsoncp alljoinchannel_config.json alljoinchannel_config_copy.json# 使用`jq`工具添加各个组织的锚节点配置jq &#x27;.channel_group.groups.Application.groups.GylSOrg2MSP.values += &#123;&quot;AnchorPeers&quot;:&#123;&quot;mod_policy&quot;: &quot;Admins&quot;,&quot;value&quot;:&#123;&quot;anchor_peers&quot;: [&#123;&quot;host&quot;: &quot;peer0.s2.supply.com&quot;,&quot;port&quot;: 8151&#125;]&#125;,&quot;version&quot;: &quot;0&quot;&#125;&#125;&#x27; alljoinchannel_config_copy.json &gt; modified_alljoinchannel_config.json 12345678# 将原始的和修改后的通道配置都转换回protobuf格式，并计算它们之间的差异。configtxlator proto_encode --input alljoinchannel_config.json --type common.Config --output alljoinchannel_config.pbconfigtxlator proto_encode --input modified_alljoinchannel_config.json --type common.Config --output modified_alljoinchannel_config.pbconfigtxlator compute_update --channel_id alljoinchannel --original alljoinchannel_config.pb --updated modified_alljoinchannel_config.pb --output alljoinchannel_config_update.pb# 把更新后的交易打包成一个更新通道配置的交易：configtxlator proto_decode --input alljoinchannel_config_update.pb --type common.ConfigUpdate --output alljoinchannel_config_update.jsonecho &#x27;&#123;&quot;payload&quot;:&#123;&quot;header&quot;:&#123;&quot;channel_header&quot;:&#123;&quot;channel_id&quot;:&quot;alljoinchannel&quot;, &quot;type&quot;:2&#125;&#125;,&quot;data&quot;:&#123;&quot;config_update&quot;:&#x27;$(cat alljoinchannel_config_update.json)&#x27;&#125;&#125;&#125;&#x27; | jq . &gt; alljoinchannel_config_update_in_envelope.jsonconfigtxlator proto_encode --input alljoinchannel_config_update_in_envelope.json --type common.Envelope --output alljoinchannel_config_update_in_envelope.pb 12345# 进到上一级目录`cd ..`，之后运行命令将交易提交给排序服务进行通道配置的更新：cd ..peer channel update -f channel-artifacts/alljoinchannel_config_update_in_envelope.pb -c alljoinchannel -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem# 验证，获取通道信息:peer channel getinfo -c alljoinchannel","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"项目实践-供应链金融","slug":"区块链/Hyperledger-Fabric/项目实践-供应链金融","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5-%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"channel","slug":"channel","permalink":"https://guozhe001.github.io/tags/channel/"},{"name":"供应链金融","slug":"供应链金融","permalink":"https://guozhe001.github.io/tags/%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D/"}]},{"title":"隐秘交易.md","slug":"blockchain/fabric/通过供应链金融练习Fabric/隐秘交易","date":"2024-11-22T06:32:06.496Z","updated":"2024-11-22T06:32:06.496Z","comments":true,"path":"2024/11/22/blockchain/fabric/通过供应链金融练习Fabric/隐秘交易/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E9%80%9A%E8%BF%87%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D%E7%BB%83%E4%B9%A0Fabric/%E9%9A%90%E7%A7%98%E4%BA%A4%E6%98%93/","excerpt":"","text":"自己开发的智能合约在channel上的所有成员都可以看到，这不符合现实世界中的交易规则。理论上两个组织之间的交易是不允许别人看到的。所以这次我使用fabric-samples提供的asset-transfer-secured-agreement来作为我的供应链金融区块链项目的chaincode。 部署链码 打包 1peer lifecycle chaincode package secured_supply.5.tar.gz --path ./asset-transfer-secured-agreement/chaincode-go --lang golang --label secured_supply_15.0 安装链码包,每个peer都要安装： 1peer lifecycle chaincode install secured_supply.5.tar.gz 批准链码定义 查看已经安装的chaincode 1peer lifecycle chaincode queryinstalled 将链码的信息保存为一个变量，两个组织都需要定义此变量： 1export CC_PACKAGE_ID=secured_supply_22.0:e815ca2d270dea029bc6992952140b1288a440aba8c430853f72eee7d5de24a7 批准链码定义，每个peer都要执行此命令： 1peer lifecycle chaincode approveformyorg -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID alljoinchannel --name secured_supply --version 23.0 --package-id $CC_PACKAGE_ID --sequence 23 --signature-policy &quot;OR(&#x27;GylCoreOrg1MSP.member&#x27;,&#x27;GylFOrg1MSP.member&#x27;,&#x27;GylSOrg1MSP.member&#x27;,&#x27;GylSOrg2MSP.member&#x27;)&quot; --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 将链码定义提交到通道 检查channel上的成员是否已经批准了链码定义： 1peer lifecycle chaincode checkcommitreadiness --channelID alljoinchannel --name secured_supply --version 23.0 --sequence 23 --signature-policy &quot;OR(&#x27;GylCoreOrg1MSP.member&#x27;,&#x27;GylFOrg1MSP.member&#x27;,&#x27;GylSOrg1MSP.member&#x27;,&#x27;GylSOrg2MSP.member&#x27;)&quot; --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --output json 在所有组织都批准之后，执行下面的命令将链码定义提交到通道： 1peer lifecycle chaincode commit -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID alljoinchannel --name secured_supply --version 23.0 --sequence 23 --signature-policy &quot;OR(&#x27;GylCoreOrg1MSP.member&#x27;,&#x27;GylFOrg1MSP.member&#x27;,&#x27;GylSOrg1MSP.member&#x27;,&#x27;GylSOrg2MSP.member&#x27;)&quot; --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt 使用 peer lifecycle chaincode querycommitted 命令来确认链码定义已经提交到通道。 1peer lifecycle chaincode querycommitted --channelID alljoinchannel --name secured_supply --output json 调用链码 创建资产 资产的内容需要打个问号，因为这个资产在后面需要被交易，如果资产的内容不能够修改那么合同和发票的hash应该不在资产的详细信息里面，这里先放这里后面再改 发行者能否放在外面而不是资产里面？哪种方式比较好呢？ 在核心企业的节点创建一个资产如下： 1export ASSET_PROPERTIES=$(echo -n &quot;&#123;\\&quot;objectType\\&quot;:\\&quot;asset_properties\\&quot;,\\&quot;assetID\\&quot;:\\&quot;asset011\\&quot;,\\&quot;issuer\\&quot;:\\&quot;GylCoreOrg1MSP\\&quot;,\\&quot;amount\\&quot;:1000,\\&quot;createDate\\&quot;:\\&quot;2020-01-11T06:57:06.963617Z\\&quot;,\\&quot;endDate\\&quot;:\\&quot;2021-07-11T06:57:06.963617Z\\&quot;,\\&quot;salt\\&quot;:\\&quot;224cba6c547aecc76ab6acfac41d12dfd96e7165\\&quot;&#125;&quot; | base64 | tr -d \\\\n) 在核心企业的节点上调用chaincode，创建资产： 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;CreateAsset&quot;,&quot;Args&quot;:[&quot;asset011&quot;, &quot;A new asset for GylCoreOrg1MSP&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_properties\\&quot;:\\&quot;$ASSET_PROPERTIES\\&quot;&#125;&quot; 在私有数据集中查询刚才创建的资产： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetPrivateProperties&quot;,&quot;Args&quot;:[&quot;asset011&quot;]&#125;&#x27;|jq 成功结果： 123456789&#123; &quot;objectType&quot;: &quot;asset_properties&quot;, &quot;assetID&quot;: &quot;asset010&quot;, &quot;issuer&quot;: &quot;GylCoreOrg1MSP&quot;, &quot;amount&quot;: 1000, &quot;createDate&quot;: &quot;2020-01-11T06:57:06.963617Z&quot;, &quot;endDate&quot;: &quot;2021-07-11T06:57:06.963617Z&quot;, &quot;salt&quot;: &quot;224cba6c547aecc76ab6acfac41d12dfd96e7165&quot;&#125; 查询账本来查看公共记录，所有在channel上的成员都可以查询得到： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ReadAsset&quot;,&quot;Args&quot;:[&quot;asset010&quot;]&#125;&#x27; 返回结果，channel上的成员只能看到资产的部分信息，详细信息是无法看到的。： 12345678&#123; &quot;objectType&quot;: &quot;asset&quot;, &quot;assetID&quot;: &quot;asset010&quot;, &quot;ownerOrg&quot;: &quot;GylCoreOrg1MSP&quot;, &quot;publicDescription&quot;: &quot;A new asset for GylCoreOrg1MSP&quot;, &quot;status&quot;: &quot;enable&quot;, &quot;parentID&quot;: &quot;&quot;&#125; 资产拥有者更改资产的公共信息 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ChangePublicDescription&quot;,&quot;Args&quot;:[&quot;asset010&quot;,&quot;This asset is for sale&quot;]&#125;&#x27; 上面的方法，在核心企业的peer节点返回日志如下： 12021-01-07 16:07:43.589 CST [chaincodeCmd] chaincodeInvokeOrQuery -&gt; INFO 001 Chaincode invoke successful. result: status:200 其他的组织如果想要调用这个链码的方法更改信息，则会报错，因为属于核心企业的资产别人不可以更改： 1Error: endorsement failure during invoke. response: status:500 message:&quot;a client from GylFOrg1MSP cannot update the description of a asset owned by GylCoreOrg1MSP&quot; 资产交易 允许出售资产 现在核心企业要与一级供应商交易核心企业的资产。首先核心企业与一级供应商要在链下对价格达成共识，并且核心企业要把资产的详情也通过链下的通道发送给一级供应商。之后买卖双方就可以对价格达成共识了。 核心企业将资产的价格设置为1000： 下面的trade_id是合同的hash值 12export ASSET_PRICE=$(echo -n &quot;&#123;\\&quot;asset_id\\&quot;:\\&quot;asset007\\&quot;,\\&quot;trade_id\\&quot;:\\&quot;93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14\\&quot;,\\&quot;price\\&quot;:1000&#125;&quot; | base64)peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;AgreeToSell&quot;,&quot;Args&quot;:[&quot;asset007&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_price\\&quot;:\\&quot;$ASSET_PRICE\\&quot;&#125;&quot; 查询核心企业的私有数据集合来读取同意的销售价格： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetSalesPrice&quot;,&quot;Args&quot;:[&quot;asset007&quot;]&#125;&#x27; 一级供应商出价1000 在一级供应商出价之前，他需要先验证资产的信息是否正确。此链码中返回true即为正确。 12#export ASSET_PROPERTIES=$(echo -n &quot;&#123;\\&quot;object_type\\&quot;:\\&quot;asset_properties\\&quot;,\\&quot;asset_id\\&quot;:\\&quot;asset006\\&quot;,\\&quot;issuer\\&quot;:\\&quot;GylCoreOrg1MSP\\&quot;,\\&quot;amount\\&quot;:1000,\\&quot;createDate\\&quot;:\\&quot;2020-01-11T06:57:06.963617Z\\&quot;,\\&quot;endDate\\&quot;:\\&quot;2021-07-11T06:57:06.963617Z\\&quot;,\\&quot;salt\\&quot;:\\&quot;224cba6c547aecc76ab6acfac41d12dfd96e7165\\&quot;&#125;&quot; | base64 | tr -d \\\\n)peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;VerifyAssetProperties&quot;,&quot;Args&quot;:[&quot;asset007&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_properties\\&quot;:\\&quot;$ASSET_PROPERTIES\\&quot;&#125;&quot; 验证通过之后，就对资产出价： 12export ASSET_PRICE=$(echo -n &quot;&#123;\\&quot;asset_id\\&quot;:\\&quot;asset007\\&quot;,\\&quot;trade_id\\&quot;:\\&quot;93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14\\&quot;,\\&quot;price\\&quot;:1000&#125;&quot; | base64)peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;AgreeToBuy&quot;,&quot;Args&quot;:[&quot;asset007&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_price\\&quot;:\\&quot;$ASSET_PRICE\\&quot;&#125;&quot; 可以在一级供应商的隐私数据集中查询到出价信息： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetBidPrice&quot;,&quot;Args&quot;:[&quot;asset007&quot;]&#125;&#x27; 如果在其他组织上查询，会看到如下错误，说明出价卖出设置的价格信息是隐秘的： 1Error: endorsement failure during query. response: status:500 message:&quot;asset price does not exist: asset001&quot; 核心企业把资产转移给一级供应商 核心企业和一级供应商对相同的价格达成共识之后，核心企业就可以把资产转移给一级供应商了。 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;TransferAsset&quot;,&quot;Args&quot;:[&quot;asset007&quot;,&quot;GylFOrg1MSP&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_properties\\&quot;:\\&quot;$ASSET_PROPERTIES\\&quot;,\\&quot;asset_price\\&quot;:\\&quot;$ASSET_PRICE\\&quot;&#125;&quot; 查询公共数据的资产归属以验证交易成功： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ReadAsset&quot;,&quot;Args&quot;:[&quot;asset001&quot;]&#125;&#x27; 交易验证 除了交易双方其他人无法查看到资产详情 验证一级供应商可以修改自己的资产的公共属性： 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ChangePublicDescription&quot;,&quot;Args&quot;:[&quot;asset005&quot;,&quot;This asset is not for sale now&quot;]&#125;&#x27; 然后通过所有四个组织查询资产ID为asset005的公共信息如下，说明一级供应商已经获得了修改权限并修改了这个资产的公共信息： 1234567(base) w:supply-finance apple$ peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ReadAsset&quot;,&quot;Args&quot;:[&quot;asset005&quot;]&#125;&#x27;|jq&#123; &quot;objectType&quot;: &quot;asset&quot;, &quot;assetID&quot;: &quot;asset005&quot;, &quot;ownerOrg&quot;: &quot;GylFOrg1MSP&quot;, &quot;publicDescription&quot;: &quot;This asset is not for sale now&quot;&#125; 验证核心企业不可以再修改这个资产的公共信息 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ChangePublicDescription&quot;,&quot;Args&quot;:[&quot;asset005&quot;,&quot;This asset is not for sale again&quot;]&#125;&#x27; 结果报错如下，符合预期： 1Error: endorsement failure during invoke. response: status:500 message:&quot;a client from GylCoreOrg1MSP cannot update the description of a asset owned by GylFOrg1MSP&quot; 验证只有一级供应商才可以查询这个资产的私有信息 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetPrivateProperties&quot;,&quot;Args&quot;:[&quot;asset005&quot;]&#125;&#x27; 结果如下，验证通过： 再一级供应商的peer节点可以查询到资产的私有属性，其他组织的peer节点都报错：Error: endorsement failure during query. response: status:500 message:&quot;asset private details does not exist in client org's collection: asset005&quot; 资产拆分 调用拆分方法 完成资产的拆分chaincode的更新之后，调用拆分的方法： 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;SplitAsset&quot;,&quot;Args&quot;:[&quot;asset010&quot;, &quot;500&quot;]&#125;&#x27; 验证拆分结果 私有数据验证 第一个资产： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetPrivateProperties&quot;,&quot;Args&quot;:[&quot;asset0101&quot;]&#125;&#x27;|jq 123456789&#123; &quot;objectType&quot;: &quot;asset_properties&quot;, &quot;assetID&quot;: &quot;asset0101&quot;, &quot;issuer&quot;: &quot;GylCoreOrg1MSP&quot;, &quot;amount&quot;: 500, &quot;createDate&quot;: &quot;2020-01-11T06:57:06.963617Z&quot;, &quot;endDate&quot;: &quot;2021-07-11T06:57:06.963617Z&quot;, &quot;salt&quot;: &quot;224cba6c547aecc76ab6acfac41d12dfd96e7165&quot;&#125; 第二个资产： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetPrivateProperties&quot;,&quot;Args&quot;:[&quot;asset0102&quot;]&#125;&#x27;|jq 结果如下： 123456789&#123; &quot;objectType&quot;: &quot;asset_properties&quot;, &quot;assetID&quot;: &quot;asset0102&quot;, &quot;issuer&quot;: &quot;GylCoreOrg1MSP&quot;, &quot;amount&quot;: 500, &quot;createDate&quot;: &quot;2020-01-11T06:57:06.963617Z&quot;, &quot;endDate&quot;: &quot;2021-07-11T06:57:06.963617Z&quot;, &quot;salt&quot;: &quot;224cba6c547aecc76ab6acfac41d12dfd96e7165&quot;&#125; 原始的资产： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetPrivateProperties&quot;,&quot;Args&quot;:[&quot;asset010&quot;]&#125;&#x27;|jq 结果如下，原始资产已经没有了： 1Error: endorsement failure during query. response: status:500 message:&quot;asset private details does not exist in client org&#x27;s collection: asset010&quot; 公共数据验证 第一个资产： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ReadAsset&quot;,&quot;Args&quot;:[&quot;asset0101&quot;]&#125;&#x27;|jq 结果如下，channel上的所有的组织都可以看到相同的数据： 12345678&#123; &quot;objectType&quot;: &quot;asset&quot;, &quot;assetID&quot;: &quot;asset0101&quot;, &quot;ownerOrg&quot;: &quot;GylCoreOrg1MSP&quot;, &quot;publicDescription&quot;: &quot;A new asset for GylCoreOrg1MSP&quot;, &quot;status&quot;: &quot;enable&quot;, &quot;parentID&quot;: &quot;asset010&quot;&#125; 第二个资产： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ReadAsset&quot;,&quot;Args&quot;:[&quot;asset0102&quot;]&#125;&#x27;|jq 结果如下： 12345678&#123; &quot;objectType&quot;: &quot;asset&quot;, &quot;assetID&quot;: &quot;asset0102&quot;, &quot;ownerOrg&quot;: &quot;GylCoreOrg1MSP&quot;, &quot;publicDescription&quot;: &quot;A new asset for GylCoreOrg1MSP&quot;, &quot;status&quot;: &quot;enable&quot;, &quot;parentID&quot;: &quot;asset010&quot;&#125; 原始的资产： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ReadAsset&quot;,&quot;Args&quot;:[&quot;asset010&quot;]&#125;&#x27;|jq 结果如下，chaincode有问题，拆分资产之后原始资产的状态应该改变： 12345678&#123; &quot;objectType&quot;: &quot;asset&quot;, &quot;assetID&quot;: &quot;asset010&quot;, &quot;ownerOrg&quot;: &quot;GylCoreOrg1MSP&quot;, &quot;publicDescription&quot;: &quot;已拆分&quot;, &quot;status&quot;: &quot;delete&quot;, &quot;parentID&quot;: &quot;&quot;&#125; 拆分后的资产交易 核心允许出售资产，价格设置为500： 下面的trade_id是合同的hash值 12export ASSET_PRICE=$(echo -n &quot;&#123;\\&quot;asset_id\\&quot;:\\&quot;asset0101\\&quot;,\\&quot;trade_id\\&quot;:\\&quot;93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14\\&quot;,\\&quot;price\\&quot;:500&#125;&quot; | base64)peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;AgreeToSell&quot;,&quot;Args&quot;:[&quot;asset0101&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_price\\&quot;:\\&quot;$ASSET_PRICE\\&quot;&#125;&quot; 查询核心企业的私有数据集合来读取同意的销售价格： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetSalesPrice&quot;,&quot;Args&quot;:[&quot;asset0101&quot;]&#125;&#x27; 一级供应商出价500 在一级供应商出价之前，他需要先验证资产的信息是否正确。此链码中返回true即为正确。 12export ASSET_PROPERTIES=$(echo -n &quot;&#123;\\&quot;objectType\\&quot;:\\&quot;asset_properties\\&quot;,\\&quot;assetID\\&quot;:\\&quot;asset0101\\&quot;,\\&quot;issuer\\&quot;:\\&quot;GylCoreOrg1MSP\\&quot;,\\&quot;amount\\&quot;:500,\\&quot;createDate\\&quot;:\\&quot;2020-01-11T06:57:06.963617Z\\&quot;,\\&quot;endDate\\&quot;:\\&quot;2021-07-11T06:57:06.963617Z\\&quot;,\\&quot;salt\\&quot;:\\&quot;224cba6c547aecc76ab6acfac41d12dfd96e7165\\&quot;&#125;&quot; | base64 | tr -d \\\\n)peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;VerifyAssetProperties&quot;,&quot;Args&quot;:[&quot;asset0101&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_properties\\&quot;:\\&quot;$ASSET_PROPERTIES\\&quot;&#125;&quot; 验证通过之后，就对资产出价： 12export ASSET_PRICE=$(echo -n &quot;&#123;\\&quot;asset_id\\&quot;:\\&quot;asset0101\\&quot;,\\&quot;trade_id\\&quot;:\\&quot;93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14\\&quot;,\\&quot;price\\&quot;:500&#125;&quot; | base64)peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;AgreeToBuy&quot;,&quot;Args&quot;:[&quot;asset0101&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_price\\&quot;:\\&quot;$ASSET_PRICE\\&quot;&#125;&quot; 可以在一级供应商的隐私数据集中查询到出价信息： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetBidPrice&quot;,&quot;Args&quot;:[&quot;asset0101&quot;]&#125;&#x27; 如果在其他组织上查询，会看到如下错误，说明出价卖出设置的价格信息是隐秘的： 1Error: endorsement failure during query. response: status:500 message:&quot;asset price does not exist: asset001&quot; 核心企业把资产转移给一级供应商 核心企业和一级供应商对相同的价格达成共识之后，核心企业就可以把资产转移给一级供应商了。 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;TransferAsset&quot;,&quot;Args&quot;:[&quot;asset0101&quot;,&quot;GylFOrg1MSP&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_properties\\&quot;:\\&quot;$ASSET_PROPERTIES\\&quot;,\\&quot;asset_price\\&quot;:\\&quot;$ASSET_PRICE\\&quot;&#125;&quot; 查询公共数据的资产归属以验证交易成功： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ReadAsset&quot;,&quot;Args&quot;:[&quot;asset0101&quot;]&#125;&#x27;|jq 结果如下： 12345678&#123; &quot;objectType&quot;: &quot;asset&quot;, &quot;assetID&quot;: &quot;asset0101&quot;, &quot;ownerOrg&quot;: &quot;GylFOrg1MSP&quot;, &quot;publicDescription&quot;: &quot;A new asset for GylCoreOrg1MSP&quot;, &quot;status&quot;: &quot;enable&quot;, &quot;parentID&quot;: &quot;asset010&quot;&#125; 交易验证 除了交易双方其他人无法查看到资产详情 验证一级供应商可以修改自己的资产的公共属性： 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ChangePublicDescription&quot;,&quot;Args&quot;:[&quot;asset0101&quot;,&quot;This asset is not for sale now&quot;]&#125;&#x27; 修改成功之后重新查询资产的公共信息，验证通过： 12345678&#123; &quot;objectType&quot;: &quot;asset&quot;, &quot;assetID&quot;: &quot;asset0101&quot;, &quot;ownerOrg&quot;: &quot;GylFOrg1MSP&quot;, &quot;publicDescription&quot;: &quot;This asset is not for sale now&quot;, &quot;status&quot;: &quot;enable&quot;, &quot;parentID&quot;: &quot;asset010&quot;&#125; 验证核心企业不可以再修改这个资产的公共信息 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ChangePublicDescription&quot;,&quot;Args&quot;:[&quot;asset0101&quot;,&quot;This asset is not for sale again&quot;]&#125;&#x27; 结果报错如下，符合预期： 1Error: endorsement failure during invoke. response: status:500 message:&quot;a client from GylCoreOrg1MSP cannot update the description of a asset owned by GylFOrg1MSP&quot; 验证只有一级供应商才可以查询这个资产的私有信息 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetPrivateProperties&quot;,&quot;Args&quot;:[&quot;asset0101&quot;]&#125;&#x27; 结果如下，验证通过： 在一级供应商的peer节点可以查询到资产的私有属性，其他组织的peer节点都报错：Error: endorsement failure during query. response: status:500 message:&quot;asset private details does not exist in client org's collection: asset005&quot; 一级供应商与二级供应商交易 调用拆分的方法，将资产拆分成200和300： 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;SplitAsset&quot;,&quot;Args&quot;:[&quot;asset0101&quot;, &quot;200&quot;]&#125;&#x27; 验证拆分结果 私有数据验证 第一个资产： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetPrivateProperties&quot;,&quot;Args&quot;:[&quot;asset01011&quot;]&#125;&#x27;|jq 第二个资产： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetPrivateProperties&quot;,&quot;Args&quot;:[&quot;asset01012&quot;]&#125;&#x27;|jq 原始的资产，原始资产已经没有了： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetPrivateProperties&quot;,&quot;Args&quot;:[&quot;asset0101&quot;]&#125;&#x27;|jq 公共数据验证 第一个资产： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ReadAsset&quot;,&quot;Args&quot;:[&quot;asset01011&quot;]&#125;&#x27;|jq 第二个资产： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ReadAsset&quot;,&quot;Args&quot;:[&quot;asset01012&quot;]&#125;&#x27;|jq 原始的资产，拆分资产之后原始资产的状态应该改变： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ReadAsset&quot;,&quot;Args&quot;:[&quot;asset0101&quot;]&#125;&#x27;|jq 拆分后的资产交易 一级供应商允许出售资产，设置价格： 下面的trade_id是合同的hash值 12export ASSET_PRICE=$(echo -n &quot;&#123;\\&quot;asset_id\\&quot;:\\&quot;asset01012\\&quot;,\\&quot;trade_id\\&quot;:\\&quot;f46555b7ddd1f8dd232bdc0dcbc5b1f34bdf1d4bb7c123a79a6ed628175f29bb\\&quot;,\\&quot;price\\&quot;:300&#125;&quot; | base64)peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;AgreeToSell&quot;,&quot;Args&quot;:[&quot;asset01012&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_price\\&quot;:\\&quot;$ASSET_PRICE\\&quot;&#125;&quot; 查询核心企业的私有数据集合来读取同意的销售价格： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetSalesPrice&quot;,&quot;Args&quot;:[&quot;asset01012&quot;]&#125;&#x27; 二级供应商2出价300 在二级供应商2出价之前，他需要先验证资产的信息是否正确。此链码中返回true即为正确。 12export ASSET_PROPERTIES=$(echo -n &quot;&#123;\\&quot;objectType\\&quot;:\\&quot;asset_properties\\&quot;,\\&quot;assetID\\&quot;:\\&quot;asset01012\\&quot;,\\&quot;issuer\\&quot;:\\&quot;GylCoreOrg1MSP\\&quot;,\\&quot;amount\\&quot;:300,\\&quot;createDate\\&quot;:\\&quot;2020-01-11T06:57:06.963617Z\\&quot;,\\&quot;endDate\\&quot;:\\&quot;2021-07-11T06:57:06.963617Z\\&quot;,\\&quot;salt\\&quot;:\\&quot;224cba6c547aecc76ab6acfac41d12dfd96e7165\\&quot;&#125;&quot; | base64 | tr -d \\\\n)peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;VerifyAssetProperties&quot;,&quot;Args&quot;:[&quot;asset01012&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_properties\\&quot;:\\&quot;$ASSET_PROPERTIES\\&quot;&#125;&quot; 验证通过之后，就对资产出价： 12export ASSET_PRICE=$(echo -n &quot;&#123;\\&quot;asset_id\\&quot;:\\&quot;asset01012\\&quot;,\\&quot;trade_id\\&quot;:\\&quot;f46555b7ddd1f8dd232bdc0dcbc5b1f34bdf1d4bb7c123a79a6ed628175f29bb\\&quot;,\\&quot;price\\&quot;:300&#125;&quot; | base64)peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;AgreeToBuy&quot;,&quot;Args&quot;:[&quot;asset01012&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_price\\&quot;:\\&quot;$ASSET_PRICE\\&quot;&#125;&quot; 可以在一级供应商的隐私数据集中查询到出价信息： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetBidPrice&quot;,&quot;Args&quot;:[&quot;asset01012&quot;]&#125;&#x27; 如果在其他组织上查询，会看到如下错误，说明出价卖出设置的价格信息是隐秘的： 1Error: endorsement failure during query. response: status:500 message:&quot;asset price does not exist: asset001&quot; 一级供应商把资产转移给二级供应商2 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;TransferAsset&quot;,&quot;Args&quot;:[&quot;asset01012&quot;,&quot;GylSOrg2MSP&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_properties\\&quot;:\\&quot;$ASSET_PROPERTIES\\&quot;,\\&quot;asset_price\\&quot;:\\&quot;$ASSET_PRICE\\&quot;&#125;&quot; 查询公共数据的资产归属以验证交易成功： 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ReadAsset&quot;,&quot;Args&quot;:[&quot;asset01012&quot;]&#125;&#x27;|jq 结果如下： 12345678&#123; &quot;objectType&quot;: &quot;asset&quot;, &quot;assetID&quot;: &quot;asset01012&quot;, &quot;ownerOrg&quot;: &quot;GylSOrg2MSP&quot;, &quot;publicDescription&quot;: &quot;This asset is not for sale now&quot;, &quot;status&quot;: &quot;enable&quot;, &quot;parentID&quot;: &quot;asset0101&quot;&#125; 交易验证 除了交易双方其他人无法查看到资产详情 验证二级级供应商2可以修改自己的资产的公共属性： 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ChangePublicDescription&quot;,&quot;Args&quot;:[&quot;asset01012&quot;,&quot;hello i am GylSOrg2MSP&quot;]&#125;&#x27; 修改成功之后重新查询资产的公共信息，验证通过： 12345678&#123; &quot;objectType&quot;: &quot;asset&quot;, &quot;assetID&quot;: &quot;asset01012&quot;, &quot;ownerOrg&quot;: &quot;GylSOrg2MSP&quot;, &quot;publicDescription&quot;: &quot;hello i am GylSOrg2MSP&quot;, &quot;status&quot;: &quot;enable&quot;, &quot;parentID&quot;: &quot;asset0101&quot;&#125; 验证只有二级级供应商2才可以查询这个资产的私有信息 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetPrivateProperties&quot;,&quot;Args&quot;:[&quot;asset01012&quot;]&#125;&#x27; 结果如下，验证通过： 在一级供应商的peer节点可以查询到资产的私有属性，其他组织的peer节点都报错：Error: endorsement failure during query. response: status:500 message:&quot;asset private details does not exist in client org's collection: asset005&quot; chaincode接口记录 查询卖出的交易信息 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;QueryAssetSaleAgreements&quot;,&quot;Args&quot;:[]&#125;&#x27; 查询资产的公共信息 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;ReadAsset&quot;,&quot;Args&quot;:[&quot;asset01012&quot;]&#125;&#x27;|jq 查询私有资产信息 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetPrivateProperties&quot;,&quot;Args&quot;:[&quot;asset01012&quot;]&#125;&#x27;|jq 查询一个资产公共信息的历史数据 1peer chaincode query -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply -c &#x27;&#123;&quot;function&quot;:&quot;QueryAssetHistory&quot;,&quot;Args&quot;:[&quot;asset01012&quot;]&#125;&#x27;|jq","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"项目实践-供应链金融","slug":"区块链/Hyperledger-Fabric/项目实践-供应链金融","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5-%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"peer","slug":"peer","permalink":"https://guozhe001.github.io/tags/peer/"},{"name":"供应链金融","slug":"供应链金融","permalink":"https://guozhe001.github.io/tags/%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D/"}]},{"title":"部署新的智能合约到channel","slug":"blockchain/fabric/通过供应链金融练习Fabric/部署智能合约到channel","date":"2024-11-22T06:32:06.496Z","updated":"2024-11-22T06:32:06.496Z","comments":true,"path":"2024/11/22/blockchain/fabric/通过供应链金融练习Fabric/部署智能合约到channel/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E9%80%9A%E8%BF%87%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D%E7%BB%83%E4%B9%A0Fabric/%E9%83%A8%E7%BD%B2%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E5%88%B0channel/","excerpt":"","text":"部署新的智能合约到channel 部署V1版本 打包 1peer lifecycle chaincode package supply.tar.gz --path /Users/apple/code/open-source/blockchain/hyperledger/supply-finance/chaincode-go/ --lang golang --label supply_1.0 运行完上面的命令，查看当前目录会发现多了supply.tar.gz包，说明打包成功。 安装链码包 一级供应商和核心企业都要安装： 核心企业： 1peer lifecycle chaincode install supply.tar.gz --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt 一级供应商： 1peer lifecycle chaincode install supply.tar.gz --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt 安装成功输出结果如下： 122020-12-28 17:12:37.540 CST [cli.lifecycle.chaincode] submitInstallProposal -&gt; INFO 001 Installed remotely: response:&lt;status:200 payload:&quot;\\nKsupply_1.0:7f51b70454bfcc78087a784c84288a67bbad56786e4007c3a7106491a492ad3a\\022\\nsupply_1.0&quot; &gt;2020-12-28 17:12:37.542 CST [cli.lifecycle.chaincode] submitInstallProposal -&gt; INFO 002 Chaincode code package identifier: supply_1.0:7f51b70454bfcc78087a784c84288a67bbad56786e4007c3a7106491a492ad3a 批准链码定义 查看已经安装的chaincode 1peer lifecycle chaincode queryinstalled 成功结果如下： 123Installed chaincodes on peer:Package ID: basic_1.0:4ec191e793b27e953ff2ede5a8bcc63152cecb1e4c3f301a26e22692c61967ad, Label: basic_1.0Package ID: supply_1.0:7f51b70454bfcc78087a784c84288a67bbad56786e4007c3a7106491a492ad3a, Label: supply_1.0 将链码的信息保存为一个变量 1export CC_PACKAGE_ID=supply_1.0:7f51b70454bfcc78087a784c84288a67bbad56786e4007c3a7106491a492ad3a 批准链码定义 核心企业和一级供应商都需要执行此命令： 1peer lifecycle chaincode approveformyorg -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID coreandfirstchannel --name supply --version 1.0 --package-id $CC_PACKAGE_ID --sequence 1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 成功结果如下： 12020-12-28 17:14:07.090 CST [chaincodeCmd] ClientWait -&gt; INFO 001 txid [5c192d72135019a4bd6d444231fc95d41b6c7391cbc80a98cb67618f5e7a85c6] committed with status (VALID) at localhost:8053 将链码定义提交到通道 检查channel上的成员是否已经批准了链码定义： 1peer lifecycle chaincode checkcommitreadiness --channelID coreandfirstchannel --name supply --version 1.0 --sequence 1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --output json 成功结果如下： 123456&#123; &quot;approvals&quot;: &#123; &quot;GylCoreOrg1MSP&quot;: true, &quot;GylFOrg1MSP&quot;: true &#125;&#125; 在两个组织都批准之后，执行下面的命令将链码定义提交到通道： 1peer lifecycle chaincode commit -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID coreandfirstchannel --name supply --version 1.0 --sequence 1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt 成功结果如下： 122020-12-28 17:14:57.631 CST [chaincodeCmd] ClientWait -&gt; INFO 001 txid [1c5e194c62a24b9fe78d51bd7003fce369f01a0b3051f63ed5e1f9ee4f6cf48b] committed with status (VALID) at localhost:80512020-12-28 17:14:57.631 CST [chaincodeCmd] ClientWait -&gt; INFO 002 txid [1c5e194c62a24b9fe78d51bd7003fce369f01a0b3051f63ed5e1f9ee4f6cf48b] committed with status (VALID) at localhost:8053 使用 peer lifecycle chaincode querycommitted 命令来确认链码定义已经提交到通道。 1peer lifecycle chaincode querycommitted --channelID coreandfirstchannel --name supply --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 成功结果如下： 12Committed chaincode definition for chaincode &#x27;supply&#x27; on channel &#x27;coreandfirstchannel&#x27;:Version: 1.0, Sequence: 1, Endorsement Plugin: escc, Validation Plugin: vscc, Approvals: [GylCoreOrg1MSP: true, GylFOrg1MSP: true] 调用链码 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C coreandfirstchannel -n supply --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;IssueVoucher&quot;,&quot;Args&quot;:[&quot;100&quot;, &quot;一级供应商&quot;]&#125;&#x27; 成功信息： 12020-12-25 17:26:22.583 CST [chaincodeCmd] chaincodeInvokeOrQuery -&gt; INFO 001 Chaincode invoke successful. result: status:200 错误信息记录： 1Error: could not assemble transaction: ProposalResponsePayloads do not match - proposal response: version:1 response:&lt;status:200 &gt; payload:&quot;\\n \\266\\367\\033\\202\\030f\\357\\010\\266zg\\350\\237\\212\\313 \\342B\\2041\\316\\351&gt;H\\037\\035\\312\\274J\\021i\\220\\022\\266\\002\\n\\237\\002\\0227\\n\\n_lifecycle\\022)\\n&#x27;\\n!namespaces/fields/supply/Sequence\\022\\002\\010\\t\\022\\343\\001\\n\\006supply\\022\\330\\001\\n\\003\\n\\0011\\032\\320\\001\\n\\0011\\032\\312\\001&#123;\\&quot;ID\\&quot;:\\&quot;1\\&quot;,\\&quot;issuer\\&quot;:\\&quot;\\346\\240\\270\\345\\277\\203\\344\\274\\201\\344\\270\\232\\&quot;,\\&quot;owner\\&quot;:\\&quot;\\346\\240\\270\\345\\277\\203\\344\\274\\201\\344\\270\\232\\&quot;,\\&quot;amount\\&quot;:100,\\&quot;createDate\\&quot;:\\&quot;2020-12-28T09:24:44.871052163Z\\&quot;,\\&quot;endDate\\&quot;:\\&quot;2021-06-28T09:24:44.871052228Z\\&quot;,\\&quot;contractHash\\&quot;:\\&quot;test\\&quot;,\\&quot;invoiceHash\\&quot;:\\&quot;test\\&quot;&#125;\\032\\003\\010\\310\\001\\&quot;\\r\\022\\006supply\\032\\0031.0&quot; endorsement:&lt;endorser:&quot;\\n\\013GylFOrg1MSP\\022\\212\\006-----BEGIN CERTIFICATE-----\\nMIICETCCAbegAwIBAgIRAKxyUt8FsMI4LRaMcjh08ZgwCgYIKoZIzj0EAwIwbTEL\\nMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG\\ncmFuY2lzY28xFjAUBgNVBAoTDWYxLnN1cHBseS5jb20xGTAXBgNVBAMTEGNhLmYx\\nLnN1cHBseS5jb20wHhcNMjAxMjI1MDkxNzAwWhcNMzAxMjIzMDkxNzAwWjBYMQsw\\nCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy\\nYW5jaXNjbzEcMBoGA1UEAxMTcGVlcjAuZjEuc3VwcGx5LmNvbTBZMBMGByqGSM49\\nAgEGCCqGSM49AwEHA0IABIChG5EnW6enlGqH2F9EiWYbilBwfA+KgqqxnN56njS5\\ngv368PElfoafV6jCrjA+p2OnbTI3gO2/RAwr2WBLB0+jTTBLMA4GA1UdDwEB/wQE\\nAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIHNOBiXoFslrjdFMBMzU7pNe\\nI5pmxxrQGrWTdgfI0cetMAoGCCqGSM49BAMCA0gAMEUCIQDEOKc114LvsauKzrMR\\n7k6ipg0HPM1+W8JJt06Jeqd1vwIgBre+xg2g/rS7F5oZaJpECUf7ALV0fy9/Dhw0\\nYDB3H+g=\\n-----END CERTIFICATE-----\\n&quot; signature:&quot;0D\\002 9\\020\\212\\014\\220\\302Ao_\\226n`o\\005\\354B\\263\\316\\346\\330\\347\\010\\217\\205^X\\&quot;\\267d\\320U\\365\\002 \\t&lt;\\024e\\324\\312X\\036\\346=\\025.I*A\\311\\223\\013\\301\\276\\320\\232\\366\\246tZm\\341g\\223\\235|&quot; &gt; 原因应该是代码中使用了Now（）来创建当前时间，两个peer的当前时间可能会有一点误差导致了校验不通过。 **解决方案：**使用ctx.GetStub().GetTxTimestamp()来获取时间，这样所有的节点创建的时间都是一致的，详见参考文档 更新智能合约 打包 1# peer lifecycle chaincode package supply.tar.gz --path /Users/apple/code/open-source/blockchain/hyperledger/fabric-samples/asset-transfer-basic/chaincode-go/ --lang golang --label supply_1.0 打包本地的代码： 1peer lifecycle chaincode package supply.5.tar.gz --path /Users/apple/code/open-source/blockchain/hyperledger/supply-finance/chaincode-go/ --lang golang --label supply_5.0 安装链码包 一级供应商和核心企业都要安装： 核心企业： 1peer lifecycle chaincode install supply.5.tar.gz --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt 一级供应商： 1peer lifecycle chaincode install supply.5.tar.gz --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt 批准链码定义 查看已经安装的chaincode 1peer lifecycle chaincode queryinstalled 将链码的信息保存为一个变量，两个组织都需要定义此变量： 1export CC_PACKAGE_ID=supply_5.0:0006888ea72e1b318238518b719382d440ab72f2d2c45b22e674f4828b7f7f9c 批准链码定义 核心企业和一级供应商都需要执行此命令： 1peer lifecycle chaincode approveformyorg -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID coreandfirstchannel --name supply --version 5.0 --package-id $CC_PACKAGE_ID --sequence 5 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 成功结果如下： 12020-12-28 17:58:55.313 CST [chaincodeCmd] ClientWait -&gt; INFO 001 txid [c4974d5c90ae4fb3bd31f179292d9943dd05aac47248f33e365d9f32ccb5ccb6] committed with status (VALID) at localhost:8051 将链码定义提交到通道 检查channel上的成员是否已经批准了链码定义： 1peer lifecycle chaincode checkcommitreadiness --channelID coreandfirstchannel --name supply --version 5.0 --sequence 5 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --output json 成功结果如下： 123456&#123; &quot;approvals&quot;: &#123; &quot;GylCoreOrg1MSP&quot;: true, &quot;GylFOrg1MSP&quot;: true &#125;&#125; 在两个组织都批准之后，执行下面的命令将链码定义提交到通道： 1peer lifecycle chaincode commit -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID coreandfirstchannel --name supply --version 5.0 --sequence 5 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt 成功结果如下： 122020-12-28 17:51:08.452 CST [chaincodeCmd] ClientWait -&gt; INFO 001 txid [87bc060e5ccdf4014cd4cf34bbbeb5d2ea10c4ff8ebb6f444d10580e2de2da50] committed with status (VALID) at localhost:80532020-12-28 17:51:08.460 CST [chaincodeCmd] ClientWait -&gt; INFO 002 txid [87bc060e5ccdf4014cd4cf34bbbeb5d2ea10c4ff8ebb6f444d10580e2de2da50] committed with status (VALID) at localhost:8051 使用 peer lifecycle chaincode querycommitted 命令来确认链码定义已经提交到通道。 1peer lifecycle chaincode querycommitted --channelID coreandfirstchannel --name supply --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 成功结果如下,可以看到已经升级到2.0版本： 12Committed chaincode definition for chaincode &#x27;supply&#x27; on channel &#x27;coreandfirstchannel&#x27;:Version: 2.0, Sequence: 2, Endorsement Plugin: escc, Validation Plugin: vscc, Approvals: [GylCoreOrg1MSP: true, GylFOrg1MSP: true] 调用链码 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C coreandfirstchannel -n supply --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;IssueVoucher&quot;,&quot;Args&quot;:[&quot;asset001&quot;, &quot;100&quot;, &quot;一级供应商&quot;]&#125;&#x27; 成功信息如下： 12020-12-28 18:37:54.285 CST [chaincodeCmd] chaincodeInvokeOrQuery -&gt; INFO 001 Chaincode invoke successful. result: status:200 错误信息如下： 1Error: could not assemble transaction: proposal response was not successful, error code 500, msg Incorrect number of params. Expected 2, received 1 - proposal response: version:1 response:&lt;status:200 &gt; payload:&quot;\\n \\177\\017\\350[\\344G6\\010V\\331\\332\\377\\354\\216&amp;\\035\\317&amp;\\251[N`\\023\\036\\033\\237\\237A\\005\\3670\\260\\022\\266\\002\\n\\237\\002\\0227\\n\\n_lifecycle\\022)\\n&#x27;\\n!namespaces/fields/supply/Sequence\\022\\002\\010\\016\\022\\343\\001\\n\\006supply\\022\\330\\001\\n\\003\\n\\0011\\032\\320\\001\\n\\0011\\032\\312\\001&#123;\\&quot;ID\\&quot;:\\&quot;1\\&quot;,\\&quot;issuer\\&quot;:\\&quot;\\346\\240\\270\\345\\277\\203\\344\\274\\201\\344\\270\\232\\&quot;,\\&quot;owner\\&quot;:\\&quot;\\346\\240\\270\\345\\277\\203\\344\\274\\201\\344\\270\\232\\&quot;,\\&quot;amount\\&quot;:100,\\&quot;createDate\\&quot;:\\&quot;2020-12-28T10:02:30.578872398Z\\&quot;,\\&quot;endDate\\&quot;:\\&quot;2021-06-28T10:02:30.578872527Z\\&quot;,\\&quot;contractHash\\&quot;:\\&quot;test\\&quot;,\\&quot;invoiceHash\\&quot;:\\&quot;test\\&quot;&#125;\\032\\003\\010\\310\\001\\&quot;\\r\\022\\006supply\\032\\0033.0&quot; endorsement:&lt;endorser:&quot;\\n\\016GylCoreOrg1MSP\\022\\222\\006-----BEGIN CERTIFICATE-----\\nMIICFjCCAbygAwIBAgIQU43L5gjtXO+uCpRP2jG2AjAKBggqhkjOPQQDAjBxMQsw\\nCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy\\nYW5jaXNjbzEYMBYGA1UEChMPY29yZS5zdXBwbHkuY29tMRswGQYDVQQDExJjYS5j\\nb3JlLnN1cHBseS5jb20wHhcNMjAxMjI1MDkxNzAwWhcNMzAxMjIzMDkxNzAwWjBa\\nMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2Fu\\nIEZyYW5jaXNjbzEeMBwGA1UEAxMVcGVlcjAuY29yZS5zdXBwbHkuY29tMFkwEwYH\\nKoZIzj0CAQYIKoZIzj0DAQcDQgAErf3R+7XpNQpmTsMO+iM4WS7IrOoafiPbAS7Q\\nbuFFR3Qs4riIczgSmjh9rOA6I1q2q0CstLhfWDbqpf+8fXPUlKNNMEswDgYDVR0P\\nAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAguznqsTisa64dNvOR\\nvPwP0KGklWohNpbSe7VgIghx4L8wCgYIKoZIzj0EAwIDSAAwRQIhALIw1VMzezCg\\n9LONbO4+V+weY42HQLbShkTP/gCFnGRYAiARyLLSDJIC2wwzSvOHNdm+aDRtbqGC\\nNJenP9hmEbYsTw==\\n-----END CERTIFICATE-----\\n&quot; signature:&quot;0E\\002!\\000\\251\\370K6S\\020\\373\\242\\321\\000\\211\\312\\0001\\333\\365&gt;\\314\\324\\231\\020&gt;u;+\\243\\303dD\\023\\221\\237\\002 z \\224\\236R\\355Z\\251\\202\\363\\035\\304\\365\\212\\277\\235\\375?\\376\\030\\371\\236\\220\\354iG6\\244\\334M\\315\\331&quot; &gt; 原因是因为下图，只有一个组织的链码更新到了最新的版本。 ![截屏2020-12-28 18.03.06](/Users/apple/Desktop/截屏2020-12-28 18.03.06.png) **解决方案：**原因是因为设置环境变量CC_PACKAGE_ID时只设置了一个组织的peer，导致旧的环境变量还在生效，重新操作一遍问题解决。 查询调用后的结果 1peer chaincode query -C coreandfirstchannel -n supply -c &#x27;&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;&#x27; 成功结果如下 1234# 核心企业[&#123;&quot;ID&quot;:&quot;asset001&quot;,&quot;issuer&quot;:&quot;核心企业&quot;,&quot;owner&quot;:&quot;核心企业&quot;,&quot;amount&quot;:100,&quot;createDate&quot;:&quot;2020-12-28T10:37:54.271518Z&quot;,&quot;endDate&quot;:&quot;2021-06-28T10:37:54.271518Z&quot;,&quot;contractHash&quot;:&quot;test&quot;,&quot;invoiceHash&quot;:&quot;test&quot;&#125;]# 一级供应商[&#123;&quot;ID&quot;:&quot;asset001&quot;,&quot;issuer&quot;:&quot;核心企业&quot;,&quot;owner&quot;:&quot;核心企业&quot;,&quot;amount&quot;:100,&quot;createDate&quot;:&quot;2020-12-28T10:37:54.271518Z&quot;,&quot;endDate&quot;:&quot;2021-06-28T10:37:54.271518Z&quot;,&quot;contractHash&quot;:&quot;test&quot;,&quot;invoiceHash&quot;:&quot;test&quot;&#125;] 调用交易方法 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C coreandfirstchannel -n supply --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;TransferAsset&quot;,&quot;Args&quot;:[&quot;asset001&quot;, &quot;一级供应商&quot;]&#125;&#x27; 再次查询：peer chaincode query -C coreandfirstchannel -n supply -c '&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;' 1234# 核心企业[&#123;&quot;ID&quot;:&quot;asset001&quot;,&quot;issuer&quot;:&quot;核心企业&quot;,&quot;owner&quot;:&quot;一级供应商&quot;,&quot;amount&quot;:100,&quot;createDate&quot;:&quot;2020-12-28T10:37:54.271518Z&quot;,&quot;endDate&quot;:&quot;2021-06-28T10:37:54.271518Z&quot;,&quot;contractHash&quot;:&quot;test&quot;,&quot;invoiceHash&quot;:&quot;test&quot;&#125;]# 一级供应商[&#123;&quot;ID&quot;:&quot;asset001&quot;,&quot;issuer&quot;:&quot;核心企业&quot;,&quot;owner&quot;:&quot;一级供应商&quot;,&quot;amount&quot;:100,&quot;createDate&quot;:&quot;2020-12-28T10:37:54.271518Z&quot;,&quot;endDate&quot;:&quot;2021-06-28T10:37:54.271518Z&quot;,&quot;contractHash&quot;:&quot;test&quot;,&quot;invoiceHash&quot;:&quot;test&quot;&#125;] 交易之后owner变成了一级供应商，没有问题。 问题记录： 虽然智能合约的代码编写方式如下，但是第二行的TransferAsset并没有执行，可能是因为第一个创建交易（CreateAsset）还没有成功，所以第二个交易（TransferAsset）没有这个资产所以没有执行？待确认 123// 创建资产s.CreateAsset(ctx, assetID, amount)s.TransferAsset(ctx, assetID, owner) 部署v6版本的supply v6版本智能合约源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159package chaincodeimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;time&quot; &quot;github.com/golang/protobuf/ptypes&quot; &quot;github.com/hyperledger/fabric-contract-api-go/contractapi&quot;)// SmartContract provides functions for managing an Assettype SmartContract struct &#123; contractapi.Contract&#125;// Asset describes basic details of what makes up a simple assettype Asset struct &#123; ID string `json:&quot;ID&quot;` Issuer string `json:&quot;issuer&quot;` Owner string `json:&quot;owner&quot;` Amount int64 `json:&quot;amount&quot;` CreateDate time.Time `json:&quot;createDate&quot;` EndDate time.Time `json:&quot;endDate&quot;` ContractHash string `json:&quot;contractHash&quot;` InvoiceHash string `json:&quot;invoiceHash&quot;`&#125;// IssueVoucher 发行凭证func (s *SmartContract) IssueVoucher(ctx contractapi.TransactionContextInterface, assetID string, amount int64) error &#123; // 创建资产 asset, err := s.createAsset(ctx, assetID, amount, &quot;核心企业&quot;, &quot;核心企业&quot;) if err != nil &#123; return err &#125; return s.PutState(ctx, asset)&#125;// createAsset issues a new asset to the world state with given details.func (s *SmartContract) createAsset(ctx contractapi.TransactionContextInterface, id string, amount int64, issuerName string, owner string) (*Asset, error) &#123; exists, err := s.AssetExists(ctx, id) if err != nil &#123; return nil, err &#125; if exists &#123; return nil, fmt.Errorf(&quot;the asset %s already exists&quot;, id) &#125; now, err := getNow(ctx) if err != nil &#123; return nil, err &#125; asset := Asset&#123;ID: id, Issuer: issuerName, Amount: amount, Owner: owner, CreateDate: now, EndDate: now.AddDate(0, 6, 0), ContractHash: &quot;test&quot;, InvoiceHash: &quot;test&quot;&#125; return &amp;asset, nil&#125;func getNow(ctx contractapi.TransactionContextInterface) (time.Time, error) &#123; now, err := ctx.GetStub().GetTxTimestamp() if err != nil &#123; return time.Now(), err &#125; return ptypes.Timestamp(now)&#125;// ReadAsset returns the asset stored in the world state with given id.func (s *SmartContract) ReadAsset(ctx contractapi.TransactionContextInterface, id string) (*Asset, error) &#123; assetJSON, err := ctx.GetStub().GetState(id) if err != nil &#123; return nil, fmt.Errorf(&quot;failed to read from world state: %v&quot;, err) &#125; if assetJSON == nil &#123; return nil, fmt.Errorf(&quot;the asset %s does not exist&quot;, id) &#125; var asset Asset err = json.Unmarshal(assetJSON, &amp;asset) if err != nil &#123; return nil, err &#125; return &amp;asset, nil&#125;// AssetExists returns true when asset with given ID exists in world statefunc (s *SmartContract) AssetExists(ctx contractapi.TransactionContextInterface, id string) (bool, error) &#123; assetJSON, err := ctx.GetStub().GetState(id) if err != nil &#123; return false, fmt.Errorf(&quot;failed to read from world state: %v&quot;, err) &#125; return assetJSON != nil, nil&#125;// TransferAsset updates the owner field of asset with given id in world state.func (s *SmartContract) TransferAsset(ctx contractapi.TransactionContextInterface, id string, newOwner string, amount int64) error &#123; asset, err := s.ReadAsset(ctx, id) if err != nil &#123; return err &#125; // 如果金额刚好等于凭证资产的金额，直接更新凭证资产的拥有者 if asset.Amount == amount &#123; asset.Owner = newOwner err = s.PutState(ctx, asset) &#125; else if asset.Amount &gt; amount &#123; // 如果凭证资产的金额大于转账的金额，则创建一个新的资产 // 创建新的资产并保存 newAsset, err := s.createAsset(ctx, asset.ID+&quot;1&quot;, amount, asset.Issuer, newOwner) if err != nil &#123; return err &#125; err = s.PutState(ctx, newAsset) if err != nil &#123; return err &#125; // 更新旧资产的金额 asset.Amount = asset.Amount - amount err = s.PutState(ctx, asset) &#125; else if asset.Amount &lt; amount &#123; // 如果资产的额度小于要转账的金额，则直接报错 err = fmt.Errorf(&quot;转账金额=%d,不能超过资产的金额=%d&quot;, amount, asset.Amount) &#125; return err&#125;// PutState 更新资产func (s *SmartContract) PutState(ctx contractapi.TransactionContextInterface, asset *Asset) error &#123; assetJSON, err := json.Marshal(asset) if err != nil &#123; return err &#125; return ctx.GetStub().PutState(asset.ID, assetJSON)&#125;// GetAllAssets returns all assets found in world statefunc (s *SmartContract) GetAllAssets(ctx contractapi.TransactionContextInterface) ([]*Asset, error) &#123; // range query with empty string for startKey and endKey does an // open-ended query of all assets in the chaincode namespace. resultsIterator, err := ctx.GetStub().GetStateByRange(&quot;&quot;, &quot;&quot;) if err != nil &#123; return nil, err &#125; defer resultsIterator.Close() var assets []*Asset for resultsIterator.HasNext() &#123; queryResponse, err := resultsIterator.Next() if err != nil &#123; return nil, err &#125; var asset Asset err = json.Unmarshal(queryResponse.Value, &amp;asset) if err != nil &#123; return nil, err &#125; assets = append(assets, &amp;asset) &#125; return assets, nil&#125; 打包 1peer lifecycle chaincode package supply.6.tar.gz --path /Users/apple/code/open-source/blockchain/hyperledger/supply-finance/chaincode-go/ --lang golang --label supply_6.0 安装链码包 一级供应商和核心企业都要安装： 核心企业： 1peer lifecycle chaincode install supply.6.tar.gz --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt 一级供应商： 1peer lifecycle chaincode install supply.6.tar.gz --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt 批准链码定义 查看已经安装的chaincode 1peer lifecycle chaincode queryinstalled 将链码的信息保存为一个变量，两个组织都需要定义此变量： 1export CC_PACKAGE_ID=supply_6.0:18a7379ed3b12a57961a735880a71bea3dd242c741fa0970f779b5a338f848de 批准链码定义 核心企业和一级供应商都需要执行此命令： 1peer lifecycle chaincode approveformyorg -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID coreandfirstchannel --name supply --version 6.0 --package-id $CC_PACKAGE_ID --sequence 6 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 成功结果如下： 12020-12-28 17:58:55.313 CST [chaincodeCmd] ClientWait -&gt; INFO 001 txid [c4974d5c90ae4fb3bd31f179292d9943dd05aac47248f33e365d9f32ccb5ccb6] committed with status (VALID) at localhost:8051 将链码定义提交到通道 检查channel上的成员是否已经批准了链码定义： 1peer lifecycle chaincode checkcommitreadiness --channelID coreandfirstchannel --name supply --version 6.0 --sequence 6 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --output json 成功结果如下： 123456&#123; &quot;approvals&quot;: &#123; &quot;GylCoreOrg1MSP&quot;: true, &quot;GylFOrg1MSP&quot;: true &#125;&#125; 在两个组织都批准之后，执行下面的命令将链码定义提交到通道： 1peer lifecycle chaincode commit -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID coreandfirstchannel --name supply --version 6.0 --sequence 6 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt 成功结果如下： 122020-12-28 17:51:08.452 CST [chaincodeCmd] ClientWait -&gt; INFO 001 txid [87bc060e5ccdf4014cd4cf34bbbeb5d2ea10c4ff8ebb6f444d10580e2de2da50] committed with status (VALID) at localhost:80532020-12-28 17:51:08.460 CST [chaincodeCmd] ClientWait -&gt; INFO 002 txid [87bc060e5ccdf4014cd4cf34bbbeb5d2ea10c4ff8ebb6f444d10580e2de2da50] committed with status (VALID) at localhost:8051 使用 peer lifecycle chaincode querycommitted 命令来确认链码定义已经提交到通道。 1peer lifecycle chaincode querycommitted --channelID coreandfirstchannel --name supply --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 成功结果如下,可以看到已经升级到2.0版本： 12Committed chaincode definition for chaincode &#x27;supply&#x27; on channel &#x27;coreandfirstchannel&#x27;:Version: 2.0, Sequence: 2, Endorsement Plugin: escc, Validation Plugin: vscc, Approvals: [GylCoreOrg1MSP: true, GylFOrg1MSP: true] 调用链码 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C coreandfirstchannel -n supply --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;IssueVoucher&quot;,&quot;Args&quot;:[&quot;asset002&quot;, &quot;1000&quot;]&#125;&#x27; 成功信息如下： 12020-12-29 10:59:48.513 CST [chaincodeCmd] chaincodeInvokeOrQuery -&gt; INFO 001 Chaincode invoke successful. result: status:200 错误信息如下： 1Error: endorsement failure during invoke. response: status:500 message:&quot;the asset asset001 already exists&quot; **解决方案：**原因是以内资产ID为asset001的资产已经存在，修改资产ID参数即可。 查询调用后的结果 1peer chaincode query -C coreandfirstchannel -n supply -c &#x27;&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;&#x27; 成功结果如下 12345678910111213141516171819202122[ &#123; &quot;ID&quot;: &quot;asset001&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;一级供应商&quot;, &quot;amount&quot;: 100, &quot;createDate&quot;: &quot;2020-12-28T10:37:54.271518Z&quot;, &quot;endDate&quot;: &quot;2021-06-28T10:37:54.271518Z&quot;, &quot;contractHash&quot;: &quot;test&quot;, &quot;invoiceHash&quot;: &quot;test&quot; &#125;, &#123; &quot;ID&quot;: &quot;asset002&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;核心企业&quot;, &quot;amount&quot;: 1000, &quot;createDate&quot;: &quot;2020-12-29T02:59:48.495257Z&quot;, &quot;endDate&quot;: &quot;2021-06-29T02:59:48.495257Z&quot;, &quot;contractHash&quot;: &quot;test&quot;, &quot;invoiceHash&quot;: &quot;test&quot; &#125;] 调用交易方法 把凭证资产拆分一部分（200）给一级供应商： 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C coreandfirstchannel -n supply --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;TransferAsset&quot;,&quot;Args&quot;:[&quot;asset002&quot;, &quot;一级供应商&quot;, &quot;200&quot;]&#125;&#x27; 再次查询：peer chaincode query -C coreandfirstchannel -n supply -c '&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;' 1234567891011121314151617181920212223242526272829303132[ &#123; &quot;ID&quot;: &quot;asset001&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;一级供应商&quot;, &quot;amount&quot;: 100, &quot;createDate&quot;: &quot;2020-12-28T10:37:54.271518Z&quot;, &quot;endDate&quot;: &quot;2021-06-28T10:37:54.271518Z&quot;, &quot;contractHash&quot;: &quot;test&quot;, &quot;invoiceHash&quot;: &quot;test&quot; &#125;, &#123; &quot;ID&quot;: &quot;asset002&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;核心企业&quot;, &quot;amount&quot;: 800, &quot;createDate&quot;: &quot;2020-12-29T02:59:48.495257Z&quot;, &quot;endDate&quot;: &quot;2021-06-29T02:59:48.495257Z&quot;, &quot;contractHash&quot;: &quot;test&quot;, &quot;invoiceHash&quot;: &quot;test&quot; &#125;, &#123; &quot;ID&quot;: &quot;asset0021&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;一级供应商&quot;, &quot;amount&quot;: 200, &quot;createDate&quot;: &quot;2020-12-29T03:02:49.495789Z&quot;, &quot;endDate&quot;: &quot;2021-06-29T03:02:49.495789Z&quot;, &quot;contractHash&quot;: &quot;test&quot;, &quot;invoiceHash&quot;: &quot;test&quot; &#125;] 交易之后，核心企业剩余800的凭证，一级供应商获得一个新的凭证。验证无误。 部署v7版本的supply v7版本智能合约源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166package chaincodeimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;time&quot; &quot;github.com/golang/protobuf/ptypes&quot; &quot;github.com/hyperledger/fabric-contract-api-go/contractapi&quot;)// SmartContract provides functions for managing an Assettype SmartContract struct &#123; contractapi.Contract&#125;// Asset describes basic details of what makes up a simple assettype Asset struct &#123; ID string `json:&quot;ID&quot;` Issuer string `json:&quot;issuer&quot;` Owner string `json:&quot;owner&quot;` Amount int64 `json:&quot;amount&quot;` CreateDate time.Time `json:&quot;createDate&quot;` EndDate time.Time `json:&quot;endDate&quot;` ContractHash string `json:&quot;contractHash&quot;` InvoiceHash string `json:&quot;invoiceHash&quot;`&#125;// IssueVoucher 发行凭证func (s *SmartContract) IssueVoucher(ctx contractapi.TransactionContextInterface, assetID string, amount int64, owner string, contractHash string, invoiceHash string) error &#123; // 创建资产 return s.CreateAssetAndSave(ctx, assetID, amount, &quot;核心企业&quot;, owner, contractHash, invoiceHash)&#125;// CreateAssetAndSave 创建资产并保存func (s *SmartContract) CreateAssetAndSave(ctx contractapi.TransactionContextInterface, id string, amount int64, issuerName string, owner string, contractHash string, invoiceHash string) error &#123; asset, err := s.createAsset(ctx, id, amount, issuerName, owner, contractHash, invoiceHash) if err != nil &#123; return err &#125; return s.PutState(ctx, asset)&#125;// createAsset issues a new asset to the world state with given details.func (s *SmartContract) createAsset(ctx contractapi.TransactionContextInterface, id string, amount int64, issuerName string, owner string, contractHash string, invoiceHash string) (*Asset, error) &#123; exists, err := s.AssetExists(ctx, id) if err != nil &#123; return nil, err &#125; if exists &#123; return nil, fmt.Errorf(&quot;the asset %s already exists&quot;, id) &#125; now, err := getNow(ctx) if err != nil &#123; return nil, err &#125; asset := Asset&#123;ID: id, Issuer: issuerName, Amount: amount, Owner: owner, CreateDate: now, EndDate: now.AddDate(0, 6, 0), ContractHash: contractHash, InvoiceHash: invoiceHash&#125; return &amp;asset, nil&#125;// 获取当前时间func getNow(ctx contractapi.TransactionContextInterface) (time.Time, error) &#123; now, err := ctx.GetStub().GetTxTimestamp() if err != nil &#123; return time.Now(), err &#125; return ptypes.Timestamp(now)&#125;// ReadAsset returns the asset stored in the world state with given id.func (s *SmartContract) ReadAsset(ctx contractapi.TransactionContextInterface, id string) (*Asset, error) &#123; assetJSON, err := ctx.GetStub().GetState(id) if err != nil &#123; return nil, fmt.Errorf(&quot;failed to read from world state: %v&quot;, err) &#125; if assetJSON == nil &#123; return nil, fmt.Errorf(&quot;the asset %s does not exist&quot;, id) &#125; var asset Asset err = json.Unmarshal(assetJSON, &amp;asset) if err != nil &#123; return nil, err &#125; return &amp;asset, nil&#125;// AssetExists returns true when asset with given ID exists in world statefunc (s *SmartContract) AssetExists(ctx contractapi.TransactionContextInterface, id string) (bool, error) &#123; assetJSON, err := ctx.GetStub().GetState(id) if err != nil &#123; return false, fmt.Errorf(&quot;failed to read from world state: %v&quot;, err) &#125; return assetJSON != nil, nil&#125;// TransferAssetByID 根据资产ID转账func (s *SmartContract) TransferAssetByID(ctx contractapi.TransactionContextInterface, id string, newOwner string, amount int64, contractHash string, invoiceHash string) error &#123; asset, err := s.ReadAsset(ctx, id) if err != nil &#123; return err &#125; return s.TransferAsset(ctx, asset, newOwner, amount, contractHash, invoiceHash)&#125;// TransferAsset updates the owner field of asset with given id in world state.func (s *SmartContract) TransferAsset(ctx contractapi.TransactionContextInterface, asset *Asset, newOwner string, amount int64, contractHash string, invoiceHash string) error &#123; // 如果金额刚好等于凭证资产的金额，直接更新凭证资产的拥有者 if asset.Amount == amount &#123; asset.Owner = newOwner return s.PutState(ctx, asset) &#125; else if asset.Amount &gt; amount &#123; // 如果凭证资产的金额大于转账的金额，则创建一个新的资产 // 创建新的资产并保存 err := s.CreateAssetAndSave(ctx, asset.ID+&quot;1&quot;, amount, asset.Issuer, newOwner, contractHash, invoiceHash) if err != nil &#123; return err &#125; // 更新旧资产的金额 asset.Amount = asset.Amount - amount return s.PutState(ctx, asset) &#125; else if asset.Amount &lt; amount &#123; // 如果资产的额度小于要转账的金额，则直接报错 return fmt.Errorf(&quot;转账金额=%d,不能超过资产的金额=%d&quot;, amount, asset.Amount) &#125; return nil&#125;// PutState 更新资产func (s *SmartContract) PutState(ctx contractapi.TransactionContextInterface, asset *Asset) error &#123; assetJSON, err := json.Marshal(asset) if err != nil &#123; return err &#125; return ctx.GetStub().PutState(asset.ID, assetJSON)&#125;// GetAllAssets returns all assets found in world statefunc (s *SmartContract) GetAllAssets(ctx contractapi.TransactionContextInterface) ([]*Asset, error) &#123; // range query with empty string for startKey and endKey does an // open-ended query of all assets in the chaincode namespace. resultsIterator, err := ctx.GetStub().GetStateByRange(&quot;&quot;, &quot;&quot;) if err != nil &#123; return nil, err &#125; defer resultsIterator.Close() var assets []*Asset for resultsIterator.HasNext() &#123; queryResponse, err := resultsIterator.Next() if err != nil &#123; return nil, err &#125; var asset Asset err = json.Unmarshal(queryResponse.Value, &amp;asset) if err != nil &#123; return nil, err &#125; assets = append(assets, &amp;asset) &#125; return assets, nil&#125; 打包 1peer lifecycle chaincode package supply.7.tar.gz --path /Users/apple/code/open-source/blockchain/hyperledger/supply-finance/chaincode-go/ --lang golang --label supply_7.0 安装链码包 一级供应商和核心企业都要安装： 核心企业： 1peer lifecycle chaincode install supply.7.tar.gz --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt 一级供应商： 1peer lifecycle chaincode install supply.7.tar.gz --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt 批准链码定义 查看已经安装的chaincode 1peer lifecycle chaincode queryinstalled 将链码的信息保存为一个变量，两个组织都需要定义此变量： 1export CC_PACKAGE_ID=supply_7.0:770f0c8f4fe3a348314f546594d402ccb3eb5f5779f12e7edee48f6ce474227b 批准链码定义 核心企业和一级供应商都需要执行此命令： 1peer lifecycle chaincode approveformyorg -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID coreandfirstchannel --name supply --version 7.0 --package-id $CC_PACKAGE_ID --sequence 7 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 将链码定义提交到通道 检查channel上的成员是否已经批准了链码定义： 1peer lifecycle chaincode checkcommitreadiness --channelID coreandfirstchannel --name supply --version 7.0 --sequence 7 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --output json 在两个组织都批准之后，执行下面的命令将链码定义提交到通道： 1peer lifecycle chaincode commit -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID coreandfirstchannel --name supply --version 7.0 --sequence 7 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt 使用 peer lifecycle chaincode querycommitted 命令来确认链码定义已经提交到通道。 1peer lifecycle chaincode querycommitted --channelID coreandfirstchannel --name supply --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 调用链码 调用链码之前先生成测试的合同hash值和发票hash值 12shasum -a 256 CORE_AND_F1_CONTRACT.txt &gt; core_and_f1_contract_hash.txtshasum -a 256 CORE_AND_F1_INVOICE.txt &gt; CORE_AND_F1_INVOICE_hash.txt 发行凭证 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C coreandfirstchannel -n supply --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;IssueVoucher&quot;,&quot;Args&quot;:[&quot;asset003&quot;, &quot;1000&quot;, &quot;一级供应商&quot;, &quot;93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14&quot;, &quot;83c02ac2d48c863dab2ccf6870455aadfc2cec073b8db269b517c879d76aa6d9&quot;]&#125;&#x27; 查询调用后的结果 1peer chaincode query -C coreandfirstchannel -n supply -c &#x27;&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;&#x27; 成功结果如下 123456789101112131415161718192021222324252627282930313233343536373839404142[ &#123; &quot;ID&quot;: &quot;asset001&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;一级供应商&quot;, &quot;amount&quot;: 100, &quot;createDate&quot;: &quot;2020-12-28T10:37:54.271518Z&quot;, &quot;endDate&quot;: &quot;2021-06-28T10:37:54.271518Z&quot;, &quot;contractHash&quot;: &quot;test&quot;, &quot;invoiceHash&quot;: &quot;test&quot; &#125;, &#123; &quot;ID&quot;: &quot;asset002&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;核心企业&quot;, &quot;amount&quot;: 800, &quot;createDate&quot;: &quot;2020-12-29T02:59:48.495257Z&quot;, &quot;endDate&quot;: &quot;2021-06-29T02:59:48.495257Z&quot;, &quot;contractHash&quot;: &quot;test&quot;, &quot;invoiceHash&quot;: &quot;test&quot; &#125;, &#123; &quot;ID&quot;: &quot;asset0021&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;一级供应商&quot;, &quot;amount&quot;: 200, &quot;createDate&quot;: &quot;2020-12-29T03:02:49.495789Z&quot;, &quot;endDate&quot;: &quot;2021-06-29T03:02:49.495789Z&quot;, &quot;contractHash&quot;: &quot;test&quot;, &quot;invoiceHash&quot;: &quot;test&quot; &#125;, &#123; &quot;ID&quot;: &quot;asset003&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;一级供应商&quot;, &quot;amount&quot;: 1000, &quot;createDate&quot;: &quot;2020-12-29T06:20:30.868298Z&quot;, &quot;endDate&quot;: &quot;2021-06-29T06:20:30.868298Z&quot;, &quot;contractHash&quot;: &quot;93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14&quot;, &quot;invoiceHash&quot;: &quot;83c02ac2d48c863dab2ccf6870455aadfc2cec073b8db269b517c879d76aa6d9&quot; &#125;] ID为asset003的资产归属为一级供应商，金额无误。 创建一级供应商与二级供应商之间的channel 创建通道： 运行下面的程序来为firstandsecondchannel通道创建一个“创建通道的交易” 1configtxgen -profile FirstAndSecondChannel -outputCreateChannelTx ./channel-artifacts/firstandsecondchannel.tx -channelID firstandsecondchannel 执行结果如下： 12342020-12-29 14:27:37.416 CST [common.tools.configtxgen] main -&gt; INFO 001 Loading configuration2020-12-29 14:27:37.430 CST [common.tools.configtxgen.localconfig] Load -&gt; INFO 002 Loaded configuration: /Users/apple/code/open-source/blockchain/hyperledger/supply-finance/config/configtx.yaml2020-12-29 14:27:37.430 CST [common.tools.configtxgen] doOutputChannelCreateTx -&gt; INFO 003 Generating new channel configtx2020-12-29 14:27:37.436 CST [common.tools.configtxgen] doOutputChannelCreateTx -&gt; INFO 004 Writing new channel tx 设置环境变量，以一级供应商管理员身份操作peerCLI，使用下面的命令把交易发给order服务创建通道： 1peer channel create -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com -c firstandsecondchannel -f ./channel-artifacts/firstandsecondchannel.tx --outputBlock ./channel-artifacts/firstandsecondchannel.block --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 错误信息记录： 1Error: got unexpected status: BAD_REQUEST -- error validating channel creation transaction for new channel &#x27;firstandsecondchannel&#x27;, could not successfully apply update to template configuration: error authorizing update: error validating DeltaSet: policy for [Group] /Channel/Application not satisfied: implicit policy evaluation failed - 0 sub-policies were satisfied, but this policy requires 1 of the &#x27;Admins&#x27; sub-policies to be satisfied 错误原因和解决方案： 由于配置文件里面配置的firstandsecondchannel里面包含一级供应商和两个二级供应商，而上面的命令是以核心企业的管理员身份运行的。所以有问题。切换成一级供应商的环境执行即可。 正确执行之后的日志： 1234567891011122020-12-29 14:34:06.203 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-12-29 14:34:06.231 CST [cli.common] readBlock -&gt; INFO 002 Expect block, but got status: &amp;&#123;NOT_FOUND&#125;2020-12-29 14:34:06.244 CST [channelCmd] InitCmdFactory -&gt; INFO 003 Endorser and orderer connections initialized2020-12-29 14:34:06.450 CST [cli.common] readBlock -&gt; INFO 004 Expect block, but got status: &amp;&#123;SERVICE_UNAVAILABLE&#125;2020-12-29 14:34:06.458 CST [channelCmd] InitCmdFactory -&gt; INFO 005 Endorser and orderer connections initialized2020-12-29 14:34:06.667 CST [cli.common] readBlock -&gt; INFO 006 Expect block, but got status: &amp;&#123;SERVICE_UNAVAILABLE&#125;2020-12-29 14:34:06.676 CST [channelCmd] InitCmdFactory -&gt; INFO 007 Endorser and orderer connections initialized2020-12-29 14:34:06.885 CST [cli.common] readBlock -&gt; INFO 008 Expect block, but got status: &amp;&#123;SERVICE_UNAVAILABLE&#125;2020-12-29 14:34:06.892 CST [channelCmd] InitCmdFactory -&gt; INFO 009 Endorser and orderer connections initialized2020-12-29 14:34:07.099 CST [cli.common] readBlock -&gt; INFO 00a Expect block, but got status: &amp;&#123;SERVICE_UNAVAILABLE&#125;2020-12-29 14:34:07.108 CST [channelCmd] InitCmdFactory -&gt; INFO 00b Endorser and orderer connections initialized2020-12-29 14:34:07.320 CST [cli.common] readBlock -&gt; INFO 00c Received block: 0 把一级供应商和二级供应商的peer加入通道 一级供应商的peer加入通道 使用下面的命令将peer加入通道 1peer channel join -b ./channel-artifacts/firstandsecondchannel.block 成功信息如下： 122020-12-29 14:35:00.679 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-12-29 14:35:00.724 CST [channelCmd] executeJoin -&gt; INFO 002 Successfully submitted proposal to join channel 通过获取通道信息确认加入成功 获取通道信息 1peer channel getinfo -c firstandsecondchannel 可以看到如下信息： 122020-12-29 14:35:28.593 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initializedBlockchain info: &#123;&quot;height&quot;:1,&quot;currentBlockHash&quot;:&quot;270CWtnSyXJmeGCxJx41sX7uTchRZpljYWKJ48dD434=&quot;&#125; 二级供应商1加入通道 设置环境变量，然后拉取通道的创世纪区块(因为是测试本次忽略)： 1peer channel fetch 0 ./channel-artifacts/coreandfirstchannel.block -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com -c coreandfirstchannel --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 加入通道： 1peer channel join -b ./channel-artifacts/firstandsecondchannel.block 成功信息如下： 122020-12-29 14:47:03.684 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-12-29 14:47:03.722 CST [channelCmd] executeJoin -&gt; INFO 002 Successfully submitted proposal to join channel 报错信息如下： 123supply-finance apple$ peer channel join -b ./channel-artifacts/coreandfirstchannel.block2020-12-29 14:43:56.186 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initializedError: proposal failed (err: rpc error: code = Unknown desc = error validating proposal: access denied: channel [] creator org [GylSOrg1M]) **错误原因：**由于环境变量设置的有问题，CORE_PEER_LOCALMSPID设置成了GylSOrg1M，应该设置为GylSOrg1MSP 二级供应商2加入通道 设置环境变量，然后拉取通道的创世纪区块(因为是测试本次忽略)： 1peer channel fetch 0 ./channel-artifacts/coreandfirstchannel.block -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com -c coreandfirstchannel --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 加入通道： 1peer channel join -b ./channel-artifacts/firstandsecondchannel.block 成功信息如下： 122020-12-29 14:52:12.969 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-12-29 14:52:13.010 CST [channelCmd] executeJoin -&gt; INFO 002 Successfully submitted proposal to join channel 设置锚节点 为GylFOrg1MSP设置锚节点 拉取最新的channel配置区块 1peer channel fetch config channel-artifacts/firstandsecondchannel_config_block.pb -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com -c firstandsecondchannel --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 成功信息如下： 12342020-12-29 14:55:57.114 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-12-29 14:55:57.120 CST [cli.common] readBlock -&gt; INFO 002 Received block: 02020-12-29 14:55:57.120 CST [channelCmd] fetch -&gt; INFO 003 Retrieving last config block: 02020-12-29 14:55:57.125 CST [cli.common] readBlock -&gt; INFO 004 Received block: 0 修改通道配置区块 切换到channel-artifacts然后把区块内容转换成json格式： 12345cd channel-artifactsconfigtxlator proto_decode --input firstandsecondchannel_config_block.pb --type common.Block --output firstandsecondchannel_config_block.jsonjq .data.data[0].payload.data.config firstandsecondchannel_config_block.json &gt; firstandsecondchannel_config.json# copy一份cp firstandsecondchannel_config.json firstandsecondchannel_config_copy.json 使用jq 工具来添加GylFOrg1MSP组织的锚节点到通道配置。 1jq &#x27;.channel_group.groups.Application.groups.GylFOrg1MSP.values += &#123;&quot;AnchorPeers&quot;:&#123;&quot;mod_policy&quot;: &quot;Admins&quot;,&quot;value&quot;:&#123;&quot;anchor_peers&quot;: [&#123;&quot;host&quot;: &quot;peer0.f1.supply.com&quot;,&quot;port&quot;: 8053&#125;]&#125;,&quot;version&quot;: &quot;0&quot;&#125;&#125;&#x27; firstandsecondchannel_config_copy.json &gt; modified_firstandsecondchannel_config.json 将原始的和修改后的通道配置都转换回protobuf格式，并计算它们之间的差异。 123configtxlator proto_encode --input firstandsecondchannel_config.json --type common.Config --output firstandsecondchannel_config.pbconfigtxlator proto_encode --input modified_firstandsecondchannel_config.json --type common.Config --output modified_firstandsecondchannel_config.pbconfigtxlator compute_update --channel_id firstandsecondchannel --original firstandsecondchannel_config.pb --updated modified_firstandsecondchannel_config.pb --output firstandsecondchannel_config_update.pb 把更新后的交易打包成一个更新通道配置的交易： 123configtxlator proto_decode --input firstandsecondchannel_config_update.pb --type common.ConfigUpdate --output firstandsecondchannel_config_update.jsonecho &#x27;&#123;&quot;payload&quot;:&#123;&quot;header&quot;:&#123;&quot;channel_header&quot;:&#123;&quot;channel_id&quot;:&quot;firstandsecondchannel&quot;, &quot;type&quot;:2&#125;&#125;,&quot;data&quot;:&#123;&quot;config_update&quot;:&#x27;$(cat firstandsecondchannel_config_update.json)&#x27;&#125;&#125;&#125;&#x27; | jq . &gt; firstandsecondchannel_config_update_in_envelope.jsonconfigtxlator proto_encode --input firstandsecondchannel_config_update_in_envelope.json --type common.Envelope --output firstandsecondchannel_config_update_in_envelope.pb 提交“更新通道配置的交易” 进到上一级目录cd ..，之后运行命令将交易提交给排序服务进行通道配置的更新： 12cd ..peer channel update -f channel-artifacts/firstandsecondchannel_config_update_in_envelope.pb -c firstandsecondchannel -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 执行成功的结果： 122020-12-29 14:57:48.872 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-12-29 14:57:48.894 CST [channelCmd] update -&gt; INFO 002 Successfully submitted channel update 验证，获取通道信息:peer channel getinfo -c firstandsecondchannel 122020-12-29 14:58:15.937 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initializedBlockchain info: &#123;&quot;height&quot;:2,&quot;currentBlockHash&quot;:&quot;4lhXvhRKDNxBsOIGL0H0A5QDdNkySgv/ehtUkobtW9Y=&quot;,&quot;previousBlockHash&quot;:&quot;270CWtnSyXJmeGCxJx41sX7uTchRZpljYWKJ48dD434=&quot;&#125; 为二级供应商1（GylSOrg1MSP）设置锚节点 修改环境变量，拉取最新的channel配置区块 1peer channel fetch config channel-artifacts/firstandsecondchannel_config_block.pb -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com -c firstandsecondchannel --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 修改通道配置区块 切换到channel-artifacts然后把区块内容转换成json格式： 12345cd channel-artifactsconfigtxlator proto_decode --input firstandsecondchannel_config_block.pb --type common.Block --output firstandsecondchannel_config_block.jsonjq .data.data[0].payload.data.config firstandsecondchannel_config_block.json &gt; firstandsecondchannel_config.json# copy一份cp firstandsecondchannel_config.json firstandsecondchannel_config_copy.json 使用jq 工具来添加GylCoreOrg1MSP组织的锚节点到通道配置。 1jq &#x27;.channel_group.groups.Application.groups.GylSOrg1MSP.values += &#123;&quot;AnchorPeers&quot;:&#123;&quot;mod_policy&quot;: &quot;Admins&quot;,&quot;value&quot;:&#123;&quot;anchor_peers&quot;: [&#123;&quot;host&quot;: &quot;peer0.s1.supply.com&quot;,&quot;port&quot;: 8055&#125;]&#125;,&quot;version&quot;: &quot;0&quot;&#125;&#125;&#x27; firstandsecondchannel_config_copy.json &gt; modified_firstandsecondchannel_config.json 将原始的和修改后的通道配置都转换回protobuf格式，并计算它们之间的差异。 123configtxlator proto_encode --input firstandsecondchannel_config.json --type common.Config --output firstandsecondchannel_config.pbconfigtxlator proto_encode --input modified_firstandsecondchannel_config.json --type common.Config --output modified_firstandsecondchannel_config.pbconfigtxlator compute_update --channel_id firstandsecondchannel --original firstandsecondchannel_config.pb --updated modified_firstandsecondchannel_config.pb --output firstandsecondchannel_config_update.pb 把更新后的交易打包成一个更新通道配置的交易： 123configtxlator proto_decode --input firstandsecondchannel_config_update.pb --type common.ConfigUpdate --output firstandsecondchannel_config_update.jsonecho &#x27;&#123;&quot;payload&quot;:&#123;&quot;header&quot;:&#123;&quot;channel_header&quot;:&#123;&quot;channel_id&quot;:&quot;firstandsecondchannel&quot;, &quot;type&quot;:2&#125;&#125;,&quot;data&quot;:&#123;&quot;config_update&quot;:&#x27;$(cat firstandsecondchannel_config_update.json)&#x27;&#125;&#125;&#125;&#x27; | jq . &gt; firstandsecondchannel_config_update_in_envelope.jsonconfigtxlator proto_encode --input firstandsecondchannel_config_update_in_envelope.json --type common.Envelope --output firstandsecondchannel_config_update_in_envelope.pb 提交“更新通道配置的交易” 进到上一级目录cd ..，之后运行命令将交易提交给排序服务进行通道配置的更新： 12cd ..peer channel update -f channel-artifacts/firstandsecondchannel_config_update_in_envelope.pb -c firstandsecondchannel -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 执行成功的结果： 122020-12-29 15:01:14.643 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-12-29 15:01:14.670 CST [channelCmd] update -&gt; INFO 002 Successfully submitted channel update 验证，获取通道信息 123(base) w:supply-finance apple$ peer channel getinfo -c firstandsecondchannel2020-12-29 15:01:26.952 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initializedBlockchain info: &#123;&quot;height&quot;:3,&quot;currentBlockHash&quot;:&quot;DPXkm090OpH9ww862WmR4EktxT0NHEM2i3Py0yHAGPE=&quot;,&quot;previousBlockHash&quot;:&quot;4lhXvhRKDNxBsOIGL0H0A5QDdNkySgv/ehtUkobtW9Y=&quot;&#125; 为二级供应商2（GylSOrg2MSP）设置锚节点 修改环境变量，拉取最新的channel配置区块 1peer channel fetch config channel-artifacts/firstandsecondchannel_config_block.pb -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com -c firstandsecondchannel --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 修改通道配置区块 切换到channel-artifacts然后把区块内容转换成json格式： 12345cd channel-artifactsconfigtxlator proto_decode --input firstandsecondchannel_config_block.pb --type common.Block --output firstandsecondchannel_config_block.jsonjq .data.data[0].payload.data.config firstandsecondchannel_config_block.json &gt; firstandsecondchannel_config.json# copy一份cp firstandsecondchannel_config.json firstandsecondchannel_config_copy.json 使用jq 工具来添加GylCoreOrg1MSP组织的锚节点到通道配置。 1jq &#x27;.channel_group.groups.Application.groups.GylSOrg2MSP.values += &#123;&quot;AnchorPeers&quot;:&#123;&quot;mod_policy&quot;: &quot;Admins&quot;,&quot;value&quot;:&#123;&quot;anchor_peers&quot;: [&#123;&quot;host&quot;: &quot;peer0.s2.supply.com&quot;,&quot;port&quot;: 8151&#125;]&#125;,&quot;version&quot;: &quot;0&quot;&#125;&#125;&#x27; firstandsecondchannel_config_copy.json &gt; modified_firstandsecondchannel_config.json 将原始的和修改后的通道配置都转换回protobuf格式，并计算它们之间的差异。 123configtxlator proto_encode --input firstandsecondchannel_config.json --type common.Config --output firstandsecondchannel_config.pbconfigtxlator proto_encode --input modified_firstandsecondchannel_config.json --type common.Config --output modified_firstandsecondchannel_config.pbconfigtxlator compute_update --channel_id firstandsecondchannel --original firstandsecondchannel_config.pb --updated modified_firstandsecondchannel_config.pb --output firstandsecondchannel_config_update.pb 把更新后的交易打包成一个更新通道配置的交易： 123configtxlator proto_decode --input firstandsecondchannel_config_update.pb --type common.ConfigUpdate --output firstandsecondchannel_config_update.jsonecho &#x27;&#123;&quot;payload&quot;:&#123;&quot;header&quot;:&#123;&quot;channel_header&quot;:&#123;&quot;channel_id&quot;:&quot;firstandsecondchannel&quot;, &quot;type&quot;:2&#125;&#125;,&quot;data&quot;:&#123;&quot;config_update&quot;:&#x27;$(cat firstandsecondchannel_config_update.json)&#x27;&#125;&#125;&#125;&#x27; | jq . &gt; firstandsecondchannel_config_update_in_envelope.jsonconfigtxlator proto_encode --input firstandsecondchannel_config_update_in_envelope.json --type common.Envelope --output firstandsecondchannel_config_update_in_envelope.pb 提交“更新通道配置的交易” 进到上一级目录cd ..，之后运行命令将交易提交给排序服务进行通道配置的更新： 12cd ..peer channel update -f channel-artifacts/firstandsecondchannel_config_update_in_envelope.pb -c firstandsecondchannel -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 执行成功的结果： 122020-12-29 15:03:39.793 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-12-29 15:03:39.817 CST [channelCmd] update -&gt; INFO 002 Successfully submitted channel update 验证，获取通道信息 123(base) w:supply-finance apple$ peer channel getinfo -c firstandsecondchannel2020-12-29 15:04:10.414 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initializedBlockchain info: &#123;&quot;height&quot;:4,&quot;currentBlockHash&quot;:&quot;PWXXje7tci4mk1ggQ9QMVzkvkP3i+N8WslOGDXreIQ0=&quot;,&quot;previousBlockHash&quot;:&quot;DPXkm090OpH9ww862WmR4EktxT0NHEM2i3Py0yHAGPE=&quot;&#125; 部署supply-v7到二级供应商的peer节点 打包 1peer lifecycle chaincode package supply.7.tar.gz --path /Users/apple/code/open-source/blockchain/hyperledger/supply-finance/chaincode-go/ --lang golang --label supply_7.0 安装链码包 两个二级供应商都要安装： 二级供应商1： 1peer lifecycle chaincode install supply.7.tar.gz --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt 二级供应商2： 1peer lifecycle chaincode install supply.7.tar.gz --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt 批准链码定义 查看已经安装的chaincode 1peer lifecycle chaincode queryinstalled 将链码的信息保存为一个变量，两个组织都需要定义此变量： 1export CC_PACKAGE_ID=supply_7.0:770f0c8f4fe3a348314f546594d402ccb3eb5f5779f12e7edee48f6ce474227b 批准链码定义 一级供应商和两个二级供应商都需要执行此命令： 1peer lifecycle chaincode approveformyorg -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID firstandsecondchannel --name supply --version 7.0 --package-id $CC_PACKAGE_ID --sequence 1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 将链码定义提交到通道 检查channel上的成员是否已经批准了链码定义： 1peer lifecycle chaincode checkcommitreadiness --channelID firstandsecondchannel --name supply --version 7.0 --sequence 1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --output json 在所有组织都批准之后，执行下面的命令将链码定义提交到通道： 1peer lifecycle chaincode commit -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID firstandsecondchannel --name supply --version 7.0 --sequence 1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt 使用 peer lifecycle chaincode querycommitted 命令来确认链码定义已经提交到通道。 1peer lifecycle chaincode querycommitted --channelID firstandsecondchannel --name supply --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 错误信息记录： 12(base) w:supply-finance apple$ peer lifecycle chaincode commit -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID firstandsecondchannel --name supply --version 7.0 --sequence 1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crtError: proposal failed with status: 500 - channel &#x27;firstandsecondchannel&#x27; not found **错误原因：**由于批准的组织中包含核心企业，核心企业并没有加入firstandsecondchannel通道，所以报错。 调用链码 调用链码之前先生成测试的合同hash值和发票hash值如下： 123476307cd9d79c76a2a7894677692ce421ff1a31e32717a7de6f07deb5de395e7a f1_and_s1_contract.txt792376c209f338959be4cf00c54dbf82662b90516082e23106faec4c43c69e49 f1_and_s1_invoice.txtf46555b7ddd1f8dd232bdc0dcbc5b1f34bdf1d4bb7c123a79a6ed628175f29bb f1_and_s2_contract.txtf807fe6dc767be2e7021d41540114b33b30fa7784f6de5521251f23a3eb66468 f1_and_s2_invoice.txt 调用转账交易：TODO 问题来了，两个channel之间如何交换资产？这是个问题 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com -C firstandsecondchannel -n supply --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;IssueVoucher&quot;,&quot;Args&quot;:[&quot;asset003&quot;, &quot;1000&quot;, &quot;一级供应商&quot;, &quot;93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14&quot;, &quot;83c02ac2d48c863dab2ccf6870455aadfc2cec073b8db269b517c879d76aa6d9&quot;]&#125;&#x27; 1peer chaincode query -C firstandsecondchannel -n supply -c &#x27;&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;&#x27; 核心企业、一级和二级供应商加入同一个channel 查看创建channel 部署supply-v7到alljoinchannel通道 打包 1# peer lifecycle chaincode package supply.7.tar.gz --path /Users/apple/code/open-source/blockchain/hyperledger/supply-finance/chaincode-go/ --lang golang --label supply_7.0 安装链码包 每个peer都要安装：peer lifecycle chaincode install supply.7.tar.gz 批准链码定义 查看已经安装的chaincode 1peer lifecycle chaincode queryinstalled 将链码的信息保存为一个变量，两个组织都需要定义此变量： 1export CC_PACKAGE_ID=supply_7.0:770f0c8f4fe3a348314f546594d402ccb3eb5f5779f12e7edee48f6ce474227b 批准链码定义 每个peer都要执行此命令： 1peer lifecycle chaincode approveformyorg -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID alljoinchannel --name supply --version 7.0 --package-id $CC_PACKAGE_ID --sequence 1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 将链码定义提交到通道 检查channel上的成员是否已经批准了链码定义： 1peer lifecycle chaincode checkcommitreadiness --channelID alljoinchannel --name supply --version 7.0 --sequence 1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --output json 在所有组织都批准之后，执行下面的命令将链码定义提交到通道： 1peer lifecycle chaincode commit -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID alljoinchannel --name supply --version 7.0 --sequence 1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt 使用 peer lifecycle chaincode querycommitted 命令来确认链码定义已经提交到通道。 1peer lifecycle chaincode querycommitted --channelID alljoinchannel --name supply --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 调用链码 调用链码之前先生成测试的合同hash值和发票hash值如下： 12345683c02ac2d48c863dab2ccf6870455aadfc2cec073b8db269b517c879d76aa6d9 CORE_AND_F1_INVOICE.txt93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14 CORE_AND_F1_CONTRACT.txt76307cd9d79c76a2a7894677692ce421ff1a31e32717a7de6f07deb5de395e7a f1_and_s1_contract.txt792376c209f338959be4cf00c54dbf82662b90516082e23106faec4c43c69e49 f1_and_s1_invoice.txtf46555b7ddd1f8dd232bdc0dcbc5b1f34bdf1d4bb7c123a79a6ed628175f29bb f1_and_s2_contract.txtf807fe6dc767be2e7021d41540114b33b30fa7784f6de5521251f23a3eb66468 f1_and_s2_invoice.txt 发行凭证 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n supply --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;IssueVoucher&quot;,&quot;Args&quot;:[&quot;asset003&quot;, &quot;1000&quot;, &quot;一级供应商&quot;, &quot;93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14&quot;, &quot;83c02ac2d48c863dab2ccf6870455aadfc2cec073b8db269b517c879d76aa6d9&quot;]&#125;&#x27; 查询资产 1peer chaincode query -C alljoinchannel -n supply -c &#x27;&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;&#x27; 结果如下： 123456789101112[ &#123; &quot;ID&quot;: &quot;asset003&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;一级供应商&quot;, &quot;amount&quot;: 1000, &quot;createDate&quot;: &quot;2020-12-29T10:07:43.665003Z&quot;, &quot;endDate&quot;: &quot;2021-06-29T10:07:43.665003Z&quot;, &quot;contractHash&quot;: &quot;93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14&quot;, &quot;invoiceHash&quot;: &quot;83c02ac2d48c863dab2ccf6870455aadfc2cec073b8db269b517c879d76aa6d9&quot; &#125;] 一级供应商与二级供应商1交易 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n supply --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;TransferAssetByID&quot;,&quot;Args&quot;:[&quot;asset003&quot;, &quot;二级供应商1&quot;, &quot;500&quot;, &quot;76307cd9d79c76a2a7894677692ce421ff1a31e32717a7de6f07deb5de395e7a&quot;, &quot;792376c209f338959be4cf00c54dbf82662b90516082e23106faec4c43c69e49&quot;]&#125;&#x27; 查询资产 1peer chaincode query -C alljoinchannel -n supply -c &#x27;&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;&#x27; 结果如下： 12345678910111213141516171819202122[ &#123; &quot;ID&quot;: &quot;asset003&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;一级供应商&quot;, &quot;amount&quot;: 500, &quot;createDate&quot;: &quot;2020-12-29T10:07:43.665003Z&quot;, &quot;endDate&quot;: &quot;2021-06-29T10:07:43.665003Z&quot;, &quot;contractHash&quot;: &quot;93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14&quot;, &quot;invoiceHash&quot;: &quot;83c02ac2d48c863dab2ccf6870455aadfc2cec073b8db269b517c879d76aa6d9&quot; &#125;, &#123; &quot;ID&quot;: &quot;asset0031&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;二级供应商1&quot;, &quot;amount&quot;: 500, &quot;createDate&quot;: &quot;2020-12-29T10:12:37.227293Z&quot;, &quot;endDate&quot;: &quot;2021-06-29T10:12:37.227293Z&quot;, &quot;contractHash&quot;: &quot;76307cd9d79c76a2a7894677692ce421ff1a31e32717a7de6f07deb5de395e7a&quot;, &quot;invoiceHash&quot;: &quot;792376c209f338959be4cf00c54dbf82662b90516082e23106faec4c43c69e49&quot; &#125;] 一级供应商与二级供应商2交易 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n supply --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;TransferAssetByID&quot;,&quot;Args&quot;:[&quot;asset003&quot;, &quot;二级供应商2&quot;, &quot;300&quot;, &quot;f46555b7ddd1f8dd232bdc0dcbc5b1f34bdf1d4bb7c123a79a6ed628175f29bb&quot;, &quot;f807fe6dc767be2e7021d41540114b33b30fa7784f6de5521251f23a3eb66468&quot;]&#125;&#x27; 错误信息记录： 1Error: endorsement failure during invoke. response: status:500 message:&quot;the asset asset0031 already exists&quot; 原因如下：如果同一个资产ID交易两次，则会出现资产ID重复的问题；代码bug。 1err := s.CreateAssetAndSave(ctx, asset.ID+&quot;1&quot;, amount, asset.Issuer, newOwner, contractHash, invoiceHash) 一级供应商与二级供应商2交易 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n supply --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;TransferAssetByID&quot;,&quot;Args&quot;:[&quot;asset0031&quot;, &quot;二级供应商2&quot;, &quot;300&quot;, &quot;f46555b7ddd1f8dd232bdc0dcbc5b1f34bdf1d4bb7c123a79a6ed628175f29bb&quot;, &quot;f807fe6dc767be2e7021d41540114b33b30fa7784f6de5521251f23a3eb66468&quot;]&#125;&#x27; 查询资产，结果如下： 1234567891011121314151617181920212223242526272829303132[ &#123; &quot;ID&quot;: &quot;asset003&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;一级供应商&quot;, &quot;amount&quot;: 500, &quot;createDate&quot;: &quot;2020-12-29T10:07:43.665003Z&quot;, &quot;endDate&quot;: &quot;2021-06-29T10:07:43.665003Z&quot;, &quot;contractHash&quot;: &quot;93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14&quot;, &quot;invoiceHash&quot;: &quot;83c02ac2d48c863dab2ccf6870455aadfc2cec073b8db269b517c879d76aa6d9&quot; &#125;, &#123; &quot;ID&quot;: &quot;asset0031&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;二级供应商1&quot;, &quot;amount&quot;: 200, &quot;createDate&quot;: &quot;2020-12-29T10:12:37.227293Z&quot;, &quot;endDate&quot;: &quot;2021-06-29T10:12:37.227293Z&quot;, &quot;contractHash&quot;: &quot;76307cd9d79c76a2a7894677692ce421ff1a31e32717a7de6f07deb5de395e7a&quot;, &quot;invoiceHash&quot;: &quot;792376c209f338959be4cf00c54dbf82662b90516082e23106faec4c43c69e49&quot; &#125;, &#123; &quot;ID&quot;: &quot;asset00311&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;二级供应商2&quot;, &quot;amount&quot;: 300, &quot;createDate&quot;: &quot;2020-12-29T10:17:26.148125Z&quot;, &quot;endDate&quot;: &quot;2021-06-29T10:17:26.148125Z&quot;, &quot;contractHash&quot;: &quot;f46555b7ddd1f8dd232bdc0dcbc5b1f34bdf1d4bb7c123a79a6ed628175f29bb&quot;, &quot;invoiceHash&quot;: &quot;f807fe6dc767be2e7021d41540114b33b30fa7784f6de5521251f23a3eb66468&quot; &#125;] 部署supply-v8到alljoinchannel通道 源码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169package chaincodeimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;time&quot; &quot;github.com/golang/protobuf/ptypes&quot; &quot;github.com/hyperledger/fabric-contract-api-go/contractapi&quot;)// SmartContract provides functions for managing an Assettype SmartContract struct &#123; contractapi.Contract&#125;// Asset describes basic details of what makes up a simple assettype Asset struct &#123; ID string `json:&quot;ID&quot;` Issuer string `json:&quot;issuer&quot;` Owner string `json:&quot;owner&quot;` Amount int64 `json:&quot;amount&quot;` CreateDate time.Time `json:&quot;createDate&quot;` EndDate time.Time `json:&quot;endDate&quot;` ContractHash string `json:&quot;contractHash&quot;` InvoiceHash string `json:&quot;invoiceHash&quot;`&#125;// IssueVoucher 发行凭证func (s *SmartContract) IssueVoucher(ctx contractapi.TransactionContextInterface, assetID string, amount int64, owner string, contractHash string, invoiceHash string) error &#123; // 创建资产 return s.CreateAssetAndSave(ctx, assetID, amount, &quot;核心企业&quot;, owner, contractHash, invoiceHash)&#125;// CreateAssetAndSave 创建资产并保存func (s *SmartContract) CreateAssetAndSave(ctx contractapi.TransactionContextInterface, id string, amount int64, issuerName string, owner string, contractHash string, invoiceHash string) error &#123; asset, err := s.createAsset(ctx, id, amount, issuerName, owner, contractHash, invoiceHash) if err != nil &#123; return err &#125; return s.PutState(ctx, asset)&#125;// createAsset issues a new asset to the world state with given details.func (s *SmartContract) createAsset(ctx contractapi.TransactionContextInterface, id string, amount int64, issuerName string, owner string, contractHash string, invoiceHash string) (*Asset, error) &#123; exists, err := s.AssetExists(ctx, id) if err != nil &#123; return nil, err &#125; if exists &#123; return nil, fmt.Errorf(&quot;the asset %s already exists&quot;, id) &#125; now, err := getNow(ctx) if err != nil &#123; return nil, err &#125; asset := Asset&#123;ID: id, Issuer: issuerName, Amount: amount, Owner: owner, CreateDate: now, EndDate: now.AddDate(0, 6, 0), ContractHash: contractHash, InvoiceHash: invoiceHash&#125; return &amp;asset, nil&#125;// 获取当前时间func getNow(ctx contractapi.TransactionContextInterface) (time.Time, error) &#123; now, err := ctx.GetStub().GetTxTimestamp() if err != nil &#123; return time.Now(), err &#125; return ptypes.Timestamp(now)&#125;// ReadAsset returns the asset stored in the world state with given id.func (s *SmartContract) ReadAsset(ctx contractapi.TransactionContextInterface, id string) (*Asset, error) &#123; assetJSON, err := ctx.GetStub().GetState(id) if err != nil &#123; return nil, fmt.Errorf(&quot;failed to read from world state: %v&quot;, err) &#125; if assetJSON == nil &#123; return nil, fmt.Errorf(&quot;the asset %s does not exist&quot;, id) &#125; var asset Asset err = json.Unmarshal(assetJSON, &amp;asset) if err != nil &#123; return nil, err &#125; return &amp;asset, nil&#125;// AssetExists returns true when asset with given ID exists in world statefunc (s *SmartContract) AssetExists(ctx contractapi.TransactionContextInterface, id string) (bool, error) &#123; assetJSON, err := ctx.GetStub().GetState(id) if err != nil &#123; return false, fmt.Errorf(&quot;failed to read from world state: %v&quot;, err) &#125; return assetJSON != nil, nil&#125;// TransferAssetByID 根据资产ID转账func (s *SmartContract) TransferAssetByID(ctx contractapi.TransactionContextInterface, id string, newID string, newOwner string, amount int64, contractHash string, invoiceHash string) error &#123; asset, err := s.ReadAsset(ctx, id) if err != nil &#123; return err &#125; return s.TransferAsset(ctx, asset, newID, newOwner, amount, contractHash, invoiceHash)&#125;// TransferAsset updates the owner field of asset with given id in world state.func (s *SmartContract) TransferAsset(ctx contractapi.TransactionContextInterface, asset *Asset, newID string, newOwner string, amount int64, contractHash string, invoiceHash string) error &#123; // 如果金额刚好等于凭证资产的金额，直接更新凭证资产的拥有者 if asset.Amount == amount &#123; asset.Owner = newOwner return s.PutState(ctx, asset) &#125; else if asset.Amount &gt; amount &#123; // 如果凭证资产的金额大于转账的金额，则创建一个新的资产 if newID == &quot;&quot; &#123; return fmt.Errorf(&quot;转账金额小于资产的金额时，newID必须不能为空&quot;) &#125; // 创建新的资产并保存 err := s.CreateAssetAndSave(ctx, newID, amount, asset.Issuer, newOwner, contractHash, invoiceHash) if err != nil &#123; return err &#125; // 更新旧资产的金额 asset.Amount = asset.Amount - amount return s.PutState(ctx, asset) &#125; else if asset.Amount &lt; amount &#123; // 如果资产的额度小于要转账的金额，则直接报错 return fmt.Errorf(&quot;转账金额=%d,不能超过资产的金额=%d&quot;, amount, asset.Amount) &#125; return nil&#125;// PutState 更新资产func (s *SmartContract) PutState(ctx contractapi.TransactionContextInterface, asset *Asset) error &#123; assetJSON, err := json.Marshal(asset) if err != nil &#123; return err &#125; return ctx.GetStub().PutState(asset.ID, assetJSON)&#125;// GetAllAssets returns all assets found in world statefunc (s *SmartContract) GetAllAssets(ctx contractapi.TransactionContextInterface) ([]*Asset, error) &#123; // range query with empty string for startKey and endKey does an // open-ended query of all assets in the chaincode namespace. resultsIterator, err := ctx.GetStub().GetStateByRange(&quot;&quot;, &quot;&quot;) if err != nil &#123; return nil, err &#125; defer resultsIterator.Close() var assets []*Asset for resultsIterator.HasNext() &#123; queryResponse, err := resultsIterator.Next() if err != nil &#123; return nil, err &#125; var asset Asset err = json.Unmarshal(queryResponse.Value, &amp;asset) if err != nil &#123; return nil, err &#125; assets = append(assets, &amp;asset) &#125; return assets, nil&#125; 打包 1peer lifecycle chaincode package supply.8.tar.gz --path /Users/apple/code/open-source/blockchain/hyperledger/supply-finance/chaincode-go/ --lang golang --label supply_8.0 安装链码包 每个peer都要安装：peer lifecycle chaincode install supply.8.tar.gz 批准链码定义 查看已经安装的chaincode 1peer lifecycle chaincode queryinstalled 将链码的信息保存为一个变量，两个组织都需要定义此变量： 1export CC_PACKAGE_ID=supply_8.0:797ec1d00145482b746640d0b8bb9bea64cb69dea3e95abb69a1195a19e34511 批准链码定义 每个peer都要执行此命令： 1peer lifecycle chaincode approveformyorg -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID alljoinchannel --name supply --version 8.0 --package-id $CC_PACKAGE_ID --sequence 2 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 将链码定义提交到通道 检查channel上的成员是否已经批准了链码定义： 1peer lifecycle chaincode checkcommitreadiness --channelID alljoinchannel --name supply --version 8.0 --sequence 2 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --output json 在所有组织都批准之后，执行下面的命令将链码定义提交到通道： 1peer lifecycle chaincode commit -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID alljoinchannel --name supply --version 8.0 --sequence 2 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt 使用 peer lifecycle chaincode querycommitted 命令来确认链码定义已经提交到通道。 1peer lifecycle chaincode querycommitted --channelID alljoinchannel --name supply --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 调用链码 调用链码之前先生成测试的合同hash值和发票hash值如下： 12345683c02ac2d48c863dab2ccf6870455aadfc2cec073b8db269b517c879d76aa6d9 CORE_AND_F1_INVOICE.txt93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14 CORE_AND_F1_CONTRACT.txt76307cd9d79c76a2a7894677692ce421ff1a31e32717a7de6f07deb5de395e7a f1_and_s1_contract.txt792376c209f338959be4cf00c54dbf82662b90516082e23106faec4c43c69e49 f1_and_s1_invoice.txtf46555b7ddd1f8dd232bdc0dcbc5b1f34bdf1d4bb7c123a79a6ed628175f29bb f1_and_s2_contract.txtf807fe6dc767be2e7021d41540114b33b30fa7784f6de5521251f23a3eb66468 f1_and_s2_invoice.txt 发行凭证 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n supply --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;IssueVoucher&quot;,&quot;Args&quot;:[&quot;asset001&quot;, &quot;1000&quot;, &quot;一级供应商&quot;, &quot;93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14&quot;, &quot;83c02ac2d48c863dab2ccf6870455aadfc2cec073b8db269b517c879d76aa6d9&quot;]&#125;&#x27; 查询资产 1peer chaincode query -C alljoinchannel -n supply -c &#x27;&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;&#x27; 结果如下： 123456789101112[ &#123; &quot;ID&quot;: &quot;asset001&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;一级供应商&quot;, &quot;amount&quot;: 1000, &quot;createDate&quot;: &quot;2020-12-30T06:57:06.963617Z&quot;, &quot;endDate&quot;: &quot;2021-06-30T06:57:06.963617Z&quot;, &quot;contractHash&quot;: &quot;93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14&quot;, &quot;invoiceHash&quot;: &quot;83c02ac2d48c863dab2ccf6870455aadfc2cec073b8db269b517c879d76aa6d9&quot; &#125;] 一级供应商与二级供应商1交易 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n supply --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;TransferAssetByID&quot;,&quot;Args&quot;:[&quot;asset001&quot;, &quot;asset0011&quot;, &quot;二级供应商1&quot;, &quot;500&quot;, &quot;76307cd9d79c76a2a7894677692ce421ff1a31e32717a7de6f07deb5de395e7a&quot;, &quot;792376c209f338959be4cf00c54dbf82662b90516082e23106faec4c43c69e49&quot;]&#125;&#x27; 查询资产 1peer chaincode query -C alljoinchannel -n supply -c &#x27;&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;&#x27; 结果如下： 12345678910111213141516171819202122[ &#123; &quot;ID&quot;: &quot;asset001&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;一级供应商&quot;, &quot;amount&quot;: 500, &quot;createDate&quot;: &quot;2020-12-30T06:57:06.963617Z&quot;, &quot;endDate&quot;: &quot;2021-06-30T06:57:06.963617Z&quot;, &quot;contractHash&quot;: &quot;93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14&quot;, &quot;invoiceHash&quot;: &quot;83c02ac2d48c863dab2ccf6870455aadfc2cec073b8db269b517c879d76aa6d9&quot; &#125;, &#123; &quot;ID&quot;: &quot;asset0011&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;二级供应商1&quot;, &quot;amount&quot;: 500, &quot;createDate&quot;: &quot;2020-12-30T06:57:50.047189Z&quot;, &quot;endDate&quot;: &quot;2021-06-30T06:57:50.047189Z&quot;, &quot;contractHash&quot;: &quot;76307cd9d79c76a2a7894677692ce421ff1a31e32717a7de6f07deb5de395e7a&quot;, &quot;invoiceHash&quot;: &quot;792376c209f338959be4cf00c54dbf82662b90516082e23106faec4c43c69e49&quot; &#125;] 一级供应商与二级供应商2交易 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n supply --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;TransferAssetByID&quot;,&quot;Args&quot;:[&quot;asset001&quot;, &quot;asset0012&quot;, &quot;二级供应商2&quot;, &quot;300&quot;, &quot;f46555b7ddd1f8dd232bdc0dcbc5b1f34bdf1d4bb7c123a79a6ed628175f29bb&quot;, &quot;f807fe6dc767be2e7021d41540114b33b30fa7784f6de5521251f23a3eb66468&quot;]&#125;&#x27; 查询资产，结果如下peer chaincode query -C alljoinchannel -n supply -c '&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;'： 1234567891011121314151617181920212223242526272829303132[ &#123; &quot;ID&quot;: &quot;asset001&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;一级供应商&quot;, &quot;amount&quot;: 200, &quot;createDate&quot;: &quot;2020-12-30T06:57:06.963617Z&quot;, &quot;endDate&quot;: &quot;2021-06-30T06:57:06.963617Z&quot;, &quot;contractHash&quot;: &quot;93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14&quot;, &quot;invoiceHash&quot;: &quot;83c02ac2d48c863dab2ccf6870455aadfc2cec073b8db269b517c879d76aa6d9&quot; &#125;, &#123; &quot;ID&quot;: &quot;asset0011&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;二级供应商1&quot;, &quot;amount&quot;: 500, &quot;createDate&quot;: &quot;2020-12-30T06:57:50.047189Z&quot;, &quot;endDate&quot;: &quot;2021-06-30T06:57:50.047189Z&quot;, &quot;contractHash&quot;: &quot;76307cd9d79c76a2a7894677692ce421ff1a31e32717a7de6f07deb5de395e7a&quot;, &quot;invoiceHash&quot;: &quot;792376c209f338959be4cf00c54dbf82662b90516082e23106faec4c43c69e49&quot; &#125;, &#123; &quot;ID&quot;: &quot;asset0012&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;二级供应商2&quot;, &quot;amount&quot;: 300, &quot;createDate&quot;: &quot;2020-12-30T06:58:33.143818Z&quot;, &quot;endDate&quot;: &quot;2021-06-30T06:58:33.143818Z&quot;, &quot;contractHash&quot;: &quot;f46555b7ddd1f8dd232bdc0dcbc5b1f34bdf1d4bb7c123a79a6ed628175f29bb&quot;, &quot;invoiceHash&quot;: &quot;f807fe6dc767be2e7021d41540114b33b30fa7784f6de5521251f23a3eb66468&quot; &#125;] 转账金额大于凭证资产的金额(期待错误) 出现错误： 12(base) w:supply-finance apple$ peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n supply --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;TransferAssetByID&quot;,&quot;Args&quot;:[&quot;asset001&quot;, &quot;asset0013&quot;, &quot;二级供应商2&quot;, &quot;300&quot;, &quot;f46555b7ddd1f8dd232bdc0dcbc5b1f34bdf1d4bb7c123a79a6ed628175f29bb&quot;, &quot;f807fe6dc767be2e7021d41540114b33b30fa7784f6de5521251f23a3eb66468&quot;]&#125;&#x27;Error: endorsement failure during invoke. response: status:500 message:&quot;\\350\\275\\254\\350\\264\\246\\351\\207\\221\\351\\242\\235=300,\\344\\270\\215\\350\\203\\275\\350\\266\\205\\350\\277\\207\\350\\265\\204\\344\\272\\247\\347\\232\\204\\351\\207\\221\\351\\242\\235=200&quot; 错误信息解码如下： 转账金额等于凭证资产的金额（变更owner，不产生新的凭证资产） 一级供应商把剩余的200转给二级供应商2: 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;&#x2F;organizations&#x2F;ordererOrganizations&#x2F;supply.com&#x2F;orderers&#x2F;orderer.supply.com&#x2F;msp&#x2F;tlscacerts&#x2F;tlsca.supply.com-cert.pem -C alljoinchannel -n supply --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;&#x2F;organizations&#x2F;peerOrganizations&#x2F;f1.supply.com&#x2F;peers&#x2F;peer0.f1.supply.com&#x2F;tls&#x2F;ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;&#x2F;organizations&#x2F;peerOrganizations&#x2F;s1.supply.com&#x2F;peers&#x2F;peer0.s1.supply.com&#x2F;tls&#x2F;ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;&#x2F;organizations&#x2F;peerOrganizations&#x2F;s2.supply.com&#x2F;peers&#x2F;peer0.s2.supply.com&#x2F;tls&#x2F;ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;&#x2F;organizations&#x2F;peerOrganizations&#x2F;core.supply.com&#x2F;peers&#x2F;peer0.core.supply.com&#x2F;tls&#x2F;ca.crt -c &#39;&#123;&quot;function&quot;:&quot;TransferAssetByID&quot;,&quot;Args&quot;:[&quot;asset001&quot;, &quot;asset0013&quot;, &quot;二级供应商2&quot;, &quot;200&quot;, &quot;f46555b7ddd1f8dd232bdc0dcbc5b1f34bdf1d4bb7c123a79a6ed628175f29bb&quot;, &quot;f807fe6dc767be2e7021d41540114b33b30fa7784f6de5521251f23a3eb66468&quot;]&#125;&#39; 查询资产，结果如下peer chaincode query -C alljoinchannel -n supply -c '&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;'： 1234567891011121314151617181920212223242526272829303132[ &#123; &quot;ID&quot;: &quot;asset001&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;二级供应商2&quot;, &quot;amount&quot;: 200, &quot;createDate&quot;: &quot;2020-12-30T06:57:06.963617Z&quot;, &quot;endDate&quot;: &quot;2021-06-30T06:57:06.963617Z&quot;, &quot;contractHash&quot;: &quot;93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14&quot;, &quot;invoiceHash&quot;: &quot;83c02ac2d48c863dab2ccf6870455aadfc2cec073b8db269b517c879d76aa6d9&quot; &#125;, &#123; &quot;ID&quot;: &quot;asset0011&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;二级供应商1&quot;, &quot;amount&quot;: 500, &quot;createDate&quot;: &quot;2020-12-30T06:57:50.047189Z&quot;, &quot;endDate&quot;: &quot;2021-06-30T06:57:50.047189Z&quot;, &quot;contractHash&quot;: &quot;76307cd9d79c76a2a7894677692ce421ff1a31e32717a7de6f07deb5de395e7a&quot;, &quot;invoiceHash&quot;: &quot;792376c209f338959be4cf00c54dbf82662b90516082e23106faec4c43c69e49&quot; &#125;, &#123; &quot;ID&quot;: &quot;asset0012&quot;, &quot;issuer&quot;: &quot;核心企业&quot;, &quot;owner&quot;: &quot;二级供应商2&quot;, &quot;amount&quot;: 300, &quot;createDate&quot;: &quot;2020-12-30T06:58:33.143818Z&quot;, &quot;endDate&quot;: &quot;2021-06-30T06:58:33.143818Z&quot;, &quot;contractHash&quot;: &quot;f46555b7ddd1f8dd232bdc0dcbc5b1f34bdf1d4bb7c123a79a6ed628175f29bb&quot;, &quot;invoiceHash&quot;: &quot;f807fe6dc767be2e7021d41540114b33b30fa7784f6de5521251f23a3eb66468&quot; &#125;] 没有产生新的资产，而是把原来的资产的拥有者变更了。 注意：这样有个问题，合同hash和发票hash不应该还是原来的。 部署supply-v9到alljoinchannel通道 源码 与v8版本相比，增加删除资产的方法 123456789101112131415// DelState 删除资产func (s *SmartContract) DelState(ctx contractapi.TransactionContextInterface, assetIds ...string) error &#123; for _, assetID := range assetIds &#123; exists, err := s.AssetExists(ctx, assetID) if err != nil &#123; return nil &#125; if !exists &#123; return fmt.Errorf(&quot;assetID=%s的资产不存在&quot;, assetID) &#125; return ctx.GetStub().DelState(assetID) &#125; return nil&#125; 打包 1peer lifecycle chaincode package supply.18.tar.gz --path /Users/apple/code/open-source/blockchain/hyperledger/supply-finance-chaincode/ --lang golang --label secured_supply_22.0 安装链码包 每个peer都要安装：peer lifecycle chaincode install supply.18.tar.gz 批准链码定义 查看已经安装的chaincode 1peer lifecycle chaincode queryinstalled 将链码的信息保存为一个变量，两个组织都需要定义此变量： 1export CC_PACKAGE_ID=secured_supply_22.0:e815ca2d270dea029bc6992952140b1288a440aba8c430853f72eee7d5de24a7 批准链码定义 每个peer都要执行此命令： 1peer lifecycle chaincode approveformyorg -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID alljoinchannel --name secured_supply --version 22.0 --package-id $CC_PACKAGE_ID --sequence 22 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 将链码定义提交到通道 检查channel上的成员是否已经批准了链码定义： 1peer lifecycle chaincode checkcommitreadiness --channelID alljoinchannel --name secured_supply --version 22.0 --sequence 22 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --output json 在所有组织都批准之后，执行下面的命令将链码定义提交到通道： 1peer lifecycle chaincode commit -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID alljoinchannel --name secured_supply --version 22.0 --sequence 22 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt 使用 peer lifecycle chaincode querycommitted 命令来确认链码定义已经提交到通道。 1peer lifecycle chaincode querycommitted --channelID alljoinchannel --name secured_supply --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 调用链码 调用链码之前先生成测试的合同hash值和发票hash值如下： 12345683c02ac2d48c863dab2ccf6870455aadfc2cec073b8db269b517c879d76aa6d9 CORE_AND_F1_INVOICE.txt93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14 CORE_AND_F1_CONTRACT.txt76307cd9d79c76a2a7894677692ce421ff1a31e32717a7de6f07deb5de395e7a f1_and_s1_contract.txt792376c209f338959be4cf00c54dbf82662b90516082e23106faec4c43c69e49 f1_and_s1_invoice.txtf46555b7ddd1f8dd232bdc0dcbc5b1f34bdf1d4bb7c123a79a6ed628175f29bb f1_and_s2_contract.txtf807fe6dc767be2e7021d41540114b33b30fa7784f6de5521251f23a3eb66468 f1_and_s2_invoice.txt 删除资产 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n supply --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;DelState&quot;,&quot;Args&quot;:[&quot;asset001 asset0011 asset0012 asset003 asset0031 asset00311&quot;]&#125;&#x27; 错误信息记录： 12(base) w:supply-finance apple$ peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n supply --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;DelState&quot;,&quot;Args&quot;:[&quot;asset001 asset0011 asset0012 asset003 asset0031 asset00311&quot;]&#125;&#x27;Error: endorsement failure during invoke. response: status:500 message:&quot;Error managing parameter param0. Conversion error. Value asset001 asset0011 asset0012 asset003 asset0031 asset00311 was not passed in expected format []string&quot; **错误原因：**因为方法使用的是可变长参数，但是不知道该怎么给他传参数 部署supply-v9.1到alljoinchannel通道 源码 与v9版本相比，修改删除资产的方法为删除单个资产 1234567891011// DelState 删除资产func (s *SmartContract) DelState(ctx contractapi.TransactionContextInterface, assetID string) error &#123; exists, err := s.AssetExists(ctx, assetID) if err != nil &#123; return nil &#125; if !exists &#123; return fmt.Errorf(&quot;assetID=%s的资产不存在&quot;, assetID) &#125; return ctx.GetStub().DelState(assetID)&#125; 打包 1peer lifecycle chaincode package supply.9.1.tar.gz --path /Users/apple/code/open-source/blockchain/hyperledger/supply-finance/chaincode-go/ --lang golang --label supply_9.1 安装链码包 每个peer都要安装：peer lifecycle chaincode install supply.9.1.tar.gz 批准链码定义 查看已经安装的chaincode 1peer lifecycle chaincode queryinstalled 将链码的信息保存为一个变量，两个组织都需要定义此变量： 1export CC_PACKAGE_ID=supply_9.1:f733e8484c17cb415e38ac1fb14ed646622f2980762906c97d6e7e1c1a90f2c3 批准链码定义 每个peer都要执行此命令： 1peer lifecycle chaincode approveformyorg -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID alljoinchannel --name supply --version 9.1 --package-id $CC_PACKAGE_ID --sequence 4 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 将链码定义提交到通道 检查channel上的成员是否已经批准了链码定义： 1peer lifecycle chaincode checkcommitreadiness --channelID alljoinchannel --name supply --version 9.1 --sequence 4 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --output json 在所有组织都批准之后，执行下面的命令将链码定义提交到通道： 1peer lifecycle chaincode commit -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --channelID alljoinchannel --name supply --version 9.1 --sequence 4 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt 使用 peer lifecycle chaincode querycommitted 命令来确认链码定义已经提交到通道。 1peer lifecycle chaincode querycommitted --channelID alljoinchannel --name supply --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem 调用链码 调用链码之前先生成测试的合同hash值和发票hash值如下： 12345683c02ac2d48c863dab2ccf6870455aadfc2cec073b8db269b517c879d76aa6d9 CORE_AND_F1_INVOICE.txt93b46869be90a6b1f688357965f89b5a8a5e32bf13710fb4ad00e25cca0f0b14 CORE_AND_F1_CONTRACT.txt76307cd9d79c76a2a7894677692ce421ff1a31e32717a7de6f07deb5de395e7a f1_and_s1_contract.txt792376c209f338959be4cf00c54dbf82662b90516082e23106faec4c43c69e49 f1_and_s1_invoice.txtf46555b7ddd1f8dd232bdc0dcbc5b1f34bdf1d4bb7c123a79a6ed628175f29bb f1_and_s2_contract.txtf807fe6dc767be2e7021d41540114b33b30fa7784f6de5521251f23a3eb66468 f1_and_s2_invoice.txt 删除资产 资产ID列表：“asset001 asset0011 asset0012 asset003 asset0031 asset00311” 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n supply --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;DelState&quot;,&quot;Args&quot;:[&quot;asset00311&quot;]&#125;&#x27; 删除之后查询： 1peer chaincode query -C alljoinchannel -n supply -c &#x27;&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;&#x27; 返回的资产列表为空，删除方法验证成功。 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;Practice_SmartContract:InitLedger&quot;,&quot;Args&quot;:[]&#125;&#x27; 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt --peerAddresses localhost:8055 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s1.supply.com/peers/peer0.s1.supply.com/tls/ca.crt --peerAddresses localhost:8151 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/s2.supply.com/peers/peer0.s2.supply.com/tls/ca.crt --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;Practice_SmartContract:SomeStubMethod&quot;,&quot;Args&quot;:[&quot;asset1&quot;]&#125;&#x27; 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C alljoinchannel -n secured_supply --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;Practice_SmartContract:InitLedger&quot;,&quot;Args&quot;:[]&#125;&#x27;","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"项目实践-供应链金融","slug":"区块链/Hyperledger-Fabric/项目实践-供应链金融","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5-%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"peer","slug":"peer","permalink":"https://guozhe001.github.io/tags/peer/"},{"name":"chaincode","slug":"chaincode","permalink":"https://guozhe001.github.io/tags/chaincode/"},{"name":"供应链金融","slug":"供应链金融","permalink":"https://guozhe001.github.io/tags/%E4%BE%9B%E5%BA%94%E9%93%BE%E9%87%91%E8%9E%8D/"}]},{"title":"ClientIdentity接口练习","slug":"blockchain/fabric/智能合约API学习/ClientIdentity接口练习","date":"2024-11-22T06:32:06.495Z","updated":"2024-11-22T06:32:06.495Z","comments":true,"path":"2024/11/22/blockchain/fabric/智能合约API学习/ClientIdentity接口练习/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6API%E5%AD%A6%E4%B9%A0/ClientIdentity%E6%8E%A5%E5%8F%A3%E7%BB%83%E4%B9%A0/","excerpt":"","text":"学习/github.com/hyperledger/fabric-chaincode-go/pkg/cid/interfaces.go中的ClientIdentity接口，源码如下，比较简单： 源码 12345678910111213141516171819202122232425262728293031323334// ClientIdentity represents information about the identity that submitted the// transaction// ClientIdentity表示提交交易的身份的信息type ClientIdentity interface &#123; // GetID returns the ID associated with the invoking identity. This ID // is guaranteed to be unique within the MSP. // 返回与调用者身份关联的ID。该ID在MSP中保证是唯一的。 GetID() (string, error) // Return the MSP ID of the client // 获取客户端的MSP的ID GetMSPID() (string, error) // GetAttributeValue returns the value of the client&#x27;s attribute named `attrName`. // If the client possesses the attribute, `found` is true and `value` equals the // value of the attribute. // If the client does not possess the attribute, `found` is false and `value` // equals &quot;&quot;. // 返回名为`attrName`的客户端的属性信息 // 如果客户端有这个属性，返回值`found`等于true并且返回值`value`等于这个属性。 // 如果这个客户端不拥有这个属性，`found`等于false并且`value`等于&quot;&quot;。 GetAttributeValue(attrName string) (value string, found bool, err error) // AssertAttributeValue verifies that the client has the attribute named `attrName` // with a value of `attrValue`; otherwise, an error is returned. // 验证客户端是否有名为`attrName`的属性，并且值为`attrValue`；如果没有或者值不一致则返回一个error AssertAttributeValue(attrName, attrValue string) error // GetX509Certificate returns the X509 certificate associated with the client, // or nil if it was not identified by an X509 certificate. // 返回与客户端关联的X509证书，如果没有被X509证书标识，则返回nil。 GetX509Certificate() (*x509.Certificate, error)&#125; 测试代码： 123456789101112131415161718192021222324252627282930313233343536373839404142package mainimport ( &quot;github.com/hyperledger/fabric-contract-api-go/contractapi&quot; &quot;log&quot;)// ClientIdentityPractice ClientIdentity接口提供的方法练习func (s *SmartContract) ClientIdentityPractice(ctx contractapi.TransactionContextInterface) error &#123; log.Println(&quot;ClientIdentityPractice==================start=====================&quot;) clientIdentity := ctx.GetClientIdentity() id, err := clientIdentity.GetID() if err != nil &#123; return err &#125; log.Printf(&quot;clientIdentity.GetID()=%s&quot;, id) mspid, err := clientIdentity.GetMSPID() if err != nil &#123; return err &#125; log.Printf(&quot;clientIdentity.GetMSPID()=%s&quot;, mspid) certificate, err := clientIdentity.GetX509Certificate() if err != nil &#123; return err &#125; log.Printf(&quot;clientIdentity.GetX509Certificate()=%#v&quot;, certificate) value, found, err := clientIdentity.GetAttributeValue(&quot;test&quot;) if err != nil &#123; return err &#125; if found &#123; log.Printf(&quot;clientIdentity.GetAttributeValue(\\&quot;test\\&quot;)=%s&quot;, value) &#125; if err := clientIdentity.AssertAttributeValue(&quot;test&quot;, &quot;hello&quot;); err != nil &#123; log.Printf(&quot;clientIdentity.AssertAttributeValue(\\&quot;test\\&quot;, \\&quot;hello\\&quot;) error!&quot;) return err &#125; log.Println(&quot;ClientIdentityPractice===================end======================&quot;) return nil&#125; 测试日志 123452021&#x2F;01&#x2F;25 03:42:33 ClientIdentityPractice&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;start&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;2021&#x2F;01&#x2F;25 03:42:33 clientIdentity.GetID()&#x3D;eDUwOTo6Q049QWRtaW5AczIuc3VwcGx5LmNvbSxMPVNhbiBGcmFuY2lzY28sU1Q9Q2FsaWZvcm5pYSxDPVVTOjpDTj1jYS5zMi5zdXBwbHkuY29tLE89czIuc3VwcGx5LmNvbSxMPVNhbiBGcmFuY2lzY28sU1Q9Q2FsaWZvcm5pYSxDPVVT2021&#x2F;01&#x2F;25 03:42:33 clientIdentity.GetMSPID()&#x3D;GylSOrg2MSP2021&#x2F;01&#x2F;25 03:42:33 clientIdentity.GetX509Certificate()&#x3D;&amp;x509.Certificate&#123;Raw:[]uint8&#123;0x30, 0x82, 0x2, 0x11, 0x30, 0x82, 0x1, 0xb7, 0xa0, 0x3, 0x2, 0x1, 0x2, 0x2, 0x11, 0x0, 0x9c, 0x36, 0x61, 0x42, 0xa4, 0x9b, 0x22, 0xae, 0xb0, 0x61, 0xe6, 0xdf, 0x70, 0xfb, 0x2e, 0x19, 0x30, 0xa, 0x6, 0x8, 0x2a, 0x86, 0x48, 0xce, 0x3d, 0x4, 0x3, 0x2, 0x30, 0x6d, 0x31, 0xb, 0x30, 0x9, 0x6, 0x3, 0x55, 0x4, 0x6, 0x13, 0x2, 0x55, 0x53, 0x31, 0x13, 0x30, 0x11, 0x6, 0x3, 0x55, 0x4, 0x8, 0x13, 0xa, 0x43, 0x61, 0x6c, 0x69, 0x66, 0x6f, 0x72, 0x6e, 0x69, 0x61, 0x31, 0x16, 0x30, 0x14, 0x6, 0x3, 0x55, 0x4, 0x7, 0x13, 0xd, 0x53, 0x61, 0x6e, 0x20, 0x46, 0x72, 0x61, 0x6e, 0x63, 0x69, 0x73, 0x63, 0x6f, 0x31, 0x16, 0x30, 0x14, 0x6, 0x3, 0x55, 0x4, 0xa, 0x13, 0xd, 0x73, 0x32, 0x2e, 0x73, 0x75, 0x70, 0x70, 0x6c, 0x79, 0x2e, 0x63, 0x6f, 0x6d, 0x31, 0x19, 0x30, 0x17, 0x6, 0x3, 0x55, 0x4, 0x3, 0x13, 0x10, 0x63, 0x61, 0x2e, 0x73, 0x32, 0x2e, 0x73, 0x75, 0x70, 0x70, 0x6c, 0x79, 0x2e, 0x63, 0x6f, 0x6d, 0x30, 0x1e, 0x17, 0xd, 0x32, 0x31, 0x30, 0x31, 0x30, 0x37, 0x30, 0x38, 0x33, 0x31, 0x30, 0x30, 0x5a, 0x17, 0xd, 0x33, 0x31, 0x30, 0x31, 0x30, 0x35, 0x30, 0x38, 0x33, 0x31, 0x30, 0x30, 0x5a, 0x30, 0x58, 0x31, 0xb, 0x30, 0x9, 0x6, 0x3, 0x55, 0x4, 0x6, 0x13, 0x2, 0x55, 0x53, 0x31, 0x13, 0x30, 0x11, 0x6, 0x3, 0x55, 0x4, 0x8, 0x13, 0xa, 0x43, 0x61, 0x6c, 0x69, 0x66, 0x6f, 0x72, 0x6e, 0x69, 0x61, 0x31, 0x16, 0x30, 0x14, 0x6, 0x3, 0x55, 0x4, 0x7, 0x13, 0xd, 0x53, 0x61, 0x6e, 0x20, 0x46, 0x72, 0x61, 0x6e, 0x63, 0x69, 0x73, 0x63, 0x6f, 0x31, 0x1c, 0x30, 0x1a, 0x6, 0x3, 0x55, 0x4, 0x3, 0xc, 0x13, 0x41, 0x64, 0x6d, 0x69, 0x6e, 0x40, 0x73, 0x32, 0x2e, 0x73, 0x75, 0x70, 0x70, 0x6c, 0x79, 0x2e, 0x63, 0x6f, 0x6d, 0x30, 0x59, 0x30, 0x13, 0x6, 0x7, 0x2a, 0x86, 0x48, 0xce, 0x3d, 0x2, 0x1, 0x6, 0x8, 0x2a, 0x86, 0x48, 0xce, 0x3d, 0x3, 0x1, 0x7, 0x3, 0x42, 0x0, 0x4, 0x9e, 0x80, 0x9f, 0x9b, 0xc7, 0x9a, 0xe8, 0x35, 0x60, 0x12, 0x14, 0x5c, 0xab, 0x83, 0xe7, 0x46, 0x49, 0xef, 0xd4, 0xe2, 0xc0, 0x39, 0x16, 0xe6, 0xe1, 0x2b, 0xd9, 0x99, 0x17, 0x53, 0x91, 0x26, 0x5f, 0x5, 0x65, 0xc7, 0x0, 0x8e, 0x2a, 0x97, 0xea, 0x28, 0xea, 0xf5, 0x5d, 0xd9, 0x34, 0xd, 0x63, 0x25, 0x1, 0x3, 0xd0, 0x23, 0x17, 0x97, 0x92, 0xd7, 0x55, 0x4, 0x9c, 0x45, 0x73, 0x82, 0xa3, 0x4d, 0x30, 0x4b, 0x30, 0xe, 0x6, 0x3, 0x55, 0x1d, 0xf, 0x1, 0x1, 0xff, 0x4, 0x4, 0x3, 0x2, 0x7, 0x80, 0x30, 0xc, 0x6, 0x3, 0x55, 0x1d, 0x13, 0x1, 0x1, 0xff, 0x4, 0x2, 0x30, 0x0, 0x30, 0x2b, 0x6, 0x3, 0x55, 0x1d, 0x23, 0x4, 0x24, 0x30, 0x22, 0x80, 0x20, 0x63, 0xbd, 0xab, 0x9a, 0x9c, 0xa7, 0x4f, 0x3d, 0x8b, 0xb6, 0xc3, 0xab, 0xc, 0xb1, 0x45, 0x87, 0x60, 0x69, 0x7e, 0xb9, 0x6, 0xfb, 0x38, 0x5f, 0x9c, 0x2, 0xb1, 0x75, 0x9b, 0xc6, 0x3d, 0xfb, 0x30, 0xa, 0x6, 0x8, 0x2a, 0x86, 0x48, 0xce, 0x3d, 0x4, 0x3, 0x2, 0x3, 0x48, 0x0, 0x30, 0x45, 0x2, 0x21, 0x0, 0x91, 0x4, 0x2f, 0xee, 0x17, 0xca, 0x28, 0x68, 0xb4, 0x33, 0x48, 0x3a, 0x3a, 0x7b, 0x9f, 0xb8, 0x51, 0xb0, 0x6a, 0x8d, 0x28, 0xb9, 0x31, 0x4c, 0xb7, 0x21, 0x87, 0xd5, 0xac, 0xce, 0x6d, 0x1d, 0x2, 0x20, 0x68, 0x61, 0xca, 0x5d, 0xc2, 0x99, 0x63, 0xba, 0xb4, 0x4f, 0x1b, 0x3a, 0x2e, 0xc6, 0xed, 0x6b, 0x25, 0xba, 0x91, 0x63, 0xce, 0x1, 0xe7, 0xba, 0x67, 0x55, 0xbc, 0xb6, 0x8a, 0x76, 0x54, 0x37&#125;, RawTBSCertificate:[]uint8&#123;0x30, 0x82, 0x1, 0xb7, 0xa0, 0x3, 0x2, 0x1, 0x2, 0x2, 0x11, 0x0, 0x9c, 0x36, 0x61, 0x42, 0xa4, 0x9b, 0x22, 0xae, 0xb0, 0x61, 0xe6, 0xdf, 0x70, 0xfb, 0x2e, 0x19, 0x30, 0xa, 0x6, 0x8, 0x2a, 0x86, 0x48, 0xce, 0x3d, 0x4, 0x3, 0x2, 0x30, 0x6d, 0x31, 0xb, 0x30, 0x9, 0x6, 0x3, 0x55, 0x4, 0x6, 0x13, 0x2, 0x55, 0x53, 0x31, 0x13, 0x30, 0x11, 0x6, 0x3, 0x55, 0x4, 0x8, 0x13, 0xa, 0x43, 0x61, 0x6c, 0x69, 0x66, 0x6f, 0x72, 0x6e, 0x69, 0x61, 0x31, 0x16, 0x30, 0x14, 0x6, 0x3, 0x55, 0x4, 0x7, 0x13, 0xd, 0x53, 0x61, 0x6e, 0x20, 0x46, 0x72, 0x61, 0x6e, 0x63, 0x69, 0x73, 0x63, 0x6f, 0x31, 0x16, 0x30, 0x14, 0x6, 0x3, 0x55, 0x4, 0xa, 0x13, 0xd, 0x73, 0x32, 0x2e, 0x73, 0x75, 0x70, 0x70, 0x6c, 0x79, 0x2e, 0x63, 0x6f, 0x6d, 0x31, 0x19, 0x30, 0x17, 0x6, 0x3, 0x55, 0x4, 0x3, 0x13, 0x10, 0x63, 0x61, 0x2e, 0x73, 0x32, 0x2e, 0x73, 0x75, 0x70, 0x70, 0x6c, 0x79, 0x2e, 0x63, 0x6f, 0x6d, 0x30, 0x1e, 0x17, 0xd, 0x32, 0x31, 0x30, 0x31, 0x30, 0x37, 0x30, 0x38, 0x33, 0x31, 0x30, 0x30, 0x5a, 0x17, 0xd, 0x33, 0x31, 0x30, 0x31, 0x30, 0x35, 0x30, 0x38, 0x33, 0x31, 0x30, 0x30, 0x5a, 0x30, 0x58, 0x31, 0xb, 0x30, 0x9, 0x6, 0x3, 0x55, 0x4, 0x6, 0x13, 0x2, 0x55, 0x53, 0x31, 0x13, 0x30, 0x11, 0x6, 0x3, 0x55, 0x4, 0x8, 0x13, 0xa, 0x43, 0x61, 0x6c, 0x69, 0x66, 0x6f, 0x72, 0x6e, 0x69, 0x61, 0x31, 0x16, 0x30, 0x14, 0x6, 0x3, 0x55, 0x4, 0x7, 0x13, 0xd, 0x53, 0x61, 0x6e, 0x20, 0x46, 0x72, 0x61, 0x6e, 0x63, 0x69, 0x73, 0x63, 0x6f, 0x31, 0x1c, 0x30, 0x1a, 0x6, 0x3, 0x55, 0x4, 0x3, 0xc, 0x13, 0x41, 0x64, 0x6d, 0x69, 0x6e, 0x40, 0x73, 0x32, 0x2e, 0x73, 0x75, 0x70, 0x70, 0x6c, 0x79, 0x2e, 0x63, 0x6f, 0x6d, 0x30, 0x59, 0x30, 0x13, 0x6, 0x7, 0x2a, 0x86, 0x48, 0xce, 0x3d, 0x2, 0x1, 0x6, 0x8, 0x2a, 0x86, 0x48, 0xce, 0x3d, 0x3, 0x1, 0x7, 0x3, 0x42, 0x0, 0x4, 0x9e, 0x80, 0x9f, 0x9b, 0xc7, 0x9a, 0xe8, 0x35, 0x60, 0x12, 0x14, 0x5c, 0xab, 0x83, 0xe7, 0x46, 0x49, 0xef, 0xd4, 0xe2, 0xc0, 0x39, 0x16, 0xe6, 0xe1, 0x2b, 0xd9, 0x99, 0x17, 0x53, 0x91, 0x26, 0x5f, 0x5, 0x65, 0xc7, 0x0, 0x8e, 0x2a, 0x97, 0xea, 0x28, 0xea, 0xf5, 0x5d, 0xd9, 0x34, 0xd, 0x63, 0x25, 0x1, 0x3, 0xd0, 0x23, 0x17, 0x97, 0x92, 0xd7, 0x55, 0x4, 0x9c, 0x45, 0x73, 0x82, 0xa3, 0x4d, 0x30, 0x4b, 0x30, 0xe, 0x6, 0x3, 0x55, 0x1d, 0xf, 0x1, 0x1, 0xff, 0x4, 0x4, 0x3, 0x2, 0x7, 0x80, 0x30, 0xc, 0x6, 0x3, 0x55, 0x1d, 0x13, 0x1, 0x1, 0xff, 0x4, 0x2, 0x30, 0x0, 0x30, 0x2b, 0x6, 0x3, 0x55, 0x1d, 0x23, 0x4, 0x24, 0x30, 0x22, 0x80, 0x20, 0x63, 0xbd, 0xab, 0x9a, 0x9c, 0xa7, 0x4f, 0x3d, 0x8b, 0xb6, 0xc3, 0xab, 0xc, 0xb1, 0x45, 0x87, 0x60, 0x69, 0x7e, 0xb9, 0x6, 0xfb, 0x38, 0x5f, 0x9c, 0x2, 0xb1, 0x75, 0x9b, 0xc6, 0x3d, 0xfb&#125;, RawSubjectPublicKeyInfo:[]uint8&#123;0x30, 0x59, 0x30, 0x13, 0x6, 0x7, 0x2a, 0x86, 0x48, 0xce, 0x3d, 0x2, 0x1, 0x6, 0x8, 0x2a, 0x86, 0x48, 0xce, 0x3d, 0x3, 0x1, 0x7, 0x3, 0x42, 0x0, 0x4, 0x9e, 0x80, 0x9f, 0x9b, 0xc7, 0x9a, 0xe8, 0x35, 0x60, 0x12, 0x14, 0x5c, 0xab, 0x83, 0xe7, 0x46, 0x49, 0xef, 0xd4, 0xe2, 0xc0, 0x39, 0x16, 0xe6, 0xe1, 0x2b, 0xd9, 0x99, 0x17, 0x53, 0x91, 0x26, 0x5f, 0x5, 0x65, 0xc7, 0x0, 0x8e, 0x2a, 0x97, 0xea, 0x28, 0xea, 0xf5, 0x5d, 0xd9, 0x34, 0xd, 0x63, 0x25, 0x1, 0x3, 0xd0, 0x23, 0x17, 0x97, 0x92, 0xd7, 0x55, 0x4, 0x9c, 0x45, 0x73, 0x82&#125;, RawSubject:[]uint8&#123;0x30, 0x58, 0x31, 0xb, 0x30, 0x9, 0x6, 0x3, 0x55, 0x4, 0x6, 0x13, 0x2, 0x55, 0x53, 0x31, 0x13, 0x30, 0x11, 0x6, 0x3, 0x55, 0x4, 0x8, 0x13, 0xa, 0x43, 0x61, 0x6c, 0x69, 0x66, 0x6f, 0x72, 0x6e, 0x69, 0x61, 0x31, 0x16, 0x30, 0x14, 0x6, 0x3, 0x55, 0x4, 0x7, 0x13, 0xd, 0x53, 0x61, 0x6e, 0x20, 0x46, 0x72, 0x61, 0x6e, 0x63, 0x69, 0x73, 0x63, 0x6f, 0x31, 0x1c, 0x30, 0x1a, 0x6, 0x3, 0x55, 0x4, 0x3, 0xc, 0x13, 0x41, 0x64, 0x6d, 0x69, 0x6e, 0x40, 0x73, 0x32, 0x2e, 0x73, 0x75, 0x70, 0x70, 0x6c, 0x79, 0x2e, 0x63, 0x6f, 0x6d&#125;, RawIssuer:[]uint8&#123;0x30, 0x6d, 0x31, 0xb, 0x30, 0x9, 0x6, 0x3, 0x55, 0x4, 0x6, 0x13, 0x2, 0x55, 0x53, 0x31, 0x13, 0x30, 0x11, 0x6, 0x3, 0x55, 0x4, 0x8, 0x13, 0xa, 0x43, 0x61, 0x6c, 0x69, 0x66, 0x6f, 0x72, 0x6e, 0x69, 0x61, 0x31, 0x16, 0x30, 0x14, 0x6, 0x3, 0x55, 0x4, 0x7, 0x13, 0xd, 0x53, 0x61, 0x6e, 0x20, 0x46, 0x72, 0x61, 0x6e, 0x63, 0x69, 0x73, 0x63, 0x6f, 0x31, 0x16, 0x30, 0x14, 0x6, 0x3, 0x55, 0x4, 0xa, 0x13, 0xd, 0x73, 0x32, 0x2e, 0x73, 0x75, 0x70, 0x70, 0x6c, 0x79, 0x2e, 0x63, 0x6f, 0x6d, 0x31, 0x19, 0x30, 0x17, 0x6, 0x3, 0x55, 0x4, 0x3, 0x13, 0x10, 0x63, 0x61, 0x2e, 0x73, 0x32, 0x2e, 0x73, 0x75, 0x70, 0x70, 0x6c, 0x79, 0x2e, 0x63, 0x6f, 0x6d&#125;, Signature:[]uint8&#123;0x30, 0x45, 0x2, 0x21, 0x0, 0x91, 0x4, 0x2f, 0xee, 0x17, 0xca, 0x28, 0x68, 0xb4, 0x33, 0x48, 0x3a, 0x3a, 0x7b, 0x9f, 0xb8, 0x51, 0xb0, 0x6a, 0x8d, 0x28, 0xb9, 0x31, 0x4c, 0xb7, 0x21, 0x87, 0xd5, 0xac, 0xce, 0x6d, 0x1d, 0x2, 0x20, 0x68, 0x61, 0xca, 0x5d, 0xc2, 0x99, 0x63, 0xba, 0xb4, 0x4f, 0x1b, 0x3a, 0x2e, 0xc6, 0xed, 0x6b, 0x25, 0xba, 0x91, 0x63, 0xce, 0x1, 0xe7, 0xba, 0x67, 0x55, 0xbc, 0xb6, 0x8a, 0x76, 0x54, 0x37&#125;, SignatureAlgorithm:10, PublicKeyAlgorithm:3, PublicKey:(*ecdsa.PublicKey)(0xc0003f4980), Version:3, SerialNumber:207641924046541125914056390919893757465, Issuer:pkix.Name&#123;Country:[]string&#123;&quot;US&quot;&#125;, Organization:[]string&#123;&quot;s2.supply.com&quot;&#125;, OrganizationalUnit:[]string(nil), Locality:[]string&#123;&quot;San Francisco&quot;&#125;, Province:[]string&#123;&quot;California&quot;&#125;, StreetAddress:[]string(nil), PostalCode:[]string(nil), SerialNumber:&quot;&quot;, CommonName:&quot;ca.s2.supply.com&quot;, Names:[]pkix.AttributeTypeAndValue&#123;pkix.AttributeTypeAndValue&#123;Type:asn1.ObjectIdentifier&#123;2, 5, 4, 6&#125;, Value:&quot;US&quot;&#125;, pkix.AttributeTypeAndValue&#123;Type:asn1.ObjectIdentifier&#123;2, 5, 4, 8&#125;, Value:&quot;California&quot;&#125;, pkix.AttributeTypeAndValue&#123;Type:asn1.ObjectIdentifier&#123;2, 5, 4, 7&#125;, Value:&quot;San Francisco&quot;&#125;, pkix.AttributeTypeAndValue&#123;Type:asn1.ObjectIdentifier&#123;2, 5, 4, 10&#125;, Value:&quot;s2.supply.com&quot;&#125;, pkix.AttributeTypeAndValue&#123;Type:asn1.ObjectIdentifier&#123;2, 5, 4, 3&#125;, Value:&quot;ca.s2.supply.com&quot;&#125;&#125;, ExtraNames:[]pkix.AttributeTypeAndValue(nil)&#125;, Subject:pkix.Name&#123;Country:[]string&#123;&quot;US&quot;&#125;, Organization:[]string(nil), OrganizationalUnit:[]string(nil), Locality:[]string&#123;&quot;San Francisco&quot;&#125;, Province:[]string&#123;&quot;California&quot;&#125;, StreetAddress:[]string(nil), PostalCode:[]string(nil), SerialNumber:&quot;&quot;, CommonName:&quot;Admin@s2.supply.com&quot;, Names:[]pkix.AttributeTypeAndValue&#123;pkix.AttributeTypeAndValue&#123;Type:asn1.ObjectIdentifier&#123;2, 5, 4, 6&#125;, Value:&quot;US&quot;&#125;, pkix.AttributeTypeAndValue&#123;Type:asn1.ObjectIdentifier&#123;2, 5, 4, 8&#125;, Value:&quot;California&quot;&#125;, pkix.AttributeTypeAndValue&#123;Type:asn1.ObjectIdentifier&#123;2, 5, 4, 7&#125;, Value:&quot;San Francisco&quot;&#125;, pkix.AttributeTypeAndValue&#123;Type:asn1.ObjectIdentifier&#123;2, 5, 4, 3&#125;, Value:&quot;Admin@s2.supply.com&quot;&#125;&#125;, ExtraNames:[]pkix.AttributeTypeAndValue(nil)&#125;, NotBefore:time.Time&#123;wall:0x0, ext:63745605060, loc:(*time.Location)(nil)&#125;, NotAfter:time.Time&#123;wall:0x0, ext:64060965060, loc:(*time.Location)(nil)&#125;, KeyUsage:1, Extensions:[]pkix.Extension&#123;pkix.Extension&#123;Id:asn1.ObjectIdentifier&#123;2, 5, 29, 15&#125;, Critical:true, Value:[]uint8&#123;0x3, 0x2, 0x7, 0x80&#125;&#125;, pkix.Extension&#123;Id:asn1.ObjectIdentifier&#123;2, 5, 29, 19&#125;, Critical:true, Value:[]uint8&#123;0x30, 0x0&#125;&#125;, pkix.Extension&#123;Id:asn1.ObjectIdentifier&#123;2, 5, 29, 35&#125;, Critical:false, Value:[]uint8&#123;0x30, 0x22, 0x80, 0x20, 0x63, 0xbd, 0xab, 0x9a, 0x9c, 0xa7, 0x4f, 0x3d, 0x8b, 0xb6, 0xc3, 0xab, 0xc, 0xb1, 0x45, 0x87, 0x60, 0x69, 0x7e, 0xb9, 0x6, 0xfb, 0x38, 0x5f, 0x9c, 0x2, 0xb1, 0x75, 0x9b, 0xc6, 0x3d, 0xfb&#125;&#125;&#125;, ExtraExtensions:[]pkix.Extension(nil), UnhandledCriticalExtensions:[]asn1.ObjectIdentifier(nil), ExtKeyUsage:[]x509.ExtKeyUsage(nil), UnknownExtKeyUsage:[]asn1.ObjectIdentifier(nil), BasicConstraintsValid:true, IsCA:false, MaxPathLen:-1, MaxPathLenZero:false, SubjectKeyId:[]uint8(nil), AuthorityKeyId:[]uint8&#123;0x63, 0xbd, 0xab, 0x9a, 0x9c, 0xa7, 0x4f, 0x3d, 0x8b, 0xb6, 0xc3, 0xab, 0xc, 0xb1, 0x45, 0x87, 0x60, 0x69, 0x7e, 0xb9, 0x6, 0xfb, 0x38, 0x5f, 0x9c, 0x2, 0xb1, 0x75, 0x9b, 0xc6, 0x3d, 0xfb&#125;, OCSPServer:[]string(nil), IssuingCertificateURL:[]string(nil), DNSNames:[]string(nil), EmailAddresses:[]string(nil), IPAddresses:[]net.IP(nil), URIs:[]*url.URL(nil), PermittedDNSDomainsCritical:false, PermittedDNSDomains:[]string(nil), ExcludedDNSDomains:[]string(nil), PermittedIPRanges:[]*net.IPNet(nil), ExcludedIPRanges:[]*net.IPNet(nil), PermittedEmailAddresses:[]string(nil), ExcludedEmailAddresses:[]string(nil), PermittedURIDomains:[]string(nil), ExcludedURIDomains:[]string(nil), CRLDistributionPoints:[]string(nil), PolicyIdentifiers:[]asn1.ObjectIdentifier(nil)&#125;2021&#x2F;01&#x2F;25 03:42:33 clientIdentity.AssertAttributeValue(&quot;test&quot;, &quot;hello&quot;) error! 测试日志分析 clientIdentity.GetID() 源码 12id := fmt.Sprintf(&quot;x509::%s::%s&quot;, getDN(&amp;c.cert.Subject), getDN(&amp;c.cert.Issuer))return base64.StdEncoding.EncodeToString([]byte(id)), nil 解码日志输出的base64编码的内容eDUwOTo6Q049QWRtaW5AczIuc3VwcGx5LmNvbSxMPVNhbiBGcmFuY2lzY28sU1Q9Q2FsaWZvcm5pYSxDPVVTOjpDTj1jYS5zMi5zdXBwbHkuY29tLE89czIuc3VwcGx5LmNvbSxMPVNhbiBGcmFuY2lzY28sU1Q9Q2FsaWZvcm5pYSxDPVVT结果如下，主要是证书里面的摘要信息： 1x509::CN=Admin@s2.supply.com,L=San Francisco,ST=California,C=US::CN=ca.s2.supply.com,O=s2.supply.com,L=San Francisco,ST=California,C=US clientIdentity.GetAttributeValue(“test”) log.Printf(&quot;clientIdentity.GetAttributeValue(\\&quot;test\\&quot;)=%s&quot;, value)这行日志没有打印，是因为没有查询到这个属性。","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"chaincode-API","slug":"区块链/Hyperledger-Fabric/chaincode-API","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/chaincode-API/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"ClientIdentity","slug":"ClientIdentity","permalink":"https://guozhe001.github.io/tags/ClientIdentity/"},{"name":"API","slug":"API","permalink":"https://guozhe001.github.io/tags/API/"}]},{"title":"contract_chaincode.go源码学习","slug":"blockchain/fabric/智能合约API学习/contract_chaincode.go源码学习","date":"2024-11-22T06:32:06.495Z","updated":"2024-11-22T06:32:06.495Z","comments":true,"path":"2024/11/22/blockchain/fabric/智能合约API学习/contract_chaincode.go源码学习/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6API%E5%AD%A6%E4%B9%A0/contract_chaincode.go%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"Chaincode如何被启用 定义智能合约 我们看下面的，名为SmartContract的结构，就是智能合约，你也可以起其他的名字，但是无论名字叫什么，智能合约都必须有一个内嵌的contractapi.Contract，我们看一下它的定义： 123type SmartContract struct &#123; contractapi.Contract&#125; 启动智能合约的入口 在每个chaincode中都必须有一个main方法，这个方法创建一个新的链码并调用它的Start()方法： 1234567891011func main() &#123; // 通过NewChaincode()方法创建链码 chaincode, err := contractapi.NewChaincode(new(SmartContract)) if err != nil &#123; log.Panicf(&quot;Error create transfer asset chaincode: %v&quot;, err) &#125; // 调用链码的Start()方法来启动链码 if err := chaincode.Start(); err != nil &#123; log.Panicf(&quot;Error starting asset chaincode: %v&quot;, err) &#125;&#125; 智能合约启动的源码 让我们完整的看一下contractapi的源码，源码路径：github.com/hyperledger/fabric-contract-api-go/contractapi/contract_chaincode.go 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477// Copyright the Hyperledger Fabric contributors. All rights reserved.// SPDX-License-Identifier: Apache-2.0package contractapiimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;reflect&quot; &quot;sort&quot; &quot;strings&quot; &quot;unicode&quot; &quot;github.com/hyperledger/fabric-chaincode-go/pkg/cid&quot; &quot;github.com/hyperledger/fabric-chaincode-go/shim&quot; &quot;github.com/hyperledger/fabric-contract-api-go/internal&quot; &quot;github.com/hyperledger/fabric-contract-api-go/internal/utils&quot; &quot;github.com/hyperledger/fabric-contract-api-go/metadata&quot; &quot;github.com/hyperledger/fabric-contract-api-go/serializer&quot; &quot;github.com/hyperledger/fabric-protos-go/peer&quot;)type contractChaincodeContract struct &#123; info metadata.InfoMetadata functions map[string]*internal.ContractFunction unknownTransaction *internal.TransactionHandler beforeTransaction *internal.TransactionHandler afterTransaction *internal.TransactionHandler transactionContextHandler reflect.Type&#125;// ContractChaincode a struct to meet the chaincode interface and provide routing of calls to contractstype ContractChaincode struct &#123; DefaultContract string contracts map[string]contractChaincodeContract metadata metadata.ContractChaincodeMetadata Info metadata.InfoMetadata TransactionSerializer serializer.TransactionSerializer&#125;// SystemContractName the name of the system smart contractconst SystemContractName = &quot;org.hyperledger.fabric&quot;// NewChaincode creates a new chaincode using contracts passed. The function parses each// of the passed functions and stores details about their make-up to be used by the chaincode.// Public functions of the contracts are stored and are made callable in the chaincode. The function// will error if contracts are invalid e.g. public functions take in illegal types. A system contract is added// to the chaincode which provides functionality for getting the metadata of the chaincode. The generated// metadata is a JSON formatted MetadataContractChaincode containing each contract as a name and details// of the public functions and types they take in/return. It also outlines version details for contracts and the// chaincode. If these are blank strings this is set to latest. The names for parameters do not match those used// in the functions, instead they are recorded as param0, param1, ..., paramN. If there exists a file// contract-metadata/metadata.json then this will overwrite the generated metadata. The contents of this file must// validate against the schema. The transaction serializer for the contract is set to be the JSONSerializer by// default. This can be updated using by changing the TransactionSerializer property// 使用传入的`ContractInterface`列表创建一个新的链码（说明链码并不是智能合约，链码包含了很多智能合约）。// 该函数解析每个被传递过来的`ContractInterface`的函数，并存储有关链码将使用的其组成的详细信息。// contracts的公共方法被存储并且可以在链码中调用这些公共方法。如果合约定义的不合法（如公共方法使用非法的类型）这个方法会报错。// 一个系统合约已添加到链码中，该合约提供了获取链码元数据的功能。// 生成的元数据是JSON格式的MetadataContractChaincode，其中包含每个合约的名称以及公共函数以及它们参数和返回的类型的详细信息。// 它还概述了合同和链码的版本详细信息。 如果这些是空白字符串，则将其设置为最新。// 元数据对于公共方法的描述的参数名称与原始定义的函数中使用的名称不匹配，而是记录为param0，param1，...，paramN。// 如果存在contract-metadata/metadata.json文件，那么它将覆盖生成的元数据。 该文件的内容必须根据架构进行验证。// 默认情况下，合约的交易序列化器设置为JSONSerializer。可以通过更改TransactionSerializer属性来更改。func NewChaincode(contracts ...ContractInterface) (*ContractChaincode, error) &#123; ciMethods := getCiMethods() // new一个ContractChaincode cc := new(ContractChaincode) // 设置cc的contracts为一个空map cc.contracts = make(map[string]contractChaincodeContract) // 遍历传入的合约列表 for _, contract := range contracts &#123; additionalExcludes := []string&#123;&#125; // 如果传入的合约类型是IgnoreContractInterface if castContract, ok := contract.(IgnoreContractInterface); ok &#123; // 则把castContract中的需要忽略的方法赋值给additionalExcludes切片 additionalExcludes = castContract.GetIgnoredFunctions() &#125; // 向cc中添加合约，下面再看addContract方法都干了什么 err := cc.addContract(contract, append(ciMethods, additionalExcludes...)) if err != nil &#123; return nil, err &#125; &#125; // 创建系统合约，并把系统合约添加到链码中 sysC := new(SystemContract) sysC.Name = SystemContractName cc.addContract(sysC, ciMethods) // should never error as system contract is good // 增加元数据 err := cc.augmentMetadata() if err != nil &#123; return nil, err &#125; metadataJSON, _ := json.Marshal(cc.metadata) // 把元数据设置到系统合约中 sysC.setMetadata(string(metadataJSON)) // 设置链码的交易序列化器 cc.TransactionSerializer = new(serializer.JSONSerializer) return cc, nil&#125;// Start starts the chaincode in the fabric shim// 在fabric shim中启动链码// 至于shim是什么，先了解大概：shim包为链码提供API，这些API可以访问状态变量、交易上下文和调用其他的链码。// shim包源码注释：// Package shim provides APIs for the chaincode to access its state// variables, transaction context and call other chaincodes.func (cc *ContractChaincode) Start() error &#123; return shim.Start(cc)&#125;// Init is called during Instantiate transaction after the chaincode container// has been established for the first time, passes off details of the request to Invoke// for handling the request if a function name is passed, otherwise returns shim.Success// 首次建立链码容器后，在实例化交易之前调用Init// 如果一个方法名被传递了过来，则把请求的详情传递给Invoke方法来处理，否则返回shim.Successfunc (cc *ContractChaincode) Init(stub shim.ChaincodeStubInterface) peer.Response &#123; nsFcn, _ := stub.GetFunctionAndParameters() if nsFcn == &quot;&quot; &#123; return shim.Success([]byte(&quot;Default initiator successful.&quot;)) &#125; return cc.Invoke(stub)&#125;// Invoke is called to update or query the ledger in a proposal transaction. Takes the// args passed in the transaction and uses the first argument to identify the contract// and function of that contract to be called. The remaining args are then used as// parameters to that function. Args are converted from strings to the expected parameter// types of the function before being passed using the set transaction serializer for the ContractChaincode.// A transaction context is generated and is passed, if required, as the first parameter to the named function.// Before and after functions are called before and after the named function passed if the contract defines such// functions to exist. If the before function returns an error the named function is not called and its error// is returned in shim.Error. If the after function returns an error then its value is returned// to shim.Error otherwise the value returned from the named function is returned as shim.Success (formatted by// the transaction serializer). If an unknown name is passed as part of the first arg a shim.Error is returned.// If a valid name is passed but the function name is unknown then the contract with that name&#x27;s// unknown function is called and its value returned as success or error depending on its return. If no// unknown function is defined for the contract then shim.Error is returned by Invoke. In the case of// unknown function names being passed (and the unknown handler returns an error) or the named function// returning an error then the after function if defined is not called. If the named function or unknown// function handler returns a non-error type then then the after transaction is sent this value. The same// transaction context is passed as a pointer to before, after, named and unknown functions on each Invoke.// If no contract name is passed then the default contract is used.func (cc *ContractChaincode) Invoke(stub shim.ChaincodeStubInterface) peer.Response &#123; // 获取方法和入参 nsFcn, params := stub.GetFunctionAndParameters() // 获取字符串&quot;:&quot;在nsFcn中最后一次出现的下标 li := strings.LastIndex(nsFcn, 字符串&quot;:&quot;在) // 合约 var ns string // 方法 var fn string // 如果nsFcn中不存在&quot;:&quot;，则说明没有指定合约名称 if li == -1 &#123; ns = cc.DefaultContract fn = nsFcn &#125; else &#123; ns = nsFcn[:li] fn = nsFcn[li+1:] &#125; // 如果合约名不在链码的合约里面，则报错 if _, ok := cc.contracts[ns]; !ok &#123; return shim.Error(fmt.Sprintf(&quot;Contract not found with name %s&quot;, ns)) &#125; // 如果方法为空，则报错 if fn == &quot;&quot; &#123; return shim.Error(&quot;Blank function name passed&quot;) &#125; originalFn := fn // 把fn强转成rune(int32类型的别名) fnRune := []rune(fn) // 如果传入的方法名的首字母是小写的，则转换成大写 if unicode.IsLower(fnRune[0]) &#123; fnRune[0] = unicode.ToUpper(fnRune[0]) fn = string(fnRune) &#125; // 从链码的合约列表中获取合约 nsContract := cc.contracts[ns] // 通过反射new一个transactionContextHandler类型；这几行有点看不懂了，暂停一下TODO ctx := reflect.New(nsContract.transactionContextHandler) ctxIface := ctx.Interface().(SettableTransactionContextInterface) ctxIface.SetStub(stub) ci, _ := cid.New(stub) ctxIface.SetClientIdentity(ci) beforeTransaction := nsContract.beforeTransaction if beforeTransaction != nil &#123; _, _, errRes := beforeTransaction.Call(ctx, nil, nil) if errRes != nil &#123; return shim.Error(errRes.Error()) &#125; &#125; var successReturn string var successIFace interface&#123;&#125; var errorReturn error serializer := cc.TransactionSerializer if _, ok := nsContract.functions[fn]; !ok &#123; unknownTransaction := nsContract.unknownTransaction if unknownTransaction == nil &#123; return shim.Error(fmt.Sprintf(&quot;Function %s not found in contract %s&quot;, originalFn, ns)) &#125; successReturn, successIFace, errorReturn = unknownTransaction.Call(ctx, nil, serializer) &#125; else &#123; var transactionSchema *metadata.TransactionMetadata for _, v := range cc.metadata.Contracts[ns].Transactions &#123; if v.Name == fn &#123; transactionSchema = &amp;v break &#125; &#125; successReturn, successIFace, errorReturn = nsContract.functions[fn].Call(ctx, transactionSchema, &amp;cc.metadata.Components, serializer, params...) &#125; if errorReturn != nil &#123; return shim.Error(errorReturn.Error()) &#125; afterTransaction := nsContract.afterTransaction if afterTransaction != nil &#123; _, _, errRes := afterTransaction.Call(ctx, successIFace, nil) if errRes != nil &#123; return shim.Error(errRes.Error()) &#125; &#125; return shim.Success([]byte(successReturn))&#125;func (cc *ContractChaincode) addContract(contract ContractInterface, excludeFuncs []string) error &#123; // 返回合同名称。当合同用于创建新的链码时，将调用此函数，然后使用返回的名称在调用Init/Invoke时在链码中标识合同。 // 此函数可以返回空白字符串，但这是未定义的行为。 ns := contract.GetName() // 如果合约名称为空，则使用合约类型通过反射的方式获取合约的名称 if ns == &quot;&quot; &#123; ns = reflect.TypeOf(contract).Elem().Name() &#125; // 如果链码中已经包含了相同的合约名称，则抛异常 if _, ok := cc.contracts[ns]; ok &#123; return fmt.Errorf(&quot;Multiple contracts being merged into chaincode with name %s&quot;, ns) &#125; ccn := contractChaincodeContract&#123;&#125; ccn.transactionContextHandler = reflect.ValueOf(contract.GetTransactionContextHandler()).Elem().Type() transactionContextPtrHandler := reflect.ValueOf(contract.GetTransactionContextHandler()).Type() ccn.functions = make(map[string]*internal.ContractFunction) // GetInfo方法返回存储的合约的信息，这个信息会用于构建合约的元数据。如果此信息中的版本信息为空，则使用&quot;latest&quot; // 如果信息中的title为空，则使用合约的GetName方法返回的名称，如果这个名称也为空，则使用合约的类型名 ccn.info = contract.GetInfo() if ccn.info.Version == &quot;&quot; &#123; ccn.info.Version = &quot;latest&quot; &#125; if ccn.info.Title == &quot;&quot; &#123; ccn.info.Title = ns &#125; contractType := reflect.PtrTo(reflect.TypeOf(contract).Elem()) contractValue := reflect.ValueOf(contract).Elem().Addr() // returns the unknown function to be used for a contract. // When the contract is used in creating a new chaincode this function is called // and the unknown transaction returned is stored. The unknown function is then // called in cases where an unknown function name is passed for a call to the // contract via Init/Invoke of the chaincode. If nil is returned the // chaincode uses its default handling for unknown function names // 返回要用于合约的未知函数，当合约被用于创建一个新的链码时此方法被调用并且返回存储的未知的交易。 // 在链码通过Init/Invoke调用合约时，如果一个未知的方法名称被传入了则调用此未知方法 // 如果此方法返回nil。则chaincode使用一个默认值来处理未知的方法名 // 个人理解就是不指定方法名调用合约时的默认处理逻辑。 ut := contract.GetUnknownTransaction() if ut != nil &#123; var err error ccn.unknownTransaction, err = internal.NewTransactionHandler(ut, transactionContextPtrHandler, internal.TransactionHandlerTypeUnknown) if err != nil &#123; return err &#125; &#125; // returns the before function to be used for a contract. // When the contract is used in creating a new chaincode this function is called // and the before transaction returned is stored. The before function is then // called before the named function on each Init/Invoke of that contract via the // chaincode. When called the before function is passed no extra args, only the // the transaction context (if specified to take it). If nil is returned // then no before function is called on Init/Invoke. // 返回需要对此合约使用的前置函数，当合约被用于创建一个新的链码时此方法被调用并且返回存储的前置交易。 // 然后通过链码在该合约使用Init/Invoke调用指定函数之前调用前置函数。 // 当调用before函数时，不传递任何额外的参数，仅传递事务上下文（如果指定使用它）。 // 如果此方法返回nil，则在调用Init/Invoke之前没有需要执行的函数。 bt := contract.GetBeforeTransaction() if bt != nil &#123; var err error ccn.beforeTransaction, err = internal.NewTransactionHandler(bt, transactionContextPtrHandler, internal.TransactionHandlerTypeBefore) if err != nil &#123; return err &#125; &#125; // 获取后置函数，在调用合约的指定方法之后调用此函数 at := contract.GetAfterTransaction() if at != nil &#123; var err error ccn.afterTransaction, err = internal.NewTransactionHandler(at, transactionContextPtrHandler, internal.TransactionHandlerTypeAfter) if err != nil &#123; return err &#125; &#125; evaluateMethods := []string&#123;&#125; if eci, ok := contract.(EvaluationContractInterface); ok &#123; // returns a list of function names that should be tagged in the // metadata as &quot;evaluate&quot; to indicate to a user of the chaincode that they should query // rather than invoke these functions // 返回应该在元数据上打上&quot;求值&quot;标签的方法列表，来向链码的用户展示他们应该查询这个函数而不是调用它 // 个人理解：所以这些函数应该只是计算一些数据的，不会对账本产生影响。如果对账本产生影响又打上这个标签是不是很流氓？ evaluateMethods = eci.GetEvaluateTransactions() &#125; // 遍历合约中的所有的方法 for i := 0; i &lt; contractType.NumMethod(); i++ &#123; typeMethod := contractType.Method(i) valueMethod := contractValue.Method(i) // 如果此方法不再排除的列表中，则可以调用 if !utils.StringInSlice(typeMethod.Name, excludeFuncs) &#123; var err error // 默认的调用方式是CallTypeSubmit var callType internal.CallType = internal.CallTypeSubmit // 如果在只用于计算的函数列表中，则调用方法修改为CallTypeEvaluate； // 两次调用StringInSlice会遍历啊两个列表，是不是可以用map把这里优化一下呢？ if utils.StringInSlice(typeMethod.Name, evaluateMethods) &#123; callType = internal.CallTypeEvaluate &#125; // 创建合约的方法 ccn.functions[typeMethod.Name], err = internal.NewContractFunctionFromReflect(typeMethod, valueMethod, callType, transactionContextPtrHandler) if err != nil &#123; return err &#125; &#125; &#125; // 如果合约方法的列表为空，则报错，一个合约中至少有一个公共方法 if len(ccn.functions) == 0 &#123; return fmt.Errorf(&quot;Contracts are required to have at least 1 (non-ignored) public method. Contract %s has none. Method names that have been ignored: %s&quot;, ns, utils.SliceAsCommaSentence(excludeFuncs)) &#125; cc.contracts[ns] = ccn // 如果链码的默认的合约为空，则把当前的合约设置为默认的合约；所以传入的第一个合约就是默认的合约 if cc.DefaultContract == &quot;&quot; &#123; cc.DefaultContract = ns &#125; return nil&#125;// 反射的方式获取元数据func (cc *ContractChaincode) reflectMetadata() metadata.ContractChaincodeMetadata &#123; reflectedMetadata := metadata.ContractChaincodeMetadata&#123;&#125; reflectedMetadata.Contracts = make(map[string]metadata.ContractMetadata) reflectedMetadata.Components.Schemas = make(map[string]metadata.ObjectMetadata) reflectedMetadata.Info = &amp;cc.Info if cc.Info.Version == &quot;&quot; &#123; reflectedMetadata.Info.Version = &quot;latest&quot; &#125; if cc.Info.Title == &quot;&quot; &#123; reflectedMetadata.Info.Title = &quot;undefined&quot; &#125; // 遍历链码的合约 for key, contract := range cc.contracts &#123; // 创建合约的元数据 contractMetadata := metadata.ContractMetadata&#123;&#125; contractMetadata.Name = key infoCopy := contract.info contractMetadata.Info = &amp;infoCopy // 如果这个合约是默认的合约，元数据的字段也设置为true if cc.DefaultContract == key &#123; contractMetadata.Default = true &#125; // 遍历合约的所有方法，并创建方法的元数据，最后把这些方法的元数据加入到合约的元数据 for key, fn := range contract.functions &#123; fnMetadata := fn.ReflectMetadata(key, &amp;reflectedMetadata.Components) contractMetadata.Transactions = append(contractMetadata.Transactions, fnMetadata) &#125; sort.Slice(contractMetadata.Transactions, func(i, j int) bool &#123; return contractMetadata.Transactions[i].Name &lt; contractMetadata.Transactions[j].Name &#125;) reflectedMetadata.Contracts[key] = contractMetadata &#125; return reflectedMetadata&#125;func (cc *ContractChaincode) augmentMetadata() error &#123; // 读取元数据的文件，就是上面说的contract-metadata/metadata.json文件 fileMetadata, err := metadata.ReadMetadataFile() // 如果报错了并且报错信息不是因为文件不存在的错误，则把错误抛出去 // 优化建议：这里能不能使用不同的error类型来做这种判断呢，这么判断如果error信息更改了就必须两个地方同时修改 if err != nil &amp;&amp; !strings.Contains(err.Error(), &quot;Failed to read metadata from file&quot;) &#123; return err &#125; reflectedMetadata := cc.reflectMetadata() fileMetadata.Append(reflectedMetadata) err = fileMetadata.CompileSchemas() if err != nil &#123; return err &#125; // 验证 err = metadata.ValidateAgainstSchema(fileMetadata) if err != nil &#123; return err &#125; cc.metadata = fileMetadata return nil&#125;// getCiMethods 获取合约接口的方法描述的切片func getCiMethods() []string &#123; // 通过反射的方式获取这个类型 contractInterfaceType := reflect.TypeOf((*ContractInterface)(nil)).Elem() ignoreContractInterfaceType := reflect.TypeOf((*IgnoreContractInterface)(nil)).Elem() evaluateContractInterfaceType := reflect.TypeOf((*EvaluationContractInterface)(nil)).Elem() interfaceTypes := []reflect.Type&#123;contractInterfaceType, ignoreContractInterfaceType, evaluateContractInterfaceType&#125; // 遍历这些反射的类型，把他们的方法描述添加到ciMethods切片中 var ciMethods []string for _, interfaceType := range interfaceTypes &#123; for i := 0; i &lt; interfaceType.NumMethod(); i++ &#123; ciMethods = append(ciMethods, interfaceType.Method(i).Name) &#125; &#125; return ciMethods&#125;","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"chaincode-API","slug":"区块链/Hyperledger-Fabric/chaincode-API","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/chaincode-API/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"API","slug":"API","permalink":"https://guozhe001.github.io/tags/API/"},{"name":"contractapi","slug":"contractapi","permalink":"https://guozhe001.github.io/tags/contractapi/"}]},{"title":"Fabric智能合约API学习","slug":"blockchain/fabric/智能合约API学习/Fabric智能合约API学习","date":"2024-11-22T06:32:06.495Z","updated":"2024-11-22T06:32:06.495Z","comments":true,"path":"2024/11/22/blockchain/fabric/智能合约API学习/Fabric智能合约API学习/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6API%E5%AD%A6%E4%B9%A0/Fabric%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6API%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"这篇文档通过学习之前写的chaincode来查看Fabric的智能合约相关的源码。并学习这些源码的功能。 智能合约里面的方法如何定义的 智能合约中的每个导出的方法都必须有contractapi.TransactionContextInterface类型的参数，并且这个方法是被定义在SmartContract上的，如下面一个获取资产出价价格的方法。 1234// GetAssetBidPrice returns the bid pricefunc (s *SmartContract) GetAssetBidPrice(ctx contractapi.TransactionContextInterface, assetID string) (string, error) &#123; return getAssetPrice(ctx, assetID, typeAssetBid)&#125; contractapi.TransactionContextInterface的源码如下： 1234567891011121314// TransactionContextInterface defines the interface which TransactionContext// meets. This can be taken by transacton functions on a contract which has not set// a custom transaction context to allow transaction functions to take an interface// to simplify unit testing.// 交易上下文接口，为了方便测试type TransactionContextInterface interface &#123; // GetStub should provide a way to access the stub set by Init/Invoke // 获取由Init/Invoke设置的存根 GetStub() shim.ChaincodeStubInterface // GetClientIdentity should provide a way to access the client identity set by Init/Invoke // 获取由Init/Invoke设置的客户端身份 GetClientIdentity() cid.ClientIdentity&#125; mock方式测试shim.ChaincodeStubInterface中的方法 接着看shim.ChaincodeStubInterface有哪些功能，源码在这里就不贴了，直接看测试用例,下面的测试用例的入口是TestStart，不包含尚未实现mock的方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344package chaincode_testimport ( &quot;encoding/json&quot; &quot;github.com/hyperledger/fabric-chaincode-go/pkg/statebased&quot; &quot;github.com/hyperledger/fabric-contract-api-go/contractapi&quot; &quot;log&quot; &quot;testing&quot; &quot;unsafe&quot; &quot;github.com/guozhe001/learn-contractapi-go/chaincode&quot; &quot;github.com/hyperledger/fabric-chaincode-go/shim&quot; &quot;github.com/hyperledger/fabric-chaincode-go/shimtest&quot; &quot;github.com/stretchr/testify/require&quot;)func mockInitLedger(t *testing.T, stub *shimtest.MockStub) &#123; assets := []chaincode.Asset&#123; &#123;ID: AssetId, Color: &quot;blue&quot;, Size: 5, Owner: &quot;Tomoko&quot;, AppraisedValue: 300&#125;, &#123;ID: &quot;asset2&quot;, Color: &quot;red&quot;, Size: 5, Owner: &quot;Brad&quot;, AppraisedValue: 400&#125;, &#123;ID: &quot;asset3&quot;, Color: &quot;green&quot;, Size: 10, Owner: &quot;Jin Soo&quot;, AppraisedValue: 500&#125;, &#123;ID: &quot;asset4&quot;, Color: &quot;yellow&quot;, Size: 10, Owner: &quot;Max&quot;, AppraisedValue: 600&#125;, &#123;ID: &quot;asset5&quot;, Color: &quot;black&quot;, Size: 15, Owner: &quot;Adriana&quot;, AppraisedValue: 700&#125;, &#123;ID: &quot;asset6&quot;, Color: &quot;white&quot;, Size: 15, Owner: &quot;Michel&quot;, AppraisedValue: 800&#125;, &#125; stub.MockTransactionStart(&quot;test&quot;) putState(t, stub, assets...) id := stub.GetTxID() timestamp, err := stub.GetTxTimestamp() channelID := stub.GetChannelID() require.NoError(t, err) require.NotNil(t, timestamp) log.Printf(&quot;GetTxID()=%s, GetTxTimestamp()=%s, GetChannelID()=%s&quot;, id, timestamp, channelID) stub.MockTransactionEnd(&quot;test&quot;)&#125;func marshal(asset chaincode.Asset, t *testing.T) []byte &#123; assetJSON, err := json.Marshal(asset) require.NoError(t, err) return assetJSON&#125;// ChaincodeStubInterface#PutState()func putState(t *testing.T, stub *shimtest.MockStub, assets ...chaincode.Asset) &#123; for _, asset := range assets &#123; log.Printf(&quot;putState=%v&quot;, asset) require.NoError(t, stub.PutState(asset.ID, marshal(asset, t))) &#125;&#125;// ChaincodeStubInterface#GetState()// ChaincodeStubInterface#PutState()// ChaincodeStubInterface#DelState()func getState(assetId string, t *testing.T, stub *shimtest.MockStub) &#123; // 获取指定key的资产的世界状态 state, err := stub.GetState(assetId) require.NoError(t, err) printAsset(t, state) newAssetID := &quot;temp001&quot; newAsset := chaincode.Asset&#123;ID: newAssetID, Color: &quot;blue&quot;, Size: 5, Owner: &quot;Tomoko&quot;, AppraisedValue: 300&#125; // put一个新的资产 putState(t, stub, newAsset) // 查询新的资产 newState, err := stub.GetState(newAssetID) require.NoError(t, err) require.NotNil(t, newState) printAsset(t, newState) // 指定资产ID删除资产 require.NoError(t, stub.DelState(newAssetID)) // 删除之后重新查询新的资产 newStateAgain, err := stub.GetState(newAssetID) require.NoError(t, err) require.Nil(t, newStateAgain)&#125;func getHistoryForKey(assetId string, t *testing.T, stub *shimtest.MockStub) &#123; // 获取key的历史数据，目前mock还未实现 history, err := stub.GetHistoryForKey(assetId) require.NoError(t, err) if history != nil &#123; if history.HasNext() &#123; next, err := history.Next() require.NoError(t, err) marshal, err := json.Marshal(next) require.NoError(t, err) log.Printf(&quot;asset=%s history=%s&quot;, assetId, marshal) &#125; history.Close() &#125;&#125;func printAsset(t *testing.T, state []byte) &#123; var a chaincode.Asset require.NoError(t, json.Unmarshal(state, &amp;a)) marshal, err := json.Marshal(a) require.NoError(t, err) log.Printf(&quot;result state json value = %s&quot;, marshal)&#125;// ChaincodeStubInterface#GetArgs()// ChaincodeStubInterface#GetStringArgs()func getArgs(t *testing.T, stub *shimtest.MockStub) &#123; args := stub.GetArgs() for _, arg := range args &#123; log.Print(string(arg)) &#125; stringArgs := stub.GetStringArgs() for _, argString := range stringArgs &#123; log.Print(argString) &#125;&#125;// ChaincodeStubInterface#GetStateByRange(startKey, endKey string) (StateQueryIteratorInterface, error)// ChaincodeStubInterface#GetStateByRangeWithPagination(startKey, endKey string, pageSize int32, bookmark string) (StateQueryIteratorInterface, *pb.QueryResponseMetadata, error)func getStateByRange(t *testing.T, stub *shimtest.MockStub) &#123; // GetStateByRange不指定startKey和endKey，会返回全部的资产；谨慎使用 states, err := stub.GetStateByRange(&quot;&quot;, &quot;&quot;) require.NoError(t, err) printStateQueryIteratorInterface(t, states) // GetStateByRangeWithPagination 因为mockStub直接返回三个nil，所以无法在mock环境测试 pagination, metadata, err := stub.GetStateByRangeWithPagination(&quot;&quot;, &quot;&quot;, 5, &quot;&quot;) require.NoError(t, err) log.Print(&quot;==========================================================================================&quot;) log.Printf(&quot;GetStateByRangeWithPagination metadata=%v&quot;, metadata) printStateQueryIteratorInterface(t, pagination)&#125;func printStateQueryIteratorInterface(t *testing.T, states shim.StateQueryIteratorInterface) &#123; if states != nil &#123; for states.HasNext() &#123; next, err := states.Next() require.NoError(t, err) log.Print(next) &#125; states.Close() &#125;&#125;// ChaincodeStubInterface#CreateCompositeKey(objectType string, attributes []string) (string, error)// ChaincodeStubInterface#SplitCompositeKey(compositeKey string) (string, []string, error)func createCompositeKey(t *testing.T, stub *shimtest.MockStub) &#123; objectType := &quot;test&quot; attributes := []string&#123;&quot;param1&quot;, &quot;param2&quot;, &quot;param3&quot;, &quot;end&quot;&#125; // 创建组合key，拼接了一下 key, err := stub.CreateCompositeKey(objectType, attributes) require.NoError(t, err) log.Printf(&quot;key=%s&quot;, key) // 分割组合key，CreateCompositeKey的逆运算 compositeKey, strings, err := stub.SplitCompositeKey(key) require.Equal(t, objectType, compositeKey) require.Equal(t, attributes, strings) newAsset := chaincode.Asset&#123;ID: key, Color: &quot;blue&quot;, Size: 5, Owner: &quot;Tomoko&quot;, AppraisedValue: 300&#125; putState(t, stub, newAsset) empty := []string&#123;&#125; // 根据创建组合key的参数查询，后面的参数可以是空，这样会全部匹配出来 states, err := stub.GetStateByPartialCompositeKey(objectType, empty) require.NoError(t, err) require.NotNil(t, states) printStateQueryIteratorInterface(t, states)&#125;const ( AssetId string = &quot;asset1&quot; TestMSP string = &quot;TestMSP&quot; TestCollection string = &quot;private_TestMSP&quot; Blank string = &quot;&quot;)// ChaincodeStubInterface#SetStateValidationParameter(key string, ep []byte) error// ChaincodeStubInterface#GetStateValidationParameter(key string) ([]byte, error)func setStateValidationParameter(t *testing.T, stub *shimtest.MockStub) &#123; // 新建一个基于状态的背书策略 endorsementPolicy, err := statebased.NewStateEP(nil) require.NoError(t, err) // 向背书策略添加需要背书的公司 require.NoError(t, endorsementPolicy.AddOrgs(statebased.RoleTypeMember, TestMSP)) policy, err := endorsementPolicy.Policy() require.NoError(t, err) // SetStateValidationParameter设置基于状态的背书策略 require.NoError(t, stub.SetStateValidationParameter(AssetId, policy)) // GetStateValidationParameter获取基于状态的背书策略 parameter, err := stub.GetStateValidationParameter(AssetId) require.NoError(t, err) str := byteToString(parameter) // 打印出来的StateValidationParameter有特殊字符，所以使用包含传入的字符的方式断言 log.Printf(&quot;ID=%s, StateValidationParameter=%s&quot;, AssetId, str) require.Contains(t, str, TestMSP)&#125;// ChaincodeStubInterface#GetPrivateData(collection, key string) ([]byte, error)// ChaincodeStubInterface#GetPrivateDataHash(collection, key string) ([]byte, error) 获取私有数据的hash值，这个方法就算不是私有数据的所有者也可以调用，mock版本没有实现；// ChaincodeStubInterface#DelPrivateData(collection, key string) error 删除私有数据，mock版本没有实现；// ChaincodeStubInterface#SetPrivateDataValidationParameter(collection, key string, ep []byte) error 设置私有数据的// ChaincodeStubInterface#GetPrivateDataValidationParameter(collection, key string) ([]byte, error)// ChaincodeStubInterface#GetPrivateDataByRange(collection, startKey, endKey string) (StateQueryIteratorInterface, error) 根据范围查询私有数据// ChaincodeStubInterface#GetPrivateDataByPartialCompositeKey(collection, objectType string, keys []string) (StateQueryIteratorInterface, error)func getPrivateData(t *testing.T, stub *shimtest.MockStub) &#123; key := &quot;private001&quot; privateAsset := chaincode.Asset&#123;ID: key, Color: &quot;blue&quot;, Size: 5, Owner: &quot;Tomoko&quot;, AppraisedValue: 300&#125; bytes, err := json.Marshal(privateAsset) require.NoError(t, err) // 添加私有数据 require.NoError(t, stub.PutPrivateData(TestCollection, key, bytes)) // 获取私有资产 data, err := stub.GetPrivateData(TestCollection, key) require.NoError(t, err) require.NotNil(t, data) printAsset(t, data) // 使用不存在的其他的collection获取私有资产，不会返回error，会返回nil数据 data, err = stub.GetPrivateData(&quot;test_collections&quot;, key) require.NoError(t, err) require.Nil(t, data) // 使用其他的key获取不存在私有资产 data, err = stub.GetPrivateData(TestCollection, AssetId) require.NoError(t, err) require.Nil(t, data) // 查询公共资产数据,断言没有这个资产 state, err := stub.GetState(key) require.NoError(t, err) require.Nil(t, state) endorsementPolicy, err := statebased.NewStateEP(nil) require.NoError(t, err) require.NoError(t, endorsementPolicy.AddOrgs(statebased.RoleTypeMember, TestMSP)) policy, err := endorsementPolicy.Policy() require.NoError(t, err) require.NoError(t, stub.SetPrivateDataValidationParameter(TestCollection, key, policy)) parameter, err := stub.GetPrivateDataValidationParameter(TestCollection, key) require.NoError(t, err) str := byteToString(parameter) // 打印出来的StateValidationParameter有特殊字符，所以使用包含传入的字符的方式断言 log.Printf(&quot;ID=%s, StateValidationParameter=%s&quot;, AssetId, str) require.Contains(t, str, TestMSP) // GetPrivateDataHash(collection, key string) ([]byte, error) 获取私有数据的hash值，这个方法就算不是私有数据的所有者也可以调用，mock版本没有实现； // DelPrivateData(collection, key string) error 删除私有数据，mock版本没有实现； //require.NoError(t, stub.DelPrivateData(TestCollection, key)) //// 删除之后再次查询，断言已经没有此资产 //data, err = stub.GetPrivateData(TestCollection, key) //require.NoError(t, err) //require.Nil(t, state) // GetPrivateDataByRange没有实现 //byRange, err := stub.GetPrivateDataByRange(TestCollection, Blank, Blank) //require.NoError(t, err) //require.NotNil(t, byRange) //for byRange.HasNext() &#123; // next, err := byRange.Next() // require.NotNil(t, err) // log.Print(next) //&#125;&#125;func byteToString(data []byte) string &#123; str := (*string)(unsafe.Pointer(&amp;data)) return *str&#125;// ChaincodeStubInterface#ChaincodeStubInterface#GetCreator() ([]byte, error) 获取签约交易提议的人，签约提议的人也是这个交易的创建者; mockstub未实现// ChaincodeStubInterface#GetTransient() (map[string][]byte, error) 获取临时数据，这个方法只有设置了临时数据的peer才能查到数据，主要是为了做隐私保护的，详情参考隐秘的交易资产// ChaincodeStubInterface#GetBinding() ([]byte, error) TODO 待理解// ChaincodeStubInterface#GetDecorations() ([]byte, error) TODO 待理解,目前看是为了传递更多关于提议的的额外数据// ChaincodeStubInterface#GetSignedProposal() ([]byte, error) 获取提议// ChaincodeStubInterface#SetEvent(name string, payload []byte) error 允许链码在提议的response设置一个事件。无论交易的有效性如何，事件都将在已提交的块中的交易内可用。一个交易只能包含一个事件，并且如果是链码调用另一个链码的情况，事件只能在最外层。func stubOthers(t *testing.T, stub *shimtest.MockStub) &#123; m := make(map[string][]byte) tempAsset := chaincode.Asset&#123;ID: &quot;temp001&quot;, Color: &quot;blue&quot;, Size: 5, Owner: &quot;Tomoko&quot;, AppraisedValue: 300&#125; m[&quot;temp_asset&quot;], _ = json.Marshal(tempAsset) require.NoError(t, stub.SetTransient(m)) transient, err := stub.GetTransient() require.NoError(t, err) require.NotNil(t, transient) for k, v := range transient &#123; log.Printf(&quot;k=%s, v=%s&quot;, k, v) &#125; decorations := stub.GetDecorations() for k, v := range decorations &#123; log.Printf(&quot;k=%s, v=%s&quot;, k, v) &#125;&#125;// 测试shim.ChaincodeStubInterface接口func stubTest(t *testing.T, stub *shimtest.MockStub) &#123; assetId := AssetId mockInitLedger(t, stub) stub.MockTransactionStart(&quot;test1&quot;) getState(assetId, t, stub) //getHistoryForKey(assetId, t, stub) getArgs(t, stub) stub.MockTransactionStart(&quot;test1&quot;) getStateByRange(t, stub) createCompositeKey(t, stub) setStateValidationParameter(t, stub) getPrivateData(t, stub) stubOthers(t, stub)&#125;// 测试contractapi.Contract的方法func contractTest(t *testing.T, ccc *contractapi.ContractChaincode, stub *shimtest.MockStub) &#123; log.Printf(&quot;DefaultContract=%s&quot;, ccc.DefaultContract) info := ccc.Info log.Printf(&quot;info=%v&quot;, info) stub.MockTransactionStart(&quot;contract_test&quot;) // 如果调用一个不存在的方法，如果实现了GetUnknownTransaction接口，则会执行此接口返回的方法；否则不执行，并且也不会报错，但是如果有before方法是会执行的 response := stub.MockInvoke(&quot;uuid_002&quot;, [][]byte&#123;[]byte(&quot;Unknow&quot;)&#125;) log.Printf(&quot;response=%#v, response.Status=%d, response.Payload=%s&quot;, response, response.Status, byteToString(response.Payload)) // 调用一个被忽略的方法, 虽然IgnoredMe方法在智能合约中存在，但是因为合约满足IgnoreContractInterface接口然后把这个方法加入到了忽略列表中，所以最后还是调用的默认方法 response = stub.MockInvoke(&quot;uuid_002&quot;, [][]byte&#123;[]byte(&quot;IgnoredMe&quot;)&#125;) log.Printf(&quot;response=%#v, response.Status=%d, response.Payload=%s&quot;, response, response.Status, byteToString(response.Payload)) // 指定某个指定合约，调用一个不存在的方法，冒号前面的部分是智能合约名称，后面是方法名称 response = stub.MockInvoke(&quot;uuid_002&quot;, [][]byte&#123;[]byte(&quot;TestSmartContract:Unknow&quot;)&#125;) log.Printf(&quot;response=%#v, response.Status=%d, response.Payload=%s&quot;, response, response.Status, byteToString(response.Payload)) //invoke := ccc.Invoke(stub) //log.Printf(&quot;response=%v&quot;, invoke) stub.MockTransactionEnd(&quot;uuid_001&quot;) transactionSerializer := ccc.TransactionSerializer log.Printf(&quot;transactionSerializer=%v&quot;, transactionSerializer)&#125;// 测试入口func TestStart(t *testing.T) &#123; // 一个链码包中可以有多个智能合约 assetChaincode, err := contractapi.NewChaincode(&amp;chaincode.SmartContract&#123;&#125;, &amp;TestSmartContract&#123;&#125;) require.NoError(t, err) // NewMockStub stub := shimtest.NewMockStub(&quot;mockSub&quot;, assetChaincode) stubTest(t, stub) contractTest(t, assetChaincode, stub)&#125;type TestSmartContract struct &#123; contractapi.Contract&#125;// GetUnknownTransaction returns the current set unknownTransaction, may be nilfunc (t *TestSmartContract) GetUnknownTransaction() interface&#123;&#125; &#123; return t.UnknownTransaction&#125;// Default 如果不指定方法名称时指定的默认方法func (t *TestSmartContract) UnknownTransaction(ctx contractapi.TransactionContextInterface) string &#123; log.Printf(&quot;hello, i&#x27;m Default func in TestSmartContract！&quot;) return &quot;i&#x27;m TestSmartContract, Bye!&quot;&#125; 在智能合约中添加了如下的一些方法： 1234567891011121314151617181920212223242526272829303132333435363738// GetUnknownTransaction returns the current set unknownTransaction, may be nilfunc (s *SmartContract) GetUnknownTransaction() interface&#123;&#125; &#123; return s.UnknownTransaction&#125;// Default 如果不指定方法名称时指定的默认方法func (s *SmartContract) UnknownTransaction(ctx contractapi.TransactionContextInterface) string &#123; log.Printf(&quot;hello, i&#x27;m Default func！&quot;) return &quot;Bye!&quot;&#125;// GetBeforeTransaction returns the current set beforeTransaction, may be nilfunc (s *SmartContract) GetBeforeTransaction() interface&#123;&#125; &#123; return s.BeforeTransaction&#125;func (s *SmartContract) BeforeTransaction(ctx contractapi.TransactionContextInterface) &#123; log.Printf(&quot;i&#x27;m BeforeTransaction&quot;)&#125;// GetAfterTransaction returns the current set afterTransaction, may be nilfunc (s *SmartContract) GetAfterTransaction() interface&#123;&#125; &#123; return s.AfterTransaction&#125;func (s *SmartContract) AfterTransaction(ctx contractapi.TransactionContextInterface) &#123; log.Printf(&quot;i&#x27;m AfterTransaction&quot;)&#125;func (s *SmartContract) IgnoredMe(ctx contractapi.TransactionContextInterface) &#123; log.Printf(&quot;Ignored Me!&quot;)&#125;func (s *SmartContract) GetIgnoredFunctions() []string &#123; return []string&#123;&quot;IgnoredMe&quot;&#125;&#125; 测试无法mock测试的shim.ChaincodeStubInterface方法 一些其他的无法使用shimtests做mock测试的shim.ChaincodeStubInterface方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119// SomeStubMethod stub其他的无法通过mock方式测试的方法练习func (s *SmartContract) SomeStubMethod(ctx contractapi.TransactionContextInterface, assetID string) error &#123; stub := ctx.GetStub() // stub.GetArgs()和stub.GetStringArgs()都是获取调用链码时的入参，第一个参数时方法名，后面的参数是这个方法的参数的信息,如下： // 2021/01/25 08:06:32 stub.GetArgs(),i=0, arg=Practice_SmartContract:SomeStubMethod //2021/01/25 08:06:32 stub.GetArgs(),i=1, arg=asset1 for i, arg := range stub.GetArgs() &#123; log.Printf(&quot;stub.GetArgs(),i=%d, arg=%s&quot;, i, byteToString(arg)) &#125; for i, arg := range stub.GetStringArgs() &#123; log.Printf(&quot;stub.GetStringArgs(),i=%d, arg=%s&quot;, i, arg) &#125; binding, err := stub.GetBinding() if err != nil &#123; return err &#125; log.Printf(&quot;stub.GetBinding()=%s&quot;, byteToString(binding)) for k, v := range stub.GetDecorations() &#123; log.Printf(&quot;stub.GetDecorations(), k=%s, v=%s&quot;, k, byteToString(v)) &#125; // stub.GetCreator()返回的是证书，如过是组织s2.supply.com的管理员发起的交易，则此处获得的是：Admin@s2.supply.com-cert.pem creator, err := stub.GetCreator() if err != nil &#123; return err &#125; log.Printf(&quot;stub.GetCreator()=%s&quot;, byteToString(creator)) // 已经签名的提议，包含以下内容： // 1.通道名称 // 2.链码名称 // 3.发起交易的组织名称 // 4.发起交易的人的证书 // 5.调用链码时的入参：方法名，参数等 // stub.GetSignedProposal().GetProposalBytes()的信息如下： //2021/01/25 08:06:32 stub.GetSignedProposal().GetProposalBytes()= //�\u0007 //v\b\u0003\u001a \b����\u0006\u0010����\u0002&quot;\u000ealljoinchannel*@252b6bbd22eeaf2193cdbc86fe7bd9fa257e33a6209a5da7d81dcc41b8bb1b9d:\u0012\u0012\u0010\u0012\u000esecured_supply\u0012�\u0006 //�\u0006 // GylSOrg2MSP\u0012�\u0006-----BEGIN CERTIFICATE----- //MIICETCCAbegAwIBAgIRAJw2YUKkmyKusGHm33D7LhkwCgYIKoZIzj0EAwIwbTEL //MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG //cmFuY2lzY28xFjAUBgNVBAoTDXMyLnN1cHBseS5jb20xGTAXBgNVBAMTEGNhLnMy //LnN1cHBseS5jb20wHhcNMjEwMTA3MDgzMTAwWhcNMzEwMTA1MDgzMTAwWjBYMQsw //CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy //YW5jaXNjbzEcMBoGA1UEAwwTQWRtaW5AczIuc3VwcGx5LmNvbTBZMBMGByqGSM49 //AgEGCCqGSM49AwEHA0IABJ6An5vHmug1YBIUXKuD50ZJ79TiwDkW5uEr2ZkXU5Em //XwVlxwCOKpfqKOr1Xdk0DWMlAQPQIxeXktdVBJxFc4KjTTBLMA4GA1UdDwEB/wQE //AwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIGO9q5qcp089i7bDqwyxRYdg //aX65Bvs4X5wCsXWbxj37MAoGCCqGSM49BAMCA0gAMEUCIQCRBC/uF8ooaLQzSDo6 //e5+4UbBqjSi5MUy3IYfVrM5tHQIgaGHKXcKZY7q0Txs6LsbtayW6kWPOAee6Z1W8 //top2VDc= //-----END CERTIFICATE----- //\u0012\u0018�w�&#125;dȧC&gt;\u000f�v�@�El�S����\u0018\u0012I //G //E\b\u0001\u0012\u0010\u0012\u000esecured_supply\u001a/ //%Practice_SmartContract:SomeStubMethod //\u0006asset1 proposal, err := stub.GetSignedProposal() if err != nil &#123; return err &#125; log.Printf(&quot;stub.GetSignedProposal()=%#v&quot;, proposal) bytes := proposal.GetProposalBytes() log.Printf(&quot;stub.GetSignedProposal().GetProposalBytes()=%s&quot;, byteToString(bytes)) p := &amp;peer.Proposal&#123;&#125; err = proto.Unmarshal(bytes, p) if err != nil &#123; return err &#125; log.Printf(&quot;stub.GetSignedProposal().GetProposalBytes(),proto.Unmarshal=%#v&quot;, p) //headerBytes:= p.GetHeader() //header := &amp;peer.ChaincodeHeaderExtension&#123;&#125; //err = proto.Unmarshal(headerBytes, header) //if err != nil &#123; // return err //&#125; //log.Printf(&quot;stub.GetSignedProposal().GetProposalBytes()-Proposal-GetHeader()=%#v&quot;, header) //payloadBytes := p.GetPayload() //payload := &amp;peer.ChaincodeProposalPayload&#123;&#125; //err = proto.Unmarshal(payloadBytes, payload) //if err != nil &#123; // return err //&#125; //log.Printf(&quot;stub.GetSignedProposal().GetProposalBytes()-Proposal-GetPayload()=%#v&quot;, payload) log.Printf(&quot;stub.GetSignedProposal().GetSignature()=%s&quot;, byteToString(proposal.GetSignature())) // 设置一个Event if err := stub.SetEvent(&quot;hello event&quot;, []byte(&quot;hello&quot;)); err != nil &#123; return err &#125; //2021/01/25 10:22:57 stub.GetHistoryForKey(asset1), next=&amp;queryresult.KeyModification&#123; //TxId:&quot;f251ce5352e294cd628fc0b5d09271ebe8253b41d66069c164195fe2783c3adc&quot;, //Value:[]uint8&#123;0x7b, 0x22, 0x49, 0x44, 0x22, 0x3a, 0x22, 0x61, 0x73, 0x73, 0x65, 0x74, 0x31, 0x22, 0x2c //, 0x22, 0x63, 0x6f, 0x6c, 0x6f, 0x72, 0x22, 0x3a, 0x22, 0x62, 0x6c, 0x75, 0x65, 0x22, 0x2c, 0x22, 0x73, 0x69, 0x7a, 0x65, 0x22, 0x3a, 0x35, 0x2c, 0x22, 0x6f, 0x77, 0x6e, 0x65, 0x72, 0x22, 0x3a, 0x22, 0x54, 0x6f, 0x6d, 0x6f, 0x6b, 0x6f, 0x22, 0x2c, 0x22, 0x61, 0x70, 0x70, 0x72, 0x61, 0x69, 0x73, 0x65, 0x64, 0x56, 0x61, 0x6c, 0x75, 0x65, 0x22, 0x3a, 0x33, 0x30, 0x30, 0x7d&#125;, //Timestamp:(*timestamp.Timestamp)(0xc00043d1a0), //IsDelete:false, XXX_NoUnkeyedLiteral:struct &#123;&#125;&#123;&#125;, //XXX_unrecognized:[]uint8(nil), //XXX_sizecache:0&#125; assetHistory, err := stub.GetHistoryForKey(assetID) if err != nil &#123; return err &#125; defer assetHistory.Close() for assetHistory.HasNext() &#123; next, err := assetHistory.Next() if err != nil &#123; return err &#125; log.Printf(&quot;stub.GetHistoryForKey(%s), next=%#v&quot;, assetID, next) &#125; return nil&#125;func byteToString(data []byte) string &#123; str := (*string)(unsafe.Pointer(&amp;data)) return *str&#125; shim包下面也有一个GetMSPID方法，具体如下： 12345678910111213// GetMSPID returns the local mspid of the peer by checking the CORE_PEER_LOCALMSPID// env var and returns an error if the env var is not set// 通过检查环境变量CORE_PEER_LOCALMSPID返回peer节点本地的mspid，如果没有设置这个环境变量则返回一个errorfunc GetMSPID() (string, error) &#123; mspid := os.Getenv(&quot;CORE_PEER_LOCALMSPID&quot;) if mspid == &quot;&quot; &#123; return &quot;&quot;, errors.New(&quot;&#x27;CORE_PEER_LOCALMSPID&#x27; is not set&quot;) &#125; return mspid, nil&#125; TODO 待整合到一起 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684/* SPDX-License-Identifier: Apache-2.0*/package mainimport ( &quot;bytes&quot; &quot;crypto/sha256&quot; &quot;encoding/json&quot; &quot;fmt&quot; &quot;log&quot; &quot;time&quot; &quot;github.com/golang/protobuf/ptypes&quot; &quot;github.com/hyperledger/fabric-chaincode-go/pkg/statebased&quot; &quot;github.com/hyperledger/fabric-chaincode-go/shim&quot; &quot;github.com/hyperledger/fabric-contract-api-go/contractapi&quot;)const ( typeAssetForSale = &quot;S&quot; typeAssetBid = &quot;B&quot; typeAssetSaleReceipt = &quot;SR&quot; typeAssetBuyReceipt = &quot;BR&quot; statusEnable = &quot;enable&quot; statusDelete = &quot;delete&quot;)type SmartContract struct &#123; contractapi.Contract&#125;// Asset struct and properties must be exported (start with capitals) to work with contract api metadatatype Asset struct &#123; ObjectType string `json:&quot;objectType&quot;` // ObjectType is used to distinguish different object types in the same chaincode namespace ID string `json:&quot;assetID&quot;` OwnerOrg string `json:&quot;ownerOrg&quot;` PublicDescription string `json:&quot;publicDescription&quot;` Status string `json:&quot;status&quot;` ParentID string `json:&quot;parentID&quot;`&#125;type receipt struct &#123; price int timestamp time.Time&#125;// AssetProperties 资产属性type AssetProperties struct &#123; ObjectType string `json:&quot;objectType&quot;` // ObjectType is used to distinguish different object types in the same chaincode namespace ID string `json:&quot;assetID&quot;` Issuer string `json:&quot;issuer&quot;` Amount int `json:&quot;amount&quot;` CreateDate time.Time `json:&quot;createDate&quot;` EndDate time.Time `json:&quot;endDate&quot;` Salt string `json:&quot;salt&quot;`&#125;// CreateAsset creates an asset and sets it as owned by the client&#x27;s orgfunc (s *SmartContract) CreateAsset(ctx contractapi.TransactionContextInterface, assetID, publicDescription string) error &#123; // 获取临时数据库的数据，返回一个map[string][]byte transientMap, err := ctx.GetStub().GetTransient() if err != nil &#123; return fmt.Errorf(&quot;error getting transient: %v&quot;, err) &#125; // Asset properties must be retrieved from the transient field as they are private immutablePropertiesJSON, ok := transientMap[&quot;asset_properties&quot;] fmt.Println(&quot;immutablePropertiesJSON:&quot;, immutablePropertiesJSON) if !ok &#123; return fmt.Errorf(&quot;asset_properties key not found in the transient map&quot;) &#125; return createAsset(ctx, immutablePropertiesJSON, assetID, publicDescription, &quot;&quot;)&#125;// CreateAsset creates an asset and sets it as owned by the client&#x27;s orgfunc createAsset(ctx contractapi.TransactionContextInterface, immutablePropertiesJSON []byte, assetID, publicDescription string, parentID string) error &#123; // Get client org id and verify it matches peer org id. // In this scenario, client is only authorized to read/write private data from its own peer. clientOrgID, err := getClientOrgID(ctx, true) fmt.Println(&quot;clientOrgID:&quot;, clientOrgID) if err != nil &#123; return fmt.Errorf(&quot;failed to get verified OrgID: %v&quot;, err) &#125; asset := Asset&#123; ObjectType: &quot;asset&quot;, ID: assetID, OwnerOrg: clientOrgID, PublicDescription: publicDescription, Status: statusEnable, ParentID: parentID, &#125; fmt.Println(&quot;asset:&quot;, asset) assetBytes, err := json.Marshal(asset) if err != nil &#123; return fmt.Errorf(&quot;failed to create asset JSON: %v&quot;, err) &#125; err = ctx.GetStub().PutState(asset.ID, assetBytes) if err != nil &#123; return fmt.Errorf(&quot;failed to put asset in public data: %v&quot;, err) &#125; // Set the endorsement policy such that an owner org peer is required to endorse future updates err = setAssetStateBasedEndorsement(ctx, asset.ID, clientOrgID) if err != nil &#123; return fmt.Errorf(&quot;failed setting state based endorsement for owner: %v&quot;, err) &#125; // Persist private immutable asset properties to owner&#x27;s private data collection collection := buildCollectionName(clientOrgID) fmt.Println(&quot;collection:&quot;, collection) err = ctx.GetStub().PutPrivateData(collection, asset.ID, immutablePropertiesJSON) if err != nil &#123; return fmt.Errorf(&quot;failed to put Asset private details: %v&quot;, err) &#125; return nil&#125;// // verifyAssetProperties 验证资产属性的信息// func verifyAssetProperties(immutablePropertiesJSON []byte, asset Asset) error &#123;// assetProperties, err := getAssetProperties(immutablePropertiesJSON)// if err != nil &#123;// return err// &#125;// // 资产的属性ID和资产ID相同// if asset.ID != assetProperties.ID &#123;// return fmt.Errorf(&quot;资产ID和资产属性ID必须相同&quot;)// &#125;// // 资产的发行者就是资产的创建者，所有人都可以发行，但是别人认不认可这个组织发行的资产是另一回事// if asset.OwnerOrg != assetProperties.Issuer &#123;// return fmt.Errorf(&quot;资产的发行方必须是当前创建资产的组织&quot;)// &#125;// // 理论上这里应该还有更多的校验，比如说创建时间和失效时间的验证// return nil// &#125;// ChangePublicDescription updates the assets public description. Only the current owner can update the public descriptionfunc (s *SmartContract) ChangePublicDescription(ctx contractapi.TransactionContextInterface, assetID string, newDescription string) error &#123; asset, err := s.ReadAsset(ctx, assetID) if err != nil &#123; return fmt.Errorf(&quot;failed to get asset: %v&quot;, err) &#125; return changeOriginAssetInfo(ctx, *asset, &quot;&quot;, newDescription)&#125;// AgreeToSell adds seller&#x27;s asking price to seller&#x27;s implicit private data collectionfunc (s *SmartContract) AgreeToSell(ctx contractapi.TransactionContextInterface, assetID string) error &#123; asset, err := s.ReadAsset(ctx, assetID) if err != nil &#123; return err &#125; clientOrgID, err := getClientOrgID(ctx, true) if err != nil &#123; return fmt.Errorf(&quot;failed to get verified OrgID: %v&quot;, err) &#125; // Verify that this clientOrgId actually owns the asset. if clientOrgID != asset.OwnerOrg &#123; return fmt.Errorf(&quot;a client from %s cannot sell an asset owned by %s&quot;, clientOrgID, asset.OwnerOrg) &#125; return agreeToPrice(ctx, assetID, typeAssetForSale)&#125;// AgreeToBuy adds buyer&#x27;s bid price to buyer&#x27;s implicit private data collectionfunc (s *SmartContract) AgreeToBuy(ctx contractapi.TransactionContextInterface, assetID string) error &#123; return agreeToPrice(ctx, assetID, typeAssetBid)&#125;// agreeToPrice adds a bid or ask price to caller&#x27;s implicit private data collectionfunc agreeToPrice(ctx contractapi.TransactionContextInterface, assetID string, priceType string) error &#123; // In this scenario, client is only authorized to read/write private data from its own peer. clientOrgID, err := getClientOrgID(ctx, true) if err != nil &#123; return fmt.Errorf(&quot;failed to get verified OrgID: %v&quot;, err) &#125; transMap, err := ctx.GetStub().GetTransient() if err != nil &#123; return fmt.Errorf(&quot;error getting transient: %v&quot;, err) &#125; // Asset price must be retrieved from the transient field as they are private price, ok := transMap[&quot;asset_price&quot;] if !ok &#123; return fmt.Errorf(&quot;asset_price key not found in the transient map&quot;) &#125; collection := buildCollectionName(clientOrgID) // Persist the agreed to price in a collection sub-namespace based on priceType key prefix, // to avoid collisions between private asset properties, sell price, and buy price assetPriceKey, err := ctx.GetStub().CreateCompositeKey(priceType, []string&#123;assetID&#125;) if err != nil &#123; return fmt.Errorf(&quot;failed to create composite key: %v&quot;, err) &#125; // The Price hash will be verified later, therefore always pass and persist price bytes as is, // so that there is no risk of nondeterministic marshaling. err = ctx.GetStub().PutPrivateData(collection, assetPriceKey, price) if err != nil &#123; return fmt.Errorf(&quot;failed to put asset bid: %v&quot;, err) &#125; return nil&#125;// VerifyAssetProperties Allows a buyer to validate the properties of// an asset against the owner&#x27;s implicit private data collectionfunc (s *SmartContract) VerifyAssetProperties(ctx contractapi.TransactionContextInterface, assetID string) (bool, error) &#123; transMap, err := ctx.GetStub().GetTransient() if err != nil &#123; return false, fmt.Errorf(&quot;error getting transient: %v&quot;, err) &#125; /// Asset properties must be retrieved from the transient field as they are private immutablePropertiesJSON, ok := transMap[&quot;asset_properties&quot;] if !ok &#123; return false, fmt.Errorf(&quot;asset_properties key not found in the transient map&quot;) &#125; asset, err := s.ReadAsset(ctx, assetID) if err != nil &#123; return false, fmt.Errorf(&quot;failed to get asset: %v&quot;, err) &#125; // 添加资产状态的验证 if (*asset).Status != statusEnable &#123; return false, fmt.Errorf(&quot;资产不可以，不允许交易: %v&quot;, err) &#125; collectionOwner := buildCollectionName(asset.OwnerOrg) immutablePropertiesOnChainHash, err := ctx.GetStub().GetPrivateDataHash(collectionOwner, assetID) if err != nil &#123; return false, fmt.Errorf(&quot;failed to read asset private properties hash from seller&#x27;s collection: %v&quot;, err) &#125; if immutablePropertiesOnChainHash == nil &#123; return false, fmt.Errorf(&quot;asset private properties hash does not exist: %s&quot;, assetID) &#125; hash := sha256.New() hash.Write(immutablePropertiesJSON) calculatedPropertiesHash := hash.Sum(nil) // verify that the hash of the passed immutable properties matches the on-chain hash if !bytes.Equal(immutablePropertiesOnChainHash, calculatedPropertiesHash) &#123; return false, fmt.Errorf(&quot;hash %x for passed immutable properties %s does not match on-chain hash %x&quot;, calculatedPropertiesHash, immutablePropertiesJSON, immutablePropertiesOnChainHash, ) &#125; return true, nil&#125;// TransferAsset checks transfer conditions and then transfers asset state to buyer.// TransferAsset can only be called by current ownerfunc (s *SmartContract) TransferAsset(ctx contractapi.TransactionContextInterface, assetID string, buyerOrgID string) error &#123; clientOrgID, err := getClientOrgID(ctx, false) if err != nil &#123; return fmt.Errorf(&quot;failed to get verified OrgID: %v&quot;, err) &#125; transMap, err := ctx.GetStub().GetTransient() if err != nil &#123; return fmt.Errorf(&quot;error getting transient data: %v&quot;, err) &#125; immutablePropertiesJSON, ok := transMap[&quot;asset_properties&quot;] if !ok &#123; return fmt.Errorf(&quot;asset_properties key not found in the transient map&quot;) &#125; priceJSON, ok := transMap[&quot;asset_price&quot;] if !ok &#123; return fmt.Errorf(&quot;asset_price key not found in the transient map&quot;) &#125; var agreement Agreement err = json.Unmarshal(priceJSON, &amp;agreement) if err != nil &#123; return fmt.Errorf(&quot;failed to unmarshal price JSON: %v&quot;, err) &#125; asset, err := s.ReadAsset(ctx, assetID) if err != nil &#123; return fmt.Errorf(&quot;failed to get asset: %v&quot;, err) &#125; // 添加资产状态的验证 if (*asset).Status != statusEnable &#123; return fmt.Errorf(&quot;资产不可以，不允许交易&quot;) &#125; err = verifyTransferConditions(ctx, asset, immutablePropertiesJSON, clientOrgID, buyerOrgID, priceJSON) if err != nil &#123; return fmt.Errorf(&quot;failed transfer verification: %v&quot;, err) &#125; err = transferAssetState(ctx, asset, immutablePropertiesJSON, clientOrgID, buyerOrgID, agreement.Price) if err != nil &#123; return fmt.Errorf(&quot;failed asset transfer: %v&quot;, err) &#125; return nil&#125;// SplitAsset 拆分资产为两个资产，传入的amount是拆分后的其中一个资产的金额func (s *SmartContract) SplitAsset(ctx contractapi.TransactionContextInterface, assetID string, amount int) error &#123; asset, err := s.ReadAsset(ctx, assetID) if err != nil &#123; return err &#125; immutableProperties, err := getAssetPrivateProperties(ctx, assetID) if err != nil &#123; return err &#125; assetProperties, err := getAssetProperties(immutableProperties) if err != nil &#123; return err &#125; if assetProperties.Amount &lt;= amount &#123; return fmt.Errorf(&quot;资产ID的金额为%d小于想要拆分的金额为%d，不允许拆分&quot;, assetProperties.Amount, amount) &#125; if err := splitAsset(ctx, assetProperties, assetID+&quot;1&quot;, amount, *asset); err != nil &#123; return err &#125; if err := splitAsset(ctx, assetProperties, assetID+&quot;2&quot;, assetProperties.Amount-amount, *asset); err != nil &#123; return err &#125; // 拆分之后删除旧资产 collection := buildCollectionName((*asset).OwnerOrg) err = ctx.GetStub().DelPrivateData(collection, asset.ID) if err != nil &#123; return fmt.Errorf(&quot;failed to delete Asset private details from org: %v&quot;, err) &#125; // 修改公共资产信息 changeOriginAssetInfo(ctx, *asset, statusDelete, &quot;已拆分&quot;) return nil&#125;// 根据transient获取的assetProperties的字节数组获取AssetPropertiesfunc getAssetProperties(immutablePropertiesJSON []byte) (AssetProperties, error) &#123; var assetProperties AssetProperties if err := json.Unmarshal(immutablePropertiesJSON, &amp;assetProperties); err != nil &#123; return assetProperties, fmt.Errorf(&quot;failed to unmarshal price JSON: %v&quot;, err) &#125; return assetProperties, nil&#125;// ChangePublicDescription updates the assets public description. Only the current owner can update the public descriptionfunc changeOriginAssetInfo(ctx contractapi.TransactionContextInterface, asset Asset, status string, newDescription string) error &#123; // No need to check client org id matches peer org id, rely on the asset ownership check instead. clientOrgID, err := getClientOrgID(ctx, false) if err != nil &#123; return fmt.Errorf(&quot;failed to get verified OrgID: %v&quot;, err) &#125; // Auth check to ensure that client&#x27;s org actually owns the asset if clientOrgID != asset.OwnerOrg &#123; return fmt.Errorf(&quot;a client from %s cannot update the description of a asset owned by %s&quot;, clientOrgID, asset.OwnerOrg) &#125; // 添加资产状态的验证 if asset.Status != statusEnable &#123; return fmt.Errorf(&quot;资产不可用，不允许修改&quot;) &#125; if status != &quot;&quot; &#123; asset.Status = status &#125; if newDescription != &quot;&quot; &#123; asset.PublicDescription = newDescription &#125; updatedAssetJSON, err := json.Marshal(asset) if err != nil &#123; return fmt.Errorf(&quot;failed to marshal asset: %v&quot;, err) &#125; return ctx.GetStub().PutState(asset.ID, updatedAssetJSON)&#125;// splitAsset 从原始资产属性拆分成指定ID和金额的资产func splitAsset(ctx contractapi.TransactionContextInterface, originAssetProperties AssetProperties, newAssetID string, newAmount int, asset Asset) error &#123; originAssetProperties.Amount = newAmount originAssetProperties.ID = newAssetID immutablePropertiesJSON, err := json.Marshal(originAssetProperties) if err != nil &#123; return err &#125; return createAsset(ctx, immutablePropertiesJSON, newAssetID, asset.PublicDescription, asset.ID)&#125;// verifyTransferConditions checks that client org currently owns asset and that both parties have agreed on pricefunc verifyTransferConditions(ctx contractapi.TransactionContextInterface, asset *Asset, immutablePropertiesJSON []byte, clientOrgID string, buyerOrgID string, priceJSON []byte) error &#123; // CHECK1: Auth check to ensure that client&#x27;s org actually owns the asset if clientOrgID != asset.OwnerOrg &#123; return fmt.Errorf(&quot;a client from %s cannot transfer a asset owned by %s&quot;, clientOrgID, asset.OwnerOrg) &#125; // CHECK2: Verify that the hash of the passed immutable properties matches the on-chain hash collectionSeller := buildCollectionName(clientOrgID) immutablePropertiesOnChainHash, err := ctx.GetStub().GetPrivateDataHash(collectionSeller, asset.ID) if err != nil &#123; return fmt.Errorf(&quot;failed to read asset private properties hash from seller&#x27;s collection: %v&quot;, err) &#125; if immutablePropertiesOnChainHash == nil &#123; return fmt.Errorf(&quot;asset private properties hash does not exist: %s&quot;, asset.ID) &#125; hash := sha256.New() hash.Write(immutablePropertiesJSON) calculatedPropertiesHash := hash.Sum(nil) // verify that the hash of the passed immutable properties matches the on-chain hash if !bytes.Equal(immutablePropertiesOnChainHash, calculatedPropertiesHash) &#123; return fmt.Errorf(&quot;hash %x for passed immutable properties %s does not match on-chain hash %x&quot;, calculatedPropertiesHash, immutablePropertiesJSON, immutablePropertiesOnChainHash, ) &#125; // CHECK3: Verify that seller and buyer agreed on the same price // Get sellers asking price assetForSaleKey, err := ctx.GetStub().CreateCompositeKey(typeAssetForSale, []string&#123;asset.ID&#125;) if err != nil &#123; return fmt.Errorf(&quot;failed to create composite key: %v&quot;, err) &#125; sellerPriceHash, err := ctx.GetStub().GetPrivateDataHash(collectionSeller, assetForSaleKey) if err != nil &#123; return fmt.Errorf(&quot;failed to get seller price hash: %v&quot;, err) &#125; if sellerPriceHash == nil &#123; return fmt.Errorf(&quot;seller price for %s does not exist&quot;, asset.ID) &#125; // Get buyers bid price collectionBuyer := buildCollectionName(buyerOrgID) assetBidKey, err := ctx.GetStub().CreateCompositeKey(typeAssetBid, []string&#123;asset.ID&#125;) if err != nil &#123; return fmt.Errorf(&quot;failed to create composite key: %v&quot;, err) &#125; // TODO 疑问：这个方法是由资产拥有者调用的，那么资产拥有者怎么可以获取资产买方的出价信息呢？如果是从公共状态获取购买方的出价hash是没问题的，但是从购买方的私有数据集中获取出价hash很让人费解。 buyerPriceHash, err := ctx.GetStub().GetPrivateDataHash(collectionBuyer, assetBidKey) if err != nil &#123; return fmt.Errorf(&quot;failed to get buyer price hash: %v&quot;, err) &#125; if buyerPriceHash == nil &#123; return fmt.Errorf(&quot;buyer price for %s does not exist&quot;, asset.ID) &#125; hash = sha256.New() hash.Write(priceJSON) calculatedPriceHash := hash.Sum(nil) // Verify that the hash of the passed price matches the on-chain sellers price hash if !bytes.Equal(calculatedPriceHash, sellerPriceHash) &#123; return fmt.Errorf(&quot;hash %x for passed price JSON %s does not match on-chain hash %x, seller hasn&#x27;t agreed to the passed trade id and price&quot;, calculatedPriceHash, priceJSON, sellerPriceHash, ) &#125; // Verify that the hash of the passed price matches the on-chain buyer price hash if !bytes.Equal(calculatedPriceHash, buyerPriceHash) &#123; return fmt.Errorf(&quot;hash %x for passed price JSON %s does not match on-chain hash %x, buyer hasn&#x27;t agreed to the passed trade id and price&quot;, calculatedPriceHash, priceJSON, buyerPriceHash, ) &#125; return nil&#125;// transferAssetState performs the public and private state updates for the transferred assetfunc transferAssetState(ctx contractapi.TransactionContextInterface, asset *Asset, immutablePropertiesJSON []byte, clientOrgID string, buyerOrgID string, price int) error &#123; asset.OwnerOrg = buyerOrgID updatedAsset, err := json.Marshal(asset) if err != nil &#123; return err &#125; err = ctx.GetStub().PutState(asset.ID, updatedAsset) if err != nil &#123; return fmt.Errorf(&quot;failed to write asset for buyer: %v&quot;, err) &#125; // Change the endorsement policy to the new owner err = setAssetStateBasedEndorsement(ctx, asset.ID, buyerOrgID) if err != nil &#123; return fmt.Errorf(&quot;failed setting state based endorsement for new owner: %v&quot;, err) &#125; // Transfer the private properties (delete from seller collection, create in buyer collection) collectionSeller := buildCollectionName(clientOrgID) err = ctx.GetStub().DelPrivateData(collectionSeller, asset.ID) if err != nil &#123; return fmt.Errorf(&quot;failed to delete Asset private details from seller: %v&quot;, err) &#125; collectionBuyer := buildCollectionName(buyerOrgID) err = ctx.GetStub().PutPrivateData(collectionBuyer, asset.ID, immutablePropertiesJSON) if err != nil &#123; return fmt.Errorf(&quot;failed to put Asset private properties for buyer: %v&quot;, err) &#125; // Delete the price records for seller assetPriceKey, err := ctx.GetStub().CreateCompositeKey(typeAssetForSale, []string&#123;asset.ID&#125;) if err != nil &#123; return fmt.Errorf(&quot;failed to create composite key for seller: %v&quot;, err) &#125; err = ctx.GetStub().DelPrivateData(collectionSeller, assetPriceKey) if err != nil &#123; return fmt.Errorf(&quot;failed to delete asset price from implicit private data collection for seller: %v&quot;, err) &#125; // Delete the price records for buyer assetPriceKey, err = ctx.GetStub().CreateCompositeKey(typeAssetBid, []string&#123;asset.ID&#125;) if err != nil &#123; return fmt.Errorf(&quot;failed to create composite key for buyer: %v&quot;, err) &#125; err = ctx.GetStub().DelPrivateData(collectionBuyer, assetPriceKey) if err != nil &#123; return fmt.Errorf(&quot;failed to delete asset price from implicit private data collection for buyer: %v&quot;, err) &#125; // Keep record for a &#x27;receipt&#x27; in both buyers and sellers private data collection to record the sale price and date. // Persist the agreed to price in a collection sub-namespace based on receipt key prefix. receiptBuyKey, err := ctx.GetStub().CreateCompositeKey(typeAssetBuyReceipt, []string&#123;asset.ID, ctx.GetStub().GetTxID()&#125;) if err != nil &#123; return fmt.Errorf(&quot;failed to create composite key for receipt: %v&quot;, err) &#125; txTimestamp, err := ctx.GetStub().GetTxTimestamp() if err != nil &#123; return fmt.Errorf(&quot;failed to create timestamp for receipt: %v&quot;, err) &#125; timestamp, err := ptypes.Timestamp(txTimestamp) if err != nil &#123; return err &#125; assetReceipt := receipt&#123; price: price, timestamp: timestamp, &#125; receipt, err := json.Marshal(assetReceipt) if err != nil &#123; return fmt.Errorf(&quot;failed to marshal receipt: %v&quot;, err) &#125; err = ctx.GetStub().PutPrivateData(collectionBuyer, receiptBuyKey, receipt) if err != nil &#123; return fmt.Errorf(&quot;failed to put private asset receipt for buyer: %v&quot;, err) &#125; receiptSaleKey, err := ctx.GetStub().CreateCompositeKey(typeAssetSaleReceipt, []string&#123;ctx.GetStub().GetTxID(), asset.ID&#125;) if err != nil &#123; return fmt.Errorf(&quot;failed to create composite key for receipt: %v&quot;, err) &#125; err = ctx.GetStub().PutPrivateData(collectionSeller, receiptSaleKey, receipt) if err != nil &#123; return fmt.Errorf(&quot;failed to put private asset receipt for seller: %v&quot;, err) &#125; return nil&#125;// getClientOrgID gets the client org ID.// The client org ID can optionally be verified against the peer org ID, to ensure that a client// from another org doesn&#x27;t attempt to read or write private data from this peer.// The only exception in this scenario is for TransferAsset, since the current owner// needs to get an endorsement from the buyer&#x27;s peer.func getClientOrgID(ctx contractapi.TransactionContextInterface, verifyOrg bool) (string, error) &#123; // GetClientIdentity()获取客户端的身份，返回ClientIdentity接口，这个接口有如下方法： // GetID returns the ID associated with the invoking identity. This ID // is guaranteed to be unique within the MSP. // * GetID() (string, error) 获取 clientOrgID, err := ctx.GetClientIdentity().GetMSPID() if err != nil &#123; return &quot;&quot;, fmt.Errorf(&quot;failed getting client&#x27;s orgID: %v&quot;, err) &#125; if verifyOrg &#123; err = verifyClientOrgMatchesPeerOrg(clientOrgID) if err != nil &#123; return &quot;&quot;, err &#125; &#125; return clientOrgID, nil&#125;// verifyClientOrgMatchesPeerOrg checks the client org id matches the peer org id.func verifyClientOrgMatchesPeerOrg(clientOrgID string) error &#123; peerOrgID, err := shim.GetMSPID() if err != nil &#123; return fmt.Errorf(&quot;failed getting peer&#x27;s orgID: %v&quot;, err) &#125; if clientOrgID != peerOrgID &#123; return fmt.Errorf(&quot;client from org %s is not authorized to read or write private data from an org %s peer&quot;, clientOrgID, peerOrgID, ) &#125; return nil&#125;// setAssetStateBasedEndorsement adds an endorsement policy to a asset so that only a peer from an owning org// can update or transfer the asset.func setAssetStateBasedEndorsement(ctx contractapi.TransactionContextInterface, assetID string, orgToEndorse string) error &#123; endorsementPolicy, err := statebased.NewStateEP(nil) if err != nil &#123; return err &#125; err = endorsementPolicy.AddOrgs(statebased.RoleTypeMember, orgToEndorse) if err != nil &#123; return fmt.Errorf(&quot;failed to add org to endorsement policy: %v&quot;, err) &#125; policy, err := endorsementPolicy.Policy() if err != nil &#123; return fmt.Errorf(&quot;failed to create endorsement policy bytes from org: %v&quot;, err) &#125; // fmt.Printf(&quot;assetID=%s, orgToEndorse=%s, policy=%s, len(policy)=%d \\n&quot;, assetID, orgToEndorse, policy, len(policy)) // fmt.Printf(&quot;assetID=%s, policy=%s, endorsementPolicy.ListOrgs=%s\\n&quot;, assetID, string(policy[:]), endorsementPolicy.ListOrgs()) return ctx.GetStub().SetStateValidationParameter(assetID, policy)&#125;func buildCollectionName(clientOrgID string) string &#123; return fmt.Sprintf(&quot;_implicit_org_%s&quot;, clientOrgID)&#125;func getClientImplicitCollectionName(ctx contractapi.TransactionContextInterface) (string, error) &#123; clientOrgID, err := getClientOrgID(ctx, true) if err != nil &#123; return &quot;&quot;, fmt.Errorf(&quot;failed to get verified OrgID: %v&quot;, err) &#125; err = verifyClientOrgMatchesPeerOrg(clientOrgID) if err != nil &#123; return &quot;&quot;, err &#125; return buildCollectionName(clientOrgID), nil&#125;func main() &#123; chaincode, err := contractapi.NewChaincode(new(SmartContract)) if err != nil &#123; log.Panicf(&quot;Error create transfer asset chaincode: %v&quot;, err) &#125; if err := chaincode.Start(); err != nil &#123; log.Panicf(&quot;Error starting asset chaincode: %v&quot;, err) &#125;&#125;","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"chaincode-API","slug":"区块链/Hyperledger-Fabric/chaincode-API","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/chaincode-API/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"API","slug":"API","permalink":"https://guozhe001.github.io/tags/API/"}]},{"title":"Ledger(账本)","slug":"blockchain/fabric/关键概念/Ledger","date":"2024-11-22T06:32:06.495Z","updated":"2024-11-22T06:32:06.495Z","comments":true,"path":"2024/11/22/blockchain/fabric/关键概念/Ledger/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E5%85%B3%E9%94%AE%E6%A6%82%E5%BF%B5/Ledger/","excerpt":"","text":"本文档来自于Ledger，为了提高学习效率而做了简化。 The Ledger Ledger：由World State和Blockchain组成 World State：是保存账本state的当前状态的数据库（个人理解：可以类比比特币的UTXO） Blockchain：记录所有导致当前World State发生的更改的事务日志（个人理解：与比特币的区块链基本一致） World State 世界状态是一些事实的键值对 世界状态是通过数据库实现的 应用程序提交改变世界状态的交易，这些交易最终被提交到账本的区块链 世界状态记录的事实都有版本，供Hyperledger Fabric内部使用，并且每次状态更改时都会递增 当首次创建分类帐时，世界状态为空 Blockchain Blockchain是有关世界状态中的state是如何到达其当前状态的事实的历史记录 Fabric中的Blockchain是由文件实现 Blockchain由Block组成 Block包含Block header、Block data和Block metadata Block header中包含Block data的hash值和上一个区块的hash值 Block data中包含交易列表 Blocks Block Header Block number: 从零开始的数字，创世区块是0，每次追加一个新的区块这个Block number自增1 Current Block Hash: 当前区块包含的所有的交易的hash值 Previous Block Header Hash: 上一个区块的Block Header中的hash值 Block Data Block Data包含已经排好序的交易列表，这些交易在排序服务创建区块时写入到Block Data Block Metadata Block Metadata包含区块创建者的证书和签名，用于通过网络节点验证块。 区块提交者将每个交易的有效/无效指示符添加到Block Metadata的bitmap中 直到（包括）该块为止的累积状态的哈希值，以便检测状态派生（这是为了在提交之前验证状态有没有被其他的交易更改） Transactions 每个交易都包含以下四部分： Header 取得有关交易的一些基本元数据-例如相关链码的名称及其版本。 Signature 包含客户端应用程序的签名；此字段用于检查交易明细是否未被篡改，因为它需要应用程序的私钥来生成。 Proposal 保存编码后的应用程序提供给智能合约的输入参数，使用这些参数来创建更新账本的提议。当智能合约运行时，该提议提供了一组输入参数，这些输入参数与当前的世界状态一起确定了新的世界状态。 Response 获取世界状态的前后值，作为读写集（RW-set）。它是智能合约的输出，如果交易成功通过验证，它将应用于账本来更新世界状态。 Endorsements 这是满足背书策略的组织的签名列表。交易响应包含了背书列表，并且只有满足交易背书策略的背书列表才会存在在此，如果不满足背书策略则不在此记录，因为也不会更新世界状态。 World State database options The world state is physically implemented as a database, to provide simple and efficient storage and retrieval of ledger states. As we’ve seen, ledger states can have simple or compound values, and to accommodate this, the world state database implementation can vary, allowing these values to be efficiently implemented. Options for the world state database currently include LevelDB and CouchDB. 世界状态在物理上是使用数据库实现的，以提供简单有效的存储和账本状态检索。如我们所见，账本状态可以具有简单值或复合值，为了适应这种情况，世界状态数据库的实现方式可能会有所不同，从而可以有效地实现这些情况。世界状态数据库的选项当前包括LevelDB和CouchDB。 LevelDB is the default and is particularly appropriate when ledger states are simple key-value pairs. A LevelDB database is co-located with the peer node – it is embedded within the same operating system process. LevelDB是默认值，当账本状态为简单键/值对时尤其适用。LevelDB数据库与peer节点位于同一位置都嵌入在同一操作系统进程中。 CouchDB is a particularly appropriate choice when ledger states are structured as JSON documents because CouchDB supports the rich queries and update of richer data types often found in business transactions. Implementation-wise, CouchDB runs in a separate operating system process, but there is still a 1:1 relation between a peer node and a CouchDB instance. All of this is invisible to a smart contract. See CouchDB as the StateDatabase for more information on CouchDB. 当账本状态被构造为JSON格式的文档时，CouchDB是一个特别合适的选择，因为CouchDB支持丰富的查询和业务交易中经常发生的丰富数据类型的更新。在实现方面，CouchDB在单独的操作系统进程中运行，但是peer节点和CouchDB实例之间仍然存在1比1的关系。 In LevelDB and CouchDB, we see an important aspect of Hyperledger Fabric – it is pluggable. The world state database could be a relational data store, or a graph store, or a temporal database. This provides great flexibility in the types of ledger states that can be efficiently accessed, allowing Hyperledger Fabric to address many different types of problems. 在LevelDB和CouchDB中，我们看到了Hyperledger Fabric的重要方面–它是插件化的。世界状态数据库可以是关系数据存储，图形存储或时态数据库。这为可以有效访问的账本状态类型提供了极大的灵活性，从而使Hyperledger Fabric可以解决许多不同类型的问题。 Example Ledger: Basic Asset Transfer 使用同一个身份创建四个资产，账本会变成下面这样： Namespaces Even though we have presented the ledger as though it were a single world state and single blockchain, that’s a little bit of an over-simplification. In reality, each chaincode has its own world state that is separate from all other chaincodes. World states are in a namespace so that only smart contracts within the same chaincode can access a given namespace. 即使我们已经将账本呈现为一个单一的世界状态和单个区块链，但这还是有点过分简化了。实际上，每个链码都有其自己的世界状态，该状态与所有其他链码分开。世界状态位于名称空间中，因此只有相同链码内的智能合约才能访问给定的名称空间。 A blockchain is not namespaced. It contains transactions from many different smart contract namespaces. You can read more about chaincode namespaces in this topic. 区块链没有命名空间。它包含来自许多不同的智能合约命名空间的交易。您可以在Chaincode namespace中阅读有关链码名称空间的更多信息。 Channels In Hyperledger Fabric, each channel has a completely separate ledger. This means a completely separate blockchain, and completely separate world states, including namespaces. It is possible for applications and smart contracts to communicate between channels so that ledger information can be accessed between them. 在Hyperledger Fabric中，每个通道都有一个完全独立的账本。这意味着完全独立的区块链，以及完全独立的世界状态以及名称空间。应用程序和智能合约可以在通道之间进行通信，以便可以在它们之间访问分类帐信息。","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"Key Concepts","slug":"区块链/Hyperledger-Fabric/Key-Concepts","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/Key-Concepts/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"Ledger","slug":"Ledger","permalink":"https://guozhe001.github.io/tags/Ledger/"}]},{"title":"Membership Service Provider (MSP)","slug":"blockchain/fabric/关键概念/MSP","date":"2024-11-22T06:32:06.495Z","updated":"2024-11-22T06:32:06.495Z","comments":true,"path":"2024/11/22/blockchain/fabric/关键概念/MSP/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E5%85%B3%E9%94%AE%E6%A6%82%E5%BF%B5/MSP/","excerpt":"","text":"Why do I need an MSP?（为什么我需要MSP） Because Fabric is a permissioned network, blockchain participants need a way to prove their identity to the rest of the network in order to transact on the network. If you’ve read through the documentation on Identity you’ve seen how a Public Key Infrastructure (PKI) can provide verifiable identities through a chain of trust. How is that chain of trust used by the blockchain network? 因为Fabric是一个许可形式的网络，区块链参与者需要一种向网络其他成员证明自己身份的方法，以便在网络上进行交易。如果你已经阅读了 Identity 文档，你已经看到PKI如何通过信任链提供可验证的身份。区块链网络如何使用该信任链？ Certificate Authorities issue identities by generating a public and private key which forms a key-pair that can be used to prove identity. Because a private key can never be shared publicly, a mechanism is required to enable that proof which is where the MSP comes in. For example, a peer uses its private key to digitally sign, or endorse, a transaction. The MSP on the ordering service contains the peer’s public key which is then used to verify that the signature attached to the transaction is valid. The private key is used to produce a signature on a transaction that only the corresponding public key, that is part of an MSP, can match. Thus, the MSP is the mechanism that allows that identity to be trusted and recognized by the rest of the network without ever revealing the member’s private key. 证书颁发机构通过生成公钥和私钥来颁发身份，该公钥和私钥形成可用于证明身份的密钥对。由于永远不能公开共享私钥，因此需要一种机制来证明他是谁，然后MSP就是做这件事的。例如一个peer节点是用他自己的私钥来签名或者背书一个交易。排序服务的MSP包含了peer节点的公钥，该公钥随后用于验证附加到交易的签名是否有效。私钥用于在交易上产生签名，只有相应的公钥（MSP的一部分）才能匹配该签名。因此，MSP是一种允许身份由网络的其余部分信任和识别，而无需透露成员的私钥的机制。 Recall from the credit card scenario in the Identity topic that the Certificate Authority is like a card provider — it dispenses many different types of verifiable identities. An MSP, on the other hand, determines which credit card providers are accepted at the store. In this way, the MSP turns an identity (the credit card) into a role (the ability to buy things at the store). 从“身份”主题中的信用卡业务情景中回想起，证书颁发机构就像发卡组织一样-它分配了许多不同类型的可验证身份。另一方面，MSP确定商店接受哪些信用卡发卡组织。这样，MSP将身份（信用卡）转变为角色（在商店购买商品的能力）。 This ability to turn verifiable identities into roles is fundamental to the way Fabric networks function, since it allows organizations, nodes, and channels the ability establish MSPs that determine who is allowed to do what at the organization, node, and channel level. 这种将可验证身份转换为角色的能力是Fabric网络运行方式的基础，因为它允许组织，节点和渠道具备建立MSP的能力，从而确定允许谁在组织，节点和渠道级别上做什么。 Identities are similar to your credit cards that are used to prove you can pay. The MSP is similar to the list of accepted credit cards. Consider a consortium of banks that operate a blockchain network. Each bank operates peer and ordering nodes, and the peers endorse transactions submitted to the network. However, each bank would also have departments and account holders. The account holders would belong to each organization, but would not run nodes on the network. They would only interact with the system from their mobile or web application. So how does the network recognize and differentiate these identities? A CA was used to create the identities, but like the card example, those identities can’t just be issued, they need to be recognized by the network. MSPs are used to define the organizations that are trusted by the network members. MSPs are also the mechanism that provide members with a set of roles and permissions within the network. Because the MSPs defining these organizations are known to the members of a network, they can then be used to validate that network entities that attempt to perform actions are allowed to. 考虑一个经营区块链网络的银行联盟。每个银行都操作peer节点和排序节点，并且peer节点认可提交给网络的交易。但是每个银行也同样有部门和账户持有者。帐户持有者将属于各自的组织，但不会在网络上运行节点。他们只能通过其移动或Web应用程序与系统进行交互。那么网络如何识别和区分这些身份呢？可以使用CA来创建身份，但是就像卡片示例一样，不能仅仅是颁发了身份，还必须由网络来识别这些身份。MSP用于定义网络成员信任的组织。MSP还是一个机制，这个机制为成员提供网络中的一组角色和权限。由于MSP定义的这些组织对网络成员而言是已知的，因此它们可以用于验证允许尝试执行操作的网络实体。 Finally, consider if you want to join an existing network, you need a way to turn your identity into something that is recognized by the network. The MSP is the mechanism that enables you to participate on a permissioned blockchain network. To transact on a Fabric network a member needs to: Have an identity issued by a CA that is trusted by the network. Become a member of an organization that is recognized and approved by the network members. The MSP is how the identity is linked to the membership of an organization. Membership is achieved by adding the member’s public key (also known as certificate, signing cert, or signcert) to the organization’s MSP. Add the MSP to either a consortium on the network or a channel. Ensure the MSP is included in the policy definitions on the network. 最后，考虑如果你想要加入一个现有网络，你需要一个方法来将你的身份转换为网络可识别的内容。MSP是使您能够参与许可的区块链网络的机制。为了在Fabric的网络上进行交易，一个成员需要： 具有由网络信任的CA颁发的身份。 成为由网络成员认可并批准的组织的成员。MSP是将身份链接到组织成员的方式。成员资格是通过将成员的公钥（也称为证书，签名证书或signcert）添加到组织的MSP中来实现的。 将MSP添加到网络上的联盟或通道上。 确保MSP包含在网络上定义的策略。 What is an MSP? Despite its name, the Membership Service Provider does not actually provide anything. Rather, the implementation of the MSP requirement is a set of folders that are added to the configuration of the network and is used to define an organization both inwardly (organizations decide who its admins are) and outwardly (by allowing other organizations to validate that entities have the authority to do what they are attempting to do). Whereas Certificate Authorities generate the certificates that represent identities, the MSP contains a list of permissioned identities. The MSP identifies which Root CAs and Intermediate CAs are accepted to define the members of a trust domain by listing the identities of their members, or by identifying which CAs are authorized to issue valid identities for their members. But the power of an MSP goes beyond simply listing who is a network participant or member of a channel. It is the MSP that turns an identity into a role by identifying specific privileges an actor has on a node or channel. Note that when a user is registered with a Fabric CA, a role of admin, peer, client, orderer, or member must be associated with the user. For example, identities registered with the “peer” role should, naturally, be given to a peer. Similarly, identities registered with the “admin” role should be given to organization admins. We’ll delve more into the significance of these roles later in the topic. In addition, an MSP can allow for the identification of a list of identities that have been revoked — as discussed in the Identity documentation — but we will talk about how that process also extends to an MSP. MSP domains MSPs occur in two domains in a blockchain network: Locally on an actor’s node (local MSP) In channel configuration (channel MSP) The key difference between local and channel MSPs is not how they function – both turn identities into roles – but their scope. Each MSP lists roles and permissions at a particular level of administration. 本地MSP和通道MSP之间的主要区别不是它们的功能（两者都将身份转换为角色），而是它们的范围。每个MSP都列出特定管理级别的角色和权限。 Local MSPs Local MSPs are defined for clients and for nodes (peers and orderers). Local MSPs define the permissions for a node (who are the peer admins who can operate the node, for example). The local MSPs of clients (the account holders in the banking scenario above), allow the user to authenticate itself in its transactions as a member of a channel (e.g. in chaincode transactions), or as the owner of a specific role into the system such as an organization admin, for example, in configuration transactions. Local MSPs是为客户端和节点（peers和订orderers）定义的。本地MSP定义了一个节点的权限（例如谁是peer的管理员，谁可以操作这个节点）。客户端的本地MSP（上述银行业务场景中的帐户持有人）允许用户在自身交易中作为通道成员进行身份验证（例如在链码中交易中），或者作为系统中特定角色（例如组织管理员）的所有者，例如，在配置事务中。 Every node must have a local MSP defined, as it defines who has administrative or participatory rights at that level (peer admins will not necessarily be channel admins, and vice versa). This allows for authenticating member messages outside the context of a channel and to define the permissions over a particular node (who has the ability to install chaincode on a peer, for example). Note that one or more nodes can be owned by an organization. An MSP defines the organization admins. And the organization, the admin of the organization, the admin of the node, and the node itself should all have the same root of trust. 每个节点都需要定义一个本地的MSP，因为它定义了在该级别具有管理或参与权的人（peer管理员不一定是通道管理员，反之亦然）。这允许在通道上下文之外对成员消息进行身份验证，并定义对特定节点的权限（如谁有能力在peer上安装链码）。请注意，一个组织可以拥有一个或多个节点。MSP定义组织管理员。组织、组织的管理员、节点的管理员以及节点本身都应具有相同的根CA。 An orderer local MSP is also defined on the file system of the node and only applies to that node. Like peer nodes, orderers are also owned by a single organization and therefore have a single MSP to list the actors or nodes it trusts. 在排序者节点的文件系统上也定义了本地MSP，它仅适用于该节点。就像peer节点一样，排序者由单个组织拥有，因此有一个MSP列出其信任的参与者或节点。 Channel MSPs In contrast, channel MSPs define administrative and participatory rights at the channel level. Peers and ordering nodes on an application channel share the same view of channel MSPs, and will therefore be able to correctly authenticate the channel participants. This means that if an organization wishes to join the channel, an MSP incorporating the chain of trust for the organization’s members would need to be included in the channel configuration. Otherwise transactions originating from this organization’s identities will be rejected. Whereas local MSPs are represented as a folder structure on the file system, channel MSPs are described in a channel configuration. 相反，通道MSP在通道级别定义了管理权和参与权。应用程序通道上的peer节点和排序节点共享通道MSP的相同视图，因此将能够正确地验证通道参与者。这意味着如果组织希望加入通道，则需要在通道配置中包含一个包含组织成员信任链的MSP。否则，来自该组织身份的交易将被拒绝。本地MSP在文件系统上表示为文件夹结构，而通道MSP则在通道配置中描述。 Snippet from a channel config.json file that includes two organization MSPs. Channel MSPs identify who has authorities at a channel level. The channel MSP defines the relationship between the identities of channel members (which themselves are MSPs) and the enforcement of channel level policies. Channel MSPs contain the MSPs of the organizations of the channel members. **通道MSP识别谁拥有通道级别的权限。**通道MSP定义了通道成员身份（本身就是MSP）和通道级策略执行之间的关系。通道MSP包含通道成员组织的MSP。 Every organization participating in a channel must have an MSP defined for it. In fact, it is recommended that there is a one-to-one mapping between organizations and MSPs. The MSP defines which members are empowered to act on behalf of the organization. This includes configuration of the MSP itself as well as approving administrative tasks that the organization has role, such as adding new members to a channel. If all network members were part of a single organization or MSP, data privacy is sacrificed. Multiple organizations facilitate privacy by segregating ledger data to only channel members. If more granularity is required within an organization, the organization can be further divided into organizational units (OUs) which we describe in more detail later in this topic. **每个参与渠道的组织都必须为其定义MSP。**实际上，建议组织与MSP之间存在一对一的映射。MSP定义了哪些成员有权代表组织行事。这包括MSP本身的配置以及批准组织所扮演的管理任务，例如将新成员添加到渠道。如果所有网络成员都是单个组织或MSP的一部分，则会牺牲数据隐私。多个组织通过将账本数据仅隔离到通道成员来促成隐私。如果在组织内需要更多的粒度，则可以将组织进一步划分为组织单位（OU），我们将在本主题的后面部分对此进行详细介绍。 The system channel MSP includes the MSPs of all the organizations that participate in an ordering service. An ordering service will likely include ordering nodes from multiple organizations and collectively these organizations run the ordering service, most importantly managing the consortium of organizations and the default policies that are inherited by the application channels. **系统通道MSP包括加入排序服务的所有组织的MSP。**排序服务可能会包括来自多个组织的排序节点，并且这些组织共同运行排序服务，最重要的是管理组织联盟和应用程序通道继承的默认策略。 Local MSPs are only defined on the file system of the node or user to which they apply. Therefore, physically and logically there is only one local MSP per node. However, as channel MSPs are available to all nodes in the channel, they are logically defined once in the channel configuration. However, a channel MSP is also instantiated on the file system of every node in the channel and kept synchronized via consensus. So while there is a copy of each channel MSP on the local file system of every node, logically a channel MSP resides on and is maintained by the channel or the network. **本地MSP仅在它们应用到的节点或用户的文件系统上定义。**因此，在物理上和逻辑上每个节点只有一个本地MSP。但是，由于通道MSP可用于通道中的所有节点，因此它们在通道配置中被逻辑定义一次。但是，通道MSP也会在该通道中每个节点的文件系统上实例化，并通过共识保持同步。因此，尽管每个节点的本地文件系统上都有每个通道MSP的副本，但从逻辑上讲，通道MSP驻留在通道或网络上并由通道或网络维护。 The following diagram illustrates how local and channel MSPs coexist on the network: 下图说明了本地和通道MSP在网络上如何共存： The MSPs for the peer and orderer are local, whereas the MSPs for a channel (including the network configuration channel, also known as the system channel) are global, shared across all participants of that channel. In this figure, the network system channel is administered by ORG1, but another application channel can be managed by ORG1 and ORG2. The peer is a member of and managed by ORG2, whereas ORG1 manages the orderer of the figure. ORG1 trusts identities from RCA1, whereas ORG2 trusts identities from RCA2. It is important to note that these are administration identities, reflecting who can administer these components. So while ORG1 administers the network, ORG2.MSP does exist in the network definition. What role does an organization play in an MSP?（组织在MSP中扮演什么角色？） An organization is a logical managed group of members. This can be something as big as a multinational corporation or a small as a flower shop. What’s most important about organizations (or orgs) is that they manage their members under a single MSP. The MSP allows an identity to be linked to an organization. Note that this is different from the organization concept defined in an X.509 certificate, which we mentioned above. 组织是成员的逻辑托管组。它可以像跨国公司一样大，也可以像花店一样小。对于组织而言最重要的是他们在单个MSP下管理成员。MSP允许将身份链接到组织。请注意，这与我们上面提到的X.509证书中定义的组织概念不同。 The exclusive relationship between an organization and its MSP makes it sensible to name the MSP after the organization, a convention you’ll find adopted in most policy configurations. For example, organization ORG1 would likely have an MSP called something like ORG1-MSP. In some cases an organization may require multiple membership groups — for example, where channels are used to perform very different business functions between organizations. In these cases it makes sense to have multiple MSPs and name them accordingly, e.g., ORG2-MSP-NATIONAL and ORG2-MSP-GOVERNMENT, reflecting the different membership roots of trust within ORG2 in the NATIONAL sales channel compared to the GOVERNMENT regulatory channel. 由于组织及其MSP之间的排他关系，因此用组织名称来命名MSP是很明智的，这是大多数策略配置中都会采用的约定。例如组织ORG1 会有一个名为ORG1-MSP的MSP。 在某些情况下组织可能需要多个成员组；例如，在组织之间使用通道执行非常不同的业务功能的情况。在这些情况下，拥有多个MSP并相应地命名它们是很有意义的，，例如ORG2-MSP-NATIONAL和ORG2-MSP-GOVERNMENT，体现出ORG2内部在交易通道和监管通道的两个不同的信任根源。 Organizational Units (OUs) and MSPs（组织单位（OU）和MSP） An organization can also be divided into multiple organizational units, each of which has a certain set of responsibilities, also referred to as affiliations. Think of an OU as a department inside an organization. For example, the ORG1 organization might have both ORG1.MANUFACTURING and ORG1.DISTRIBUTION OUs to reflect these separate lines of business. When a CA issues X.509 certificates, the OU field in the certificate specifies the line of business to which the identity belongs. A benefit of using OUs like this is that these values can then be used in policy definitions in order to restrict access or in smart contracts for attribute-based access control. Otherwise, separate MSPs would need to be created for each organization. 一个组织也可以分为多个组织单位，每个组织单位都有一定的职责集，也称为从属关系。将OU视为组织内部的一个部门。例如，ORG1组织可能同时具有ORG1.MANUFACTURING和ORG1.DISTRIBUTION 两个组织单位，以反映这些单独的业务线。当CA颁发X.509证书时，证书中的OU字段会指定身份所属的业务范围。使用这样的OU的好处是，可将其用于策略定义中以限制访问，或用于基于属性的访问控制的智能合约中。否则，将需要为每个组织创建单独的MSP。 Specifying OUs is optional. If OUs are not used, all of the identities that are part of an MSP — as identified by the Root CA and Intermediate CA folders — will be considered members of the organization. 指定OU是可选的。如果不使用OU，则MSP部分的所有身份（由根CA和中级CA文件夹标识）将被视为组织的成员。 Node OU Roles and MSPs Additionally, there is a special kind of OU, sometimes referred to as a Node OU, that can be used to confer a role onto an identity. These Node OU roles are defined in the $FABRIC_CFG_PATH/msp/config.yaml file and contain a list of organizational units whose members are considered to be part of the organization represented by this MSP. This is particularly useful when you want to restrict the members of an organization to the ones holding an identity (signed by one of MSP designated CAs) with a specific Node OU role in it. For example, with node OU’s you can implement a more granular endorsement policy that requires Org1 peers to endorse a transaction, rather than any member of Org1. 此外，还有一种特殊的OU，有时也称为节点OU，可用于将角色赋予身份。这些节点OU角色在$FABRIC_CFG_PATH/msp/config.yaml文件中定义，并且包含一个组织单位列表，其成员被视为此MSP代表的组织的一部分。当您希望将组织的成员限制为持有具有特定Node OU角色的身份（由MSP指定的CA之一签名）的成员时，此功能特别有用。例如，通过节点OU，您可以实施更精细的认可政策，该政策要求Org1peer认可交易，而不是Org1的任何成员。 In order to use the Node OU roles, the “identity classification” feature must be enabled for the network. When using the folder-based MSP structure, this is accomplished by enabling “Node OUs” in the config.yaml file which resides in the root of the MSP folder: 为了使用节点OU角色，必须为网络启用“身份分类”功能。当使用基于文件夹的MSP结构时，可通过启用位于MSP文件夹根目录中的config.yaml文件中的 “Node OUs”来实现 1234567891011121314NodeOUs: Enable: true ClientOUIdentifier: Certificate: cacerts/ca.sampleorg-cert.pem OrganizationalUnitIdentifier: client PeerOUIdentifier: Certificate: cacerts/ca.sampleorg-cert.pem OrganizationalUnitIdentifier: peer AdminOUIdentifier: Certificate: cacerts/ca.sampleorg-cert.pem OrganizationalUnitIdentifier: admin OrdererOUIdentifier: Certificate: cacerts/ca.sampleorg-cert.pem OrganizationalUnitIdentifier: orderer In the example above, there are 4 possible Node OU ROLES for the MSP: client peer admin orderer This convention allows you to distinguish MSP roles by the OU present in the CommonName attribute of the X509 certificate. The example above says that any certificate issued by cacerts/ca.sampleorg-cert.pem in which OU=client will identified as a client, OU=peer as a peer, etc. Starting with Fabric v1.4.3, there is also an OU for the orderer and for admins. The new admins role means that you no longer have to explicitly place certs in the admincerts folder of the MSP directory. Rather, the admin role present in the user’s signcert qualifies the identity as an admin user. 此约定允许您通过X509证书的CommonName属性中存在的OU区分MSP角色。上面的示例表明，由cacerts/ca.sampleorg-cert.pem颁发的证书中，OU=client 将被标识为客户端，OU=peer 将被标识为peer。从Fabric v1.4.3开始，排序者和管理员也有对应的OU。新的管理员角色意味着您不再需要将证书明确放置在MSP目录的admincerts文件夹中；而是用户签名证书中的管理员角色可以将身份标识为管理员用户。 These Role and OU attributes are assigned to an identity when the Fabric CA or SDK is used to register a user with the CA. It is the subsequent enroll user command that generates the certificates in the users’ /msp folder. 当使用Fabric的CA或SDK向CA注册用户时，这些角色和OU属性将分配给一个身份。随后使用用户命令enroll 在用户 /msp 文件夹中生成证书。 The resulting ROLE and OU attributes are visible inside the X.509 signing certificate located in the /signcerts folder. The ROLE attribute is identified as hf.Type and refers to an actor’s role within its organization, (specifying, for example, that an actor is a peer). See the following snippet from a signing certificate shows how the Roles and OUs are represented in the certificate. 生成的ROLE和OU属性在/signcerts 文件夹中的X.509签名证书中可以看到。ROLE属性标识为hf.Type，是指参与者在其组织中的角色(例如指定是一个peer)。请参阅签名证书中的以下片段，以显示角色和OU如何在证书中表示。 Note: For Channel MSPs, just because an actor has the role of an administrator it doesn’t mean that they can administer particular resources. The actual power a given identity has with respect to administering the system is determined by the policies that manage system resources. For example, a channel policy might specify that ORG1-MANUFACTURING administrators, meaning identities with a role of admin and a Node OU of ORG1-MANUFACTURING, have the rights to add new organizations to the channel, whereas the ORG1-DISTRIBUTION administrators have no such rights. **注意：**对于通道MSP，仅仅因为参与者具有管理员角色，并不意味着他们可以管理特定资源。给定身份在管理系统方面的实际能力由管理系统资源的策略确定。例如，渠道策略可能指定ORG1-MANUFACTURING管理员，即具有admin角色和ORG1-MANUFACTURING的节点OU的身份，有权向频道添加新组织，而ORG1-DISTRIBUTION管理员则无此权利。 Finally, OUs could be used by different organizations in a consortium to distinguish each other. But in such cases, the different organizations have to use the same Root CAs and Intermediate CAs for their chain of trust, and assign the OU field to identify members of each organization. When every organization has the same CA or chain of trust, this makes the system more centralized than what might be desirable and therefore deserves careful consideration on a blockchain network. 最后，联盟中的不同组织可以使用OU来区分彼此。但是在这种情况下，不同的组织必须为它们的信任链使用相同的根CA和中间CA，并分配OU字段以标识每个组织的成员。当每个组织都具有相同的CA或信任链时，这会使系统比可能需要的系统更加集中，因此在区块链网络上值得仔细考虑。 MSP Structure Let’s explore the MSP elements that render the functionality we’ve described so far. 让我们探索MSP的元素呈现我们到目前为止所描述的功能。 A local MSP folder contains the following sub-folders: 本地MSP文件夹包含以下子文件夹： The figure above shows the subfolders in a local MSP on the file system 上图显示了文件系统上本地MSP中的子文件夹 config.yaml: Used to configure the identity classification feature in Fabric by enabling “Node OUs” and defining the accepted roles. 用于通过启用“Node OUs”并定义接受的角色来在Fabric中配置身份分类功能。 cacerts: This folder contains a list of self-signed X.509 certificates of the Root CAs trusted by the organization represented by this MSP. There must be at least one Root CA certificate in this MSP folder. 此文件夹包含由此MSP代表的组织信任的根CA的自签名X.509证书的列表。此MSP文件夹中至少必须有一个根CA证书。 This is the most important folder because it identifies the CAs from which all other certificates must be derived to be considered members of the corresponding organization to form the chain of trust. 这是最重要的文件夹，它标识了必须从中导出所有其他证书的CA，才能将其视为相应组织的成员以形成信任链。 intermediatecerts: This folder contains a list of X.509 certificates of the Intermediate CAs trusted by this organization. Each certificate must be signed by one of the Root CAs in the MSP or by any Intermediate CA whose issuing CA chain ultimately leads back to a trusted Root CA. 此文件夹包含此组织信任的中间CA的X.509证书的列表。每个证书必须由MSP中的一个根CA签名，或由其发行CA链最终引回到受信任的根CA的任何中间CA。 An intermediate CA may represent a different subdivision of the organization (like ORG1-MANUFACTURING and ORG1-DISTRIBUTION do for ORG1), or the organization itself (as may be the case if a commercial CA is leveraged for the organization’s identity management). In the latter case intermediate CAs can be used to represent organization subdivisions. Here you may find more information on best practices for MSP configuration. Notice, that it is possible to have a functioning network that does not have an Intermediate CA, in which case this folder would be empty. 中间CA可能代表组织的不同部门（例如ORG1的ORG1-MANUFACTURING和ORG1-DISTRIBUTION），或者是组织本身（如果利用商业CA来进行组织的身份管理，可能就是这种情况）。在后一种情况下，中间CA可以用来表示组织细分。请注意，一个正常运行的网络可能没有中间，在这种情况下，此文件夹将为空。 Like the Root CA folder, this folder defines the CAs from which certificates must be issued to be considered members of the organization. 与“根CA”文件夹类似，此文件夹定义的证书必须是由当前组织的成员所颁发的。 admincerts (Deprecated from Fabric v1.4.3 and higher): This folder contains a list of identities that define the actors who have the role of administrators for this organization. In general, there should be one or more X.509 certificates in this list. 该文件夹包含一个身份列表，这些身份定义了哪些参与者具有该组织的管理员角色。通常，此列表中应该有一个或多个X.509证书。 Note: Prior to Fabric v1.4.3, admins were defined by explicitly putting certs in the admincerts folder in the local MSP directory of your peer. With Fabric v1.4.3 or higher, certificates in this folder are no longer required. Instead, it is recommended that when the user is registered with the CA, that the admin role is used to designate the node administrator. Then, the identity is recognized as an admin by the Node OU role value in their signcert. As a reminder, in order to leverage the admin role, the “identity classification” feature must be enabled in the config.yaml above by setting “Node OUs” to Enable: true. We’ll explore this more later. 注意： 在Fabric v1.4.3之前，通过显式将证书放入peer的本地MSP目录下的admincerts文件夹中来定义管理员。对于Fabric v1.4.3或更高版本，不再需要此文件夹中的证书。相反，建议在向CA注册用户后，使用admin角色指定节点管理员。然后通过其签名证书中的节点OU角色值将身份识别为管理员。提醒一下，为了利用管理员角色，必须在上面的config.yaml中通过将“Node OUs”设置为Enable：true来启用“身份分类”功能。我们将在以后进行探讨。 And as a reminder, for Channel MSPs, just because an actor has the role of an administrator it doesn’t mean that they can administer particular resources. The actual power a given identity has with respect to administering the system is determined by the policies that manage system resources. For example, a channel policy might specify that ORG1-MANUFACTURING administrators have the rights to add new organizations to the channel, whereas the ORG1-DISTRIBUTION administrators have no such rights. 提醒一下，对于通道MSP，仅仅因为参与者具有管理员角色，并不意味着他们可以管理特定资源。给定身份在管理系统方面的实际能力由管理系统资源的策略确定。例如，通道政策可能指定ORG1-MANUFACTURING管理员有权向该渠道添加新组织，而ORG1-DISTRIBUTION管理员没有这种权利。 keystore: (private Key) This folder is defined for the local MSP of a peer or orderer node (or in a client’s local MSP), and contains the node’s private key. This key is used to sign data — for example to sign a transaction proposal response, as part of the endorsement phase. 此文件夹是为peer节点或orderer节点的本地MSP（或在客户端的本地MSP中）定义的，它包含节点的私钥。这个私钥用于签名数据 - 例如在背书阶段签署交易建议响应。 This folder is mandatory for local MSPs, and must contain exactly one private key. Obviously, access to this folder must be limited only to the identities of users who have administrative responsibility on the peer. 对于本地MSP，此文件夹是必需的，并且必须仅包含一个私钥。显然，对此文件夹的访问必须仅限于对peer具有管理责任的用户的身份。 The channel MSP configuration does not include this folder, because channel MSPs solely aim to offer identity validation functionalities and not signing abilities. 通道MSP配置不包括此文件夹，因为通道MSP仅旨在提供身份验证功能而不是签名功能。 Note: If you are using a Hardware Security Module(HSM) for key management, this folder is empty because the private key is generated by and stored in the HSM. 注意： 如果你使用硬件级别的安全模块(HSM) 来管理key，这个文件夹是空的因为私钥已经被生成并存储在HSM。 signcert: For a peer or orderer node (or in a client’s local MSP) this folder contains the node’s certificate issued by CA. The certificate represents the node’s identity, and this certificate’s corresponding private key can be used to generate signatures which may be verified by anyone with a copy of this certificate. 对于peer节点ordered节点（或在客户端的本地MSP中），此文件夹包含CA颁发的节点的证书。该证书代表节点的身份，并且该证书的相应私钥可用于生成签名，任何拥有此证书副本的人都可以对其进行验证。 This folder is mandatory for local MSPs, and must contain exactly one public key. Obviously, access to this folder must be limited only to the identities of users who have administrative responsibility on the peer. 此文件夹对于本地MSP是必需的，并且必须仅包含一个公共密钥。显然，对此文件夹的访问必须仅限于对peer具有管理责任的用户的身份。 Configuration of a channel MSP does not include this folder, as channel MSPs solely aim to offer identity validation functionalities and not signing abilities. 通道MSP的配置不包括此文件夹，因为通道MSP仅旨在提供身份验证功能而不是签名功能。 tlscacerts: This folder contains a list of self-signed X.509 certificates of the Root CAs trusted by this organization for secure communications between nodes using TLS. An example of a TLS communication would be when a peer needs to connect to an orderer so that it can receive ledger updates. 此文件夹包含此组织信任的根CA的自签名X.509证书列表，以使用TLS在节点之间进行安全通信。TLS通信的一个示例是peer需要连接到ordered以便接收账本更新。 MSP TLS information relates to the nodes inside the network — the peers and the orderers, in other words, rather than the applications and administrations that consume the network. MSP TLS信息与网络内部的节点有关（peers和orderers），换句话说，而不是消耗网络的应用程序和管理。 There must be at least one TLS Root CA certificate in this folder. For more information about TLS, see Securing Communication with Transport Layer Security (TLS). 此文件夹中至少必须有一个TLS根CA证书， 有关TLS的更多信息请查看 Securing Communication with Transport Layer Security (TLS)。 tlsintermediatecacerts: This folder contains a list intermediate CA certificates CAs trusted by the organization represented by this MSP for secure communications between nodes using TLS. This folder is specifically useful when commercial CAs are used for TLS certificates of an organization. Similar to membership intermediate CAs, specifying intermediate TLS CAs is optional. 此文件夹包含此MSP代表的组织信任的中间CA证书CA列表，用于使用TLS的节点之间的安全通信。当组织使用商业CA作为TLS证书时，此文件夹特别有用。与成员资格中间CA相似，指定中间TLS CA是可选的。 operationscerts: This folder contains the certificates required to communicate with the Fabric Operations Service API. 该文件夹包含与 Fabric Operations Service API通信所需的证书。 A channel MSP includes the following additional folder: 通道MSP包括以下额外的文件夹： Revoked Certificates: If the identity of an actor has been revoked, identifying information about the identity — not the identity itself — is held in this folder. For X.509-based identities, these identifiers are pairs of strings known as Subject Key Identifier (SKI) and Authority Access Identifier (AKI), and are checked whenever the certificate is being used to make sure the certificate has not been revoked. 如果参与者的身份已被撤销，则有关该身份的识别信息（而不是身份本身）将保存在此文件夹中。对于基于X.509的身份，这些标识符是称为Subject Key Identifier（SKI）和授权访问标识符（AKI）的字符串对，并在使用证书时进行检查，以确保证书未被吊销。 This list is conceptually the same as a CA’s Certificate Revocation List (CRL), but it also relates to revocation of membership from the organization. As a result, the administrator of a channel MSP can quickly revoke an actor or node from an organization by advertising the updated CRL of the CA. This “list of lists” is optional. It will only become populated as certificates are revoked. 此列表在概念上与CA的证书吊销列表（CRL）相同，但也与组织的成员资格吊销有关。结果，通道MSP的管理员可以通过发布CA的更新的CRL来快速从组织撤消参与者或节点。此“列表”是可选的。仅当证书被吊销时，它才会被填充。 If you’ve read this doc as well as our doc on Identity, you should now have a pretty good grasp of how identities and MSPs work in Hyperledger Fabric. You’ve seen how a PKI and MSPs are used to identify the actors collaborating in a blockchain network. You’ve learned how certificates, public/private keys, and roots of trust work, in addition to how MSPs are physically and logically structured. 如果你已经阅读过我们的Identity文档，您现在应该对身份和MSP在Hyperledger Fabric中的工作方式有了很好的了解。您已经了解了如何使用PKI和MSP来识别在区块链网络中进行协作的参与者。您已经了解了证书、公钥/私钥和信任根的工作原理，以及MSP的物理和逻辑结构。","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"Key Concepts","slug":"区块链/Hyperledger-Fabric/Key-Concepts","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/Key-Concepts/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"MSP","slug":"MSP","permalink":"https://guozhe001.github.io/tags/MSP/"},{"name":"Membership Service Provider","slug":"Membership-Service-Provider","permalink":"https://guozhe001.github.io/tags/Membership-Service-Provider/"}]},{"title":"Peers","slug":"blockchain/fabric/关键概念/Peers","date":"2024-11-22T06:32:06.495Z","updated":"2024-11-22T06:32:06.495Z","comments":true,"path":"2024/11/22/blockchain/fabric/关键概念/Peers/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E5%85%B3%E9%94%AE%E6%A6%82%E5%BF%B5/Peers/","excerpt":"","text":"官方文档：Peers Peers A blockchain network is comprised primarily of a set of peer nodes (or, simply, peers). Peers are a fundamental element of the network because they host ledgers and smart contracts. Recall that a ledger immutably records all the transactions generated by smart contracts (which in Hyperledger Fabric are contained in a chaincode, more on this later). Smart contracts and ledgers are used to encapsulate the shared processes and shared information in a network, respectively. These aspects of a peer make them a good starting point to understand a Fabric network. 区块链网络主要由一组peer节点组成（简称peers）。peers是网络的基本元素，是因为它们托管账本和智能合约。回想一下，账本一成不变地记录了智能合约生成的所有交易。智能合约和账本分别用于封装网络中的共享程序和共享信息。peers的这些方面使它们成为了解Fabric网络的良好起点。 Other elements of the blockchain network are of course important: ledgers and smart contracts, orderers, policies, channels, applications, organizations, identities, and membership, and you can read more about them in their own dedicated sections. This section focusses on peers, and their relationship to those other elements in a Fabric network. 组成区块链网络的其他元素当然也很重要：账本和智能合约、orderers、策略、通道、应用程序、组织、身份识别，以及联盟成员，您可以在他们自己的专用部分中阅读有关它们的更多信息。本节重点介绍peers及其与Fabric网络中其他元素的关系。 A blockchain network is comprised of peer nodes, each of which can hold copies of ledgers and copies of smart contracts. In this example, the network N consists of peers P1, P2 and P3, each of which maintain their own instance of the distributed ledger L1. P1, P2 and P3 use the same chaincode, S1, to access their copy of that distributed ledger. 智能合约的网络是由peer节点构成，每个peer节点都托管账本的副本以及智能合约的副本。略。。。 Peers can be created, started, stopped, reconfigured, and even deleted. They expose a set of APIs that enable administrators and applications to interact with the services that they provide. We’ll learn more about these services in this section. Peers可以被删除、启动、停止、重新配置甚至删除。它们暴露了一组API，使管理员和应用程序可以与其提供的服务进行交互。我们将在本节中详细了解这些服务。 A word on terminology（术语） Fabric implements smart contracts with a technology concept it calls chaincode — simply a piece of code that accesses the ledger, written in one of the supported programming languages. In this topic, we’ll usually use the term chaincode, but feel free to read it as smart contract if you’re more used to that term. It’s the same thing! If you want to learn more about chaincode and smart contracts, check out our documentation on smart contracts and chaincode. Fabric通过称为链码的技术概念实现智能合约，chaincode是用一种使用Fabric支持的编程语言编写的访问账本的一段代码。在本主题中，我们通常使用chaincode一词，但如果您更习惯smart contract术语，也可以将其作为智能合约阅读。It’s the same thing! If you want to learn more about chaincode and smart contracts, check out our documentation on smart contracts and chaincode. Ledgers and Chaincode Let’s look at a peer in a little more detail. We can see that it’s the peer that hosts both the ledger and chaincode. More accurately, the peer actually hosts instances of the ledger, and instances of chaincode. Note that this provides a deliberate redundancy in a Fabric network — it avoids single points of failure. We’ll learn more about the distributed and decentralized nature of a blockchain network later in this section. 让我们再详细的看一下peer。我们可以看到peer既托管了账本也托管了链码。更准确地说，peer实际上托管账本实例和链码实例。请注意，这在Fabric网络中提供了有意的冗余-避免了单点故障。在本节的后面，我们将详细了解区块链网络的分布式和分散式性质。 A peer hosts instances of ledgers and instances of chaincodes. In this example, P1 hosts an instance of ledger L1 and an instance of chaincode S1. There can be many ledgers and chaincodes hosted on an individual peer. Because a peer is a host for ledgers and chaincodes, applications and administrators must interact with a peer if they want to access these resources. That’s why peers are considered the most fundamental building blocks of a Fabric network. When a peer is first created, it has neither ledgers nor chaincodes. We’ll see later how ledgers get created, and how chaincodes get installed, on peers. 因为peer托管了账本和链码，因此应用程序和系统管理员如果想要获取这些资源必须与peer进行交互。这就是为什么将peer视为Fabric网络的最基本组成部分。当peer在一开始被创建时，它既没有账本也没有链码。我们会在后面看到在peers上账本是如何创建的以及链码是如何安装的。 Multiple Ledgers A peer is able to host more than one ledger, which is helpful because it allows for a flexible system design. The simplest configuration is for a peer to manage a single ledger, but it’s absolutely appropriate for a peer to host two or more ledgers when required. A peer hosting multiple ledgers. Peers host one or more ledgers, and each ledger has zero or more chaincodes that apply to them. In this example, we can see that the peer P1 hosts ledgers L1 and L2. Ledger L1 is accessed using chaincode S1. Ledger L2 on the other hand can be accessed using chaincodes S1 and S2. peer托管了一个或多个账本，并且托管了0个或更多的链码 Although it is perfectly possible for a peer to host a ledger instance without hosting any chaincodes which access that ledger, it’s rare that peers are configured this way. The vast majority of peers will have at least one chaincode installed on it which can query or update the peer’s ledger instances. It’s worth mentioning in passing that, whether or not users have installed chaincodes for use by external applications, peers also have special system chaincodes that are always present. These are not discussed in detail in this topic. 尽管对等点完全有可能托管一个账本实例而不托管任何访问该账本的链码，但很少有peer以这种方式配置。绝大多数对等点将至少安装一个链码，可以查询或更新peer的账本实例。值得一提的是，无论用户是否安装了供外部应用程序使用的链码，peer都有始终存在的特殊的系统链码。这些将不在本主题中详细讨论。 Multiple Chaincodes There isn’t a fixed relationship between the number of ledgers a peer has and the number of chaincodes that can access that ledger. A peer might have many chaincodes and many ledgers available to it. Peer拥有的账本数量与可以访问该账本的链码数量之间的关系不是固定的。一个peer可能有许多可用的链码和分类帐。 An example of a peer hosting multiple chaincodes. Each ledger can have many chaincodes which access it. In this example, we can see that peer P1 hosts ledgers L1 and L2, where L1 is accessed by chaincodes S1 and S2, and L2 is accessed by S1 and S3. We can see that S1 can access both L1 and L2. 如上图所示，既可以有多个链码访问同一个账本；也可以一个链码访问多个账本。 We’ll see a little later why the concept of channels in Fabric is important when hosting multiple ledgers or multiple chaincodes on a peer. 我们稍后再看到当在peer上托管多个分类帐或多个链码时，Fabric中的通道概念重要的原因。 Applications and Peers We’re now going to show how applications interact with peers to access the ledger. Ledger-query interactions involve a simple three-step dialogue between an application and a peer; ledger-update interactions are a little more involved, and require two extra steps. We’ve simplified these steps a little to help you get started with Fabric, but don’t worry — what’s most important to understand is the difference in application-peer interactions for ledger-query compared to ledger-update transaction styles. 现在，我们将展示应用程序如何与peer交互以访问账本。账本查询交互包括应用程序和peer之间简单的三步对话；账本更新的交互要复杂得多，并且需要两个额外的步骤。我们已简化了这些步骤，以帮助您开始使用Fabric，但请放心，最重要的是要了解账本查询与账本更新两种交易方式之间的应用程序和peer交互的差异。 Applications always connect to peers when they need to access ledgers and chaincodes. The Fabric Software Development Kit (SDK) makes this easy for programmers — its APIs enable applications to connect to peers, invoke chaincodes to generate transactions, submit transactions to the network that will get ordered, validated and committed to the distributed ledger, and receive events when this process is complete. 当应用程序需要访问账本和链码时总是与peer链接。Fabric的SDK让这变得简单，它的API可以让应用程序链接到peers，调用链码来生成交易，提交交易到网络并且获得排序，验证和提交到分布式账本以及当这些程序结束时接收事件。 Through a peer connection, applications can execute chaincodes to query or update a ledger. The result of a ledger query transaction is returned immediately, whereas ledger updates involve a more complex interaction between applications, peers and orderers. Let’s investigate this in a little more detail. 通过连接到一个peer，应用程序可以执行链码来查询或者更新账本。账本的查询交易结果将立即返回，但是账本的更新将涉及应用程序、peers和orderers之间的更复杂的的交互。让我们对此进行更详细的研究。 Peers, in conjunction with orderers, ensure that the ledger is kept up-to-date on every peer. In this example, application A connects to P1 and invokes chaincode S1 to query or update the ledger L1. P1 invokes S1 to generate a proposal response that contains a query result or a proposed ledger update. Application A receives the proposal response and, for queries, the process is now complete. For updates, A builds a transaction from all of the responses, which it sends to O1 for ordering. O1 collects transactions from across the network into blocks, and distributes these to all peers, including P1. P1 validates the transaction before committing to L1. Once L1 is updated, P1 generates an event, received by A, to signify completion. 查询时有图中的1、2、3三个步骤。更新时需要额外的4、5两个步骤的操作。 1 应用程序链接到peer 2 应用程序（带着交易提议）调用链码 2.1 peer（带着交易提议）调用托管在peer上的链码 2.2 链码生成查询或更新的提议响应 3 peer把提议响应返回给应用程序 4 应用程序请求排序节点对交易进行排序 4.1 排序节点把排好序并打包在区块中交易发送给peers 4.2 peer使用交易区块更新本地的账本 5 peer发出账本更新的事件 A peer can return the results of a query to an application immediately since all of the information required to satisfy the query is in the peer’s local copy of the ledger. Peers never consult with other peers in order to respond to a query from an application. Applications can, however, connect to one or more peers to issue a query; for example, to corroborate a result between multiple peers, or retrieve a more up-to-date result from a different peer if there’s a suspicion that information might be out of date. In the diagram, you can see that ledger query is a simple three-step process. peer可以马上把查询结果返回给应用程序是因为查询的所有信息都存在于peer节点的本地账本副本中。Peers从不与其他peer协商以响应来自应用程序的查询。但是应用程序可以链接一个或多个peer来发出查询，例如，在多个peer之间确认结果，或者如果怀疑信息可能已过时，则从另一个peer检索最新结果。 An update transaction starts in the same way as a query transaction, but has two extra steps. Although ledger-updating applications also connect to peers to invoke a chaincode, unlike with ledger-querying applications, an individual peer cannot perform a ledger update at this time, because other peers must first agree to the change — a process called consensus. Therefore, peers return to the application a proposed update — one that this peer would apply subject to other peers’ prior agreement. The first extra step — step four — requires that applications send an appropriate set of matching proposed updates to the entire network of peers as a transaction for commitment to their respective ledgers. This is achieved by the application by using an orderer to package transactions into blocks, and distributing them to the entire network of peers, where they can be verified before being applied to each peer’s local copy of the ledger. As this whole ordering processing takes some time to complete (seconds), the application is notified asynchronously, as shown in step five. Later in this section, you’ll learn more about the detailed nature of this ordering process — and for a really detailed look at this process see the Transaction Flow topic. Peers and Channels Although this section is about peers rather than channels, it’s worth spending a little time understanding how peers interact with each other, and with applications, via channels — a mechanism by which a set of components within a blockchain network can communicate and transact privately. 尽管本部分介绍的是peer而不是通道，但是值得花一些时间来了解peer如何通过通道与其他peer以及应用程序进行交互。通道是一种机制，区块链网络中的一组组件可以通过该机制进行私下通信和交易。 These components are typically peer nodes, orderer nodes and applications and, by joining a channel, they agree to collaborate to collectively share and manage identical copies of the ledger associated with that channel. Conceptually, you can think of channels as being similar to groups of friends (though the members of a channel certainly don’t need to be friends!). A person might have several groups of friends, with each group having activities they do together. These groups might be totally separate (a group of work friends as compared to a group of hobby friends), or there can be some crossover between them. Nevertheless, each group is its own entity, with “rules” of a kind. 这些组件通常是peer节点，orderer节点和应用程序，通过加入通道，它们同意协作以共同共享和管理与该通道关联的账本的相同副本。从概念上讲，您可以将通道视为与朋友组相似。一个人可能有多组朋友，每组都有他们一起做的活动。这些组可能完全分开，它们之间也可能会有交叉。但是，每个组都是其自己的实体，具有某种“规则”。 Channels allow a specific set of peers and applications to communicate with each other within a blockchain network. In this example, application A can communicate directly with peers P1 and P2 using channel C. You can think of the channel as a pathway for communications between particular applications and peers. (For simplicity, orderers are not shown in this diagram, but must be present in a functioning network.) 在区块链网络中通道允许指定的一组peer和应用程序进行通信。 We see that channels don’t exist in the same way that peers do — it’s more appropriate to think of a channel as a logical structure that is formed by a collection of physical peers. It is vital to understand this point — peers provide the control point for access to, and management of, channels. 通道是一组物理peer的逻辑结构，peer提供了对通道的访问与管理权限。 Peers and Organizations Now that you understand peers and their relationship to ledgers, chaincodes and channels, you’ll be able to see how multiple organizations come together to form a blockchain network. Blockchain networks are administered by a collection of organizations rather than a single organization. Peers are central to how this kind of distributed network is built because they are owned by — and are the connection points to the network for — these organizations. 区块链网络由多个组织管理，而不是单个组织管理。peers对于这种分布式网络的构建至关重要因为他们属于他们的组织，并且他们是他们组织的网络连接点。 Peers in a blockchain network with multiple organizations. The blockchain network is built up from the peers owned and contributed by the different organizations. In this example, we see four organizations contributing eight peers to form a network. The channel C connects five of these peers in the network N — P1, P3, P5, P7 and P8. The other peers owned by these organizations have not been joined to this channel, but are typically joined to at least one other channel. Applications that have been developed by a particular organization will connect to their own organization’s peers as well as those of different organizations. Again, for simplicity, an orderer node is not shown in this diagram. It’s really important that you can see what’s happening in the formation of a blockchain network. The network is both formed and managed by the multiple organizations who contribute resources to it. Peers are the resources that we’re discussing in this topic, but the resources an organization provides are more than just peers. There’s a principle at work here — the network literally does not exist without organizations contributing their individual resources to the collective network. Moreover, the network grows and shrinks with the resources that are provided by these collaborating organizations. 区块链由向其贡献资源的多个组织组成和管理。 You can see that (other than the ordering service) there are no centralized resources — in the example above, the network, N, would not exist if the organizations did not contribute their peers. This reflects the fact that the network does not exist in any meaningful sense unless and until organizations contribute the resources that form it. Moreover, the network does not depend on any individual organization — it will continue to exist as long as one organization remains, no matter which other organizations may come and go. This is at the heart of what it means for a network to be decentralized. Applications in different organizations, as in the example above, may or may not be the same. That’s because it’s entirely up to an organization as to how its applications process their peers’ copies of the ledger. This means that both application and presentation logic may vary from organization to organization even though their respective peers host exactly the same ledger data. 如上例所示，不同组织中的应用程序可能相同，也可能不同。 Applications connect either to peers in their organization, or peers in another organization, depending on the nature of the ledger interaction that’s required. For ledger-query interactions, applications typically connect to their own organization’s peers. For ledger-update interactions, we’ll see later why applications need to connect to peers representing every organization that is required to endorse the ledger update. 应用程序可以连接到自己组织的peer节点，也可以连接到其他组织的peer节点，具体取决于所需的账本交互的性质。对于账本查询交互，应用程序通常会连接到自己组织的peer节点。对于账本更新交互，我们将在后面看到为什么应用程序需要连接到代表认可账本更新所需的每个组织的peer。 Peers and Identity Now that you’ve seen how peers from different organizations come together to form a blockchain network, it’s worth spending a few moments understanding how peers get assigned to organizations by their administrators. Peers have an identity assigned to them via a digital certificate from a particular certificate authority. You can read lots more about how X.509 digital certificates work elsewhere in this guide but, for now, think of a digital certificate as being like an ID card that provides lots of verifiable information about a peer. Each and every peer in the network is assigned a digital certificate by an administrator from its owning organization. Peers具有通过特定证书颁发机构通过数字证书分配给他们的身份。***。网络中的每个peer节点都由其所属组织的管理员分配的数字证书。 When a peer connects to a channel, its digital certificate identifies its owning organization via a channel MSP. In this example, P1 and P2 have identities issued by CA1. Channel C determines from a policy in its channel configuration that identities from CA1 should be associated with Org1 using ORG1.MSP. Similarly, P3 and P4 are identified by ORG2.MSP as being part of Org2. 当peer连接到通道时，其数字证书通过通道MSP标识其归属的组织。 Whenever a peer connects using a channel to a blockchain network, a policy in the channel configuration uses the peer’s identity to determine its rights. The mapping of identity to organization is provided by a component called a Membership Service Provider (MSP) — it determines how a peer gets assigned to a specific role in a particular organization and accordingly gains appropriate access to blockchain resources. Moreover, a peer can be owned only by a single organization, and is therefore associated with a single MSP. We’ll learn more about peer access control later in this section, and there’s an entire section on MSPs and access control policies elsewhere in this guide. But for now, think of an MSP as providing linkage between an individual identity and a particular organizational role in a blockchain network. 每当peer使用通道连接到区块链网络时，通道配置中的策略都会使用peer的身份来确定其权利。*** To digress for a moment, peers as well as everything that interacts with a blockchain network acquire their organizational identity from their digital certificate and an MSP. Peers, applications, end users, administrators and orderers must have an identity and an associated MSP if they want to interact with a blockchain network. We give a name to every entity that interacts with a blockchain network using an identity — a principal. You can learn lots more about principals and organizations elsewhere in this guide, but for now you know more than enough to continue your understanding of peers! Peers以及与区块链网络交互的所有事物均从其数字证书和MSP获取其组织身份。*** Finally, note that it’s not really important where the peer is physically located — it could reside in the cloud, or in a data centre owned by one of the organizations, or on a local machine — it’s the digital certificate associated with it that identifies it as being owned by a particular organization. In our example above, P3 could be hosted in Org1’s data center, but as long as the digital certificate associated with it is issued by CA2, then it’s owned by Org2. 最后，注意peer的物理位置不是很重要，它可以部署在云上，也可以部署在本地物理机上；不管它在哪里，之相关联的数字证书将其标识为特定组织所拥有。*** Peers and Orderers We’ve seen that peers form the basis for a blockchain network, hosting ledgers and smart contracts which can be queried and updated by peer-connected applications. However, the mechanism by which applications and peers interact with each other to ensure that every peer’s ledger is kept consistent with each other is mediated by special nodes called orderers, and it’s to these nodes we now turn our attention. An update transaction is quite different from a query transaction because a single peer cannot, on its own, update the ledger — updating requires the consent of other peers in the network. A peer requires other peers in the network to approve a ledger update before it can be applied to a peer’s local ledger. This process is called consensus, which takes much longer to complete than a simple query. But when all the peers required to approve the transaction do so, and the transaction is committed to the ledger, peers will notify their connected applications that the ledger has been updated. You’re about to be shown a lot more detail about how peers and orderers manage the consensus process in this section. 更新交易与查询交易是有很大区别的，因为单独的peer不可以自己完成更新账本的工作。更新账本的操作需要网络中其他peer的同意。peer需要网络中的其他peer批准账本更新，然后才能将其应用于peer上的本地账本。此过程称为共识，与简单的查询相比，此过程需要更长的时间才能完成。但是，当所有需要批准交易的peer节点都批准了该交易并将交易提交到账本时，peer将通知其连接的应用程序账本已更新。在本部分中，您将获得有关peers和peers如何管理共识过程的更多详细信息。 Specifically, applications that want to update the ledger are involved in a 3-phase process, which ensures that all the peers in a blockchain network keep their ledgers consistent with each other. 具体来说，想要更新账本的应用程序需要3个阶段的过程，这确保了区块链网络中的所有peer保持账本彼此一致。 In the first phase, applications work with a subset of endorsing peers, each of which provide an endorsement of the proposed ledger update to the application, but do not apply the proposed update to their copy of the ledger. 在第一个阶段，应用程序与一些背书peer节点一起工作，每个背书peer节点都向应用程序提供对提议的账本更新的背书，但不将提议的更新应用于其账本的副本。 In the second phase, these separate endorsements are collected together as transactions and packaged into blocks. 在第二阶段，这些单独的背书将作为交易收集在一起，并打包成块。 In the third and final phase, these blocks are distributed back to every peer where each transaction is validated before being committed to that peer’s copy of the ledger. 在第三阶段（也是最后阶段），这些区块会重新分配给每个peer节点，在此之前，每个交易均经过验证，然后再提交给该peer的账本副本。 As you will see, orderer nodes are central to this process, so let’s investigate in a little more detail how applications and peers use orderers to generate ledger updates that can be consistently applied to a distributed, replicated ledger. 如您所见，排序者节点是此过程的核心，因此，让我们更详细地研究一下应用程序和peer如何使用排序服务来生成账本更新，该更新可始终应用于分布式复制分类帐。 Phase 1: Proposal Phase 1 of the transaction workflow involves an interaction between an application and a set of peers — it does not involve orderers. Phase 1 is only concerned with an application asking different organizations’ endorsing peers to agree to the results of the proposed chaincode invocation. 交易流程的第一阶段涉及应用程序与一组peer之间的交互-它不涉及排序者。第一阶段只关心应用程序要求不同组织的背书节点同意提议的链码调用的结果。 To start phase 1, applications generate a transaction proposal which they send to each of the required set of peers for endorsement. Each of these endorsing peers then independently executes a chaincode using the transaction proposal to generate a transaction proposal response. It does not apply this update to the ledger, but rather simply signs it and returns it to the application. Once the application has received a sufficient number of signed proposal responses, the first phase of the transaction flow is complete. Let’s examine this phase in a little more detail. 为了开始第一阶段，应用程序生成一个交易提议，然后发送这个交易提议到每个需要背书的peer列表。然后每个背书节点使用交易提议执行链码来生成交易提议响应。它不会将此更新应用于账本，而只是对其进行签名并将其返回给应用程序。一旦应用程序收到足够数量的已签名提案响应后，交易流程的第一阶段就完成了。让我们更详细地研究这个阶段。 Transaction proposals are independently executed by peers who return endorsed proposal responses. In this example, application A1 generates transaction T1 proposal P which it sends to both peer P1 and peer P2 on channel C. P1 executes S1 using transaction T1 proposal P generating transaction T1 response R1 which it endorses with E1. Independently, P2 executes S1 using transaction T1 proposal P generating transaction T1 response R2 which it endorses with E2. Application A1 receives two endorsed responses for transaction T1, namely E1 and E2. 交易提议被每个peer节点独立的执行然后返回背书提议响应。 Initially, a set of peers are chosen by the application to generate a set of proposed ledger updates. Which peers are chosen by the application? Well, that depends on the endorsement policy (defined for a chaincode), which defines the set of organizations that need to endorse a proposed ledger change before it can be accepted by the network. This is literally what it means to achieve consensus — every organization who matters must have endorsed the proposed ledger change before it will be accepted onto any peer’s ledger. 最初应用程序选择一组peer节点来生成一组提议的账本更新。应用程序会选择哪些peer节点呢？这取决于（为链码定义的）背书策略，该策略定义了一个需要在网络接受之前批准提议的账本更新的组织列表。从字面上看，这是达成共识的意思 – 每个重要的组织都必须已经批准提议的账本更新，然后该更改才会被接受到其他peer的账本中。 A peer endorses a proposal response by adding its digital signature, and signing the entire payload using its private key. This endorsement can be subsequently used to prove that this organization’s peer generated a particular response. In our example, if peer P1 is owned by organization Org1, endorsement E1 corresponds to a digital proof that “Transaction T1 response R1 on ledger L1 has been provided by Org1’s peer P1!”. peer节点通过添加数字签名来认可提议响应，并且使用它的私钥对整个负载的数据进行签名。这个背书随后可以被用于证明这个组织的peer生成了响应。*** Phase 1 ends when the application receives signed proposal responses from sufficient peers. We note that different peers can return different and therefore inconsistent transaction responses to the application for the same transaction proposal. It might simply be that the result was generated at different times on different peers with ledgers at different states, in which case an application can simply request a more up-to-date proposal response. Less likely, but much more seriously, results might be different because the chaincode is non-deterministic. Non-determinism is the enemy of chaincodes and ledgers and if it occurs it indicates a serious problem with the proposed transaction, as inconsistent results cannot, obviously, be applied to ledgers. An individual peer cannot know that their transaction result is non-deterministic — transaction responses must be gathered together for comparison before non-determinism can be detected. (Strictly speaking, even this is not enough, but we defer this discussion to the transaction section, where non-determinism is discussed in detail.) 当应用程序收到足够的peer签署的提议响应时，阶段一就结束了。对于同一交易提议，客户端应用程序可能收到不一致的交易响应。这可能只是简单的因为结果是在不同的时间、不同的peer节点使用不同的账本状态下生成的，在这种情况下，应用程序可以简单地请求最新的提议响应。可能性较小但是更严重的是，结果可能会因为链码是不确定的而有所不同。非确定性是链码和账本的敌人，如果发生，则表明提议交易存在严重问题，因为不一致的结果显然不能应用于账本。单个peer无法知道其交易结果是不确定的 – 必须先收集交易响应以进行比较，然后才能检测到不确定性。（严格说来，这还不够，但是我们将讨论推迟到交易部分，在此部分将详细讨论不确定性。） At the end of phase 1, the application is free to discard inconsistent transaction responses if it wishes to do so, effectively terminating the transaction workflow early. We’ll see later that if an application tries to use an inconsistent set of transaction responses to update the ledger, it will be rejected. 在阶段一结束时，应用程序可以随意丢弃不一致的交易响应，从而有效地尽早终止交易流程。稍后我们将看到，如果应用程序尝试使用一组不一致的交易响应来更新账本，它将被拒绝。 Phase 2: Ordering and packaging transactions into blocks The second phase of the transaction workflow is the packaging phase. The orderer is pivotal to this process — it receives transactions containing endorsed transaction proposal responses from many applications, and orders the transactions into blocks. For more details about the ordering and packaging phase, check out our conceptual information about the ordering phase. 交易流程的第二个阶段是打包阶段。排序者对于此过程至关重要-它从许多应用程序接收包含背书的交易提议响应的交易，并将交易排序打包成区块。*** Phase 3: Validation and commit At the end of phase 2, we see that orderers have been responsible for the simple but vital processes of collecting proposed transaction updates, ordering them, and packaging them into blocks, ready for distribution to the peers. The final phase of the transaction workflow involves the distribution and subsequent validation of blocks from the orderer to the peers, where they can be committed to the ledger. Specifically, at each peer, every transaction within a block is validated to ensure that it has been consistently endorsed by all relevant organizations before it is committed to the ledger. Failed transactions are retained for audit, but are not committed to the ledger. 交易流程的最后阶段涉及从排序者到peer节点的区块分配和后续验证，在这个阶段可以将它们提交到账本。具体来说，每个peer节点对区块中的每个交易都进行验证，以确保在将其提交到账本之前所有相关组织都一致认可该交易。失败的交易将保留以进行审核，但不会提交到分类账。 The second role of an orderer node is to distribute blocks to peers. In this example, orderer O1 distributes block B2 to peer P1 and peer P2. Peer P1 processes block B2, resulting in a new block being added to ledger L1 on P1. In parallel, peer P2 processes block B2, resulting in a new block being added to ledger L1 on P2. Once this process is complete, the ledger L1 has been consistently updated on peers P1 and P2, and each may inform connected applications that the transaction has been processed. 排序者节点的第二个指责是将区块分发到peer节点。 Phase 3 begins with the orderer distributing blocks to all peers connected to it. Peers are connected to orderers on channels such that when a new block is generated, all of the peers connected to the orderer will be sent a copy of the new block. Each peer will process this block independently, but in exactly the same way as every other peer on the channel. In this way, we’ll see that the ledger can be kept consistent. It’s also worth noting that not every peer needs to be connected to an orderer — peers can cascade blocks to other peers using the gossip protocol, who also can process them independently. But let’s leave that discussion to another time! 第三阶段开始于排序者分发区块到链接它的所有peer节点上。peer节点链接到通道上的排序节点，这样当一个新的区块生成是，所有的链接到排序节点的peer都会收到一个新区块的副本。每个peer都使用与通道上的其他节点一样的方式来独立处理这个区块。通过这种方式账本就可以保持一致了。还值得注意的是，并非每个peer节点都需要连接到排序者 – peer节点可以使用八卦协议将块级联到其他peer，这些peer也可以独立处理区块。 Upon receipt of a block, a peer will process each transaction in the sequence in which it appears in the block. For every transaction, each peer will verify that the transaction has been endorsed by the required organizations according to the endorsement policy of the chaincode which generated the transaction. For example, some transactions may only need to be endorsed by a single organization, whereas others may require multiple endorsements before they are considered valid. This process of validation verifies that all relevant organizations have generated the same outcome or result. Also note that this validation is different than the endorsement check in phase 1, where it is the application that receives the response from endorsing peers and makes the decision to send the proposal transactions. In case the application violates the endorsement policy by sending wrong transactions, the peer is still able to reject the transaction in the validation process of phase 3. 收到区块之后后，peer节点将按照区块块中的顺序处理每个交易。对于每笔交易，每个peer节点都将根据产生交易的链码的背书政策来验证该交易是否已被所需的组织背书。例如，某些交易可能只需要由单个组织背书，而其他交易可能需要多个背书才能被视为有效。这个验证过程验证所有相关的组织都生成相同的产物或结果。另请注意，此验证与第一阶段中的背书检查不同，第一阶段的背书检查是应用程序在接收到来自背书节点的响应并做出发送提议交易的决定。如果应用程序发送了错误的交易违反了背书策略，在第三阶段的验证程序中peer节点仍然有能力拒绝此交易。 If a transaction has been endorsed correctly, the peer will attempt to apply it to the ledger. To do this, a peer must perform a ledger consistency check to verify that the current state of the ledger is compatible with the state of the ledger when the proposed update was generated. This may not always be possible, even when the transaction has been fully endorsed. For example, another transaction may have updated the same asset in the ledger such that the transaction update is no longer valid and therefore can no longer be applied. In this way, the ledger is kept consistent across each peer in the channel because they each follow the same rules for validation. 如果交易已被正确的认可，则peer节点将尝试将其应用于账本。为此，peer节点必须执行账本一致性检查，以验证生成提议的更新时账本的状态与当前账本的状态一致。即使交易已得到完全认可，这也不总是一致的。例如，另一笔交易可能已更新账本中的同一资产，因此该交易更新不再有效，因此无法再应用。这样，账本在通道中的每个peer节点之间保持一致，因为它们都遵循相同的验证规则。 After a peer has successfully validated each individual transaction, it updates the ledger. Failed transactions are not applied to the ledger, but they are retained for audit purposes, as are successful transactions. This means that peer blocks are almost exactly the same as the blocks received from the orderer, except for a valid or invalid indicator on each transaction in the block. 在peer节点成功验证了每个单独的交易后，它将更新分类帐。失败的交易不会被应用于账本，但保留它们以进行审计，就像成功交易一样。这意味着peer节点的区块几乎与从排序者接收到的区块完全相同，除了该块中每个交易的有效或无效指示符。 We also note that phase 3 does not require the running of chaincodes — this is done only during phase 1, and that’s important. It means that chaincodes only have to be available on endorsing nodes, rather than throughout the blockchain network. This is often helpful as it keeps the logic of the chaincode confidential to endorsing organizations. This is in contrast to the output of the chaincodes (the transaction proposal responses) which are shared with every peer in the channel, whether or not they endorsed the transaction. This specialization of endorsing peers is designed to help scalability and confidentiality. 我们还注意到，第3阶段不需要运行Chaincode，这仅在第1阶段才做，这一点很重要。这意味着链码仅在背书节点上可用，而不是在整个区块链网络上可用。这通常很有用，因为它可以使背书组织的链码逻辑保持私密。这与链码的输出（交易提议响应）相反，链码的输出与通道中的每个peer节点共享，无论他们是否认可交易。这种背书节点的专业化旨在帮助提高可伸缩性和机密性。 Finally, every time a block is committed to a peer’s ledger, that peer generates an appropriate event. Block events include the full block content, while block transaction events include summary information only, such as whether each transaction in the block has been validated or invalidated. Chaincode events that the chaincode execution has produced can also be published at this time. Applications can register for these event types so that they can be notified when they occur. These notifications conclude the third and final phase of the transaction workflow. 最后，每次将一个区块提交给peer节点的账本之后，该peer节点都会生成一个适当的event。 Block events 包含所有的区块内容， block transaction events 只包含摘要信息（例如区块中的每笔交易是否已通过验证或无效） Chaincode events 链码执行时产生的Chaincode events也可以在此时发布 应用程序可以注册这些事件类型，以便在事件发生时得到通知。这些通知结束了交易流程的第三阶段也就是最后阶段。 In summary, phase 3 sees the blocks which are generated by the orderer consistently applied to the ledger. The strict ordering of transactions into blocks allows each peer to validate that transaction updates are consistently applied across the blockchain network. 总结来说，第三阶段将看到排序者生成的区块一致的应用于账本。严格的将交易排序然后打包到区块使每个peer节点验证交易更新被一致应用到blockchain网络中。 Orderers and Consensus This entire transaction workflow process is called consensus because all peers have reached agreement on the order and content of transactions, in a process that is mediated by orderers. Consensus is a multi-step process and applications are only notified of ledger updates when the process is complete — which may happen at slightly different times on different peers. 整个交易流程被称为共识，是因为在排序节点的调解下所有peer节点都已就交易的顺序和内容达成共识。共识是一个多步骤的过程，只有在该过程完成后，才将账本更新通知应用程序 – 在不同的peer上，发生时间可能略有不同。 We will discuss orderers in a lot more detail in a future orderer topic, but for now, think of orderers as nodes which collect and distribute proposed ledger updates from applications for peers to validate and include on the ledger. That’s it! We’ve now finished our tour of peers and the other components that they relate to in Fabric. We’ve seen that peers are in many ways the most fundamental element — they form the network, host chaincodes and the ledger, handle transaction proposals and responses, and keep the ledger up-to-date by consistently applying transaction updates to it.","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"Key Concepts","slug":"区块链/Hyperledger-Fabric/Key-Concepts","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/Key-Concepts/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"Peers","slug":"Peers","permalink":"https://guozhe001.github.io/tags/Peers/"}]},{"title":"Smart Contracts and Chaincode","slug":"blockchain/fabric/关键概念/Smart Contracts and Chaincode","date":"2024-11-22T06:32:06.495Z","updated":"2024-11-22T06:32:06.495Z","comments":true,"path":"2024/11/22/blockchain/fabric/关键概念/Smart Contracts and Chaincode/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E5%85%B3%E9%94%AE%E6%A6%82%E5%BF%B5/Smart%20Contracts%20and%20Chaincode/","excerpt":"","text":"官方文档：Smart Contracts and Chaincode TODO 下图展示Fabric是如何处理验证成功的交易和验证不成功的交易的。 All transactions have an identifier, a proposal, and a response signed by a set of organizations. All transactions are recorded on the blockchain, whether valid or invalid, but only valid transactions contribute to the world state. Intercommunication A Smart Contract can call other smart contracts both within the same channel and across different channels. It this way, they can read and write world state data to which they would not otherwise have access due to smart contract namespaces. There are limitations to this inter-contract communication, which are described fully in the chaincode namespace topic.","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"Key Concepts","slug":"区块链/Hyperledger-Fabric/Key-Concepts","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/Key-Concepts/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"Smart Contracts and Chaincode","slug":"Smart-Contracts-and-Chaincode","permalink":"https://guozhe001.github.io/tags/Smart-Contracts-and-Chaincode/"}]},{"title":"Private data","slug":"blockchain/fabric/关键概念/Private data","date":"2024-11-22T06:32:06.495Z","updated":"2024-11-22T06:32:06.495Z","comments":true,"path":"2024/11/22/blockchain/fabric/关键概念/Private data/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E5%85%B3%E9%94%AE%E6%A6%82%E5%BF%B5/Private%20data/","excerpt":"","text":"官方文档：Private data What is a private data collection? A collection is the combination of two elements: The actual private data, sent peer-to-peer via gossip protocol to only the organization(s) authorized to see it. This data is stored in a private state database on the peers of authorized organizations, which can be accessed from chaincode on these authorized peers. The ordering service is not involved here and does not see the private data. Note that because gossip distributes the private data peer-to-peer across authorized organizations, it is required to set up anchor peers on the channel, and configure CORE_PEER_GOSSIP_EXTERNALENDPOINT on each peer, in order to bootstrap cross-organization communication. A hash of that data, which is endorsed, ordered, and written to the ledgers of every peer on the channel. The hash serves as evidence of the transaction and is used for state validation and can be used for audit purposes. The following diagram illustrates the ledger contents of a peer authorized to have private data and one which is not. Collection members may decide to share the private data with other parties if they get into a dispute or if they want to transfer the asset to a third party. The third party can then compute the hash of the private data and see if it matches the state on the channel ledger, proving that the state existed between the collection members at a certain point in time. In some cases, you may decide to have a set of collections each comprised of a single organization. For example an organization may record private data in their own collection, which could later be shared with other channel members and referenced in chaincode transactions. We’ll see examples of this in the sharing private data topic below.","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"Key Concepts","slug":"区块链/Hyperledger-Fabric/Key-Concepts","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/Key-Concepts/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"Private data","slug":"Private-data","permalink":"https://guozhe001.github.io/tags/Private-data/"}]},{"title":"Policies(策略)","slug":"blockchain/fabric/关键概念/Policies","date":"2024-11-22T06:32:06.495Z","updated":"2024-11-22T06:32:06.495Z","comments":true,"path":"2024/11/22/blockchain/fabric/关键概念/Policies/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E5%85%B3%E9%94%AE%E6%A6%82%E5%BF%B5/Policies/","excerpt":"","text":"What is a policy At its most basic level, a policy is a set of rules that define the structure for how decisions are made and specific outcomes are reached. To that end, policies typically describe a who and a what, such as the access or rights that an individual has over an asset. We can see that policies are used throughout our daily lives to protect assets of value to us, from car rentals, health, our homes, and many more. 在最基本的级别上，策略是一组规则，这些规则定义了如何制定决策和达到特定结果的结构。为此，策略通常描述WHO和WHAT，例如个人对ASSET的访问或权利。我们可以看到，策略在我们的日常生活中一直被用来保护对我们有价值的资产，使其免受汽车租赁，医疗，房屋等的侵害。 For example, an insurance policy defines the conditions, terms, limits, and expiration under which an insurance payout will be made. The policy is agreed to by the policy holder and the insurance company, and defines the rights and responsibilities of each party. 例如，保险单定义了将要支付保险金的条件，条款，限额和有效期。该保单经保单持有人和保险公司同意，并定义了双方的权利和责任。 Whereas an insurance policy is put in place for risk management, in Hyperledger Fabric, policies are the mechanism for infrastructure management. Fabric policies represent how members come to agreement on accepting or rejecting changes to the network, a channel, or a smart contract. Policies are agreed to by the consortium members when a network is originally configured, but they can also be modified as the network evolves. For example, they describe the criteria for adding or removing members from a channel, change how blocks are formed, or specify the number of organizations required to endorse a smart contract. All of these actions are described by a policy which defines who can perform the action. Simply put, everything you want to do on a Fabric network is controlled by a policy. 尽管已为风险管理制定了保险单，但在Hyperledger Fabric中，风险管理是基础架构管理的机制。Fabric的策略代表成员如何就接受或拒绝对网络，渠道或智能合约的更改达成协议。最初配置网络时，策略是由联盟成员同意的，但是也可以随着网络的发展而修改策略。例如，它们描述了在通道中添加或删除成员，更改区块的形成方式或指定认可智能合约所需的组织数量的标准。所有这些动作均由定义了谁可以执行该动作的策略来描述。简而言之，您要在Fabric网络上执行的所有操作均受策略控制。 Why are policies needed Policies are one of the things that make Hyperledger Fabric different from other blockchains like Ethereum or Bitcoin. In those systems, transactions can be generated and validated by any node in the network. The policies that govern the network are fixed at any point in time and can only be changed using the same process that governs the code. Because Fabric is a permissioned blockchain whose users are recognized by the underlying infrastructure, those users have the ability to decide on the governance of the network before it is launched, and change the governance of a running network. 策略是使Hyperledger Fabric与以太坊或比特币等其他区块链不同的原因之一。在比特币或以太坊系统中，交易可以由网络上的任意节点生成和验证。支配网络的策略在任何时间都是固定的，并且只能使用支配代码的相同过程进行更改。由于Fabric是许可的区块链，其用户被基础架构所识别，因此这些用户具有在启动网络之前决定网络治理的能力，并且也具有更改运行中网络的治理的能力。 Policies allow members to decide which organizations can access or update a Fabric network, and provide the mechanism to enforce those decisions. Policies contain the lists of organizations that have access to a given resource, such as a user or system chaincode. They also specify how many organizations need to agree on a proposal to update a resource, such as a channel or smart contracts. Once they are written, policies evaluate the collection of signatures attached to transactions and proposals and validate if the signatures fulfill the governance agreed to by the network. 策略允许成员决定哪些组织可以访问或更新一个Fabric网络，并提供执行这些决定的机制。策略包含对给定的资源的有访问权限的组织的列表，比如一个用户或者系统链码。策略还指定有多少组织需要就更新资源（例如通道或智能合约）的提案达成协议。一旦写入，策略将评估附加在交易和提议中的签名的集合，并验证签名是否满足网络所同意的治理。 How are policies implemented throughout Fabric Policies are implemented at different levels of a Fabric network. Each policy domain governs different aspects of how a network operates. 策略是在Fabric网络的不同级别上实现的。每个策略域管理网络运行的不同方面。 A visual representation of the Fabric policy hierarchy. Fabric策略层次结构的直观表示。 System channel configuration Every network begins with an ordering system channel. There must be exactly one ordering system channel for an ordering service, and it is the first channel to be created. The system channel also contains the organizations who are the members of the ordering service (ordering organizations) and those that are on the networks to transact (consortium organizations). 每个网络都从一个排序系统通道开始。对排序服来说，必须有一个确定的排序系统通道，并且他是第一个需要创建的通道。系统通道还包含作为排序服务成员的组织（排序组织）和在网络上进行交易的组织（联盟组织）。 The policies in the ordering system channel configuration blocks govern the consensus used by the ordering service and define how new blocks are created. The system channel also governs which members of the consortium are allowed to create new channels. 排序系统通道配置区块中的策略控制排序服务使用的共识，并定义如何创建新区块。系统通道也控制联盟中的哪些成员允许创建新的通道。 Application channel configuration Application channels are used to provide a private communication mechanism between organizations in the consortium. 应用程序通道用于在联盟中的组织之间提供专用的通信机制。 The policies in an application channel govern the ability to add or remove members from the channel. Application channels also govern which organizations are required to approve a chaincode before the chaincode is defined and committed to a channel using the Fabric chaincode lifecycle. When an application channel is initially created, it inherits all the ordering service parameters from the orderer system channel by default. However, those parameters (and the policies governing them) can be customized in each channel. 应用程序通道中的策略控制了从通道中添加或者移除成员的能力。应用程序通道也控制了在使用Fabric链码生命周期定义链码并将其提交给通道之前，需要哪些成员需要。最初创建应用程序通道时，默认情况下它将从排序系统通道继承所有排序服务参数。但是，可以在每个通道中自定义这些参数（以及控制它们的策略）。 Access control lists (ACLs) Network administrators will be especially interested in the Fabric use of ACLs, which provide the ability to configure access to resources by associating those resources with existing policies. These “resources” could be functions on system chaincode (e.g., “GetBlockByNumber” on the “qscc” system chaincode) or other resources (e.g.,who can receive Block events). ACLs refer to policies defined in an application channel configuration and extends them to control additional resources. The default set of Fabric ACLs is visible in the configtx.yaml file under the Application: &amp;ApplicationDefaults section but they can and should be overridden in a production environment. The list of resources named in configtx.yaml is the complete set of all internal resources currently defined by Fabric. 网络管理员可能对Fabric使用的AC特别感兴趣，ACL可以通过将资源与现有策略相关联来配置对资源的访问。这些“资源”可以是系统链码上的功能（如，在“ qscc”系统链码上的“ GetBlockByNumber”）或其他资源（如谁可以接收Block事件）。ACL引用在应用程序通道配置中定义的策略，并将其扩展以控制其他资源。默认的Fabric ACL集在configtx.yaml文件里的 Application: &amp;ApplicationDefaults 部分下的可见，但是可以并且应该在生产环境中覆盖它们。configtx.yaml中命名的资源列表是Fabric当前定义的所有内部资源的完整集合。 In that file, ACLs are expressed using the following format: 在该文件中，ACL使用以下格式表示： 12# ACL policy for chaincode to chaincode invocationpeer/ChaincodeToChaincode: /Channel/Application/Readers Where peer/ChaincodeToChaincode represents the resource being secured and /Channel/Application/Readers refers to the policy which must be satisfied for the associated transaction to be considered valid. 其中 peer/ChaincodeToChaincode 表示受保护的资源， /Channel/Application/Readers是指必须满足的策略，关联交易才被视为有效。 For a deeper dive into ACLS, refer to the topic in the Operations Guide on ACLs. 要深入了解ACLS，请参阅ACLs的操作指南中的主题。 Smart contract endorsement policies（智能合约的背书策略） Every smart contract inside a chaincode package has an endorsement policy that specifies how many peers belonging to different channel members need to execute and validate a transaction against a given smart contract in order for the transaction to be considered valid. Hence, the endorsement policies define the organizations (through their peers) who must “endorse” (i.e., approve of) the execution of a proposal. 链码包里面的每个智能合约都有一个背书策略，这个背书策略指定了需要多少个来自不同通道成员的peer节点需要针对给定的智能合约执行和验证交易，以便该交易被视为有效。因此，背书政策定义了必须“背书”（即批准）提案执行的组织（通过其peer）。 Modification policies（修改政策） There is one last type of policy that is crucial to how policies work in Fabric, the Modification policy. Modification policies specify the group of identities required to sign (approve) any configuration update. It is the policy that defines how the policy is updated. Thus, each channel configuration element includes a reference to a policy which governs its modification. 最后一种策略对于Fabric中的策略工作至关重要，即Modification policy。修改策略指定了任何配置更新时需要签名（批准）的一组身份。该策略定义了如何更新策略。因此，每个通道配置元素都包含一个对管理其修改的策略的引用。 The Fabric policy domains While Fabric policies are flexible and can be configured to meet the needs of a network, the policy structure naturally leads to a division between the domains governed by either the Ordering Service organizations or the members of the consortium. In the following diagram you can see how the default policies implement control over the Fabric policy domains below. 虽然Fabric的策略是灵活的，可以配置为满足网络需求，但是策略结构自然会导致由排序服务组织或联盟成员管理的域之间的划分。在下图中你会看到默认策略是如何实现对结构策略域的控制。 A more detailed look at the policy domains governed by the Orderer organizations and consortium organizations. 更详细地了解由订购者组织和财团组织管理的策略域。 A fully functional Fabric network can feature many organizations with different responsibilities. The domains provide the ability to extend different privileges and roles to different organizations by allowing the founders of the ordering service the ability to establish the initial rules and membership of the consortium. They also allow the organizations that join the consortium to create private application channels, govern their own business logic, and restrict access to the data that is put on the network. 功能齐全的Fabric网络可以使许多个组织承担不同的职责。域通过允许排序服务的创建者建立联盟的初始规则和成员资格的能力来提供将不同的特权和角色扩展到不同组织的能力。域还允许加入该联盟的组织创建私有应用程序通道，管理他们自己的业务逻辑，并限制对网络上放置的数据的访问。 The system channel configuration and a portion of each application channel configuration provides the ordering organizations control over which organizations are members of the consortium, how blocks are delivered to channels, and the consensus mechanism used by the nodes of the ordering service. 系统通道配置和每个应用程序通道配置的一部分为排序组织提供了控制，这些组织可以控制哪些组织是联盟的成员，如何将区块交付到渠道以及排序服务的节点所使用的共识机制。 The system channel configuration provides members of the consortium the ability to create channels. Application channels and ACLs are the mechanism that consortium organizations use to add or remove members from a channel and restrict access to data and smart contracts on a channel. 系统通道提供了哪些联盟的成员有能力创建通道。系统通道和ACL是联盟组织用于在通道中添加或删除成员并限制对通道上数据和智能合约的访问的机制。 How do you write a policy in Fabric If you want to change anything in Fabric, the policy associated with the resource describes who needs to approve it, either with an explicit sign off from individuals, or an implicit sign off by a group. In the insurance domain, an explicit sign off could be a single member of the homeowners insurance agents group. And an implicit sign off would be analogous to requiring approval from a majority of the managerial members of the homeowners insurance group. This is particularly useful because the members of that group can change over time without requiring that the policy be updated. In Hyperledger Fabric, explicit sign offs in policies are expressed using the Signature syntax and implicit sign offs use the ImplicitMeta syntax. 如果要更改Fabric中的任何内容，则与资源相关联的策略描述了谁需要批准它，可以是个人的显示签名，也可以是组的隐式签名。在保险领域，显示签名可以是房主保险代理人组的单个成员。隐式签名类似于要求房主保险集团的大多数管理人员批准。这特别有用，因为该组的成员可以随时间变化而无需更新策略。在Hyperledger Fabric中，策略中的显式签名使用Signature语法表示，而隐式签名使用ImplicitMeta语法。 Signature policies Signature policies define specific types of users who must sign in order for a policy to be satisfied such as OR('Org1.peer', 'Org2.peer'). These policies are considered the most versatile because they allow for the construction of extremely specific rules like: “An admin of org A and 2 other admins, or 5 of 6 organization admins”. The syntax supports arbitrary combinations of AND, OR and NOutOf. For example, a policy can be easily expressed by using AND('Org1.member', 'Org2.member') which means that a signature from at least one member in Org1 AND one member in Org2 is required for the policy to be satisfied. Signature 策略定义了必须由指定类型的用户签名才能满足策略，例如 OR('Org1.peer', 'Org2.peer')。这些策略被认为是最通用的，因为它们允许构建极其特定的规则，例如：“组织A的一个管理员和2个其他管理员，或6个组织中的5个管理员”。 ImplicitMeta policies ImplicitMeta policies are only valid in the context of channel configuration which is based on a tiered hierarchy of policies in a configuration tree. ImplicitMeta policies aggregate the result of policies deeper in the configuration tree that are ultimately defined by Signature policies. They are Implicit because they are constructed implicitly based on the current organizations in the channel configuration, and they are Meta because their evaluation is not against specific MSP principals, but rather against other sub-policies below them in the configuration tree. ImplicitMeta 策略仅在通道配置的上下文中有效，该配置基于配置树中策略的分层层次结构。 ImplicitMeta策略将在配置树中更深的策略的结果汇总在一起，这些策略最终由签名策略定义。它们是Implicit的，因为它们是基于渠道配置中的当前组织隐式构造的，之所以称为Meta，是因为它们的评估不是针对特定的MSP主体，而是针对配置树中位于其下方的其他子策略。 The following diagram illustrates the tiered policy structure for an application channel and shows how the ImplicitMeta channel configuration admins policy, named /Channel/Admins, is resolved when the sub-policies named Admins below it in the configuration hierarchy are satisfied where each check mark represents that the conditions of the sub-policy were satisfied. 下图说明了应用程序通道的分层策略结构,并显示名为 /Channel/Admins的 ImplicitMeta 通道配置管理员策略，当满足配置层次结构中位于其下方的名为Admins的子策略时，将解决此问题，其中每个复选标记表示已满足该子策略的条件。 As you can see in the diagram above, ImplicitMeta policies, Type = 3, use a different syntax, &quot;&lt;ANY|ALL|MAJORITY&gt; &lt;SubPolicyName&gt;&quot;, for example: 如上图所示，ImplicitMeta 策略， Type = 3，使用不同的语法&quot;&lt;ANY|ALL|MAJORITY&gt; &lt;SubPolicyName&gt;&quot;，例如： 1&#96;MAJORITY sub policy: Admins&#96; The diagram shows a sub-policy Admins, which refers to all the Admins policy below it in the configuration tree. You can create your own sub-policies and name them whatever you want and then define them in each of your organizations. 该图显示了一个子策略Admins，它引用配置树中其下方的所有Admins策略。您可以创建自己的子策略，并根据需要命名它们，然后在你的每个组织中对其进行定义。 As mentioned above, a key benefit of an ImplicitMeta policy such as MAJORITY Admins is that when you add a new admin organization to the channel, you do not have to update the channel policy. Therefore ImplicitMeta policies are considered to be more flexible as the consortium members change. The consortium on the orderer can change as new members are added or an existing member leaves with the consortium members agreeing to the changes, but no policy updates are required. Recall that ImplicitMeta policies ultimately resolve the Signature sub-policies underneath them in the configuration tree as the diagram shows. 如上所述，ImplicitMeta策略（例如MAJORITY Admins）的主要优势在于，当您向通道添加新的管理员组织时，不必更新频道策略。因此，随着联盟成员的变化，ImplicitMeta策略被认为更加灵活。当添加新成员或现有成员离开时，排序者上的联盟可以更改，联盟成员同意更改，但是不需要更新策略。回想一下，ImplicitMeta策略最终在配置树中解决了其下方的Signature子策略，如图所示。 You can also define an application level implicit policy to operate across organizations, in a channel for example, and either require that ANY of them are satisfied, that ALL are satisfied, or that a MAJORITY are satisfied. This format lends itself to much better, more natural defaults, so that each organization can decide what it means for a valid endorsement. 您还可以定义一个应用程序级别的隐式策略，以在组织中（例如，在一个通道中）进行操作，并要求满足它们中的任何一个，满足所有条件或满足大多数条件。这种格式适合于更好，更自然的默认设置，以便每个组织可以决定对有效背书的含义。 Further granularity and control can be achieved if you include NodeOUs in your organization definition. Organization Units (OUs) are defined in the Fabric CA client configuration file and can be associated with an identity when it is created. In Fabric, NodeOUs provide a way to classify identities in a digital certificate hierarchy. For instance, an organization having specific NodeOUs enabled could require that a ‘peer’ sign for it to be a valid endorsement, whereas an organization without any might simply require that any member can sign. 如果在组织定义中包含NodeOU，则可以实现进一步的粒度和控制。组织单位（OU）在Fabric CA客户端配置文件中定义，并且在创建时可以与身份相关联。NodeOU提供了一种在数字证书层次结构中对身份进行分类的方法。例如，启用了特定NodeOU的组织可能要求“peer”标志才能有效地背书，而只有组织而不包含任何其他可能只要求任何成员都可以签名。 An example: channel configuration policy Understanding policies begins with examining the configtx.yaml where the channel policies are defined. We can use the configtx.yaml file in the Fabric test network to see examples of both policy syntax types. We are going to examine the configtx.yaml file used by the fabric-samples/test-network sample. The first section of the file defines the organizations of the network. Inside each organization definition are the default policies for that organization, Readers, Writers, Admins, and Endorsement, although you can name your policies anything you want. Each policy has a Type which describes how the policy is expressed (Signature or ImplicitMeta) and a Rule. The test network example below shows the Org1 organization definition in the system channel, where the policy Type is Signature and the endorsement policy rule is defined as &quot;OR('Org1MSP.peer')&quot;. This policy specifies that a peer that is a member of Org1MSP is required to sign. It is these signature policies that become the sub-policies that the ImplicitMeta policies point to. 123456789101112131415161718192021222324252627282930313233################################################################################## SECTION: Application## - This section defines the values to encode into a config transaction or# genesis block for application related parameters#################################################################################Application: &amp;ApplicationDefaults # Organizations is the list of orgs which are defined as participants on # the application side of the network Organizations: # Policies defines the set of policies at this level of the config tree # For Application policies, their canonical path is # /Channel/Application/&lt;PolicyName&gt; Policies: Readers: Type: ImplicitMeta Rule: &quot;ANY Readers&quot; Writers: Type: ImplicitMeta Rule: &quot;ANY Writers&quot; Admins: Type: ImplicitMeta Rule: &quot;MAJORITY Admins&quot; LifecycleEndorsement: Type: ImplicitMeta Rule: &quot;MAJORITY Endorsement&quot; Endorsement: Type: ImplicitMeta Rule: &quot;MAJORITY Endorsement&quot; The next example shows the ImplicitMeta policy type used in the Application section of the configtx.yaml. These set of policies lie on the /Channel/Application/ path. If you use the default set of Fabric ACLs, these policies define the behavior of many important features of application channels, such as who can query the channel ledger, invoke a chaincode, or update a channel config. These policies point to the sub-policies defined for each organization. The Org1 defined in the section above contains Reader, Writer, and Admin sub-policies that are evaluated by the Reader, Writer, and Admin ImplicitMeta policies in the Application section. Because the test network is built with the default policies, you can use the example Org1 to query the channel ledger, invoke a chaincode, and approve channel updates for any test network channel that you create. 123456789101112131415161718192021222324252627282930313233################################################################################## SECTION: Application## - This section defines the values to encode into a config transaction or# genesis block for application related parameters#################################################################################Application: &amp;ApplicationDefaults # Organizations is the list of orgs which are defined as participants on # the application side of the network Organizations: # Policies defines the set of policies at this level of the config tree # For Application policies, their canonical path is # /Channel/Application/&lt;PolicyName&gt; Policies: Readers: Type: ImplicitMeta Rule: &quot;ANY Readers&quot; Writers: Type: ImplicitMeta Rule: &quot;ANY Writers&quot; Admins: Type: ImplicitMeta Rule: &quot;MAJORITY Admins&quot; LifecycleEndorsement: Type: ImplicitMeta Rule: &quot;MAJORITY Endorsement&quot; Endorsement: Type: ImplicitMeta Rule: &quot;MAJORITY Endorsement&quot; Fabric chaincode lifecycle In the Fabric 2.0 release, a new chaincode lifecycle process was introduced, whereby a more democratic process is used to govern chaincode on the network. The new process allows multiple organizations to vote on how a chaincode will be operated before it can be used on a channel. This is significant because it is the combination of this new lifecycle process and the policies that are specified during that process that dictate the security across the network. More details on the flow are available in the Fabric chaincode lifecycle concept topic, but for purposes of this topic you should understand how policies are used in this flow. The new flow includes two steps where policies are specified: when chaincode is approved by organization members, and when it is committed to the channel. The Application section of the configtx.yaml file includes the default chaincode lifecycle endorsement policy. In a production environment you would customize this definition for your own use case. 123456789101112131415161718192021222324252627282930313233################################################################################## SECTION: Application## - This section defines the values to encode into a config transaction or# genesis block for application related parameters#################################################################################Application: &amp;ApplicationDefaults # Organizations is the list of orgs which are defined as participants on # the application side of the network Organizations: # Policies defines the set of policies at this level of the config tree # For Application policies, their canonical path is # /Channel/Application/&lt;PolicyName&gt; Policies: Readers: Type: ImplicitMeta Rule: &quot;ANY Readers&quot; Writers: Type: ImplicitMeta Rule: &quot;ANY Writers&quot; Admins: Type: ImplicitMeta Rule: &quot;MAJORITY Admins&quot; LifecycleEndorsement: Type: ImplicitMeta Rule: &quot;MAJORITY Endorsement&quot; Endorsement: Type: ImplicitMeta Rule: &quot;MAJORITY Endorsement&quot; The LifecycleEndorsement policy governs who needs to approve a chaincode definition. LifecycleEndorsement 策略管理谁需要批准链码定义 The Endorsement policy is the default endorsement policy for a chaincode. More on this below. Endorsement策略是链码的默认背书策略，详情在下面。 Chaincode endorsement policies The endorsement policy is specified for a chaincode when it is approved and committed to the channel using the Fabric chaincode lifecycle (that is, one endorsement policy covers all of the state associated with a chaincode). The endorsement policy can be specified either by reference to an endorsement policy defined in the channel configuration or by explicitly specifying a Signature policy. 在使用Fabric链码生命周期批准链码并将其提交给通道时便指定了链码的背书策略（即，一种背书策略涵盖了与链码相关联的所有状态）。可以通过参考在通道配置中定义的背书策略来指定背书策略，也可以通过显式指定签名策略来指定背书策略。 If an endorsement policy is not explicitly specified during the approval step, the default Endorsement policy &quot;MAJORITY Endorsement&quot; is used which means that a majority of the peers belonging to the different channel members (organizations) need to execute and validate a transaction against the chaincode in order for the transaction to be considered valid. This default policy allows organizations that join the channel to become automatically added to the chaincode endorsement policy. If you don’t want to use the default endorsement policy, use the Signature policy format to specify a more complex endorsement policy (such as requiring that a chaincode be endorsed by one organization, and then one of the other organizations on the channel). Signature policies also allow you to include principals which are simply a way of matching an identity to a role. Principals are just like user IDs or group IDs, but they are more versatile because they can include a wide range of properties of an actor’s identity, such as the actor’s organization, organizational unit, role or even the actor’s specific identity. When we talk about principals, they are the properties which determine their permissions. Principals are described as ‘MSP.ROLE’, where MSP represents the required MSP ID (the organization), and ROLE represents one of the four accepted roles: Member, Admin, Client, and Peer. A role is associated to an identity when a user enrolls with a CA. You can customize the list of roles available on your Fabric CA. Some examples of valid principals are: ‘Org0.Admin’: an administrator of the Org0 MSP ‘Org1.Member’: a member of the Org1 MSP ‘Org1.Client’: a client of the Org1 MSP ‘Org1.Peer’: a peer of the Org1 MSP ‘OrdererOrg.Orderer’: an orderer in the OrdererOrg MSP There are cases where it may be necessary for a particular state (a particular key-value pair, in other words) to have a different endorsement policy. This state-based endorsement allows the default chaincode-level endorsement policies to be overridden by a different policy for the specified keys. For a deeper dive on how to write an endorsement policy refer to the topic on Endorsement policies in the Operations Guide. Note: Policies work differently depending on which version of Fabric you are using: In Fabric releases prior to 2.0, chaincode endorsement policies can be updated during chaincode instantiation or by using the chaincode lifecycle commands. If not specified at instantiation time, the endorsement policy defaults to “any member of the organizations in the channel”. For example, a channel with “Org1” and “Org2” would have a default endorsement policy of “OR(‘Org1.member’, ‘Org2.member’)”. Starting with Fabric 2.0, Fabric introduced a new chaincode lifecycle process that allows multiple organizations to agree on how a chaincode will be operated before it can be used on a channel. The new process requires that organizations agree to the parameters that define a chaincode, such as name, version, and the chaincode endorsement policy. Overriding policy definitions Hyperledger Fabric includes default policies which are useful for getting started, developing, and testing your blockchain, but they are meant to be customized in a production environment. You should be aware of the default policies in the configtx.yaml file. Channel configuration policies can be extended with arbitrary verbs, beyond the default Readers, Writers, Admins in configtx.yaml. The orderer system and application channels are overridden by issuing a config update when you override the default policies by editing the configtx.yaml for the orderer system channel or the configtx.yaml for a specific channel. See the topic on Updating a channel configuration for more information.","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"Key Concepts","slug":"区块链/Hyperledger-Fabric/Key-Concepts","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/Key-Concepts/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"Policies","slug":"Policies","permalink":"https://guozhe001.github.io/tags/Policies/"}]},{"title":"The Ordering Service","slug":"blockchain/fabric/关键概念/The-Ordering-Service","date":"2024-11-22T06:32:06.495Z","updated":"2024-11-22T06:32:06.495Z","comments":true,"path":"2024/11/22/blockchain/fabric/关键概念/The-Ordering-Service/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E5%85%B3%E9%94%AE%E6%A6%82%E5%BF%B5/The-Ordering-Service/","excerpt":"","text":"本文档来自The Ordering Service,有所简化。 What is ordering? Many distributed blockchains, such as Ethereum and Bitcoin, are not permissioned, which means that any node can participate in the consensus process, wherein transactions are ordered and bundled into blocks. Because of this fact, these systems rely on probabilistic consensus algorithms which eventually guarantee ledger consistency to a high degree of probability, but which are still vulnerable to divergent ledgers (also known as a ledger “fork”), where different participants in the network have a different view of the accepted order of transactions. 许多的分布式区块链系统，例如以太坊和比特币都是不需要认可的；这意味着任何节点都可以参与共识过程，这个共识就是把交易排序并打包成区块。由于这个事实，这些系统依赖于概率共识算法（目前是Pow共识算法），该算法最终可以确保分类帐的一致性具有很高的概率，但是它们仍然容易收到分叉的影响，在分叉的分类账中，网络中的不同参与者对接受的交易顺序有不同的看法。 Hyperledger Fabric works differently. It features a node called an orderer (it’s also known as an “ordering node”) that does this transaction ordering, which along with other orderer nodes forms an ordering service. Because Fabric’s design relies on deterministic consensus algorithms, any block validated by the peer is guaranteed to be final and correct. Ledgers cannot fork the way they do in many other distributed and permissionless blockchain networks. Hyperledger Fabric的工作方式有所不同。它具有一个称为“排序者”的节点（也称为“排序节点”）来执行此交易的排序，该节点与其他排序节点一起构成排序服务。由于Fabric的设计依赖于确定性共识算法，因此可以保证peer验证的任何块都是最终的和正确的。账本也不会像以太坊和比特币那样出现分叉。 In addition to promoting finality, separating the endorsement of chaincode execution (which happens at the peers) from ordering gives Fabric advantages in performance and scalability, eliminating bottlenecks which can occur when execution and ordering are performed by the same nodes. 除了促进不可变性之外，将链码执行的背书（在同级中发生）与排序分开可以使Fabric在性能和可伸缩性方面具有优势，消除了由相同节点执行和排序时可能发生的瓶颈。 Orderer nodes and channel configuration In addition to their ordering role, orderers also maintain the list of organizations that are allowed to create channels. This list of organizations is known as the “consortium”, and the list itself is kept in the configuration of the “orderer system channel” (also known as the “ordering system channel”). By default, this list, and the channel it lives on, can only be edited by the orderer admin. Note that it is possible for an ordering service to hold several of these lists, which makes the consortium a vehicle for Fabric multi-tenancy. 除了作为排序的角色之外，orderers还维护允许创建通道的组织的列表。这个组织的列表被称为“联盟”，并且这个列表被保存在 “orderer system channel” 的配置中。默认情况下，此列表及其所处的通道只能由orderer的管理员进行编辑。 Orderers also enforce basic access control for channels, restricting who can read and write data to them, and who can configure them. Remember that who is authorized to modify a configuration element in a channel is subject to the policies that the relevant administrators set when they created the consortium or the channel. Configuration transactions are processed by the orderer, as it needs to know the current set of policies to execute its basic form of access control. In this case, the orderer processes the configuration update to make sure that the requestor has the proper administrative rights. If so, the orderer validates the update request against the existing configuration, generates a new configuration transaction, and packages it into a block that is relayed to all peers on the channel. The peers then process the configuration transactions in order to verify that the modifications approved by the orderer do indeed satisfy the policies defined in the channel. Orderers还对通道实施基本访问控制，限制谁可以向通道读取和写入数据以及谁可以对其进行配置。 Orderer nodes and identity Everything that interacts with a blockchain network, including peers, applications, admins, and orderers, acquires their organizational identity from their digital certificate and their Membership Service Provider (MSP) definition. For more information about identities and MSPs, check out our documentation on Identity and Membership. Just like peers, ordering nodes belong to an organization. And similar to peers, a separate Certificate Authority (CA) should be used for each organization. Whether this CA will function as the root CA, or whether you choose to deploy a root CA and then intermediate CAs associated with that root CA, is up to you. Orderers and the transaction flow Phase one: Proposal We’ve seen from our topic on Peers that they form the basis for a blockchain network, hosting ledgers, which can be queried and updated by applications through smart contracts. Specifically, applications that want to update the ledger are involved in a process with three phases that ensures all of the peers in a blockchain network keep their ledgers consistent with each other. 具体来说，应用程序想要更新账本需要涉及三个阶段的过程来确保区块链网络中的所有peer节点保持账本彼此一致。 In the first phase, a client application sends a transaction proposal to a subset of peers that will invoke a smart contract to produce a proposed ledger update and then endorse the results. The endorsing peers do not apply the proposed update to their copy of the ledger at this time. Instead, the endorsing peers return a proposal response to the client application. The endorsed transaction proposals will ultimately be ordered into blocks in phase two, and then distributed to all peers for final validation and commit in phase three. 在第一个阶段中，客户端应用程序将交易建议发送给一些peer节点，这些peer节点将调用智能合约以产生提议的账本更新，然后对结果进行背书。背书的peer节点此时不将建议的更新应用于其账本副本。相反，背书的对等方将提议响应返回到客户端应用程序。然后认可的交易建议将最终在第二阶段按顺序排列，然后分发给所有peer节点以进行最终验证并在第三阶段进行提交。 For an in-depth look at the first phase, refer back to the Peers topic. Phase two: Ordering and packaging transactions into blocks After the completion of the first phase of a transaction, a client application has received an endorsed transaction proposal response from a set of peers. It’s now time for the second phase of a transaction. 在完成交易的第一阶段之后，客户端应用程序已经接收到来自一群peer节点的已经背书的交易提议响应。*** In this phase, application clients submit transactions containing endorsed transaction proposal responses to an ordering service node. The ordering service creates blocks of transactions which will ultimately be distributed to all peers on the channel for final validation and commit in phase three. 在这个阶段，客户端应用程序提交包含已经背书的交易提议响应的交易到一个排序服务节点。排序服务创建包含交易的区块，这个区块最终将分发给通道上的所有peer节点，以进行最终验证并在第三阶段进行提交。 Ordering service nodes receive transactions from many different application clients concurrently. These ordering service nodes work together to collectively form the ordering service. Its job is to arrange batches of submitted transactions into a well-defined sequence and package them into blocks. These blocks will become the blocks of the blockchain! 排序服务节点同时接收来自许多不同应用程序客户端的交易。这些排序服务节点一起工作以共同形成排序服务。排序服务的工作是对提交过来的批量的交易安排一个明确定义的顺序，并将它们打包成区块。这些区块将成为区块链的区块！ The number of transactions in a block depends on channel configuration parameters related to the desired size and maximum elapsed duration for a block (BatchSize and BatchTimeout parameters, to be exact). The blocks are then saved to the orderer’s ledger and distributed to all peers that have joined the channel. If a peer happens to be down at this time, or joins the channel later, it will receive the blocks after reconnecting to an ordering service node, or by gossiping with another peer. We’ll see how this block is processed by peers in the third phase. 区块中的交易数量取决于通道配置参数，与区块的所需大小和最大经过时间有关（更精确的说是BatchSize 和 BatchTimeout 两个参数）。然后这个区块被保存到排序者的账本中并分发给加入到通道的所有peer节点。如果某个peer节点在这时发生了宕机或者在这以后加入到通道，他会在重新连接到排序服务节点之后收到此区块，或者通过gossiping从其他peer获取。 The first role of an ordering node is to package proposed ledger updates. In this example, application A1 sends a transaction T1 endorsed by E1 and E2 to the orderer O1. In parallel, Application A2 sends transaction T2 endorsed by E1 to the orderer O1. O1 packages transaction T1 from application A1 and transaction T2 from application A2 together with other transactions from other applications in the network into block B2. We can see that in B2, the transaction order is T1,T2,T3,T4,T6,T5 – which may not be the order in which these transactions arrived at the orderer! (This example shows a very simplified ordering service configuration with only one ordering node.) 排序节点的第一个角色时打包提议的账本更新。 It’s worth noting that the sequencing of transactions in a block is not necessarily the same as the order received by the ordering service, since there can be multiple ordering service nodes that receive transactions at approximately the same time. What’s important is that the ordering service puts the transactions into a strict order, and peers will use this order when validating and committing transactions. 值得注意的是，一个区块中的交易顺序不一定与排序服务所接收的订单顺序相同，因为可能有多个排序服务节点大约在同一时间接收交易。重要的是排序服务将交易置于严格的顺序中，并且peer节点在验证和提交交易时将使用该顺序。 个人理解：看第一遍时觉得多个排序服务节点收到不同的交易进行排序，这些排序服务是如何保持交易顺序的一致性的呢？如果把排序服务看作一个整体这个问题就解决了，不同的排序服务节点接收到交易之后还会对所有的接收到的交易做一个汇总，并不是每个排序服务节点都对交易进行排序。况且每个排序服务节点只是接收连接到这个排序服务节点的应用程序的交易，所以接收到的交易并不是整个通道上的所有的交易内容，因此肯定是不能够由排序服务节点进行单独排序的。 This strict ordering of transactions within blocks makes Hyperledger Fabric a little different from other blockchains where the same transaction can be packaged into multiple different blocks that compete to form a chain. In Hyperledger Fabric, the blocks generated by the ordering service are final. Once a transaction has been written to a block, its position in the ledger is immutably assured. As we said earlier, Hyperledger Fabric’s finality means that there are no ledger forks — validated transactions will never be reverted or dropped. 这种区块内的交易具有严格的顺序使Hyperledger Fabric和其他的区块链系统有一点不同，其他的区块链系统相同的交易可以被打包到不同区块中然后竞争形成一个链。在 Hyperledger Fabric中，由排序服务生成的区块是最终的。一旦一个交易被写入一个区块，它在账本中的位置就永远不变了。像我们之前说的， Hyperledger Fabric的最终性意味着没有账本分叉 – 经验证的交易将永远不会被回滚或丢弃。 We can also see that, whereas peers execute smart contracts and process transactions, orderers most definitely do not. Every authorized transaction that arrives at an orderer is mechanically packaged in a block — the orderer makes no judgement as to the content of a transaction (except for channel configuration transactions, as mentioned earlier). 我们还可以看到，peer节点执行智能合约并处理交易，而排序者绝对不会做这些。到达排序者的每笔已经授权交易以机械方式打包在一个区块中 – 排序者不对交易的内容做出判断（除了前面所述的通道配置交易）。 At the end of phase two, we see that orderers have been responsible for the simple but vital processes of collecting proposed transaction updates, ordering them, and packaging them into blocks, ready for distribution. 在第二阶段的最后，我们看到排序者负责简单但至关重要的过程，这些过程包括收集提议的交易更新，进行排序并将它们打包成区块以便分发。 Phase three: Validation and commit The third phase of the transaction workflow involves the distribution and subsequent validation of blocks from the orderer to the peers, where they can be committed to the ledger. Phase 3 begins with the orderer distributing blocks to all peers connected to it. It’s also worth noting that not every peer needs to be connected to an orderer — peers can cascade blocks to other peers using the gossip protocol. Each peer will validate distributed blocks independently, but in a deterministic fashion, ensuring that ledgers remain consistent. Specifically, each peer in the channel will validate each transaction in the block to ensure it has been endorsed by the required organization’s peers, that its endorsements match, and that it hasn’t become invalidated by other recently committed transactions which may have been in-flight when the transaction was originally endorsed. Invalidated transactions are still retained in the immutable block created by the orderer, but they are marked as invalid by the peer and do not update the ledger’s state. The second role of an ordering node is to distribute blocks to peers. In this example, orderer O1 distributes block B2 to peer P1 and peer P2. Peer P1 processes block B2, resulting in a new block being added to ledger L1 on P1. In parallel, peer P2 processes block B2, resulting in a new block being added to ledger L1 on P2. Once this process is complete, the ledger L1 has been consistently updated on peers P1 and P2, and each may inform connected applications that the transaction has been processed. In summary, phase three sees the blocks generated by the ordering service applied consistently to the ledger. The strict ordering of transactions into blocks allows each peer to validate that transaction updates are consistently applied across the blockchain network. For a deeper look at phase 3, refer back to the Peers topic. Ordering service implementations While every ordering service currently available handles transactions and configuration updates the same way, there are nevertheless several different implementations for achieving consensus on the strict ordering of transactions between ordering service nodes. 当前可用的每个排序服务都以相同的方式处理交易和配置更新，但是有几种不同的实现方式可用于在排序服务节点之间对严格的交易顺序达成共识。 For information about how to stand up an ordering node (regardless of the implementation the node will be used in), check out our documentation on standing up an ordering node. Raft (recommended) New as of v1.4.1, Raft is a crash fault tolerant (CFT) ordering service based on an implementation of Raft protocol in etcd. Raft follows a “leader and follower” model, where a leader node is elected (per channel) and its decisions are replicated by the followers. Raft ordering services should be easier to set up and manage than Kafka-based ordering services, and their design allows different organizations to contribute nodes to a distributed ordering service. 自v1.4.1起新增，Raft是基于etcd的 Raft 协议 实现的故障容错排序服务。Raft遵从“领导者和跟随者”模型，这个模型是领导者节点（按通道）被选出并由跟随者复制其决策。Raft协议排序服务相较于基于Kafka的排序服务更容易设置和管理，其设计允许不同的组织将节点贡献给分布式排序服务。（个人理解最后一句话是说排序服务是由不同组织的排序服务节点组成） Kafka (deprecated in v2.x) Similar to Raft-based ordering, Apache Kafka is a CFT implementation that uses a “leader and follower” node configuration. Kafka utilizes a ZooKeeper ensemble for management purposes. The Kafka based ordering service has been available since Fabric v1.0, but many users may find the additional administrative overhead of managing a Kafka cluster intimidating or undesirable. 与基于Raft的排序类似，Apache Kafka是使用“领导者和跟随者”节点配置的CFT实现。Kafka利用ZooKeeper集合进行管理。从Fabric v1.0开始提供基于Kafka的排序服务，但是许多用户可能会发现管理Kafka群集的额外管理开销令人生畏或不受欢迎。 Solo (deprecated in v2.x) The Solo implementation of the ordering service is intended for test only and consists only of a single ordering node. It has been deprecated and may be removed entirely in a future release. Existing users of Solo should move to a single node Raft network for equivalent function. 排序服务的Solo实现仅用于测试，并且仅包含一个订购节点。它已被弃用，在将来的发行版中可能会完全删除。Solo的现有用户应移至单节点Raft网络以实现等效功能。 Raft For information on how to configure a Raft ordering service, check out our documentation on configuring a Raft ordering service. The go-to ordering service choice for production networks, the Fabric implementation of the established Raft protocol uses a “leader and follower” model, in which a leader is dynamically elected among the ordering nodes in a channel (this collection of nodes is known as the “consenter set”), and that leader replicates messages to the follower nodes. Because the system can sustain the loss of nodes, including leader nodes, as long as there is a majority of ordering nodes (what’s known as a “quorum”) remaining, Raft is said to be “crash fault tolerant” (CFT). In other words, if there are three nodes in a channel, it can withstand the loss of one node (leaving two remaining). If you have five nodes in a channel, you can lose two nodes (leaving three remaining nodes). This feature of a Raft ordering service is a factor in the establishment of a high availability strategy for your ordering service. Additionally, in a production environment, you would want to spread these nodes across data centers and even locations. For example, by putting one node in three different data centers. That way, if a data center or entire location becomes unavailable, the nodes in the other data centers continue to operate. 生产网络的首选排序服务实现方式，Fabric中已建立的Raft协议的实现是使用“领导者和跟随者”模型，其中领导者是在通道中的排序节点之间动态选举的（该节点集合称为“同意者集”），领导者将消息复制到跟随者节点。因为系统可以承受包括领导节点在内的节点的丢失，所以只要剩下大多数排序节点（所谓的“法定人数”）即可，因此Raft被称为“故障容错”（CFT）。换句话说，如果通道中有三个节点，那么它可以承受一个节点的损失（剩下两个活着的节点）。如果通道中有五个节点，则允许丢失两个节点（剩下三个剩余节点）。Raft排序服务的此功能是为您的排序服务建立高可用性策略的一个因素。此外，在生产环境中，您可能希望将这些节点分布在数据中心甚至本地。例如，通过将节点放置在三个不同的数据中心中。这样，如果一个数据中心或整个位置不可用，则其他数据中心中的节点将继续运行。 From the perspective of the service they provide to a network or a channel, Raft and the existing Kafka-based ordering service (which we’ll talk about later) are similar. They’re both CFT ordering services using the leader and follower design. If you are an application developer, smart contract developer, or peer administrator, you will not notice a functional difference between an ordering service based on Raft versus Kafka. However, there are a few major differences worth considering, especially if you intend to manage an ordering service: 从它们提供给网络或通道的服务的角度来看，Raft与现有的基于Kafka的排序服务（我们将在后面讨论）很相似。 它们都是采用领导者和跟随者设计的CFT排序服务。如果你是一个应用程序开发者、智能合约开发者或者是peer绩点管理员，您不会注意到基于Raft和Kafka的排序服务之间的功能差异。但是，有一些主要差异值得考虑，尤其是如果您打算管理排序服务： Raft is easier to set up. Although Kafka has many admirers, even those admirers will (usually) admit that deploying a Kafka cluster and its ZooKeeper ensemble can be tricky, requiring a high level of expertise in Kafka infrastructure and settings. Additionally, there are many more components to manage with Kafka than with Raft, which means that there are more places where things can go wrong. And Kafka has its own versions, which must be coordinated with your orderers. With Raft, everything is embedded into your ordering node. Raft的排序服务更容易搭建。 Kafka and Zookeeper are not designed to be run across large networks. While Kafka is CFT, it should be run in a tight group of hosts. This means that practically speaking you need to have one organization run the Kafka cluster. Given that, having ordering nodes run by different organizations when using Kafka (which Fabric supports) doesn’t give you much in terms of decentralization because the nodes will all go to the same Kafka cluster which is under the control of a single organization. With Raft, each organization can have its own ordering nodes, participating in the ordering service, which leads to a more decentralized system. Kafka和Zookeeper并非是为了跨大型网络运行而设计的。 Raft is supported natively, which means that users are required to get the requisite images and learn how to use Kafka and ZooKeeper on their own. Likewise, support for Kafka-related issues is handled through Apache, the open-source developer of Kafka, not Hyperledger Fabric. The Fabric Raft implementation, on the other hand, has been developed and will be supported within the Fabric developer community and its support apparatus. Where Kafka uses a pool of servers (called “Kafka brokers”) and the admin of the orderer organization specifies how many nodes they want to use on a particular channel, Raft allows the users to specify which ordering nodes will be deployed to which channel. In this way, peer organizations can make sure that, if they also own an orderer, this node will be made a part of a ordering service of that channel, rather than trusting and depending on a central admin to manage the Kafka nodes. Raft is the first step toward Fabric’s development of a byzantine fault tolerant (BFT) ordering service. As we’ll see, some decisions in the development of Raft were driven by this. If you are interested in BFT, learning how to use Raft should ease the transition. Raft是Fabric开发拜占庭式容错（BFT）排序服务的第一步。 Note: Similar to Solo and Kafka, a Raft ordering service can lose transactions after acknowledgement of receipt has been sent to a client. For example, if the leader crashes at approximately the same time as a follower provides acknowledgement of receipt. Therefore, application clients should listen on peers for transaction commit events regardless (to check for transaction validity), but extra care should be taken to ensure that the client also gracefully tolerates a timeout in which the transaction does not get committed in a configured timeframe. Depending on the application, it may be desirable to resubmit the transaction or collect a new set of endorsements upon such a timeout. 在已将回执确认发送给客户之后，Raft排序服务可能会丢失交易。例如，如果领导者大约在追随者提供回执确认的同时崩溃。因此，无论如何应用程序客户端都应在peer上侦听交易提交事件（以检查交易有效性），但应格外小心，以确保客户端也能容忍超时，在该超时中不会在配置的时间范围内提交事务。 Raft concepts While Raft offers many of the same features as Kafka — albeit in a simpler and easier-to-use package — it functions substantially different under the covers from Kafka and introduces a number of new concepts, or twists on existing concepts, to Fabric. 尽管Raft提供了许多与Kafka相同的功能 – 尽管采用了更简单易用的软件包 – 它的功能与Kafka的表面大不相同，并为Fabric引入了许多新概念或扭曲现有的概念。 Log entry. The primary unit of work in a Raft ordering service is a “log entry”, with the full sequence of such entries known as the “log”. We consider the log consistent if a majority (a quorum, in other words) of members agree on the entries and their order, making the logs on the various orderers replicated. Raft排序服务的主要工作单元是 “log entry”，这些条目的完整序列称为“log”。如果多数成员（换言之，为法定人数）同意条目及其顺序，则我们认为日志是一致的，使日志复制到各个排序者上。 Consenter set. The ordering nodes actively participating in the consensus mechanism for a given channel and receiving replicated logs for the channel. This can be all of the nodes available (either in a single cluster or in multiple clusters contributing to the system channel), or a subset of those nodes. 同意者集。排序节点积极参与给定通道的共识机制，并接收该通道的复制日志。这可以是所有可用节点（在单个群集中或在组成系统通道的多个群集中），也可以是那些节点的子集。 Finite-State Machine (FSM). Every ordering node in Raft has an FSM and collectively they’re used to ensure that the sequence of logs in the various ordering nodes is deterministic (written in the same sequence). 有限状态机。Raft中的每个排序节点都有一个FSM，并共同使用它们来确保各个排序节点中的日志顺序是确定的（以相同的顺序写入）。 Quorum. Describes the minimum number of consenters that need to affirm a proposal so that transactions can be ordered. For every consenter set, this is a majority of nodes. In a cluster with five nodes, three must be available for there to be a quorum. If a quorum of nodes is unavailable for any reason, the ordering service cluster becomes unavailable for both read and write operations on the channel, and no new logs can be committed. 法定人数。描述需要确认提议以便可以排序交易的同意者的最小数量。对于每个同意集，这是大多数节点。在一个由五个节点组成的集群中，必须有三个节点可用才能达到法定人数。如果由于任何原因无法达到法定数量的节点，排序服务群集将无法用于通道上的读取和写入操作，并且无法提交任何新日志。 Leader. This is not a new concept — Kafka also uses leaders, as we’ve said — but it’s critical to understand that at any given time, a channel’s consenter set elects a single node to be the leader (we’ll describe how this happens in Raft later). The leader is responsible for ingesting new log entries, replicating them to follower ordering nodes, and managing when an entry is considered committed. This is not a special type of orderer. It is only a role that an orderer may have at certain times, and then not others, as circumstances determine. 领导者。 这不是一个新概念 – 正如我们所说的，Kafka也使用领导者 – 但至关重要的是要了解，在任何给定时间，通道的同意者集会选举一个节点作为领导者（我们稍后将描述在Raft中如何发生）。领导者负责获取新的日志条目，将它们复制到跟随者排序节点，并管理何时将条目视为已提交。这不是排序者的特殊类型。这只是排序者可能在某些时候扮演的角色，***。 Follower. Again, not a new concept, but what’s critical to understand about followers is that the followers receive the logs from the leader and replicate them deterministically, ensuring that logs remain consistent. As we’ll see in our section on leader election, the followers also receive “heartbeat” messages from the leader. In the event that the leader stops sending those message for a configurable amount of time, the followers will initiate a leader election and one of them will be elected the new leader. 追随者。了解追随者的关键是追随者从领导者那里接收日志并确定性地复制它们，以确保日志保持一致。正如我们在领导者选举部分中所看到的那样，追随者还会从领导者那里接收“心跳”消息。如果领导者在可配置的时间内停止发送这些消息，则跟随者将发起领导者选举，其中一个将被选举为新领导者。 Raft in a transaction flow Every channel runs on a separate instance of the Raft protocol, which allows each instance to elect a different leader. This configuration also allows further decentralization of the service in use cases where clusters are made up of ordering nodes controlled by different organizations. While all Raft nodes must be part of the system channel, they do not necessarily have to be part of all application channels. Channel creators (and channel admins) have the ability to pick a subset of the available orderers and to add or remove ordering nodes as needed (as long as only a single node is added or removed at a time). 每个通道都运行一个单独的Raft协议实例，这允许每个实例选择不同的领导者。在由不同组织控制的排序节点组成的群集用例中，此配置还允许进一步分散服务。尽管所有Raft节点都必须是系统通道的一部分，但不一定必须是所有应用程序通道的一部分。通道创建者（和通道管理员）可以选择可用订购者的子集，并根据需要添加或删除订购节点（只要一次仅添加或删除一个节点）。 While this configuration creates more overhead in the form of redundant heartbeat messages and goroutines, it lays necessary groundwork for BFT. 虽然此配置以冗余心跳消息和goroutine的形式创建了更多开销，但为BFT奠定了必要的基础。 In Raft, transactions (in the form of proposals or configuration updates) are automatically routed by the ordering node that receives the transaction to the current leader of that channel. This means that peers and applications do not need to know who the leader node is at any particular time. Only the ordering nodes need to know. 在Raft中，交易（以建议书或配置更新的形式）由接收交易的排序节点自动路由到该通道的当前leader节点。这意味着peer节点和应用程序节点不需要知道当前时间谁是leader节点。只有排序服务节点需要知道。 When the orderer validation checks have been completed, the transactions are ordered, packaged into blocks, consented on, and distributed, as described in phase two of our transaction flow. Architectural notes How leader election works in Raft Although the process of electing a leader happens within the orderer’s internal processes, it’s worth noting how the process works. Raft nodes are always in one of three states: follower, candidate, or leader. All nodes initially start out as a follower. In this state, they can accept log entries from a leader (if one has been elected), or cast votes for leader. If no log entries or heartbeats are received for a set amount of time (for example, five seconds), nodes self-promote to the candidate state. In the candidate state, nodes request votes from other nodes. If a candidate receives a quorum of votes, then it is promoted to a leader. The leader must accept new log entries and replicate them to the followers. Raft的节点一直处于三种状态之一：follower，candidate（候选），或leader。所有的节点的最初状态都是follower。在这种状态下，他们可以从leader接收日志条目，或者投票选举leader。如果在设置的时间段内（例如，五秒钟）未接收到日志条目或心跳，则节点会自动升级为 candidate 状态。在候选状态下，节点会向其他节点请求投票。如果候选人获得法定人数的选票，则将其晋升为 leader。leader节点必须接受新的日志条目并且将其复制到followers。 For a visual representation of how the leader election process works, check out The Secret Lives of Data. Snapshots If an ordering node goes down, how does it get the logs it missed when it is restarted? 如果一个排序节点宕机了，它如何在重新启动时获取丢失的日志信息呢？ While it’s possible to keep all logs indefinitely, in order to save disk space, Raft uses a process called “snapshotting”, in which users can define how many bytes of data will be kept in the log. This amount of data will conform to a certain number of blocks (which depends on the amount of data in the blocks. Note that only full blocks are stored in a snapshot). 尽管可以无限期保留所有日志，但是为了节省磁盘空间，Raft使用了一种称为“snapshotting”的程序，用户可以在其中定义将在日志中保留多少字节的数据。此数据量将符合一定数量的区块（这取决于块中的数据量，请注意，快照中仅存储完整块）。 For example, let’s say lagging replica R1 was just reconnected to the network. Its latest block is 100. Leader L is at block 196, and is configured to snapshot at amount of data that in this case represents 20 blocks. R1 would therefore receive block 180 from L and then make a Deliver request for blocks 101 to 180. Blocks 180 to 196 would then be replicated to R1 through the normal Raft protocol. 举个例子，假设滞后的副本R1刚刚重新连接到网络。它的最后一个区块是100.Leader节点L最后一个区块是196，并且设置快照的数量代表20个区块。因此，R1将从L接收区块180个，然后对区块101到180发出 Deliver 请求。180到196之间的区块会使用常规的Raft协议复制到R1。 Kafka (deprecated in v2.x) The other crash fault tolerant ordering service supported by Fabric is an adaptation of a Kafka distributed streaming platform for use as a cluster of ordering nodes. You can read more about Kafka at the Apache Kafka Web site, but at a high level, Kafka uses the same conceptual “leader and follower” configuration used by Raft, in which transactions (which Kafka calls “messages”) are replicated from the leader node to the follower nodes. In the event the leader node goes down, one of the followers becomes the leader and ordering can continue, ensuring fault tolerance, just as with Raft. The management of the Kafka cluster, including the coordination of tasks, cluster membership, access control, and controller election, among others, is handled by a ZooKeeper ensemble and its related APIs. Kafka clusters and ZooKeeper ensembles are notoriously tricky to set up, so our documentation assumes a working knowledge of Kafka and ZooKeeper. If you decide to use Kafka without having this expertise, you should complete, at a minimum, the first six steps of the Kafka Quickstart guide before experimenting with the Kafka-based ordering service. You can also consult this sample configuration file for a brief explanation of the sensible defaults for Kafka and ZooKeeper. To learn how to bring up a Kafka-based ordering service, check out our documentation on Kafka.","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"Key Concepts","slug":"区块链/Hyperledger-Fabric/Key-Concepts","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/Key-Concepts/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"Ordering Service","slug":"Ordering-Service","permalink":"https://guozhe001.github.io/tags/Ordering-Service/"}]},{"title":"身份识别","slug":"blockchain/fabric/关键概念/身分识别","date":"2024-11-22T06:32:06.495Z","updated":"2024-11-22T06:32:06.495Z","comments":true,"path":"2024/11/22/blockchain/fabric/关键概念/身分识别/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E5%85%B3%E9%94%AE%E6%A6%82%E5%BF%B5/%E8%BA%AB%E5%88%86%E8%AF%86%E5%88%AB/","excerpt":"","text":"官方文档Identity What is an Identity?（什么是身份识别） The different actors in a blockchain network include peers, orderers, client applications, administrators and more. Each of these actors — active elements inside or outside a network able to consume services — has a digital identity encapsulated in an X.509 digital certificate. These identities really matter because they determine the exact permissions over resources and access to information that actors have in a blockchain network. 区块链网络中包含不同的成员，包括peers、orderers、client applications、administrators等。这些参与者（网络内部或外部能够使用服务的活动元素）中的每一个都有封装在X.509数字证书中的数字身份。这些身份确实很重要，因为它们确定了对资源的确切权限以及对参与者在区块链网络中拥有的访问信息的权限。 A digital identity furthermore has some additional attributes that Fabric uses to determine permissions, and it gives the union of an identity and the associated attributes a special name — principal. Principals are just like userIDs or groupIDs, but a little more flexible because they can include a wide range of properties of an actor’s identity, such as the actor’s organization, organizational unit, role or even the actor’s specific identity. When we talk about principals, they are the properties which determine their permissions. 此外，数字身份还具有Fabric用来确定权限的其他一些属性，它为身份和相关属性的并集提供了一个特殊名称-主体。主体就像是userIDs或groupIDs，但更加灵活，因为它们可以包含成员身份的各种属性，例如成员的组织，组织单位，角色，甚至成员的特定身份。当我们谈论主体时，它们是确定其权限的属性。 For an identity to be verifiable, it must come from a trusted authority. A membership service provider (MSP) is that trusted authority in Fabric. More specifically, an MSP is a component that defines the rules that govern the valid identities for this organization. The default MSP implementation in Fabric uses X.509 certificates as identities, adopting a traditional Public Key Infrastructure (PKI) hierarchical model (more on PKI later). 为了使身份可验证，它必须来自受信任的权威。 membership service provider (MSP)就是一个在Fabric中的受信任的权威。更具体地说，MSP是定义用于管理该组织角色的有效身份的组件。。 Fabric中的默认MSP实现是使用X.509证书作为身份，并采用传统的公共密钥基础结构（PKI）层次模型（稍后将在PKI上进行介绍）。 A Simple Scenario to Explain the Use of an Identity（通过一个简单的方案来解释身份识别的用法） Imagine that you visit a supermarket to buy some groceries. At the checkout you see a sign that says that only Visa, Mastercard and AMEX cards are accepted. If you try to pay with a different card — let’s call it an “ImagineCard” — it doesn’t matter whether the card is authentic and you have sufficient funds in your account. It will be not be accepted. 想象一下你去一个超级市场去买一些杂货。在结账时你看到一个标志说只支持Visa、Mastercard和AMEX银行卡。如果你尝试使用其他银行卡-让我们叫它“想象的卡片”-银行卡是否真实和帐户中是否有足够的资金都没关系。它将不被接受。 Having a valid credit card is not enough — it must also be accepted by the store! PKIs and MSPs work together in the same way — a PKI provides a list of identities, and an MSP says which of these are members of a given organization that participates in the network. 拥有一个合法的信用卡还不够，他还必须被商店接受！PKIs和MSPs以相同的方式一起工作-PKI提供了身份识别的列表，MSP指出其中的哪些是参与该网络的给定组织的成员。 PKI certificate authorities and MSPs provide a similar combination of functionalities. A PKI is like a card provider — it dispenses many different types of verifiable identities. An MSP, on the other hand, is like the list of card providers accepted by the store, determining which identities are the trusted members (actors) of the store payment network. MSPs turn verifiable identities into the members of a blockchain network. PKI证书颁发机构和MSP提供了类似的功能组合。PKI就像银行卡发卡组织一样，它分配许多不同类型的可验证身份。另一方面，MSP就像商店接受的发卡组织列表一样，确定哪些身份是商店支付网络的受信任成员（参与者）。MSP将可验证身份转换为区块链网络的成员。 Let’s drill into these concepts in a little more detail. 让我们更详细地研究这些概念。 What are PKIs?（什么是PKIs？） A public key infrastructure (PKI) is a collection of internet technologies that provides secure communications in a network. It’s PKI that puts the S in HTTPS — and if you’re reading this documentation on a web browser, you’re probably using a PKI to make sure it comes from a verified source. 公钥基础结构（PKI）是网络技术的集合，这些技术在网络中提供安全的通信。是PKI将S置于HTTPS中-如果您正在网络浏览器上阅读此文档，您可能正在使用PKI来确保它来自经过验证的来源。 The elements of Public Key Infrastructure (PKI). A PKI is comprised of Certificate Authorities who issue digital certificates to parties (e.g., users of a service, service provider), who then use them to authenticate themselves in the messages they exchange in their environment. A CA’s Certificate Revocation List (CRL) constitutes a reference for the certificates that are no longer valid. Revocation of a certificate can happen for a number of reasons. For example, a certificate may be revoked because the cryptographic private material associated to the certificate has been exposed. 公钥基础结构（PKI）的元素。PKI由证书颁发机构组成，证书颁发机构向各方颁发数字证书，然后他们使用它们在环境中交换的消息中对自己进行身份验证。CA的证书吊销列表（CRL）构成了不再有效的证书的参考。吊销证书的原因有很多。例如，由于与证书关联的加密私有材料已被暴露，因此证书可能被吊销。 Although a blockchain network is more than a communications network, it relies on the PKI standard to ensure secure communication between various network participants, and to ensure that messages posted on the blockchain are properly authenticated. It’s therefore important to understand the basics of PKI and then why MSPs are so important. 尽管区块链网络不仅仅是通信网络，但它依赖于PKI标准来确保各种网络参与者之间的安全通信，并确保正确验证发布在区块链上的消息。因此，重要的是要了解PKI的基础知识，然后理解MSP为何如此重要。 There are four key elements to PKI，PKI有四个关键元素: Digital Certificates（数字证书） Public and Private Keys（公私钥对） Certificate Authorities（证书颁发机构） Certificate Revocation Lists（证书吊销列表） Let’s quickly describe these PKI basics, and if you want to know more details, Wikipedia is a good place to start. 让我们快速介绍一下这些PKI基础知识，如果您想了解更多详细信息，那么Public_key_infrastructure是一个不错的起点。 Digital Certificates(数字证书) A digital certificate is a document which holds a set of attributes relating to the holder of the certificate. The most common type of certificate is the one compliant with the X.509 standard, which allows the encoding of a party’s identifying details in its structure. 数字证书是一种文档，其中包含与证书持有者有关的一组属性。最常见的证书类型是符合X.509标准的证书，该证书允许在其结构中对参与方的标识详细信息进行编码。 For example, Mary Morris in the Manufacturing Division of Mitchell Cars in Detroit, Michigan might have a digital certificate with a SUBJECT attribute of C=US, ST=Michigan, L=Detroit, O=Mitchell Cars, OU=Manufacturing, CN=Mary Morris /UID=123456. Mary’s certificate is similar to her government identity card — it provides information about Mary which she can use to prove key facts about her. There are many other attributes in an X.509 certificate, but let’s concentrate on just these for now. 例如，底特律Mitchell汽车制造部门的Mary Morris，密歇根州可能有一个数字证书，其SUBJECT属性为C = US，ST = Michigan，L = Detroit，O = Mitchell Cars，OU = Manufacturing，CN = Mary Morris / UID = 123456。Mary的证书类似于她的政府身份证，它提供了有关玛丽的信息，她可以用来证明有关她的关键事实。X.509证书中还有许多其他属性，但现在让我们仅关注这些属性。 A digital certificate describing a party called Mary Morris. Mary is the SUBJECT of the certificate, and the highlighted SUBJECT text shows key facts about Mary. The certificate also holds many more pieces of information, as you can see. Most importantly, Mary’s public key is distributed within her certificate, whereas her private signing key is not. This signing key must be kept private. 数字证书描述了一个叫做Mary Morris的当事人，Mary是证书的SUBJECT ，突出显示的SUBJECT 文本显示了有关Mary的关键事实。如您所见，该证书还包含更多信息。最重要的是，Mary的公钥在证书中描述，但是私钥没有在证书中。签名用的私钥必须保密。 What is important is that all of Mary’s attributes can be recorded using a mathematical technique called cryptography (literally, “secret writing”) so that tampering will invalidate the certificate. Cryptography allows Mary to present her certificate to others to prove her identity so long as the other party trusts the certificate issuer, known as a Certificate Authority (CA). As long as the CA keeps certain cryptographic information securely (meaning, its own private signing key), anyone reading the certificate can be sure that the information about Mary has not been tampered with — it will always have those particular attributes for Mary Morris. Think of Mary’s X.509 certificate as a digital identity card that is impossible to change. 重要的是，可以使用称为加密的数学技术来记录Mary的所有属性，以免篡改证书。只要对方信任证书颁发者（Certificate Authority (CA)），密码学就可以允许Mary向他人出示她的证书以证明自己的身份。只要CA安全地保存某些加密信息（即其自己的专用签名密钥），任何阅读证书的人都可以确保有关Mary的信息未被篡改-它始终具有Mary Morris的那些特定属性。将Mary的X.509证书视为无法更改的数字身份证。 Authentication, Public keys, and Private Keys（认证方式，公钥和私钥） Authentication and message integrity are important concepts in secure communications. Authentication requires that parties who exchange messages are assured of the identity that created a specific message. For a message to have “integrity” means that cannot have been modified during its transmission. For example, you might want to be sure you’re communicating with the real Mary Morris rather than an impersonator. Or if Mary has sent you a message, you might want to be sure that it hasn’t been tampered with by anyone else during transmission. 身份验证和消息完整性是安全通信中的重要概念。身份验证要求交换消息的各方确保创建了特定消息的身份。消息具有“完整性”意味着不能在其传输过程中对其进行修改。例如，您可能要确保与真实的玛丽·莫里斯（Mary Morris）而非模仿者进行交流。或者如果Mary已经给你发送了一个消息，你可能想要确保在传输过程中没有被其他任何人篡改过该消息。 Traditional authentication mechanisms rely on digital signatures that, as the name suggests, allow a party to digitally sign its messages. Digital signatures also provide guarantees on the integrity of the signed message. Technically speaking, digital signature mechanisms require each party to hold two cryptographically connected keys: a public key that is made widely available and acts as authentication anchor, and a private key that is used to produce digital signatures on messages. Recipients of digitally signed messages can verify the origin and integrity of a received message by checking that the attached signature is valid under the public key of the expected sender. The unique relationship between a private key and the respective public key is the cryptographic magic that makes secure communications possible. The unique mathematical relationship between the keys is such that the private key can be used to produce a signature on a message that only the corresponding public key can match, and only on the same message. In the example above, Mary uses her private key to sign the message. The signature can be verified by anyone who sees the signed message using her public key. Certificate Authorities（证书颁发机构） As you’ve seen, an actor or a node is able to participate in the blockchain network, via the means of a digital identity issued for it by an authority trusted by the system. In the most common case, digital identities (or simply identities) have the form of cryptographically validated digital certificates that comply with X.509 standard and are issued by a Certificate Authority (CA). CAs are a common part of internet security protocols, and you’ve probably heard of some of the more popular ones: Symantec (originally Verisign), GeoTrust, DigiCert, GoDaddy, and Comodo, among others. A Certificate Authority dispenses certificates to different actors. These certificates are digitally signed by the CA and bind together the actor with the actor’s public key (and optionally with a comprehensive list of properties). As a result, if one trusts the CA (and knows its public key), it can trust that the specific actor is bound to the public key included in the certificate, and owns the included attributes, by validating the CA’s signature on the actor’s certificate. Certificates can be widely disseminated, as they do not include either the actors’ nor the CA’s private keys. As such they can be used as anchor of trusts for authenticating messages coming from different actors. CAs also have a certificate, which they make widely available. This allows the consumers of identities issued by a given CA to verify them by checking that the certificate could only have been generated by the holder of the corresponding private key (the CA). In a blockchain setting, every actor who wishes to interact with the network needs an identity. In this setting, you might say that one or more CAs can be used to define the members of an organization’s from a digital perspective. It’s the CA that provides the basis for an organization’s actors to have a verifiable digital identity. Root CAs, Intermediate CAs and Chains of Trust（根CA、中级CA和信任链） CAs come in two flavors: Root CAs and Intermediate CAs. Because Root CAs (Symantec, Geotrust, etc) have to securely distribute hundreds of millions of certificates to internet users, it makes sense to spread this process out across what are called Intermediate CAs. These Intermediate CAs have their certificates issued by the root CA or another intermediate authority, allowing the establishment of a “chain of trust” for any certificate that is issued by any CA in the chain. This ability to track back to the Root CA not only allows the function of CAs to scale while still providing security — allowing organizations that consume certificates to use Intermediate CAs with confidence — it limits the exposure of the Root CA, which, if compromised, would endanger the entire chain of trust. If an Intermediate CA is compromised, on the other hand, there will be a much smaller exposure. A chain of trust is established between a Root CA and a set of Intermediate CAs as long as the issuing CA for the certificate of each of these Intermediate CAs is either the Root CA itself or has a chain of trust to the Root CA. Intermediate CAs provide a huge amount of flexibility when it comes to the issuance of certificates across multiple organizations, and that’s very helpful in a permissioned blockchain system (like Fabric). For example, you’ll see that different organizations may use different Root CAs, or the same Root CA with different Intermediate CAs — it really does depend on the needs of the network. Fabric CA It’s because CAs are so important that Fabric provides a built-in CA component to allow you to create CAs in the blockchain networks you form. This component — known as Fabric CA is a private root CA provider capable of managing digital identities of Fabric participants that have the form of X.509 certificates. Because Fabric CA is a custom CA targeting the Root CA needs of Fabric, it is inherently not capable of providing SSL certificates for general/automatic use in browsers. However, because some CA must be used to manage identity (even in a test environment), Fabric CA can be used to provide and manage certificates. It is also possible — and fully appropriate — to use a public/commercial root or intermediate CA to provide identification. 因为CA非常重要，所以Fabric提供了内置的CA组件，可让您在形成的区块链网络中创建CA。该组件（称为Fabric CA）是私有的根CA提供者，能够管理具有X.509证书形式的Fabric参与者的数字身份。由于Fabric CA是针对Fabric的根CA需求的自定义CA，因此它固有地无法提供SSL证书供浏览器中的常规/自动使用。但是，由于必须使用某些CA来管理身份（即使在测试环境中也是如此），因此可以将Fabric CA用于提供和管理证书。使用公共/商业根或中间CA进行标识也是可能的，并且是完全合适的。 If you’re interested, you can read a lot more about Fabric CA in the CA documentation section. 如果你感兴趣，你可以 在the CA documentation section文档中阅读更多的关于 Fabric CA的内容。 Certificate Revocation Lists（证书吊销列表） A Certificate Revocation List (CRL) is easy to understand — it’s just a list of references to certificates that a CA knows to be revoked for one reason or another. If you recall the store scenario, a CRL would be like a list of stolen credit cards. When a third party wants to verify another party’s identity, it first checks the issuing CA’s CRL to make sure that the certificate has not been revoked. A verifier doesn’t have to check the CRL, but if they don’t they run the risk of accepting a compromised identity. Using a CRL to check that a certificate is still valid. If an impersonator tries to pass a compromised digital certificate to a validating party, it can be first checked against the issuing CA’s CRL to make sure it’s not listed as no longer valid. Note that a certificate being revoked is very different from a certificate expiring. Revoked certificates have not expired — they are, by every other measure, a fully valid certificate. For more in-depth information about CRLs, click here. Now that you’ve seen how a PKI can provide verifiable identities through a chain of trust, the next step is to see how these identities can be used to represent the trusted members of a blockchain network. That’s where a Membership Service Provider (MSP) comes into play — it identifies the parties who are the members of a given organization in the blockchain network. To learn more about membership, check out the conceptual documentation on MSPs.","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"Key Concepts","slug":"区块链/Hyperledger-Fabric/Key-Concepts","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/Key-Concepts/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"Identity","slug":"Identity","permalink":"https://guozhe001.github.io/tags/Identity/"}]},{"title":"Hyperledger-Fabric开发环境准备","slug":"blockchain/fabric/how_to/Hyperledger-Fabric开发环境准备","date":"2024-11-22T06:32:06.494Z","updated":"2024-11-22T06:32:06.494Z","comments":true,"path":"2024/11/22/blockchain/fabric/how_to/Hyperledger-Fabric开发环境准备/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/how_to/Hyperledger-Fabric%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/","excerpt":"","text":"安装homebrew 查看清华大学开源软件镜像站配置国内镜像加快安装软件的速度。 安装Fabric的环境依赖 使用brew安装git、go、jq、softhsm、docker: 12brew install git go jq softhsmbrew cask install --appdir=&quot;/Applications&quot; docker 我在安装的时候因为Great Wall的原因有个go的工具没有下载下来，记录一下 123Failure while executing; `git clone --branch release-branch.go1.15 -c advice.detachedHead=false https://go.googlesource.com/tools.git /Users/apple/Library/Caches/Homebrew/go--gotools--git` exited with 128. Here&#x27;s the output:Cloning into &#x27;/Users/apple/Library/Caches/Homebrew/go--gotools--git&#x27;...fatal: unable to access &#x27;https://go.googlesource.com/tools.git/&#x27;: Failed to connect to go.googlesource.com port 443: Operation timed out fabric源码下载 为了加速，在gitee上导入项目：https://github.com/hyperledger/fabric然后clone到本地。 安装开发工具 1、在fabric目录下，运行命令： 1make gotools 2、安装完成工具之后，验证环境是否正常 12make basic-checks integration-test-prereqsginkgo -r ./integration/nwo 我的第二部测试没有通过，记录如下： 12345678910111213141516171819202122(base) apple@WHOAMIdeMacBook-Pro:~/code/open-source/blockchain/hyperledger/fabric$ ginkgo -r ./integration/nwoRunning Suite: New World Order Suite====================================Random Seed: 1607936946Will run 4 of 4 specsFailure [0.011 seconds][BeforeSuite] BeforeSuite/Users/apple/code/open-source/blockchain/hyperledger/fabric/integration/nwo/nwo_suite_test.go:29 missing required image: hyperledger/fabric-ccenv:latest /Users/apple/code/open-source/blockchain/hyperledger/fabric/integration/nwo/buildserver.go:56------------------------------Ran 4 of 0 Specs in 0.512 secondsFAIL! -- 0 Passed | 4 Failed | 0 Pending | 0 Skipped--- FAIL: TestNewWorldOrder (0.51s)FAILGinkgo ran 1 suite in 3.561084735sTest Suite Failed 3、从脚本运行中的信息可以直到依赖了哪些软件： library/alpine:3.12 hyperledger/fabric-baseos golang:1.14.12-alpine3.12 hyperledger/fabric-ccenv confluentinc/cp-zookeeper:5.3.1 confluentinc/cp-kafka:5.3.1 library/couchdb:3.1.1 5.添加更多的依赖 123456# 添加 gnu-tarbrew install gnu-tar --with-default-names# 添加 libtoolbrew install libtool# 编译 configtxgenmake configtxgen","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"HOW-TO","slug":"区块链/Hyperledger-Fabric/HOW-TO","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/HOW-TO/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"}]},{"title":"Fabric测试网络使用","slug":"blockchain/fabric/how_to/Fabric测试网络使用","date":"2024-11-22T06:32:06.494Z","updated":"2024-11-22T06:32:06.494Z","comments":true,"path":"2024/11/22/blockchain/fabric/how_to/Fabric测试网络使用/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/how_to/Fabric%E6%B5%8B%E8%AF%95%E7%BD%91%E7%BB%9C%E4%BD%BF%E7%94%A8/","excerpt":"","text":"Fabric测试网络使用 测试网络设置环境变量记录 Org1： 1234567export PATH=$&#123;PWD&#125;/../bin:$&#123;PWD&#125;:$PATHexport FABRIC_CFG_PATH=$PWD/../config/export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crtexport CORE_PEER_ADDRESS=localhost:7051 Org2： 1234567export PATH=$&#123;PWD&#125;/../bin:$&#123;PWD&#125;:$PATHexport FABRIC_CFG_PATH=$PWD/../config/export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;export CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtexport CORE_PEER_ADDRESS=localhost:9051 2.2.1下载样例源码 运行命令下载最新版的Fabric和Fabric CA以及 hyperledger/fabric-samples 1curl -sSL https://bit.ly/2ysbOFE | bash -s 上面的命令干了这些事情： 下载 hyperledger/fabric-samples 签出适当的版本标签 将Hyperledger Fabric平台特定的二进制文件和配置文件安装到Fabric-samples的/ bin和/ config目录中指定的版本 下载指定版本的Hyperledger Fabric docker镜像，包括： hyperledger/fabric-peer hyperledger/fabric-orderer hyperledger/fabric-ccenv hyperledger/fabric-tools hyperledger/fabric-baseos hyperledger/fabric-ca 2.2.2使用Fabric测试网络 启动Fabric测试网络 1.进入fabric-samples/test-network，可以看到network.sh文件,可以运行./network.sh -h来显示帮助 1cd fabric-samples/test-network 1234567891011(base) apple@WHOAMIdeMacBook-Pro:~/code/open-source/blockchain/hyperledger/fabric-samples/test-network$ lltotal 72-rw-r--r-- 1 apple staff 777 Dec 14 18:36 README.mddrwxr-xr-x 12 apple staff 384 Dec 14 18:36 addOrg3drwxr-xr-x 3 apple staff 96 Dec 14 18:36 configtxdrwxr-xr-x 5 apple staff 160 Dec 14 18:36 docker-rwxr-xr-x 1 apple staff 18645 Dec 14 18:36 network.shdrwxr-xr-x 7 apple staff 224 Dec 14 18:36 organizations-rwxr-xr-x 1 apple staff 8202 Dec 14 18:36 scriptUtils.shdrwxr-xr-x 6 apple staff 192 Dec 14 18:36 scriptsdrwxr-xr-x 3 apple staff 96 Dec 14 18:36 system-genesis-block 2.停止原来正在运行的docker容器 1./network.sh down 3.启动网络 **注意事项：**必须在$USER/fabric-samples/test-network目录下执行此脚本，否则会报错 1./network.sh up 这个脚本启动两个peer节点，一个ordering节点。这个脚本不会创建channel，我的脚本运行结果如下： 123456789101112131415Creating network &quot;net_test&quot; with the default driverCreating volume &quot;net_orderer.example.com&quot; with default driverCreating volume &quot;net_peer0.org1.example.com&quot; with default driverCreating volume &quot;net_peer0.org2.example.com&quot; with default driverCreating orderer.example.com ... doneCreating peer0.org1.example.com ... doneCreating peer0.org2.example.com ... doneCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES31c36a007eb0 hyperledger/fabric-peer:latest &quot;peer node start&quot; 1 second ago Up Less than a second 7051/tcp, 0.0.0.0:9051-&gt;9051/tcp peer0.org2.example.com42f314195c64 hyperledger/fabric-orderer:latest &quot;orderer&quot; 1 second ago Up Less than a second 0.0.0.0:7050-&gt;7050/tcp orderer.example.comde62f2f44a03 hyperledger/fabric-peer:latest &quot;peer node start&quot; 1 second ago Up Less than a second 0.0.0.0:7051-&gt;7051/tcp peer0.org1.example.come9af4c11538c cordite/network-map:latest &quot;/usr/bin/java -cp /…&quot; 5 days ago Exited (143) 3 days ago network-map5128423bb8d7 redis:5.0 &quot;docker-entrypoint.s…&quot; 5 months ago Exited (0) 7 weeks ago redis6796aadc5173 mysql &quot;docker-entrypoint.s…&quot; 7 months ago Exited (0) 7 weeks ago mysql66c3ac55f920 neo4j &quot;/sbin/tini -g -- /d…&quot; 7 months ago Exited (0) 7 months ago docker面板显示如下： Peers是Fabric network的组成部分，Peers存储区块链账本并在提交之前验证交易。Peers运行包含业务逻辑的智能合约，智能合约用于管理区块链上的账本。 在网络上的每个Peer都属于一个团体，上图显示的测试网络中的两个peer分别属于组织peer0.org1.example.com和组织peer0.org2.example.com。 每个Fabric network同样包含ordering service，Peers在验证交易和提交交易到区块链的时候，他们不自己决定交易的顺序和区块中包含哪些交易。在分布式网络中，peers可能分布的特别远，所以让peers对交易顺序达成共识的成本是很高的。 ordering service的存在是为了让peers专注于交易验证和提交到账本中。在接收到客户端提交的交易时，ordering service会对其进行排序，然后把这些交易添加到区块中。然后将这些区块分发给peer节点，peer节点再把区块写入区块链。Ordering节点还运行系统通道，该通道定义了Fabric network的能力，像如何制作区块以及节点可以使用哪些版本的Fabric。系统通道还定义了哪些组织是属于该联盟的。 上面的测试网络只运行了一个Ordering节点，在实际的网络中可能存在多个Ordering节点，由一个或多个组织进行操作。不同的Ordering节点使用Raft共识算法来就网络上的交易顺序达成一致。 创建channel 通道是特定网络成员之间的专用通信层。通道只能由被邀请加入通道的的组织使用，并且对网络上的其他成员不可见。每个通道都有一个单独的区块链账单，被邀请的组织加入通道上的其他peer以存储channel账本和验证通道上的交易。 在org2和org2之间创建通道，默认的channel名称为mychannel。 1./network.sh createChannel 如果运行成功，则会看到如下日志 1Channel successfully joined 也可以指定channel的名称，并且你可以创建多个channel。 1./network.sh createChannel -c channel1 如果你想一步启动测试网络并创建channel，可以使用下面的命令。 1./network.sh up createChannel 在channel上启动chaincode 启动成功之后，就可以开始使用智能合约来操作channel账本了。智能合约包含了管理区块链账本上资产的业务逻辑。运行在网络上的程序可以调用智能合约在账本上创建、修改、交易资产，这些程序也查询智能合约以读取账本上的数据。 为了确保交易的有效性，使用智能合约创建的交易通常需要通道上的多个组织签名才能被提交到channel账本。交易也需要多次背书，来防止渠道上的某个组织篡改账本或使用未经过同意的逻辑。要签署交易，每个组织都需要在其peer上调用并执行智能合约，然后再签署交易的output。如果output一致并且收集到了足够的签名，交易就可以被提交到账本。指定需要哪些组织执行智能合约的策略叫做背书策略，该策略是为每个chaincode设置的，作为chaincode定义的一部分。 在Fabric中，智能合约以称为chaincode的软件包部署在网络上。chaincode安装在组织的peers上，然后部署到channel，然后就可以在该渠道中用于认可交易并与区块链账本进行交互。在讲chaincode部署到channel上之前，channel上的组织需要对chaincode的内容达成共识。当所需数量的组织达成共识之后，chaincode就可以被提交到channel上，然后chaincode就准备好可以使用了。 搭建完成测试环境之后，可以使用下面的命令来启动chaincode： 1./network.sh deployCC 我本地的运行结果如下： 123456789101112131415161718Chaincode definition committed on channel &#x27;mychannel&#x27;Using organization 1Querying chaincode definition on peer0.org1 on channel &#x27;mychannel&#x27;...Attempting to Query committed status on peer0.org1, Retry after 3 seconds.+ peer lifecycle chaincode querycommitted --channelID mychannel --name basic+ res=0Committed chaincode definition for chaincode &#x27;basic&#x27; on channel &#x27;mychannel&#x27;:Version: 1.0, Sequence: 1, Endorsement Plugin: escc, Validation Plugin: vscc, Approvals: [Org1MSP: true, Org2MSP: true]Query chaincode definition successful on peer0.org1 on channel &#x27;mychannel&#x27;Using organization 2Querying chaincode definition on peer0.org2 on channel &#x27;mychannel&#x27;...Attempting to Query committed status on peer0.org2, Retry after 3 seconds.+ peer lifecycle chaincode querycommitted --channelID mychannel --name basic+ res=0Committed chaincode definition for chaincode &#x27;basic&#x27; on channel &#x27;mychannel&#x27;:Version: 1.0, Sequence: 1, Endorsement Plugin: escc, Validation Plugin: vscc, Approvals: [Org1MSP: true, Org2MSP: true]Query chaincode definition successful on peer0.org2 on channel &#x27;mychannel&#x27;Chaincode initialization is not required 与网络互动 在启用测试网络之后，你可以使用peerCLI与测试网络进行互动。peerCLI允许你调用已经部署的智能合约、更新channels；也可以通过CLI更新或者部署新的智能合约。 请确保你的操作在test-network目录下进行。 1、把fabric-samples的bin目录下的二进制命令安装到你的客户端环境： 1export PATH=$&#123;PWD&#125;/../bin:$PATH 2、还需要将FABRIC_CFG_PATH设置为指向fabric-samples存储库中的core.yaml文件： 1export FABRIC_CFG_PATH=$PWD/../config/ 3、现在设置环境变量允许你使用Org1的身份操作peerCLI。 12345export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=localhost:7051 4、使用下面的命令用资产初始化账本 1peer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n basic --peerAddresses localhost:7051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses localhost:9051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;InitLedger&quot;,&quot;Args&quot;:[]&#125;&#x27; 如果成功你会看到像下面的结果： 12020-12-16 15:35:41.511 CST [chaincodeCmd] chaincodeInvokeOrQuery -&gt; INFO 001 Chaincode invoke successful. result: status:200 5、现在你可以使用下面的命令查询账本上的资产 1peer chaincode query -C mychannel -n basic -c &#x27;&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;&#x27; 如果成功你会看到下面的结果： 12345678[ &#123;&quot;ID&quot;: &quot;asset1&quot;, &quot;color&quot;: &quot;blue&quot;, &quot;size&quot;: 5, &quot;owner&quot;: &quot;Tomoko&quot;, &quot;appraisedValue&quot;: 300&#125;, &#123;&quot;ID&quot;: &quot;asset2&quot;, &quot;color&quot;: &quot;red&quot;, &quot;size&quot;: 5, &quot;owner&quot;: &quot;Brad&quot;, &quot;appraisedValue&quot;: 400&#125;, &#123;&quot;ID&quot;: &quot;asset3&quot;, &quot;color&quot;: &quot;green&quot;, &quot;size&quot;: 10, &quot;owner&quot;: &quot;Jin Soo&quot;, &quot;appraisedValue&quot;: 500&#125;, &#123;&quot;ID&quot;: &quot;asset4&quot;, &quot;color&quot;: &quot;yellow&quot;, &quot;size&quot;: 10, &quot;owner&quot;: &quot;Max&quot;, &quot;appraisedValue&quot;: 600&#125;, &#123;&quot;ID&quot;: &quot;asset5&quot;, &quot;color&quot;: &quot;black&quot;, &quot;size&quot;: 15, &quot;owner&quot;: &quot;Adriana&quot;, &quot;appraisedValue&quot;: 700&#125;, &#123;&quot;ID&quot;: &quot;asset6&quot;, &quot;color&quot;: &quot;white&quot;, &quot;size&quot;: 15, &quot;owner&quot;: &quot;Michel&quot;, &quot;appraisedValue&quot;: 800&#125;] 6、网络上的成员想要交易资产或者更新资产时就会调用chaincode，使用下面的命令来调用资产转移chaincode来更改资产的owner。 1peer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n basic --peerAddresses localhost:7051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses localhost:9051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;TransferAsset&quot;,&quot;Args&quot;:[&quot;asset6&quot;,&quot;Christopher&quot;]&#125;&#x27; 如果成功结果如下： 12020-12-16 15:43:18.062 CST [chaincodeCmd] chaincodeInvokeOrQuery -&gt; INFO 001 Chaincode invoke successful. result: status:200 重新查询可以发现asset6的owner已经更改。 1234567[&#123;&quot;ID&quot;:&quot;asset1&quot;,&quot;color&quot;:&quot;blue&quot;,&quot;size&quot;:5,&quot;owner&quot;:&quot;Tomoko&quot;,&quot;appraisedValue&quot;:300&#125;,&#123;&quot;ID&quot;:&quot;asset2&quot;,&quot;color&quot;:&quot;red&quot;,&quot;size&quot;:5,&quot;owner&quot;:&quot;Brad&quot;,&quot;appraisedValue&quot;:400&#125;,&#123;&quot;ID&quot;:&quot;asset3&quot;,&quot;color&quot;:&quot;green&quot;,&quot;size&quot;:10,&quot;owner&quot;:&quot;Jin Soo&quot;,&quot;appraisedValue&quot;:500&#125;,&#123;&quot;ID&quot;:&quot;asset4&quot;,&quot;color&quot;:&quot;yellow&quot;,&quot;size&quot;:10,&quot;owner&quot;:&quot;Max&quot;,&quot;appraisedValue&quot;:600&#125;,&#123;&quot;ID&quot;:&quot;asset5&quot;,&quot;color&quot;:&quot;black&quot;,&quot;size&quot;:15,&quot;owner&quot;:&quot;Adriana&quot;,&quot;appraisedValue&quot;:700&#125;,&#123;&quot;ID&quot;:&quot;asset6&quot;,&quot;color&quot;:&quot;white&quot;,&quot;size&quot;:15,&quot;owner&quot;:&quot;Christopher&quot;,&quot;appraisedValue&quot;:800&#125;] 7、我们在调用chaincode之后，我们来查一下这个调用是如何改变资产的。我们使用Org2来操作，配置环境变量如下： 12345export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_ADDRESS=localhost:9051 执行peer chaincode query -C mychannel -n basic -c '&#123;&quot;Args&quot;:[&quot;ReadAsset&quot;,&quot;asset6&quot;]&#125;'命令结果如下： 1&#123;&quot;ID&quot;:&quot;asset6&quot;,&quot;color&quot;:&quot;white&quot;,&quot;size&quot;:15,&quot;owner&quot;:&quot;Christopher&quot;,&quot;appraisedValue&quot;:800&#125; 中断网络 通过执行./network.sh down来中断网络，该命令会停止并删除peer河chaincode的容器；删除org的密钥等数据并从Docker中remove掉chaincode的镜像。该命令还会删除网路上的channel，如果有任何问题可以继续运行./network.sh up。 问题处理 创建channel失败，日志如下： 1234567891011121314151617Channel &#x27;mychannel&#x27; createdJoin Org1 peers to the channel...Using organization 1+ peer channel join -b ./channel-artifacts/mychannel.block+ res=1+ peer channel join -b ./channel-artifacts/mychannel.block+ res=1+ peer channel join -b ./channel-artifacts/mychannel.block+ res=1+ peer channel join -b ./channel-artifacts/mychannel.block+ res=12020-12-21 11:22:02.781 CST [comm.tls] ClientHandshake -&gt; ERRO 001 Client TLS handshake failed after 1.769196ms with error: EOF remoteaddress=[::1]:70512020-12-21 11:22:03.785 CST [comm.tls] ClientHandshake -&gt; ERRO 002 Client TLS handshake failed after 2.054333ms with error: EOF remoteaddress=[::1]:70512020-12-21 11:22:05.113 CST [comm.tls] ClientHandshake -&gt; ERRO 003 Client TLS handshake failed after 2.849348ms with error: EOF remoteaddress=[::1]:7051Error: error getting endorser client for channel: endorser client failed to connect to localhost:7051: failed to create new connection: context deadline exceededAfter 5 attempts, peer0.org1 has failed to join channel &#x27;mychannel&#x27;Create channel failed 解决方案： 删除所有的测试网络相关的容器 运行./network.sh down 删除docker本地未使用的volume 重试","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"HOW-TO","slug":"区块链/Hyperledger-Fabric/HOW-TO","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/HOW-TO/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"}]},{"title":"在Fabric中使用私有数据","slug":"blockchain/fabric/how_to/在Fabric中使用私有数据","date":"2024-11-22T06:32:06.494Z","updated":"2024-11-22T06:32:06.494Z","comments":true,"path":"2024/11/22/blockchain/fabric/how_to/在Fabric中使用私有数据/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/how_to/%E5%9C%A8Fabric%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%A7%81%E6%9C%89%E6%95%B0%E6%8D%AE/","excerpt":"","text":"在Fabric中使用私有数据 官方文档：Using Private Data in Fabric This tutorial will demonstrate the use of Private Data Collections (PDC) to provide storage and retrieval of private data on the blockchain network for authorized peers of organizations. The collection is specified using a collection definition file containing the policies governing that collection. 本教程将演示如何使用私有数据集（PDC）为组织的有权限的peer在区块链网络上提供私有数据的存储和检索。使用包含定义该PDC策略的集合定义文件来管理PDC。 The information in this tutorial assumes knowledge of private data stores and their use cases. For more information, check out Private data. 本教程中的信息假定您了解私有数据存储及其使用案例。有关更多信息，请查看Private data。 The tutorial will take you through the following steps to practice defining, configuring and using private data with Fabric: 本教程将指导您完成以下步骤，以练习定义、配置和使用Fabric私有数据： Asset transfer private data sample use case 资产转移私有数据样例使用方法 Build a collection definition JSON file 构建一个集合定义JSON文件 Read and Write private data using chaincode APIs 使用chaincode API读写私有数据 Deploy the private data smart contract to the channel 部署私有数据智能合约到通道 Register identities 注册身份 Create an asset in private data 在私有数据集中创建资产 Query the private data as an authorized peer 通过有权限的peer查询私有数据 Query the private data as an unauthorized peer 通过没有权限的peer查询私有数据 Transfer the Asset 交易在私有数据集中的资产 Purge Private Data 清除私有数据 Using indexes with private data 对私有数据使用索引 Additional resources 额外资源 This tutorial will deploy the asset transfer private data sample to the Fabric test network to demonstrate how to create, deploy, and use a collection of private data. You should have completed the task Install Samples, Binaries, and Docker Images. 这个教程会部署 asset transfer private data sample到Fabric的测试网络来演示如何创建、部署以及使用PDC。 Asset transfer private data sample use case（资产转移私有数据样例使用方法） This sample demonstrates the use of three private data collections, assetCollection, Org1MSPPrivateCollection &amp; Org2MSPPrivateCollection to transfer an asset between Org1 and Org2, using following use case: 这个样例使用以下用例演示使用三个私有数据集（PDC）来在Org1和Org2组织之间交易资产；这三个PDC为：assetCollection, Org1MSPPrivateCollection &amp; Org2MSPPrivateCollection 。 A member of Org1 creates a new asset, henceforth referred as owner. The public details of the asset, including the identity of the owner, are stored in the private data collection named assetCollection. The asset is also created with an appraised value supplied by the owner. The appraised value is used by each participant to agree to the transfer of the asset, and is only stored in owner organization’s collection. In our case, the initial appraisal value agreed by the owner is stored in the Org1MSPPrivateCollection. 组织Org1的一个成员创建一个新的资产，并拥有这个资产。公共的资产详情，包括拥有者的身份被存储在称作 assetCollection的私有数据集中。资产所有者也会为这个资产创建一个评估价值，通道上的每个参与者都使用这个评估价值来同意资产转让，并且它仅存储在所有者组织的集合中。在我们的案例中，所有者确认的初始评估值存储在Org1MSPPrivateCollection中。 To purchase the asset, the buyer needs to agree to the same appraised value as the asset owner. In this step, the buyer (a member of Org2) creates an agreement to trade and agree to an appraisal value using smart contract function 'AgreeToTransfer'. This value is stored in Org2MSPPrivateCollection collection. Now, the asset owner can transfer the asset to the buyer using smart contract function 'TransferAsset'. The 'TransferAsset' function uses the hash on the channel ledger to confirm that the owner and the buyer have agreed to the same appraised value before transferring the asset. 要购买资产，购买者需要同意与资产所有者相同的评估价值。在此步骤中，买方（Org2的成员）使用智能合约的“AgreeToTransfer”方法来创建交易协议并同意评估价值。此值存储在Org2MSPPrivateCollection集合中。现在资产的拥有者可以通过智能合约中的'TransferAsset'方法来交易资产了。 'TransferAsset' 方法在转让资产之前先使用通道账本上的hash来验证买卖双方已经对相同的评估价格达成了一致。 Before we go through the transfer scenario, we will discuss how organizations can use private data collections in Fabric. 在此之前，我们将讨论组织如何在Fabric中使用私有数据集合。 Build a collection definition JSON file（构建一个集合定义JSON文件） Before a set of organizations can transact using private data, all organizations on channel need to build a collection definition file that defines the private data collections associated with each chaincode. Data that is stored in a private data collection is only distributed to the peers of certain organizations instead of all members of the channel. The collection definition file describes all of the private data collections that organizations can read and write to from a chaincode. 在一组组织可以使用私有数据进行交易之前，通道上的所有组织需要构建一个集合定义文件，这个文件定义与每个链码关联的私有数据集合。存储在私有数据集合中的数据仅分发给相同组织的peer节点，而不是分发给通道的所有成员。集合定义文件描述了组织可以通过链码读写的所有私有数据集。 Each collection is defined by the following properties: name: Name of the collection. policy: Defines the organization peers allowed to persist the collection data. requiredPeerCount: Number of peers required to disseminate the private data as a condition of the endorsement of the chaincode maxPeerCount: For data redundancy purposes, the number of other peers that the current endorsing peer will attempt to distribute the data to. If an endorsing peer goes down, these other peers are available at commit time if there are requests to pull the private data. blockToLive: For very sensitive information such as pricing or personal information, this value represents how long the data should live on the private database in terms of blocks. The data will live for this specified number of blocks on the private database and after that it will get purged, making this data obsolete from the network. To keep private data indefinitely, that is, to never purge private data, set the blockToLive property to 0. memberOnlyRead: a value of true indicates that peers automatically enforce that only clients belonging to one of the collection member organizations are allowed read access to private data. memberOnlyWrite: a value of true indicates that peers automatically enforce that only clients belonging to one of the collection member organizations are allowed write access to private data. endorsementPolicy: defines the endorsement policy that needs to be met in order to write to the private data collection. The collection level endorsement policy overrides to chaincode level policy. For more information on building a policy definition refer to the Endorsement policies topic. 所有的集合都是用下面的属性来定义： name: 集合名称 policy: 定义允许持久化集合数据的组织的peer节点。 requiredPeerCount: 传播私有数据所需的peer数目，以作为对链码的认可 maxPeerCount: 为了数据冗余，当前合法peer将尝试向其分发数据的其他peer的数量。如果一个合法的peer挂了，如果有请求拉私有数据的请求，则这些其他peer在提交时可用。 blockToLive: 对于如价格或个人信息这类非常敏感的信息，此值表示数据应在私有数据库的块上保存的时间。数据将在私有数据库块上保留指定的时间，然后清除，使该数据从网络上过时。要无限期保留私有数据，即从不清除私有数据，请将blockToLive属性设置为0。 memberOnlyRead: 值为true表示peer节点自动强制只有属于集合成员组织的客户端才允许读取私有数据。 memberOnlyWrite:值为true表示peer节点自动强制只有属于集合成员组织的客户端才允许写入私有数据。 endorsementPolicy: 定义了写入私有数据集合需要满足的认可策略。集合级别的背书策略会覆盖chaincode级别的策略。有关构建策略定义的更多信息，请参考 Endorsement policies主题。 The same collection definition file needs to be deployed by all organizations that use the chaincode, even if the organization does not belong to any collections. In addition to the collections that are explicitly defined in a collection file, each organization has access to an implicit collection on their peers that can only be read by their organization. For an example that uses implicit data collections, see the Secured asset transfer in Fabric. 所有使用同一个chaincode的组织都要部署相同的集合定义文件，即使这个组织不属于任何集合。除了在集合文件中显式定义的集合之外，每个组织都可以访问其peer节点上的隐式集合，这些隐式集合只能由其组织读取。使用隐式数据集的例子可以看Secured asset transfer in Fabric。 The asset transfer private data example contains a collections_config.json file that defines three private data collection definitions: assetCollection, Org1MSPPrivateCollection, and Org2MSPPrivateCollection. 资产转移私有数据的示例包含一个collections_config.json文件，该文件定义了三个私有数据集合定义：assetCollection, Org1MSPPrivateCollection, and Org2MSPPrivateCollection。 12345678910111213141516171819202122232425262728293031323334353637// collections_config.json[ &#123; &quot;name&quot;: &quot;assetCollection&quot;, &quot;policy&quot;: &quot;OR(&#x27;Org1MSP.member&#x27;, &#x27;Org2MSP.member&#x27;)&quot;, &quot;requiredPeerCount&quot;: 1, &quot;maxPeerCount&quot;: 1, &quot;blockToLive&quot;:1000000, &quot;memberOnlyRead&quot;: true, &quot;memberOnlyWrite&quot;: true &#125;, &#123; &quot;name&quot;: &quot;Org1MSPPrivateCollection&quot;, &quot;policy&quot;: &quot;OR(&#x27;Org1MSP.member&#x27;)&quot;, &quot;requiredPeerCount&quot;: 0, &quot;maxPeerCount&quot;: 1, &quot;blockToLive&quot;:3, &quot;memberOnlyRead&quot;: true, &quot;memberOnlyWrite&quot;: false, &quot;endorsementPolicy&quot;: &#123; &quot;signaturePolicy&quot;: &quot;OR(&#x27;Org1MSP.member&#x27;)&quot; &#125; &#125;, &#123; &quot;name&quot;: &quot;Org2MSPPrivateCollection&quot;, &quot;policy&quot;: &quot;OR(&#x27;Org2MSP.member&#x27;)&quot;, &quot;requiredPeerCount&quot;: 0, &quot;maxPeerCount&quot;: 1, &quot;blockToLive&quot;:3, &quot;memberOnlyRead&quot;: true, &quot;memberOnlyWrite&quot;: false, &quot;endorsementPolicy&quot;: &#123; &quot;signaturePolicy&quot;: &quot;OR(&#x27;Org2MSP.member&#x27;)&quot; &#125; &#125;] The policy property in the assetCollection definition specifies that both Org1 and Org2 can store the collection on their peers. The memberOnlyRead and memberOnlyWrite parameters are used to specify that only Org1 and Org2 clients can read and write to this collection. assetCollection定义中的policy属性指定Org1和Org2都可以在其peer节点上存储集合。 memberOnlyRead 和 memberOnlyWrite 参数被用于指定只有Org1和Org2的客户端可以读写这个集合。 The Org1MSPPrivateCollection collection allows only peers of Org1 to have the private data in their private database, while the Org2MSPPrivateCollection collection can only be stored by the peers of Org2. The endorsementPolicy parameter is used to create a collection specific endorsement policy. Each update to Org1MSPPrivateCollection or Org2MSPPrivateCollection needs to be endorsed by the organization that stores the collection on their peers. We will see how these collections are used to transfer the asset in the course of the tutorial. Org1MSPPrivateCollection 集合只允许Org1的peer节点在他们的私有数据库中拥有私有数据，而Org2MSPPrivateCollection集合只能由Org2的peer节点存储。 endorsementPolicy 参数用于创建特定集合的认可策略。对Org1MSPPrivateCollection或Org2MSPPrivateCollection的每次更新都需要由将集合存储在其peer节点的组织认可。在本教程中，我们将了解如何使用这些集合来转移资产。 This collection definition file is deployed when the chaincode definition is committed to the channel using the peer lifecycle chaincode commit command. More details on this process are provided in Section 3 below. 这个集合定义文件是在使用peer lifecycle chaincode commit command把链码定义提交到通道时被部署的。 Read and Write private data using chaincode APIs（使用chaincode API读写私有数据） The next step in understanding how to privatize data on a channel is to build the data definition in the chaincode. The asset transfer private data sample divides the private data into three separate data definitions according to how the data will be accessed. 下一步是了解如何在链码中建立数据定义来对通道上的数据进行私有化。资产转移私有数据实例根据访问数据的方式将私有数据分为三个单独的数据定义。 12345678910111213141516171819202122// Peers in Org1 and Org2 will have this private data in a side databasetype Asset struct &#123; Type string `json:&quot;objectType&quot;` //Type is used to distinguish the various types of objects in state database ID string `json:&quot;assetID&quot;` Color string `json:&quot;color&quot;` Size int `json:&quot;size&quot;` Owner string `json:&quot;owner&quot;`&#125;// AssetPrivateDetails describes details that are private to owners// Only peers in Org1 will have this private data in a side databasetype AssetPrivateDetails struct &#123; ID string `json:&quot;assetID&quot;` AppraisedValue int `json:&quot;appraisedValue&quot;`&#125;// Only peers in Org2 will have this private data in a side databasetype AssetPrivateDetails struct &#123; ID string `json:&quot;assetID&quot;` AppraisedValue int `json:&quot;appraisedValue&quot;`&#125; Specifically, access to the private data will be restricted as follows: objectType, color, size, and owner are stored in assetCollection and hence will be visible to members of the channel per the definition in the collection policy (Org1 and Org2). AppraisedValue of an asset is stored in collection Org1MSPPrivateCollection or Org2MSPPrivateCollection , depending on the owner of the asset. The value is only accessible to the users who belong to the organization that can store the collection. 具体来说，对私有数据的访问将受到以下限制： objectType, color, size, and owner 被存储在 assetCollection 因此，根据集合策略中的定义，这些数据对通道上的Org1和Org2是可以访问的。 资产的评估价值被存储在 Org1MSPPrivateCollection 或 Org2MSPPrivateCollection 集合中，取决于资产的所有者。只有属于可以存储集合的组织的用户才能访问该评估值。","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"HOW-TO","slug":"区块链/Hyperledger-Fabric/HOW-TO","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/HOW-TO/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"Secured","slug":"Secured","permalink":"https://guozhe001.github.io/tags/Secured/"},{"name":"Private Data","slug":"Private-Data","permalink":"https://guozhe001.github.io/tags/Private-Data/"}]},{"title":"创建一个新的channel","slug":"blockchain/fabric/how_to/创建一个新的channel","date":"2024-11-22T06:32:06.494Z","updated":"2024-11-22T06:32:06.494Z","comments":true,"path":"2024/11/22/blockchain/fabric/how_to/创建一个新的channel/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/how_to/%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84channel/","excerpt":"","text":"创建一个新的channel 官方文档 You can use this tutorial to learn how to create new channels using the configtxgen CLI tool and then use the peer channel commands to join a channel with your peers. While this tutorial will leverage the Fabric test network to create the new channel, the steps in this tutorial can also be used by network operators in a production environment. 你可以通过这个教程来学习通过 configtxgenCLI工具来创建新的通道，然后通过 peer channel 命令将peer节点加入通道。尽管本教程将利用Fabric测试网络来创建新渠道，网络操作人员也可以在生产环境中使用本教程中的步骤。 In the process of creating the channel, this tutorial will take you through the following steps and concepts: 在创建频道的过程中，本教程将带您完成以下步骤和概念： Setting up the configtxgen tool：设置configtxgen工具 Using the configtx.yaml file：使用configtx.yaml配置文件 The orderer system channel：排序的系统通道介绍 Creating an application channel：创建一个应用通道 Joining peers to the channel：将peer节点加入通道 Setting anchor peers：设置锚节点 Setting up the configtxgen tool（设置configtxgen工具） Channels are created by building a channel creation transaction and submitting the transaction to the ordering service. The channel creation transaction specifies the initial configuration of the channel and is used by the ordering service to write the channel genesis block. While it is possible to build the channel creation transaction file manually, it is easier to use the configtxgen tool. The tool works by reading a configtx.yaml file that defines the configuration of your channel, and then writing the relevant information into the channel creation transaction. Before we discuss the configtx.yaml file in the next section, we can get started by downloading and setting up the configtxgen tool. 通道的创建是通过构建一个创建通道的交易然后将此交易提交给排序服务来完成的。“创建通道的交易”指明了此通道的初始化配置并且由排序服务写入通道的创世纪区块中。尽管可以手动构建“创建通道的交易”，但使用configtxgen工具更容易。configtxgen工具读取定义了channle配置的configtx.yaml文件，然后将相关信息写入“创建通道的交易”中。在我们讨论 configtx.yaml 文件之前，我们先开始下载并设置configtxgen 工具。 You can download the configtxgen binaries by following the steps to install the samples, binaries and Docker images. configtxgen will be downloaded to the bin folder of your local clone of the fabric-samples repository along with other Fabric tools. 你可以跟着 install the samples, binaries and Docker images的步骤来下载 configtxgen 。 configtxgen 会下载到fabric-samples仓库的bin目录下。 For the purposes of this tutorial, we will want to operate from the test-network directory inside fabric-samples. Navigate to that directory using the following command: 为了本教程的目的，我们会想要在fabric-samples下面的 test-network 目录下进行操作，使用下面的命令切换到此目录： 1cd fabric-samples/test-network We will operate from the test-network directory for the remainder of the tutorial. Use the following command to add the configtxgen tool to your CLI path: 在本教程的其余部分中，我们将从test-network目录进行操作。使用以下命令将configtxgen工具添加到您的CLI路径： 1export PATH=$&#123;PWD&#125;/../bin:$PATH In order to use configtxgen, you need to the set the FABRIC_CFG_PATH environment variable to the path of the directory that contains your local copy of the configtx.yaml file. For this tutorial, we will reference the configtx.yaml used to setup the Fabric test network in the configtx folder: 为了使用configtxgen，您需要将FABRIC_CFG_PATH环境变量设置为包含configtx.yaml的本地目录。对于本教程，我们将在此环境变量设置为在Fabric test network目录下的包含configtx.yaml的configtx 目录： 1export FABRIC_CFG_PATH=$&#123;PWD&#125;/configtx You can check that you can are able to use the tool by printing the configtxgen help text: 你可以通过打印 configtxgen工具的help来检查是否已经设置好: 1configtxgen --help The configtx.yaml file（configtx.yaml文件） The configtx.yaml file specifies the channel configuration of new channels. The information that is required to build the channel configuration is specified in a readable and editable form in the configtx.yaml file. The configtxgen tool uses the channel profiles defined in the configtx.yaml file to create the channel configuration and write it to the protobuf format that can be read by Fabric. configtx.yaml 文件指明了一个新的通道的通道配置。在configtx.yaml文件中可以读取和编辑构建通道配置所需的信息。 configtxgen 工具通过使用 configtx.yaml文件中的通道属性的定义来创建通道配置，并将其写入可由Fabric读取的 protobuf格式。 You can find the configtx.yaml file that is used to deploy the test network in the configtx folder in the test-network directory. The file contains the following information that we will use to create our new channel: 你可以在test-network目录的configtx 文件夹下面看到 configtx.yaml 文件，这个文件包含在创建新通道时会用到的下面的信息： Organizations: The organizations that can become members of your channel. Each organization has a reference to the cryptographic material that is used to build the channel MSP. 可以成为你的通道成员的组织信息，每一个组织都有对用于构建通道MSP的加密材料的引用。 Ordering service: Which ordering nodes will form the ordering service of the network, and consensus method they will use to agree to a common order of transactions. The file also contains the organizations that will become the ordering service administrators. 哪些排序节点将形成网络中的排序服务，以及它们用于同意交易顺序的共识方法。此文件还包含了会成为排序服务管理员的组织的信息。 Channel policies： Different sections of the file work together to define the policies that will govern how organizations interact with the channel and which organizations need to approve channel updates. For the purposes of this tutorial, we will use the default policies used by Fabric. 文件的不同部分一起定义通道策略，这些策略将控制组织与通道的交互方式以及哪些组织需要批准渠道更新。就本教程而言，我们将使用Fabric使用的默认策略。 Channel profiles Each channel profile references information from other sections of the configtx.yaml file to build a channel configuration. The profiles are used the create the genesis block of the orderer system channel and the channels that will be used by peer organizations. To distinguish them from the system channel, the channels used by peer organizations are often referred to as application channels. 每个通道的配置信息都引用configtx.yaml文件的其他部分来构建通道配置。这些配置信息是用来创建orderer system channel 的创世纪区块的，然后通道会被同等的其他组织所使用。为了将它们（orderer system channel）与系统通道区分开来，组织使用的通道通常称为应用程序通道。 The configtxgen tool uses configtx.yaml file to create a complete genesis block for the system channel. As a result, the system channel profile needs to specify the full system channel configuration. The channel profile used to create the channel creation transaction only needs to contain the additional configuration information required to create an application channel. configtxgen工具使用configtx.yaml文件为系统通道创建完整的创世块。结果，系统通道配置文件需要指定完整的系统通道配置。用于创建“创建通道的交易”使用的通道配置仅需要包含创建应用程序通道所需的其他配置信息。 You can visit the Using configtx.yaml to create a channel genesis block tutorial to learn more about this file. For now, we will return to the operational aspects of creating the channel, though we will reference parts of this file in future steps. 你可以访问 Using configtx.yaml to create a channel genesis block 教程来学习此文件的更多信息。现在我们回到创建通道的操作方面。 Start the network（启动网络） 参考Fabric测试网络使用 Our instance of the test network was deployed without creating an application channel. However, the test network script creates the system channel when you issue the ./network.sh up command. Under the covers, the script uses the configtxgen tool and the configtx.yaml file to build the genesis block of the system channel. Because the system channel is used to create other channels, we need to take some time to understand the orderer system channel before we can create an application channel. 我们部署的测试网络实例未创建应用程序通道。但是测试网络脚本在你运行./network.sh up 命令时创建了系统通道。在幕后，脚本使用configtxgen工具和configtx.yaml文件来构建系统通道的创世纪块。因为系统通道是用来创建其他通道的，所以我们在创建一个应用通道之前需要花一些时间去了解排序系统通道（ orderer system channel ） The orderer system channel（排序系统通道） 略 Creating an application channel（创建一个应用通道） Now that we have deployed the nodes of the network and created the orderer system channel using the network.sh script, we can start the process of creating a new channel for our peer organizations. We have already set the environment variables that are required to use the configtxgen tool. Run the following command to create a channel creation transaction for channel1: 现在我们已经使用network.sh脚本在测试网络中部署了节点，并且创建了排序系统通道。我们现在可以开始为我们的组织创建一个新通道的程序了。我们已经设置了使用configtxgen工具所需的环境变量。运行下面的程序来为channel1通道创建一个“创建通道的交易”： 1configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel1.tx -channelID channel1 The -channelID will be the name of the future channel. Channel names must be all lower case, less than 250 characters long and match the regular expression [a-z][a-z0-9.-]*. The command uses the uses the -profile flag to reference the TwoOrgsChannel: profile from configtx.yaml that is used by the test network to create application channels: -channelID标志制定了创建的通道的名称，通道的名称必须全是小写，不超过250个字符并且符合正则表达式[a-z][a-z0-9.-]*。该命令使用-profile标志来引用configtx.yaml文件中的TwoOrgsChannel：配置，测试网络使用它来创建应用程序通道： 12345678910TwoOrgsChannel: Consortium: SampleConsortium &lt;&lt;: *ChannelDefaults Application: &lt;&lt;: *ApplicationDefaults Organizations: - *Org1 - *Org2 Capabilities: &lt;&lt;: *ApplicationCapabilities The profile references the name of the SampleConsortium from the system channel, and includes both peer organizations from the consortium as channel members. Because the system channel is used as a template to create the application channel, the ordering nodes defined in the system channel become the default consenter set of the new channel, while the administrators of the ordering service become the orderer administrators of the channel. Ordering nodes and ordering organizations can be added or removed from the consenter set using channel updates. 该配置文件从系统通道引用SampleConsortium的名称，并且包含来自该联盟的两个组织作为通道成员。因为系统通道被用作模版来创建应用通道，系统通道中定义的排序节点成为新渠道的默认consenter set，而排序服务的管理员将成为新渠道的排序管理员。可以使用通道更新在consenter set中添加或删除排序节点和排序组织。 If the command successful, you will see logs of configtxgen loading the configtx.yaml file and printing a channel creation transaction: 如果上面的命令执行成功，你会看到configtxgen 工具加载 configtx.yaml 文件并且打印了一个创建通道的交易： 12342020-12-23 14:25:49.175 CST [common.tools.configtxgen] main -&gt; INFO 001 Loading configuration2020-12-23 14:25:49.185 CST [common.tools.configtxgen.localconfig] Load -&gt; INFO 002 Loaded configuration: /Users/apple/code/open-source/blockchain/hyperledger/fabric-samples/test-network/configtx/configtx.yaml2020-12-23 14:25:49.185 CST [common.tools.configtxgen] doOutputChannelCreateTx -&gt; INFO 003 Generating new channel configtx2020-12-23 14:25:49.188 CST [common.tools.configtxgen] doOutputChannelCreateTx -&gt; INFO 004 Writing new channel tx We can use the peer CLI to submit the channel creation transaction to the ordering service. To use the peer CLI, we need to set the FABRIC_CFG_PATH to the core.yaml file located in the fabric-samples/config directory. Set the FABRIC_CFG_PATH environment variable by running the following command: 你可以使用 peerCLI来把这个“创建通道的交易”提交到排序服务。为了使用peer CLI，我们需要设置环境变量FABRIC_CFG_PATH为 fabric-samples/config 目录下的core.yaml文件，运行下面的命令来设置FABRIC_CFG_PATH环境变量： 1export FABRIC_CFG_PATH=$PWD/../config/ Before the ordering service creates the channel, the ordering service will check the permission of the identity that submitted the request. By default, only admin identities of organizations that belong to the system channel consortium can create a new channel. Issue the commands below to operate the peer CLI as the admin user from Org1: 在排序服务创建通道时，排序服务会检查提交请求的身份的权限。默认情况下，只有属于系统通道联盟的组织的管理员身份才能创建新的通道。运行下面的命令来以Org1的管理员身份操作 peer CLI: 12345export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=localhost:7051 You can now create the channel by using the following command: 你现在可以使用下面的命令来创建通道了： 1peer channel create -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com -c channel1 -f ./channel-artifacts/channel1.tx --outputBlock ./channel-artifacts/channel1.block --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem The command above provides the path to the channel creation transaction file using the -f flag and uses the -c flag to specify the channel name. The -o flag is used to select the ordering node that will be used to create the channel. The --cafile is the path to the TLS certificate of the ordering node. When you run the peer channel create command, the peer CLI will generate the following response: 上面的命令使用 -f标志来指定“创建通道的交易”的文件，并且使用 -c 标志来指定通道名称。-o标志是用来选择用来创建通道的排序节点的。--cafile 标志是排序节点的TLS证书路径。当你运行 peer channel create命令时， peer CLI会生成下面的响应： 122020-12-23 14:36:09.386 CST [channelCmd] InitCmdFactory -&gt; INFO 00b Endorser and orderer connections initialized2020-12-23 14:36:09.595 CST [cli.common] readBlock -&gt; INFO 00c Received block: 0 Because we are using a Raft ordering service, you may get some status unavailable messages that you can safely ignore. The command will return the genesis block of the new channel to the location specified by the --outputBlock flag. 因为我们使用一个Raft策略的排序服务，你可能会收到一些状态不可用的信息你可以放心的忽略他们。该命令会将新通道的创世纪区块输出到--outputBlock标志指定的位置。 Join peers to the channel（把节点加入通道中） After the channel has been created, we can join the channel with our peers. Organizations that are members of the channel can fetch the channel genesis block from the ordering service using the peer channel fetch command. The organization can then use the genesis block to join the peer to the channel using the peer channel join command. Once the peer is joined to the channel, the peer will build the blockchain ledger by retrieving the other blocks on the channel from the ordering service. 在通道创建之后，我们可以把我们的peer节点加入到通道。属于通道成员的组织可以使用 peer channel fetch命令从排序服务那里获取通道的创世纪区块。然后这个组织就可以使用这个创世纪区块来通过 peer channel join 命令将peer节点加入到通道了。一旦peer节点加入了通道，peer节点将通过从排序服务中检索其他区块来构建区块链账本了。 Since we are already operating the peer CLI as the Org1 admin, let’s join the Org1 peer to the channel. Since Org1 submitted the channel creation transaction, we already have the channel genesis block on our file system. Join the Org1 peer to the channel using the command below. 因为我们已经通过Org1的管理员操作了 peer CLI ，让我们把Org1的peer节点加入到通道。因为是Org1组织提交的“创建通道的交易”，我们已经在我们本地的文件系统中拥有了通道的创世纪区块。使用下面的命令将组织Org1的peer节点加入到通道中： 1peer channel join -b ./channel-artifacts/channel1.block The CORE_PEER_ADDRESS environment variable has been set to target peer0.org1.example.com. A successful command will generate a response from peer0.org1.example.com joining the channel: 环境变量CORE_PEER_ADDRESS已经设置为指向了peer0.org1.example.com，如果命令成功的话会获取 peer0.org1.example.com 加入通道的响应： 122020-03-06 17:49:09.903 EST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-03-06 17:49:10.060 EST [channelCmd] executeJoin -&gt; INFO 002 Successfully submitted proposal to join channel 我本地的运行报错如下，记录TODO，最终使用最新2.3.0的版本就没有这个问题。2.2.0版本没有成功启动org1的peer。 12345(base) apple@WHOAMIdeMacBook-Pro:~/code/open-source/blockchain/hyperledger/fabric-samples/test-network$ peer channel join -b ./channel-artifacts/channel1.block2020-12-23 14:59:02.760 CST [comm.tls] ClientHandshake -&gt; ERRO 001 Client TLS handshake failed after 2.782623ms with error: EOF remoteaddress=[::1]:70512020-12-23 14:59:03.768 CST [comm.tls] ClientHandshake -&gt; ERRO 002 Client TLS handshake failed after 2.438885ms with error: EOF remoteaddress=[::1]:70512020-12-23 14:59:05.075 CST [comm.tls] ClientHandshake -&gt; ERRO 003 Client TLS handshake failed after 1.857716ms with error: EOF remoteaddress=[::1]:7051Error: error getting endorser client for channel: endorser client failed to connect to localhost:7051: failed to create new connection: context deadline exceeded You can verify that the peer has joined the channel using the peer channel getinfo command: 你可以使用 peer channel getinfo 命令来验证peer节点已经加入了通道： 1peer channel getinfo -c channel1 The command will list the block height of the channel and the hash of the most recent block. Because the genesis block is the only block on the channel, the height of the channel will be 1: 这个命令会列出通道区块的高度和最新的区块的hash值，因为这个通道上只有一个创世纪区块，所以这个通道上的区块高度是1: 122020-03-13 10:50:06.978 EDT [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initializedBlockchain info: &#123;&quot;height&quot;:1,&quot;currentBlockHash&quot;:&quot;kvtQYYEL2tz0kDCNttPFNC4e6HVUFOGMTIDxZ+DeNQM=&quot;&#125; We can now join the Org2 peer to the channel. Set the following environment variables to operate the peer CLI as the Org2 admin. The environment variables will also set the Org2 peer, peer0.org1.example.com, as the target peer. 我们现在可以把组织Org2的peer节点加入通道了。设置下面的环境变量来使用Org2的管理员操作peer CLI。 12345export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_ADDRESS=localhost:9051 While we still have the channel genesis block on our file system, in a more realistic scenario, Org2 would have the fetch the block from the ordering service. As an example, we will use the peer channel fetch command to get the genesis block for Org2: 然而在我们本地系统中仍然存在通道的创世纪区块，在一个更真实的情形中，组织Org2应该从排序服务获取这个区块。例如，我们将使用 peer channel fetch命令来为组织Org2获取创世纪区块： 1peer channel fetch 0 ./channel-artifacts/channel_org2.block -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com -c channel1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem The command uses 0 to specify that it needs to fetch the genesis block that is required to join the channel. If the command is successful, you should see the following output: 该命令使用0来指明它需要获取创世纪块，该创世纪区块用于加入通道。如果命令执行成功，你会看到下面的输出： 122020-03-13 11:32:06.309 EDT [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-03-13 11:32:06.336 EDT [cli.common] readBlock -&gt; INFO 002 Received block: 0 The command returns the channel genesis block and names it channel_org2.block to distinguish it from the block pulled by org1. You can now use the block to join the Org2 peer to the channel: 这个命令会获取到名为 channel_org2.block 的通道创世纪区块，以与Org1的区块作区分。你现在可以使用这个区块把Org2的peer节点加入到通道： 1peer channel join -b ./channel-artifacts/channel_org2.block Set anchor peers（设置锚节点） After an organizations has joined their peers to the channel, they should select at least one of their peers to become an anchor peer. Anchor peers are required in order to take advantage of features such as private data and service discovery. Each organization should set multiple anchor peers on a channel for redundancy. For more information about gossip and anchor peers, see the Gossip data dissemination protocol. 在一个组织将他们的peer节点加入到通道之后，他们还需要在他们的组织内部选择至少一个peer节点作为锚节点。Anchor peers 需要锚节点的好处是他能够利用私有数据以及做服务发现。每个组织都应在一个通道上设置多个锚节点以实现冗余。 The endpoint information of the anchor peers of each organization is included in the channel configuration. Each channel member can specify their anchor peers by updating the channel. We will use the configtxlator tool to update the channel configuration and select an anchor peer for Org1 and Org2. The process for setting an anchor peer is similar to the steps that are required to make other channel updates and provides an introduction to how to use configtxlator to update a channel configuration. You will also need to install the jq tool on your local machine. 通道配置中包含每个组织的锚节点的终点信息。每个组织都可以通过更新通道配置来知名他们的锚节点。我们会使用 configtxlator工具来更新通道配置并且为组织Org1和Org2各选择一个锚节点。设置锚节点的流程与教程update a channel configuration的步骤很类似。你还需要在你的本地安装jq 工具。 We will start by selecting an anchor peer as Org1. The first step is to pull the most recent channel configuration block using the peer channel fetch command. Set the following environment variables to operate the peer CLI as the Org1 admin: 我们先以Org1的身份来选择一个锚节点。第一步是使用peer channel fetch 命令拉去最新的通道配置区块。设置环境变量以Org1管理员的身份操作 peer CLI ： 123456export FABRIC_CFG_PATH=$PWD/../config/export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=localhost:7051 You can use the following command to fetch the channel configuration: 你可以通过下面的命令来获取通道配置： 1peer channel fetch config channel-artifacts/config_block.pb -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com -c channel1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem Because the most recent channel configuration block is the channel genesis block, you will see the command return block 0 from the channel. 因为最新的通道配置区块是通道的创世纪区块，你会看到该命令会返回通道上的0区块。 12342020-12-23 16:37:33.686 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-12-23 16:37:33.689 CST [cli.common] readBlock -&gt; INFO 002 Received block: 02020-12-23 16:37:33.689 CST [channelCmd] fetch -&gt; INFO 003 Retrieving last config block: 02020-12-23 16:37:33.693 CST [cli.common] readBlock -&gt; INFO 004 Received block: 0 The channel configuration block was stored in the channel-artifacts folder to keep the update process separate from other artifacts. Change into the channel-artifacts folder to complete the next steps: 通道配置区块被存储在channel-artifacts目录下，以使更新流程与其他的组件区分开。进入 channel-artifacts 目录下来完成接下来的步骤： 1cd channel-artifacts We can now start using the configtxlator tool to start working with the channel configuration. The first step is to decode the block from protobuf into a JSON object that can be read and edited. We also strip away the unnecessary block data, leaving only the channel configuration. 我们现在开始使用 configtxlator 工具和通道配置一起工作。第一步是将来自区块的protobuf格式解码为可以读取和编辑的JSON格式。我们还将去除不必要的块数据，仅保留通道配置。 12configtxlator proto_decode --input config_block.pb --type common.Block --output config_block.jsonjq .data.data[0].payload.data.config config_block.json &gt; config.json These commands convert the channel configuration block into a streamlined JSON, config.json, that will serve as the baseline for our update. Because we don’t want to edit this file directly, we will make a copy that we can edit. We will use the original channel config in a future step. 这些命令将通道配置区块转换为简化的JSON格式的文件config.json，它将作为我们更新的基准。因为我们不想直接编辑这个文件，我们会先创建一个可以编辑的副本。我们将在以后的步骤中使用原始的通道配置。 1cp config.json config_copy.json You can use the jq tool to add the Org1 anchor peer to the channel configuration. 你可以使用jq 工具来添加Org1组织的锚节点到通道配置。 1jq &#x27;.channel_group.groups.Application.groups.Org1MSP.values += &#123;&quot;AnchorPeers&quot;:&#123;&quot;mod_policy&quot;: &quot;Admins&quot;,&quot;value&quot;:&#123;&quot;anchor_peers&quot;: [&#123;&quot;host&quot;: &quot;peer0.org1.example.com&quot;,&quot;port&quot;: 7051&#125;]&#125;,&quot;version&quot;: &quot;0&quot;&#125;&#125;&#x27; config_copy.json &gt; modified_config.json After this step, we have an updated version of channel configuration in JSON format in the modified_config.json file. We can now convert both the original and modified channel configurations back into protobuf format and calculate the difference between them. 完成此步骤后，我们在modified_config.json文件中以JSON格式获取了通道配置的更新版本。现在，我们可以将原始的和修改后的通道配置都转换回protobuf格式，并计算它们之间的差异。 123configtxlator proto_encode --input config.json --type common.Config --output config.pbconfigtxlator proto_encode --input modified_config.json --type common.Config --output modified_config.pbconfigtxlator compute_update --channel_id channel1 --original config.pb --updated modified_config.pb --output config_update.pb The new protobuf named channel_update.pb contains the anchor peer update that we need to apply to the channel configuration. We can wrap the configuration update in a transaction envelope to create the channel configuration update transaction. 格式为protobuf的新的channel_update.pb文件包含我们需要应用于通道配置上的锚节点更新。我们可以将配置更新包装在交易信封中以创建通道配置更新交易。 123configtxlator proto_decode --input config_update.pb --type common.ConfigUpdate --output config_update.jsonecho &#x27;&#123;&quot;payload&quot;:&#123;&quot;header&quot;:&#123;&quot;channel_header&quot;:&#123;&quot;channel_id&quot;:&quot;channel1&quot;, &quot;type&quot;:2&#125;&#125;,&quot;data&quot;:&#123;&quot;config_update&quot;:&#x27;$(cat config_update.json)&#x27;&#125;&#125;&#125;&#x27; | jq . &gt; config_update_in_envelope.jsonconfigtxlator proto_encode --input config_update_in_envelope.json --type common.Envelope --output config_update_in_envelope.pb We can now use the final artifact, config_update_in_envelope.pb, that can be used to update the channel. Navigate back to the test-network directory: 现在，我们可以使用最终工件config_update_in_envelope.pb，该工件可以用于更新通道。回到test-network 目录： 1cd .. We can add the anchor peer by providing the new channel configuration to the peer channel update command. Because we are updating a section of the channel configuration that only affects Org1, other channel members do not need to approve the channel update. 我们可以通过向peer channel update命令提供新的通道配置来添加锚节点。因为我们正在更新仅影响Org1的部分通道配置，所以其他通道成员不需要批准通道更新。 1peer channel update -f channel-artifacts/config_update_in_envelope.pb -c channel1 -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem When the channel update is successful, you should see the following response: 当渠道更新成功后，你会看到下面的响应： 122020-12-23 17:05:48.187 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2020-12-23 17:05:48.222 CST [channelCmd] update -&gt; INFO 002 Successfully submitted channel update We can set the anchor peers for Org2. Because we are going through the process a second time, we will go through the steps more quickly. Set the environment variables to operate the peer CLI as the Org2 admin: 我们可以为Org2设置锚节点。因为我们是第二次进行该过程，所以我们将更快地完成这些步骤。设置环境变量以Org2管理员的身份操作 peer CLI ： 12345export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_ADDRESS=localhost:9051 Pull the latest channel configuration block, which is now the second block on the channel: 拉去最新的通道配置区块，即目前通道上的第二个区块： 1peer channel fetch config channel-artifacts/config_block.pb -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com -c channel1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem Navigate back to the channel-artifacts directory（切换回 channel-artifacts 目录）: 1cd channel-artifacts You can then decode and copy the configuration block.（你可以解码并复制配置区块） 123configtxlator proto_decode --input config_block.pb --type common.Block --output config_block.jsonjq .data.data[0].payload.data.config config_block.json &gt; config.jsoncp config.json config_copy.json Add the Org2 peer that is joined to the channel as the anchor peer in the channel configuration: 在通道配置中添加Org2的已经加入通道的节点作为锚节点: 1jq &#x27;.channel_group.groups.Application.groups.Org2MSP.values += &#123;&quot;AnchorPeers&quot;:&#123;&quot;mod_policy&quot;: &quot;Admins&quot;,&quot;value&quot;:&#123;&quot;anchor_peers&quot;: [&#123;&quot;host&quot;: &quot;peer0.org2.example.com&quot;,&quot;port&quot;: 9051&#125;]&#125;,&quot;version&quot;: &quot;0&quot;&#125;&#125;&#x27; config_copy.json &gt; modified_config.json We can now convert both the original and updated channel configurations back into protobuf format and calculate the difference between them. 我们可以将原始的和修改后的通道配置都转换回protobuf格式，并计算它们之间的差异。 123configtxlator proto_encode --input config.json --type common.Config --output config.pbconfigtxlator proto_encode --input modified_config.json --type common.Config --output modified_config.pbconfigtxlator compute_update --channel_id channel1 --original config.pb --updated modified_config.pb --output config_update.pb Wrap the configuration update in a transaction envelope to create the channel configuration update transaction: 将配置更新包装在交易信封中以创建通道配置更新交易： 123configtxlator proto_decode --input config_update.pb --type common.ConfigUpdate --output config_update.jsonecho &#x27;&#123;&quot;payload&quot;:&#123;&quot;header&quot;:&#123;&quot;channel_header&quot;:&#123;&quot;channel_id&quot;:&quot;channel1&quot;, &quot;type&quot;:2&#125;&#125;,&quot;data&quot;:&#123;&quot;config_update&quot;:&#x27;$(cat config_update.json)&#x27;&#125;&#125;&#125;&#x27; | jq . &gt; config_update_in_envelope.jsonconfigtxlator proto_encode --input config_update_in_envelope.json --type common.Envelope --output config_update_in_envelope.pb Navigate back to the test-network directory. 1cd .. Update the channel and set the Org2 anchor peer by issuing the following command: 1peer channel update -f channel-artifacts/config_update_in_envelope.pb -c channel1 -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem You can confirm that the channel has been updated successfully by running the peer channel info command: 你可以使用 peer channel info命令来确认通道已经成功更新。 1peer channel getinfo -c channel1 Now that the channel has been updated by adding two channel configuration blocks to the channel genesis block, the height of the channel will have grown to three: 现在已经通过在创世纪区块上添加两个通道配置区块更新了通道，通道的区块高度会增长到3: 122020-12-23 17:19:08.620 CST [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initializedBlockchain info: &#123;&quot;height&quot;:3,&quot;currentBlockHash&quot;:&quot;0xMLgGnvbUE+gfDpxjbfB1OsxROF3djLzPX9S76ai2I=&quot;,&quot;previousBlockHash&quot;:&quot;6oIrHH8zjeOuhlj2/rrpzxh0pNmGOdPTDjiphJwCXcQ=&quot;&#125; Deploy a chaincode to the new channel（部署链码到新通道上） We can confirm that the channel was created successfully by deploying a chaincode to the channel. We can use the network.sh script to deploy the Basic asset transfer chaincode to any test network channel. Deploy a chaincode to our new channel using the following command: 我们可以通过在通道上部署链码来确认通道已经创建成功。我们可以使用 network.sh 脚本部署Basic asset transfer 链码到任何测试通道，使用下面的命令将链码部署到新通道上： 1./network.sh deployCC -ccn basic -ccp ../asset-transfer-basic/chaincode-go/ -ccl go -c channel1 -cci InitLedger After you run the command, you should see the chaincode being deployed to the channel in your logs. The chaincode is invoked to add data to the channel ledger. 运行命令后，您应该在日志中看到链码已部署到通道。调用链码将数据添加到通道账本。 1peer chaincode query -C channel1 -n basic -c &#x27;&#123;&quot;Args&quot;:[&quot;getAllAssets&quot;]&#125;&#x27; After you run the query, you should see the assets that were added to the channel ledger. 在运行查询之后，你会看到已经添加到通道账本上的资产列表。 1[&#123;&quot;ID&quot;:&quot;asset1&quot;,&quot;color&quot;:&quot;blue&quot;,&quot;size&quot;:5,&quot;owner&quot;:&quot;Tomoko&quot;,&quot;appraisedValue&quot;:300&#125;,&#123;&quot;ID&quot;:&quot;asset2&quot;,&quot;color&quot;:&quot;red&quot;,&quot;size&quot;:5,&quot;owner&quot;:&quot;Brad&quot;,&quot;appraisedValue&quot;:400&#125;,&#123;&quot;ID&quot;:&quot;asset3&quot;,&quot;color&quot;:&quot;green&quot;,&quot;size&quot;:10,&quot;owner&quot;:&quot;Jin Soo&quot;,&quot;appraisedValue&quot;:500&#125;,&#123;&quot;ID&quot;:&quot;asset4&quot;,&quot;color&quot;:&quot;yellow&quot;,&quot;size&quot;:10,&quot;owner&quot;:&quot;Max&quot;,&quot;appraisedValue&quot;:600&#125;,&#123;&quot;ID&quot;:&quot;asset5&quot;,&quot;color&quot;:&quot;black&quot;,&quot;size&quot;:15,&quot;owner&quot;:&quot;Adriana&quot;,&quot;appraisedValue&quot;:700&#125;,&#123;&quot;ID&quot;:&quot;asset6&quot;,&quot;color&quot;:&quot;white&quot;,&quot;size&quot;:15,&quot;owner&quot;:&quot;Michel&quot;,&quot;appraisedValue&quot;:800&#125;]","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"HOW-TO","slug":"区块链/Hyperledger-Fabric/HOW-TO","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/HOW-TO/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"channel","slug":"channel","permalink":"https://guozhe001.github.io/tags/channel/"}]},{"title":"添加一个新的组织到channel","slug":"blockchain/fabric/how_to/添加一个新的组织到channel","date":"2024-11-22T06:32:06.494Z","updated":"2024-11-22T06:32:06.494Z","comments":true,"path":"2024/11/22/blockchain/fabric/how_to/添加一个新的组织到channel/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/how_to/%E6%B7%BB%E5%8A%A0%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84%E7%BB%84%E7%BB%87%E5%88%B0channel/","excerpt":"","text":"添加一个新的组织到channel 官方文档 This tutorial extends the Fabric test network by adding a new organization – Org3 – to an application channel. 本教程通过向应用程序通道添加新组织Org3扩展了Fabric测试网络。 While we will focus on adding a new organization to the channel, you can use a similar process to make other channel configuration updates (updating modification policies or altering batch size, for example). To learn more about the process and possibilities of channel config updates in general, check out Updating a channel configuration). It’s also worth noting that channel configuration updates like the one demonstrated here will usually be the responsibility of an organization admin (rather than a chaincode or application developer). 我们将专注于向channel添加新组织，你可以使用相似的流程来进行其他情况的通道配置更新。略 Setup the Environment（启动环境） 启动测试环境并创建默认的channel，请参考：Fabric测试网络使用 Bring Org3 into the Channel with the Script（使用脚本将Org3加入到通道） You should be in the test-network directory. To use the script, simply issue the following commands: 12cd addOrg3./addOrg3.sh up The output here is well worth reading. You’ll see the Org3 crypto material being generated, the Org3 organization definition being created, and then the channel configuration being updated, signed, and then submitted to the channel. 这里的输出值的我们一读。你会看到生成Org3组织的加密材料，创建组织Org3的定义然后通道配置会被更新、签名并且提交到通道。 If everything goes well, you’ll get this message: 1========= Finished adding Org3 to your test network! ========= Now that we have confirmed we can add Org3 to our channel, we can go through the steps to update the channel configuration that the script completed behind the scenes. 现在我们已经确认我们可以把组织Org3添加到我们的通道，我们可以按照以下步骤更新通道配置来完成脚本在幕后完成工作。 Bring Org3 into the Channel Manually（手动将Org3加入通道） If you just used the addOrg3.sh script, you’ll need to bring your network down. The following command will bring down all running components and remove the crypto material for all organizations: 如果你刚才使用了 addOrg3.sh脚本，你需要先把网络关闭。下面的命令会关闭所有正在运行的组件并且移除所有组织的加密材料： 12cd addOrg3./addOrg3.sh down After the network is brought down, bring it back up again（网络关闭之后，重新启动它）: 12cd .../network.sh up createChannel This will bring your network back to the same state it was in before you executed the addOrg3.sh script. 这将使您的网络恢复到执行addOrg3.sh脚本之前的状态。 Now we’re ready to add Org3 to the channel manually. As a first step, we’ll need to generate Org3’s crypto material. 现在我们已经准备好手动的将Org3添加到通道中了，第一步，我们需要生成Org3的加密材料。 Generate the Org3 Crypto Material（生成Org3的加密材料） In another terminal, change into the addOrg3 subdirectory from test-network. 在另一个终端切换到 test-network目录的子目录 addOrg3中： 1cd addOrg3 First, we are going to create the certificates and keys for the Org3 peer, along with an application and admin user. Because we are updating an example channel, we are going to use the cryptogen tool instead of using a Certificate Authority. The following command uses cryptogen to read the org3-crypto.yaml file and generate the Org3 crypto material in a new org3.example.com folder: 首先，我们将为Org3组织的peer节点包括应用程序和管理员用户创建证书和密钥。因为我们正在更新示例通道，所以我们将使用cryptogen工具而不是使用证书颁发机构。 下面的命令使用cryptogen读取 org3-crypto.yaml文件然后在新的 org3.example.com 文件夹下面生成Org3的加密材料。 1../../bin/cryptogen generate --config=org3-crypto.yaml --output=&quot;../organizations&quot;","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"HOW-TO","slug":"区块链/Hyperledger-Fabric/HOW-TO","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/HOW-TO/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"channel","slug":"channel","permalink":"https://guozhe001.github.io/tags/channel/"},{"name":"peer","slug":"peer","permalink":"https://guozhe001.github.io/tags/peer/"}]},{"title":"在Fabric中交易受保护的资产","slug":"blockchain/fabric/how_to/在Fabric中交易受保护的资产","date":"2024-11-22T06:32:06.494Z","updated":"2024-11-22T06:32:06.494Z","comments":true,"path":"2024/11/22/blockchain/fabric/how_to/在Fabric中交易受保护的资产/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/how_to/%E5%9C%A8Fabric%E4%B8%AD%E4%BA%A4%E6%98%93%E5%8F%97%E4%BF%9D%E6%8A%A4%E7%9A%84%E8%B5%84%E4%BA%A7/","excerpt":"","text":"在Fabric中交易受保护的资产 官方文档：Secured asset transfer in Fabric This tutorial will demonstrate how an asset can be represented and traded between organizations in a Hyperledger Fabric blockchain channel, while keeping details of the asset and transaction private using private data. Each on-chain asset is a non-fungible token (NFT) that represents a specific asset having certain immutable metadata properties (such as size and color) with a unique owner. When the owner wants to sell the asset, both parties need to agree to the same price before the asset is transferred. The private asset transfer smart contract enforces that only the owner of the asset can transfer the asset. In the course of this tutorial, you will learn how Fabric features such as state based endorsement, private data, and access control come together to provide secured transactions that are both private and verifiable. 本文档会演示如何在Hyperledger Fabric区块链的通道中的组织之间表示和交易资产，同时保持资产和交易的私有性。链上的每个资产都是一个NFT（non-fungible token，不可替代令牌），这个NFT代表具有唯一拥有者、具有某些不变的元数据属性（例如大小和颜色）的特定资产。当所有者想要出售资产时，双方需要在转让资产之前达成一致的价格。私有资产转让智能合约强制规定只有资产所有者才能转让资产。在本教程的过程中，您将学习如何把Fabric的特性（如基于状态的背书、私有数据和访问控制）组合在一起，以提供私有且可验证的安全交易。 This tutorial will deploy the secured asset transfer sample to demonstrate how to transfer a private asset between two organizations without publicly sharing data. You should have completed the task Install Samples, Binaries, and Docker Images. 本教程会部署 secured asset transfer sample 来演示如何在两个组织之间转移私有资产而不公开共享数据。 Scenario requirements（方案要求） The private asset transfer scenario is bound by the following requirements: An asset may be issued by the first owner’s organization (in the real world issuance may be restricted to some authority that certifies an asset’s properties). Ownership is managed at the organization level (the Fabric permissioning scheme would equally support ownership at an individual identity level within an organization). The asset identifier and owner is stored as public channel data for all channel members to see. The asset metadata properties however are private information known only to the asset owner (and prior owners). An interested buyer will want to verify an asset’s private properties. An interested buyer will want to verify an asset’s provenance, specifically the asset’s origin and chain of custody. They will also want to verify that the asset has not changed since issuance, and that all prior transfers have been legitimate. To transfer an asset, a buyer and seller must first agree on the sales price. Only the current owner may transfer their asset to another organization. The actual private asset transfer must verify that the legitimate asset is being transferred, and verify that the price has been agreed to. Both buyer and seller must endorse the transfer. 私有资产交易方案受以下要求约束： 一个资产可能由第一个拥有者的组织发行（在现实世界中，可能只能由某个权威的可以证明资产属性的组织来发行）。 所有权是在组织级别进行管理的（Fabric许可方案将同样支持组织内个人身份级别的所有权）。 资产的ID和所有人作为可以被channel上的所有成员可见的公共数据被存储。 但是资产的元数据作为私有信息，只能被资产的所有者看到（也包括前所有者）。 有兴趣的买家将希望验证资产的私有属性。 有兴趣的买家将希望验证资产的出处，特别是资产的来源和产销监管链。他们还希望验证资产自从发行之后没有被篡改过，并且这个资产的前面的所有交易都是合法的。 在资产交易之前，买卖双方必须对资产的价格达成一致。 只有当前拥有者可以把他们的资产转让给另一个组织。 实际的私有资产交易必须确认合法资产正在转让，并确认双方已经对价格达成一致。买卖双方都必须对交易进行背书。 How privacy is maintained（如何保持隐私性） The smart contract uses the following techniques to ensure that the asset properties remain private: The asset metadata properties are stored in the current owning organization’s implicit private data collection on the organization’s peers only. Each organization on a Fabric channel has a private data collection that their own organization can use. This collection is implicit because it does not need to be explicitly defined in the chaincode. Although a hash of the private properties is automatically stored on-chain for all channel members to see, a random salt is included in the private properties so that other channel members cannot guess the private data pre-image through a dictionary attack. Smart contract requests utilize the transient field for private data so that private data does not get included in the final on-chain transaction. Private data queries must originate from a client whose org id matches the peer’s org id, which must be the same as the asset owner’s org id. 智能合约使用以下技术来确保资产属性保持隐私： 资产元数据属性仅存储在当前拥有组织的节点的隐式私有数据集合中。每个组织在Fabric通道上都有一个只能由组织自己可以使用的私有数据集合。该集合是隐式的，因为不需要在链码中显式定义它。 虽然私有属性的hash值被自动保存在链上然后通道上所有成员都可以看到，但是私有属性中包含随机盐，因此其他的通道成员无法通过字典攻击猜测私有数据原像。 智能合约请求将瞬态字段用于私有数据，因此私有数据不会包含在最终的链上交易中。 对私有数据的查询必须来自组织ID与peer的组织ID一致的客户端，并且该客户端的ID必须与资产所有者的组织ID相同。 How the transfer is implemented（交易是如何实施的） Before we start using the private asset transfer smart contract we will provide an overview of the transaction flow and how Fabric features are used to protect the asset created on the blockchain: 在我们开始使用私有资产交易的智能合约之前，我们将概述交易流程以及如何使用Fabric功能来保护在区块链上创建的资产： Creating the asset（创建资产） The private asset transfer smart contract is deployed with an endorsement policy that requires an endorsement from any channel member. This allows any organization to create an asset that they own without requiring an endorsement from other channel members. The creation of the asset is the only transaction that uses the chaincode level endorsement policy. Transactions that update or transfer existing assets will be governed by state based endorsement policies or the endorsement policies of private data collections. Note that in other scenarios, you may want an issuing authority to also endorse create transactions. 私有资产交易智能合约在部署时有一个背书策略，这个背书策略是：不需要任何渠道成员的认可。这样任何组织都可以创建属于他们自己的资产，而不需要其他的通道成员批准。资产的创建是唯一使用链码级背书策略的交易。更新或交易现有资产的交易将受基于状态认可政策或私有数据集合认可政策的约束。注意在其他情况下，你可能想要一个发行机构也认可创建交易。 The smart contract uses the following Fabric features to ensure that the asset can only be updated or transferred by the organization that owns the asset: When the asset is created, the smart contract gets the MSP ID of the organization that submitted the request, and stores the MSP ID as the owner in the asset key/value in the public chaincode world state. Subsequent smart contract requests to update or transfer the asset will use access control logic to verify that the requesting client is from the same organization. Note that in other scenarios, the ownership could be based on a specific client identity within an organization, rather than an organization itself. Also when the asset is created, the smart contract sets a state based endorsement policy for the asset key. The state based policy specifies that a peer from the organization that owns the asset must endorse a subsequent request to update or transfer the asset. This prevents any other organization from updating or transferring the asset using a smart contract that has been maliciously altered on their own peers. 智能合约使用以下的Fabric功能来确保资产只能由拥有它的组织进行更新和交易： 在资产创建后，智能合约会获取提交请求的组织的MSP ID ，并且把这个MSP ID作为资产的拥有者存储在公共链码世界状态的key/value中。后续的更新或交易资产的智能合约请求将会使用访问控制逻辑来验证发出请求的客户端来自同一个组织。请注意在其他情况下，所有权可以基于组织内的特定客户端身份，而不是组织本身。 同样，在创建资产时，智能合约会为资产密钥设置基于状态的背书策略。基于状态的策略指定拥有资产的组织中的peer节点必须认可后续的更新或转让资产的请求。这样可以防止任何其他组织利用恶意更改的智能合约来更改和交易资产。 Agreeing to the transfer（同意交易） After a asset is created, channel members can use the smart contract to agree to transfer the asset: The owner of the asset can change the description in the public ownership record, for example to advertise that the asset is for sale. Smart contract access control enforces that this change needs to be submitted from a member of the asset owner organization. The state based endorsement policy enforces that this description change must be endorsed by a peer from the owner’s organization. 在资产创建之后，通道上的成员可以使用智能合约来同意交易资产： 资产的拥有者可以更改公共记录上的描述，例如广告说这个资产要卖出。智能合约访问控制强制要求此更改需要从拥有此资产的组织的成员提交。基于状态的背书策略规定，此描述更改必须得到拥有资产的组织的成员确认。 The asset owner and the asset buyer agree to transfer the asset for a certain price: The price agreed to by the buyer and the seller is stored in each organization’s implicit private data collection. The private data collection keeps the agreed price secret from other members of the channel. The endorsement policy of the private data collection ensures that the respective organization’s peer endorsed the price agreement, and the smart contract access control logic ensures that the price agreement was submitted by a client of the associated organization. A hash of each price agreement is stored on the ledger. The two hashes will match only if the two organizations have agreed to the same price. This allows the organizations to verify that they have come to agreement on the transfer details before the transfer takes place. A random trade id is added to the price agreement, which serves as a salt to ensure that other channel members can not use the hash on the ledger to guess the price. 资产所有者和资产购买者同意以一定价格交易资产： 买卖双方都同意的价格被存储在他们各自的隐式私有数据集合中。私有数据集合保证成交价格对通道上的其他成员来说是私密的。私有数据集合背书策略确保各自组织的peer节点对价格达成了一致，智能合约访问控制逻辑确保价格协议是由与组织有关联的客户端提交的。 交易双方生成的价格协议的hash值被存储在了账本上。只有在两个组织同意同一个价格时，这两个hash值才会匹配。这使组织能够在转移发生之前验证他们已就转移细节达成协议。价格协议中添加了随机交易ID，这是确保通道其他成员不能使用账本上的哈希值来猜测价格的一种盐。 Transferring the asset（交易资产） After the two organizations have agreed to the same price, the asset owner can use the transfer function to transfer the asset to the buyer: Smart contract access control ensures that the transfer must be initiated by a member of the organization that owns the asset. The transfer function verifies that the asset’s private immutable properties passed to the transfer function matches the on chain hash of the asset data in private collection, to ensure that the asset owner is selling the same asset that they own. The transfer function uses the hash of the price agreement on the ledger to ensure that both organizations have agreed to the same price. If the transfer conditions are met, the transfer function adds the asset to the implicit private data collection of the buyer, and deletes the asset from the collection of the seller. The transfer also updates the owner in the public ownership record. Because of the endorsement policies of the seller and buyer implicit data collections, and the state based endorsement policy of the public record (requiring the seller to endorse), the transfer needs to be endorsed by peers from both buyer and seller. The state based endorsement policy of the public asset record is updated so that only a peer of the new owner of the asset can update or sell their new asset. The price agreements are also deleted from both the seller and buyer implicit private data collection, and a sales receipt is created in each private data collection. 在两个组织已经对相同的价格达成一致之后，资产的拥有者可以使用转让方法来把资产转让给买方： 智能合约访问控制确保转账必须由拥有资产的组织的成员来发起 转账方法验证传递给它的资产的私有不可变属性是否与私有集合中资产数据的链上哈希匹配，确保资产所有者在出售他们拥有的相同的资产。 转账方法使用账本上的价格协议的hash值来确保两个组织已经同意了相同的价格。 如果满足转让条件，则转账函数会将资产添加到买方的隐式私有数据集合中，并且从卖方的集合中删除这个资产。转让还会更新公共所有权记录中的资产的所有者。 因为买卖双方隐式数据集合的背书策略和公共数据的基于状态的背书策略（要求卖方确认），所以交易需要得到买卖双方节点的认可。 公共资产记录的基于状态的背书策略需要更新，这样只有新的所有者的peer节点才能够更新和出售他们的新资产。 价格协议也从买卖双方隐式私人数据集合中删除，并且在每个私人数据集合中创建销售收据。 Running the private asset transfer smart contract（运行私有资产转账智能合约） You can use the Fabric test network to run the private asset transfer smart contract. The test network contains two peer organizations, Org1 and Org1, that operate one peer each. In this tutorial, we will deploy the smart contract to a channel of the test network joined by both organizations. We will first create an asset that is owned by Org1. After the two organizations agree on the price, we will transfer the asset from Org1 to Org2. 我们可以使用Fabric的test网络来运行私有资产转账智能合约。（省略。。。）我们先通过Org1组织创建一个资产，在两个组织对价格达成一致之后，我们把资产由Org1组织交易到Org2组织。 Deploy the test network（部署测试网络） 请参考：Fabric测试网络使用 Deploy the smart contract(部署智能合约) You can use the test network script to deploy the secured asset transfer smart contract to the channel. Run the following command to deploy the smart contract to mychannel: 你可以使用测试网络脚本来部署安全资产交易智能合约到通道上。运行下面的命令来部署智能合约到mychannel： 1.&#x2F;network.sh deployCC -ccn secured -ccp ..&#x2F;asset-transfer-secured-agreement&#x2F;chaincode-go&#x2F; -ccl go -ccep &quot;OR(&#39;Org1MSP.peer&#39;,&#39;Org2MSP.peer&#39;)&quot; Note that we are using the -ccep flag to deploy the smart contract with an endorsement policy of &quot;OR('Org1MSP.peer','Org2MSP.peer')&quot;. This allows either organization to create an asset without receiving an endorsement from the other organization. 注意我们使用-ccep标志来部署智能合约，这个智能合约有一个背书策略&quot;OR('Org1MSP.peer','Org2MSP.peer')&quot;。者允许任意一个组织在创建一个新的资产时不需要其他组织的确认。 Set the environment variables to operate as Org2（设置环境变量以Org2的管理员身份操作） 略，可以使用两个终端分别以Org1和Org2组织管理员的身份操作peer。环境变量设置参考：[Fabric测试网络使用](https://guozhe001.github.io/2024/11/22/blockchain/fabric/how_to/Fabric测试网络使用/ [) Create an asset（创建一个资产） Any channel member can use the smart contract to create an asset that is owned by their organization. The details of the asset will be stored in a private data collection, and can only accessed by the organization that owns the asset. A public record of the asset, its owner, and a public description is stored on the channel ledger. Any channel member can access the public ownership record to see who owns the asset, and can read the description to see if the asset is for sale. 任何一个通道成员都可以使用这个智能合约来创建一个属于组织自己的资产。资产的详情会存储在私有数据集合中，并且只能由拥有资产的组织访问。资产，其所有者和公共描述的公共记录存储在通道账本中。任何通道成员都可以访问公共记录来查看谁拥有这个资产，并且可以查看描述来判断资产是否在出售。 Operate from the Org1 terminal（通过Org1的终端操作） Before we create the asset, we need to specify the details of what our asset will be. Issue the following command to create a JSON that will describe the asset. The &quot;salt&quot; parameter is a random string that would prevent another member of the channel from guessing the asset using the hash on the ledger. If there was no salt, a user could theoretically guess asset parameters until the hash of the of the guess and the hash on the ledger matched (this is known as a dictionary attack). This string is encoded in Base64 format so that it can be passed to the creation transaction as transient data. 在创建资产之前，我们需要指定资产的详细信息。通过下面的命令来创建一个JSON来描述资产。&quot;salt&quot;参数是一个随机字符串来防止通道上的另一个成员通过账本上的hash值来猜测这个资产。如果没有盐，理论上用户可以猜测资产参数，直到猜测的哈希值和账本的哈希值匹配（这称为字典攻击）为止。该字符串以Base64格式编码，因此可以作为临时数据传递给创建交易。 1export ASSET_PROPERTIES=$(echo -n &quot;&#123;\\&quot;object_type\\&quot;:\\&quot;asset_properties\\&quot;,\\&quot;asset_id\\&quot;:\\&quot;asset1\\&quot;,\\&quot;color\\&quot;:\\&quot;blue\\&quot;,\\&quot;size\\&quot;:35,\\&quot;salt\\&quot;:\\&quot;a94a8fe5ccb19ba61c4c0873d391e987982fbbd3\\&quot;&#125;&quot; | base64 | tr -d \\\\n) We can now use the following command to create a asset that belongs to Org1: 我们现在可以使用下面的命令来创建一个属于Org1组织的资产： 1peer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;CreateAsset&quot;,&quot;Args&quot;:[&quot;asset1&quot;, &quot;A new asset for Org1MSP&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_properties\\&quot;:\\&quot;$ASSET_PROPERTIES\\&quot;&#125;&quot; We can can query the Org1 implicit data collection to see the asset that was created: 我们可以查询Org1组织的隐私数据集合来查看创建的资产： 1peer chaincode query -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetPrivateProperties&quot;,&quot;Args&quot;:[&quot;asset1&quot;]&#125;&#x27; When successful, the command will return the following result: 如果成功，命令会返回下面的结果： 1234567&#123; &quot;object_type&quot;: &quot;asset_properties&quot;, &quot;asset_id&quot;: &quot;asset1&quot;, &quot;color&quot;: &quot;blue&quot;, &quot;size&quot;: 35, &quot;salt&quot;: &quot;a94a8fe5ccb19ba61c4c0873d391e987982fbbd3&quot;&#125; We can also query the ledger to see the public ownership record: 我们还可以查询账本来查看公共记录： 1peer chaincode query -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;ReadAsset&quot;,&quot;Args&quot;:[&quot;asset1&quot;]&#125;&#x27; The command will return the record that the asset1 is owned by Org1: 这个命令会返回数据说明资产asset1属于Org1： 123456&#123; &quot;objectType&quot;: &quot;asset&quot;, &quot;assetID&quot;: &quot;asset1&quot;, &quot;ownerOrg&quot;: &quot;Org1MSP&quot;, &quot;publicDescription&quot;: &quot;A new asset for Org1MSP&quot;&#125; Because the market for assets is hot, Org1 wants to flip this asset and put it up for sale. As the asset owner, Org1 can update the public description to advertise that the asset is for sale. Run the following command to change the asset description: 因为资产市场很热，所以Org1希望翻转该资产并将其出售。作为资产的拥有者，Org1组织可以更新公共描述来广告说资产在出售。运行下面的命令来更新资产描述： 1peer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;ChangePublicDescription&quot;,&quot;Args&quot;:[&quot;asset1&quot;,&quot;This asset is for sale&quot;]&#125;&#x27; Query the ledger again to see the updated description: 重新查询账本来查看更新后的描述： 1peer chaincode query -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;ReadAsset&quot;,&quot;Args&quot;:[&quot;asset1&quot;]&#125;&#x27; We can now see that the asset is for sale: 我们现在可以看到这个资产在出售： 123456&#123; &quot;objectType&quot;: &quot;asset&quot;, &quot;assetID&quot;: &quot;asset1&quot;, &quot;ownerOrg&quot;: &quot;Org1MSP&quot;, &quot;publicDescription&quot;: &quot;This asset is for sale&quot;&#125; Figure 1: When Org1 creates an asset that they own, the asset details are stored in the Org1 implicit data collection on the Org1 peer. The public ownership record is stored in the channel world state, and is stored on both the Org1 and Org2 peers. A hash of the asset key and a hash the asset details are also visible in the channel world state and are stored on the peers of both organizations. 图片1:当组织Org1创建了一个属于他们的资产时，资产的细节保存在属于组织Org1的peer的隐式数据集合中。公共的记录被保存在通道的世界状态，并且保存在组织Org1和Org2的peer节点。资产的key的hash和资产详情的hash在通道的世界状态是可访问的，并且存储在所有组织的peer节点。 Operate from the Org2 terminal（通过组织Org2的终端操作） If we operate from the Org2 terminal, we can use the smart contract query the public asset data: 如果我们通过组织Org2的终端操作，我们可以使用智能合约来查询公共的资产数据： 1peer chaincode query -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;ReadAsset&quot;,&quot;Args&quot;:[&quot;asset1&quot;]&#125;&#x27; From this query, Org2 learns that asset1 is for sale（通过这个查询，组织Org2知道了资产asset1正在出售）: 123456&#123; &quot;objectType&quot;: &quot;asset&quot;, &quot;assetID&quot;: &quot;asset1&quot;, &quot;ownerOrg&quot;: &quot;Org1MSP&quot;, &quot;publicDescription&quot;: &quot;This asset is for sale&quot;&#125; In a real chaincode you may want to query for all assets for sale, by using a JSON query, or by creating a different sale key and using a key range query to find the assets currently for sale. Any changes to the public description of the asset owned by Org1 needs to be endorsed by Org1. The endorsement policy is reinforced by an access control policy within the chaincode that any update needs to be submitted by the organization that owns the asset. Lets see what happens if Org2 tried to change the public description as a prank: *在真实的链码中，您可能希望通过使用JSON查询或通过创建其他销售密钥并使用密钥的范围来查找当前待售资产，以查询所有待售资产。*所有属于组织Org1的资产的公共描述在进行任何更改时都必须得到组织Org1的认可。链码中的访问控制策略加强了背书策略，任何更新都必须由来自于资产拥有者的组织来提交。让我们看看如果Org2试图以恶作剧方式更改公共描述会发生什么： 1peer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;ChangePublicDescription&quot;,&quot;Args&quot;:[&quot;asset1&quot;,&quot;the worst asset&quot;]&#125;&#x27; The smart contract does not allow Org2 to access the public description of the asset. 智能合约不允许组织Org2访问这个资产的公共描述。 1Error: endorsement failure during invoke. response: status:500 message:&quot;a client from Org2MSP cannot update the description of a asset owned by Org1MSP&quot; Agree to sell the asset(允许出售资产) To sell an asset, both the buyer and the seller must agree on an asset price. Each party stores the price that they agree to in their own private data collection. The private asset transfer smart contract enforces that both parties need to agree to the same price before the asset can be transferred. 为了出售资产。买卖双方都必须同意相同的资产价格。每一方都需要在他们的私有数据集合中保存他们同意的价格。私有资产交易智能合约强制双方必须同意相同的价格才能转让资产。 Agree to sell as Org1（以Org1的身份同意出售） Operate from the Org1 terminal. Org1 will agree to set the asset price as 110 dollars. The trade_id is used as salt to prevent a channel member that is not a buyer or a seller from guessing the price. This value needs to be passed out of band, through email or other communication, between the buyer and the seller. The buyer and the seller can also add salt to the asset key to prevent other members of the channel from guessing which asset is for sale. 通过组织Org1的终端进行操作。Org1同意将资产价格设置为110美元。trade_id用作盐以防止不是买家或卖家的通道成员猜测价格。这个价格需要通过买卖双方之间以电子邮件或其他通信方式在账本外传递。买卖双方还可以对资产的key进行“加盐”，以防止渠道的其他成员猜测要出售的资产。 12export ASSET_PRICE=$(echo -n &quot;&#123;\\&quot;asset_id\\&quot;:\\&quot;asset1\\&quot;,\\&quot;trade_id\\&quot;:\\&quot;109f4b3c50d7b0df729d299bc6f8e9ef9066971f\\&quot;,\\&quot;price\\&quot;:110&#125;&quot; | base64)peer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;AgreeToSell&quot;,&quot;Args&quot;:[&quot;asset1&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_price\\&quot;:\\&quot;$ASSET_PRICE\\&quot;&#125;&quot; We can query the Org1 private data collection to read the agreed to selling price: 我们可以查询组织Org1的私有数据集合来读取同意的销售价格： 1peer chaincode query -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetSalesPrice&quot;,&quot;Args&quot;:[&quot;asset1&quot;]&#125;&#x27; Agree to buy as Org2(以Org2的身份同意购买) Operate from the Org2 terminal. Run the following command to verify the asset properties before agreeing to buy. The asset properties and salt would be passed out of band, through email or other communication, between the buyer and seller. 通过Org2的终端操作。运行下面的命令在同意购买之前验证资产的属性。资产的属性和盐会在区块链账本外在买卖双方之间通过邮件或者其他方式进行传递。 12export ASSET_PROPERTIES=$(echo -n &quot;&#123;\\&quot;object_type\\&quot;:\\&quot;asset_properties\\&quot;,\\&quot;asset_id\\&quot;:\\&quot;asset1\\&quot;,\\&quot;color\\&quot;:\\&quot;blue\\&quot;,\\&quot;size\\&quot;:35,\\&quot;salt\\&quot;:\\&quot;a94a8fe5ccb19ba61c4c0873d391e987982fbbd3\\&quot;&#125;&quot; | base64)peer chaincode query -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;VerifyAssetProperties&quot;,&quot;Args&quot;:[&quot;asset1&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_properties\\&quot;:\\&quot;$ASSET_PROPERTIES\\&quot;&#125;&quot; Run the following command to agree to buy asset1 for 100 dollars. As of now, Org2 will agree to a different price than Org2. Don’t worry, the two organizations will agree to the same price in a future step. However, we we can use this temporary disagreement as a test of what happens if the buyer and the seller agree to a different price. Org2 needs to use the same trade_id as Org1. 使用下面的命令来同意以100刀的价格购买asset1。现在Org2同意了一个与Org1不同的价格。不要担心，这两个组织会在接下来的步骤同意相同的价格。但是我们通过临时的分歧来测试如果买方和卖方同意了不同的价格将会发生什么。Org2需要使用与Org1相同的 trade_id 。 12export ASSET_PRICE=$(echo -n &quot;&#123;\\&quot;asset_id\\&quot;:\\&quot;asset1\\&quot;,\\&quot;trade_id\\&quot;:\\&quot;109f4b3c50d7b0df729d299bc6f8e9ef9066971f\\&quot;,\\&quot;price\\&quot;:100&#125;&quot; | base64)peer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;AgreeToBuy&quot;,&quot;Args&quot;:[&quot;asset1&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_price\\&quot;:\\&quot;$ASSET_PRICE\\&quot;&#125;&quot; You can read the agreed purchase price from the Org2 implicit data collection: 您可以从Org2隐式数据集合中读取约定的购买价格： 1peer chaincode query -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetBidPrice&quot;,&quot;Args&quot;:[&quot;asset1&quot;]&#125;&#x27; Figure 2: After Org1 and Org2 agree to transfer the asset, the price agreed to by each organization is stored in their private data collections. A composite key for the seller and the buyer is used to prevent a collision with the asset details and asset ownership record. The price that is agreed to is only stored on the peers of each organization. However, the hash of both agreements is stored in the channel world state on every peer joined to the channel. 图2:在Org1和Org2同意交易这个资产，每个组织的同意的价格被存储在他们的私有数据集合中。买卖双方的组合键用于防止与资产详细信息和资产所有权记录发生冲突。已经同意的价格只是存储在双方组织的peer节点。但是两个协议的hash值被存储在加入通道的所有peer节点的通道的世界状态中。 Transfer the asset from Org1 to Org2（把资产从Org1交易到Org2） After both organizations have agreed to their price, Org1 can attempt to transfer the asset to Org2. The private asset transfer function in the smart contract uses the hash on the ledger to check that both organizations have agreed to the same price. The function will also use the hash of the private asset details to check that the asset that is transferred is the same asset that Org1 owns. 在双方组织都同意了他们的价格之后，Org1可以尝试将资产交易给Org2。在智能合约中的私有资产交易方法使用账本上的hash来检查两个组织是否同意了相同的价格。这个方法也会使用私有资产详情的hash值来检查被交易的资产与属于Org1的资产是同一笔资产。 Transfer the asset as Org1（以Org1的身份交易资产） Operate from the Org1 terminal. The owner of the asset needs to initiate the transfer. Note that the command below uses the --peerAddresses flag to target the peers of both Org1 and Org2. Both organizations need to endorse the transfer. Also note that the asset properties and price are passed in the transfer request as transient properties. These are passed so that the current owner can be sure that the correct asset is transferred for the correct price. These properties will be checked against the on-chain hashes by both endorsers. 通过Org1的终端操作。资产的所有者需要发起这个交易。注意下面的命令使用--peerAddresses 标志来指定Org1和Org2的peer节点。两个组织都需要确认这个交易。另外请注意，资产属性和价格在交易请求中作为临时属性传递。传递这些是为了当前的拥有者可以确保以当前的价格来转让当前的资产。两个背书者将对照链上哈希检查这些属性。 1peer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;TransferAsset&quot;,&quot;Args&quot;:[&quot;asset1&quot;,&quot;Org2MSP&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_properties\\&quot;:\\&quot;$ASSET_PROPERTIES\\&quot;,\\&quot;asset_price\\&quot;:\\&quot;$ASSET_PRICE\\&quot;&#125;&quot; --peerAddresses localhost:7051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses localhost:9051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt Because the two organizations have not agreed to the same price, the transfer cannot be completed: 因为两个组织同意的价格不一致，这个交易不能完成： 1Error: endorsement failure during invoke. response: status:500 message:&quot;failed transfer verification: hash 0fc413250501855af7c9896af00993b973510995fb10d56cddbb85ca47bd5dba for passed price JSON &#123;\\&quot;asset_id\\&quot;:\\&quot;asset1\\&quot;,\\&quot;trade_id\\&quot;:\\&quot;109f4b3c50d7b0df729d299bc6f8e9ef9066971f\\&quot;,\\&quot;price\\&quot;:110&#125; does not match on-chain hash 84b0d57eaa5c77076483ae8f482c96a64912c47df5541451e94fb7698bf37ee9, buyer hasn&#x27;t agreed to the passed trade id and price&quot; As a result, Org1 and Org2 come to a new agreement on the price at which the asset will be purchased. Org1 drops the price of the asset to 100: 结果，Org1和Org2就购买资产的价格达成了新协议。 Org1将资产价格降至100： 12export ASSET_PRICE=$(echo -n &quot;&#123;\\&quot;asset_id\\&quot;:\\&quot;asset1\\&quot;,\\&quot;trade_id\\&quot;:\\&quot;109f4b3c50d7b0df729d299bc6f8e9ef9066971f\\&quot;,\\&quot;price\\&quot;:100&#125;&quot; | base64)peer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;AgreeToSell&quot;,&quot;Args&quot;:[&quot;asset1&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_price\\&quot;:\\&quot;$ASSET_PRICE\\&quot;&#125;&quot; Now that the buyer and seller have agreed to the same price, Org1 can transfer the asset to Org2. 现在买卖双方已经同意了相同的价格，Org1可以将资产交易给Org2。 1peer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;TransferAsset&quot;,&quot;Args&quot;:[&quot;asset1&quot;,&quot;Org2MSP&quot;]&#125;&#x27; --transient &quot;&#123;\\&quot;asset_properties\\&quot;:\\&quot;$ASSET_PROPERTIES\\&quot;,\\&quot;asset_price\\&quot;:\\&quot;$ASSET_PRICE\\&quot;&#125;&quot; --peerAddresses localhost:7051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses localhost:9051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt You can query the asset ownership record to verify that the transfer was successful. 你可以查询资产的归属信息来验证交易已经成功. 1peer chaincode query -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;ReadAsset&quot;,&quot;Args&quot;:[&quot;asset1&quot;]&#125;&#x27; The record now lists Org2 as the asset owner: 123456&#123; &quot;objectType&quot;: &quot;asset&quot;, &quot;assetID&quot;: &quot;asset1&quot;, &quot;ownerOrg&quot;: &quot;Org2MSP&quot;, &quot;publicDescription&quot;: &quot;This asset is for sale&quot;&#125; Figure 3: After the asset is transferred, the asset details are placed in the Org2 implicit data collection and deleted from the Org1 implicit data collection. As a result, the asset details are now only stored on the Org2 peer. The asset ownership record on the ledger is updated to reflect that the asset is owned by Org1. 图3:在资产交易之后，资产细节存在于Org2的隐式数据集合并且从Org1的隐式数据集合中被删除。结果，资产的私有信息值保存在Org2的peer节点。在账本上的资产的归属信息也被更新，以反映资产归Org2所有。 Update the asset description as Org2（以Org2的身份更新资产描述） Operate from the Org2 terminal. Now that Org2 owns the asset, we can read the asset details from the Org2 implicit data collection: 通过Org2的终端操作，现在Org2拥有这个资产，我们可以通过Org2的隐式数据集合读取资产的详情： 1peer chaincode query -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;GetAssetPrivateProperties&quot;,&quot;Args&quot;:[&quot;asset1&quot;]&#125;&#x27; Org2 can now update the asset public description（Org2现在可以更新资产的公共描述）: 1peer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;ChangePublicDescription&quot;,&quot;Args&quot;:[&quot;asset1&quot;,&quot;This asset is not for sale&quot;]&#125;&#x27; Query the ledger to verify that the asset is no longer for sale: 1peer chaincode query -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n secured -c &#x27;&#123;&quot;function&quot;:&quot;ReadAsset&quot;,&quot;Args&quot;:[&quot;asset1&quot;]&#125;&#x27; Clean up When you are finished transferring assets, you can bring down the test network. The command will remove all the nodes of the test network, and delete any ledger data that you created: 1.&#x2F;network.sh down 流程图 自己的理解画的流程图如下：","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"HOW-TO","slug":"区块链/Hyperledger-Fabric/HOW-TO","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/HOW-TO/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"Secured","slug":"Secured","permalink":"https://guozhe001.github.io/tags/Secured/"}]},{"title":"创建一个新的channel","slug":"blockchain/fabric/how_to/部署生产环境","date":"2024-11-22T06:32:06.494Z","updated":"2024-11-22T06:32:06.494Z","comments":true,"path":"2024/11/22/blockchain/fabric/how_to/部署生产环境/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/how_to/%E9%83%A8%E7%BD%B2%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83/","excerpt":"","text":"官方文档:deployment_guide_overview Deploying a production network Step one: Decide on your network configuration Step two: Set up a cluster for your resources Step three: Set up your CAs Step four: Use the CA to create identities and MSPs Step five: Deploy peers and ordering nodes Creating a peerCreating an ordering node Step one: Decide on your network configuration Certificate Authority configuration. Use Organizational Units or not? Database type. （相同的channel的peer节点必须使用相同的数据库） Channels and private data. Container orchestration. Chaincode deployment method（使用内置的部署方式还是外部的部署方式，如使用k8s部署） Using firewalls Step two: Set up a cluster for your resources Managing your infrastructure Using secret objects to securely store important configuration files in your cluster. （使用秘密对象将重要的配置文件安全地存储在群集中。） Cluster considerations and node sizing. How you choose to mount your volumes. It is a best practice to mount the volumes relevant to your nodes external to the place where your nodes are deployed. (您如何选择挂载卷。最佳实践是将与您的节点相关的卷挂载到部署节点的外部。) How you will monitor your resources. Step three: Set up your CAs The first component that must be deployed in a Fabric network is a CA. This is because the certificates associated with a node (not just for the node itself but also the certificates identifying who can administer the node) must be created before the node itself can be deployed. 必须在Fabric网络中部署的第一个组件是CA。这是因为必须先创建与节点关联的证书（不仅是针对节点本身的证书，而且还包括标识谁可以管理该节点的证书），然后才能部署节点本身。 One CA (or more, if you are using intermediate CAs — more on intermediate CAs below) is used to generate (through a process called “enrollment”) the certificates of the admin of an organization, the MSP of that organization, and any nodes owned by that organization. This CA will also generate the certificates for any additional users.This CA will also generate the certificates for any additional users. Because of its role in “enrolling” identities, this CA is sometimes called the “enrollment CA” or the “ecert CA”. 一个CA用于生成该组织管理员、该组织的MSP和该组织所拥有的任何节点的证书。该CA还将为任何其他用户生成证书。由于其在“注册”身份中的作用，因此有时将该CA称为“注册CA”或“证书CA”。 The other CA generates the certificates used to secure communications on Transport Layer Security (TLS).For this reason, this CA is often referred to as a “TLS CA”. These TLS certificates are attached to actions as a way of preventing “man in the middle” attacks. 另一个CA生成用于保护传输层安全性（TLS）上的通信的证书。因此，该CA通常被称为“ TLS CA”。将这些TLS证书附加到操作中，以防止“中间人”攻击。 Deploy a Production CA Planning for a CA Checklist for a production CA server CA deployment steps Step four: Use the CA to create identities and MSPs For each organization, you will need to, at a minimum: Register and enroll an admin identity and create an MSP. you must create the org admin identity before creating the local MSP of a node, since the certificate of the node admin must be used when creating the local MSP. Register and enroll node identities. Step five: Deploy peers and ordering nodes Before any node can be deployed, its configuration file must be customized. For the peer, this file is called core.yaml, while the configuration file for ordering nodes is called orderer.yaml. 在任何的节点可以被部署之前，必须先自定义配置文件。 peer节点的配置文件： core.yaml ordering节点的配置文件orderer.yaml You have three main options for tuning your configuration. Edit the YAML file bundled with the binaries. Use environment variable overrides when deploying. Specify flags on CLI commands. Creating a peer Among the parameters in core.yaml, there are: Identifiers: these include not just the paths to the relevant local MSP and Transport Layer Security (TLS) certificates, but also the name (known as the “peer ID”) of the peer and the MSP ID of the organization that owns the peer. Addresses and paths: because peers are not entities unto themselves but interact with other peers and components, you must specify a series of addresses in the configuration. These include addresses where the peer itself can be found by other components as well as the addresses where, for example, chaincodes can be found (if you are employing external chaincodes). Similarly, you will need to specify the location of your ledger (as well as your state database type) and the path to your external builders (again, if you intend to employ external chaincodes). These include Operations and metrics, which allow you to set up methods for monitoring the health and performance of your peer through the configuration of endpoints. Gossip: components in Fabric networks communicate with each other using the “gossip” protocol. Through this protocol, they can be discovered by the discovery service and disseminate blocks and private data to each other. Note that gossip communications are secured using TLS. Deploying a production peer Planning for a production peer Checklist for a production peer Deploy the peer Creating an ordering node Among the parameters in orderer.yaml, there are: Identifiers: these include not just the paths to the relevant local MSP and Transport Layer Security (TLS) certificates, but also the MSP ID of the organization that owns the ordering node. Addresses and paths: because ordering nodes interact with other components, you must specify a series of addresses in the configuration. These include addresses where the ordering node itself can be found by other components as well as Operations and metrics, which allow you to set up methods for monitoring the health and performance of your ordering node through the configuration of endpoints. Deploying a production ordering node Planning for an ordering service Checklist for a production ordering node Deploy the ordering service","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"HOW-TO","slug":"区块链/Hyperledger-Fabric/HOW-TO","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/HOW-TO/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"channel","slug":"channel","permalink":"https://guozhe001.github.io/tags/channel/"}]},{"title":"将智能合约部署到通道","slug":"blockchain/fabric/how_to/将智能合约部署到通道","date":"2024-11-22T06:32:06.494Z","updated":"2024-11-22T06:32:06.494Z","comments":true,"path":"2024/11/22/blockchain/fabric/how_to/将智能合约部署到通道/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/how_to/%E5%B0%86%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E9%83%A8%E7%BD%B2%E5%88%B0%E9%80%9A%E9%81%93/","excerpt":"","text":"Deploying a smart contract to a channel（将智能合约部署到通道） 参考文档 最终用户通过调用智能合约与区块链账本进行交互。在Hyperledger Fabric中，智能合约通过称为chaincode的软件包进行部署。一个组织想要验证交易或者查询账本的内容，就需要在其peer节点上部署chaincode。当一个已经安装了chaincode的节点加入channel之后，channel的成员就可以把chaincode部署到channel上，然后使用chaincode上的智能合约来创建和更新chanel账本上的资产。 我们使用一个叫做Fabric链码生命周期的程序来将chaincode部署到channel上；在链码可以被使用于交易之前，Fabric链码生命周期需要多个组织同意链码将如何操作。（个人理解：需要组织同意智能合约的内容，智能合约才能部署到channel上）举个例子，当一个背书策略制定哪些组织需要执行chaincode来验证一个交易时，channel上的成员需要使用Fabric链码生命周期来同意链码的背书策略。有关如何在通道上部署和管理链码的更深入的概述，请参阅Fabric chaincode lifecycle。 你可以使用 peer lifecycle chaincode commands这个教程来学习在Fabric测试网络中如何使用peer lifecycle chaincode commands来部署链码到channel。了解命令后，您可以使用本教程中的步骤将自己的链码部署到测试或生产网络。在这个教程中，你会部署教程Writing your first application tutorial使用的链码程序。 **注意：**当前教程使用v2.0版本中引入的Fabric链码生命周期。 Start the network（启动测试网络） 启动测试网络并创建channel，具体步骤参考Fabric测试网络使用。 你可以根据以下步骤使用节点的CLI来部署 asset-transfer (basic) 链码到channel中： [第一步：打包智能合约] [第二步：安装链码包] [第三步：批准链码定义] [第四部：提交链码定义到channel中] Setup Logspout (optional)（启动日志输出，可选） 此步骤不是必需的，但是对于故障排除链码非常有用。要监视智能合约的日志，管理员可以使用logspout查看一组Docker容器的聚合输出。这个工具收集不同的Docker容器的输出流到一个位置，这样就可以在一个窗口看这些容器都发生了什么。这可以帮助管理员在安装智能合约或者是开发人员调用智能合约时调试问题。因为某些容器的创建纯粹是为了启动智能合约，并且仅存在很短的时间，所以从网络中收集所有日志将很有帮助。 Fabric的商业票据示例中已经包含了用于安装和配置Logspout的脚本monitordocker.sh。在本教程中，我们还将使用相同的脚本。Logspout工具将持续向您的终端流式传输日志，因此您将需要使用新的终端窗口。打开一个新终端，然后导航到test-network目录。 1cd fabric-samples/test-network 你可以在任何目录下运行 monitordocker.sh脚本，为了方便使用我们把 monitordocker.sh 从commercial-paper拷贝到你的工作目录(test-network)。 1cp ../commercial-paper/organization/digibank/configuration/cli/monitordocker.sh . 你可以使用下面的命令来启动Logspout： 1./monitordocker.sh net_test 你会看到类似下面的输出： 123456789Starting monitoring on all containers on the network net_basicUnable to find image &#x27;gliderlabs/logspout:latest&#x27; locallylatest: Pulling from gliderlabs/logspout4fe2ade4980c: Pull completedecca452f519: Pull completead60f6b6c009: Pull completeDigest: sha256:374e06b17b004bddc5445525796b5f7adb8234d64c5c5d663095fccafb6e4c26Status: Downloaded newer image for gliderlabs/logspout:latest1f99d130f15cf01706eda3e1f040496ec885036d485cb6bcc0da4a567ad84361 在我们部署链码之前你不会看到太多的日志。 Package the smart contract（打包智能合约） We need to package the chaincode before it can be installed on our peers. The steps are different if you want to install a smart contract written in Go, JavaScript, or Typescript. 在把智能合约安装到我们的节点之前需要先将其打包。根据编写智能合约的语言的不同，其步骤也是不一样的。（本次只使用Go，其他语言如Go, JavaScript, or Typescript请参考官方文档） Go 在我们打包链码之前，我们需要先安装链码的依赖。切换到Go版本的 asset-transfer (basic) 项目目录下： 1cd fabric-samples/asset-transfer-basic/chaincode-go 该示例使用Go模块来安装chaincode依赖项。依赖关系列在asset-transfer-basic / chaincode-go目录的go.mod文件中。您应该花一点时间来检查此文件。 1234567891011module github.com/hyperledger/fabric-samples/asset-transfer-basic/chaincode-gogo 1.14require ( github.com/golang/protobuf v1.3.2 github.com/hyperledger/fabric-chaincode-go v0.0.0-20200424173110-d7076418f212 github.com/hyperledger/fabric-contract-api-go v1.1.0 github.com/hyperledger/fabric-protos-go v0.0.0-20200424173316-dd554ba3746e github.com/stretchr/testify v1.5.1) go.mod文件将Fabric合约API导入到智能合约包中。你可以打开asset-transfer-basic/chaincode-go/chaincode/smartcontract.go来查看在智能合约的最开始是如使用contract API来定义SmartContract类的。 1234// SmartContract provides functions for managing an Assettype SmartContract struct &#123; contractapi.Contract&#125; 然后，将SmartContract类型用于为智能合约中定义的方法创建交易上下文，该方法可将数据读取和写入区块链账本。 12345678910111213141516171819202122232425// CreateAsset issues a new asset to the world state with given details.func (s *SmartContract) CreateAsset(ctx contractapi.TransactionContextInterface, id string, color string, size int, owner string, appraisedValue int) error &#123; exists, err := s.AssetExists(ctx, id) if err != nil &#123; return err &#125; if exists &#123; return fmt.Errorf(&quot;the asset %s already exists&quot;, id) &#125; asset := Asset&#123; ID: id, Color: color, Size: size, Owner: owner, AppraisedValue: appraisedValue, &#125; assetJSON, err := json.Marshal(asset) if err != nil &#123; return err &#125; return ctx.GetStub().PutState(id, assetJSON)&#125; 你可以通过访问 API documentation 和 smart contract processing topic来学习更多的关于合约API的内容。 为了安装智能合约的依赖，在asset-transfer-basic/chaincode-go 目录下运行下面的命令： 1GO111MODULE=on go mod vendor 如果命令成功，则go软件包将安装vendor文件夹中。 现在我们已经有了依赖的包，我们可以创建chaincode的包了。把当前目录切换到test-network 以便我们可以将链码于其他网络组件打包在一起。 1cd ..&#x2F;..&#x2F;test-network You can use the peer CLI to create a chaincode package in the required format. The peer binaries are located in the bin folder of the fabric-samples repository. Use the following command to add those binaries to your CLI Path: 您可以使用peerCLI创建所需格式的链码包。peer二进制文件位于fabric-samples存储库的bin文件夹中。可以使用下面的命令添加到你的环境变量中。 1export PATH=$&#123;PWD&#125;/../bin:$PATH 您还需要将FABRIC_CFG_PATH设置为指向fabric-samples存储库中的core.yaml文件： 1export FABRIC_CFG_PATH=$PWD/../config/ 使用下面的命令来查看peer的版本，如果输出正常说明你已经可以使用peerCLI了。 1peer version You can now create the chaincode package using the peer lifecycle chaincode package command: 现在你可以通过 peer lifecycle chaincode package 命令来创建链码包了: 1peer lifecycle chaincode package basic.tar.gz --path ../asset-transfer-basic/chaincode-go/ --lang golang --label basic_1.0 This command will create a package named basic.tar.gz in your current directory. The --lang flag is used to specify the chaincode language and the --path flag provides the location of your smart contract code. The path must be a fully qualified path or a path relative to your present working directory. The --label flag is used to specify a chaincode label that will identity your chaincode after it is installed. It is recommended that your label include the chaincode name and version. 这个命令会在你的当前目录下创建一个名为basic.tar.gz的压缩包。--lang标志是制定chaincode的语言，而--path 标志用于提供智能合约代码的位置。该路径必须是标准路径或相对于您当前工作目录的路径。--label标志用于指定一个链码标签，该标签将在安装链码后对其进行标识。建议您的标签包含链码名称和版本。 Now that we created the chaincode package, we can install the chaincode on the peers of the test network. 现在我们已经创建了链码包，我们可以把链码安装到网络上的节点上了。 Install the chaincode package（安装链码包） After we package the asset-transfer (basic) smart contract, we can install the chaincode on our peers. The chaincode needs to be installed on every peer that will endorse a transaction. Because we are going to set the endorsement policy to require endorsements from both Org1 and Org2, we need to install the chaincode on the peers operated by both organizations: 在我们打包了 asset-transfer (basic) 的智能合约之后，我们就可以将此链码安装到我们的peer节点上了。需要在所有的交易背书节点上安装链码。因为我们将设置背书策略要求来自Org1和Org2的背书，所以我们需要在两个组织运营的对等方上安装链码： peer0.org1.example.com peer0.org2.example.com Let’s install the chaincode on the Org1 peer first. Set the following environment variables to operate the peer CLI as the Org1 admin user. The CORE_PEER_ADDRESS will be set to point to the Org1 peer, peer0.org1.example.com. 让我们先把链码安装到Org1的节点上。设置以下环境变量来使用Org1的admin用户的身份运行peerCLI。将CORE_PEER_ADDRESS设置为指向Org1的节点的peer0.org1.example.com。 12345export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=localhost:7051 Issue the peer lifecycle chaincode install command to install the chaincode on the peer: 发出在peer节点上安装链码的命令： 1peer lifecycle chaincode install basic.tar.gz If the command is successful, the peer will generate and return the package identifier. This package ID will be used to approve the chaincode in the next step. You should see output similar to the following: 如果命令执行成功，则peer将生成并返回安装包的标识符。这个包的ID会在下一步批准这个链码时使用。你会看到类似下面的输出： 122020-12-21 14:46:18.360 CST [cli.lifecycle.chaincode] submitInstallProposal -&gt; INFO 001 Installed remotely: response:&lt;status:200 payload:&quot;\\nJbasic_1.0:2c47b5b060a64aafa3c878b4bcb0ca680bdb2417ca8855b5440fa595562517d2\\022\\tbasic_1.0&quot; &gt;2020-12-21 14:46:18.361 CST [cli.lifecycle.chaincode] submitInstallProposal -&gt; INFO 002 Chaincode code package identifier: basic_1.0:2c47b5b060a64aafa3c878b4bcb0ca680bdb2417ca8855b5440fa595562517d2 在运行monitordocker.sh的终端可以看到下面的日志： 1234peer0.org1.example.com|2020-12-21 06:46:18.363 UTC [lifecycle] InstallChaincode -&gt; INFO 046 Successfully installed chaincode with package ID &#x27;basic_1.0:2c47b5b060a64aafa3c878b4bcb0ca680bdb2417ca8855b5440fa595562517d2&#x27;peer0.org1.example.com|2020-12-21 06:46:18.363 UTC [endorser] callChaincode -&gt; INFO 047 finished chaincode: _lifecycle duration: 35751ms channel= txID=26a66cb7peer0.org1.example.com|2020-12-21 06:46:18.363 UTC [comm.grpc.server] 1 -&gt; INFO 048 unary call completed grpc.service=protos.Endorser grpc.method=ProcessProposal grpc.peer_address=172.19.0.1:62970 grpc.code=OK grpc.call_duration=35.752599039s We can now install the chaincode on the Org2 peer. Set the following environment variables to operate as the Org2 admin and target target the Org2 peer, peer0.org2.example.com. 现在我们把链码安装到Org2组织的peer节点上。先设置环境变量让我们可以以Org2的管理员身份来操作Org2的节点： 12345export CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtexport CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_ADDRESS=localhost:9051 Issue the following command to install the chaincode（发出以下命令来安装链码）: 1peer lifecycle chaincode install basic.tar.gz The chaincode is built by the peer when the chaincode is installed. The install command will return any build errors from the chaincode if there is a problem with the smart contract code. 在安装链码时，由peer节点来构建链码。如果智能合约有问题，安装命令会把所有构建的错误返回。 Approve a chaincode definition（批准链码定义） After you install the chaincode package, you need to approve a chaincode definition for your organization. The definition includes the important parameters of chaincode governance such as the name, version, and the chaincode endorsement policy. 在安装链码包之后，需要你所在的组织批准链码的定义。这个定义包括链码管理的重要参数，例如名称、版本以及链码的背书策略。 The set of channel members who need to approve a chaincode before it can be deployed is governed by the Application/Channel/lifeycleEndorsement policy.By default, this policy requires that a majority of channel members need to approve a chaincode before it can used on a channel.Because we have only two organizations on the channel, and a majority of 2 is 2, we need approve a chaincode definition of asset-transfer (basic) as Org1 and Org2. 在channel上的哪些成员需要在其可以部署链码之前批准，是定义在Application/Channel/lifeycleEndorsement策略中。默认情况下，此策略要求大多数channel的成员需要批准链码后才能在频道上使用。因为在我们的channel上只有两个组织，并且大多数就是2，我们需要以Org1和Org2的身份来批准asset-transfer (basic)的链码定义。 If an organization has installed the chaincode on their peer, they need to include the packageID in the chaincode definition approved by their organization. The package ID is used to associate the chaincode installed on a peer with an approved chaincode definition, and allows an organization to use the chaincode to endorse transactions. You can find the package ID of a chaincode by using the peer lifecycle chaincode queryinstalled command to query your peer. 如果一个组织已经在其peer节点上安装了链码，这个组织需要在其批准的链码定义中包含packageID。packageID是用来把安装在节点上的chaincode和已经批准通过的链码定义关联起来的，并且允许一个组织在背书节点使用这个链码。你可以使用peer lifecycle chaincode queryinstalled 命令在你的peer节点上查询一个链码的packageID。 1peer lifecycle chaincode queryinstalled The package ID is the combination of the chaincode label and a hash of the chaincode binaries. Every peer will generate the same package ID. You should see output similar to the following: packageID是链码标签和链码二进制文件的哈希值的组合。每个peer将生成相同的程序包ID。您应该看到类似于以下内容的输出： 12Installed chaincodes on peer:Package ID: basic_1.0:2c47b5b060a64aafa3c878b4bcb0ca680bdb2417ca8855b5440fa595562517d2, Label: basic_1.0 We are going to use the package ID when we approve the chaincode, so let’s go ahead and save it as an environment variable. Paste the package ID returned by peer lifecycle chaincode queryinstalled into the command below. Note: The package ID will not be the same for all users, so you need to complete this step using the package ID returned from your command window in the previous step. 在我们批准链码时我们需要使用这个 package ID，所以让我们先把它保存为一个环境变量： 1export CC_PACKAGE_ID=basic_1.0:2c47b5b060a64aafa3c878b4bcb0ca680bdb2417ca8855b5440fa595562517d2 Because the environment variables have been set to operate the peer CLI as the Org2 admin, we can approve the chaincode definition of asset-transfer (basic) as Org2. Chaincode is approved at the organization level, so the command only needs to target one peer. The approval is distributed to the other peers within the organization using gossip. Approve the chaincode definition using the peer lifecycle chaincode approveformyorg command: 因为当前的环境变量已经设置为以Org2组织的管理员来操作peerCLI，我们可以以组织Org2的身份批准这个asset-transfer (basic)的链码定义。链码是在组织的级别进行批准的，所以这个命令只需要针对一个peer节点即可。这个批准的动作会使用gossip来在组织内部传播。使用 peer lifecycle chaincode approveformyorg命令来批准链码定义： 1peer lifecycle chaincode approveformyorg -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --channelID mychannel --name basic --version 1.0 --package-id $CC_PACKAGE_ID --sequence 1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem The command above uses the --package-id flag to include the package identifier in the chaincode definition. The --sequence parameter is an integer that keeps track of the number of times a chaincode has been defined or updated. Because the chaincode is being deployed to the channel for the first time, the sequence number is 1. When the asset-transfer (basic) chaincode is upgraded, the sequence number will be incremented to 2. If you are using the low level APIs provided by the Fabric Chaincode Shim API, you could pass the --init-required flag to the command above to request the execution of the Init function to initialize the chaincode. The first invoke of the chaincode would need to target the Init function and include the --isInit flag before you could use the other functions in the chaincode to interact with the ledger. 上面的命令使用--package-id标志将软件包标识符包含在链码定义中。--sequence参数是一个整数，用于跟踪定义或更新链码的次数；由于链码是第一次部署到channel，因此序列号为1。当asset-transfer (basic) 的链码在更新时，这个序列号会增加到2。链代码的首次调用需要使用--isInit来指明调用链码的Init函数，然后才能使用链代码中的其他函数与账本进行交互。 We could have provided a --signature-policy or --channel-config-policy argument to the approveformyorg command to specify a chaincode endorsement policy. The endorsement policy specifies how many peers belonging to different channel members need to validate a transaction against a given chaincode. Because we did not set a policy, the definition of asset-transfer (basic) will use the default endorsement policy, which requires that a transaction be endorsed by a majority of channel members present when the transaction is submitted. This implies that if new organizations are added or removed from the channel, the endorsement policy is updated automatically to require more or fewer endorsements. In this tutorial, the default policy will require a majority of 2 out of 2 and transactions will need to be endorsed by a peer from Org1 and Org2. If you want to specify a custom endorsement policy, you can use the Endorsement Policies operations guide to learn about the policy syntax. 我们可以在approveformyorg命令中提供--signature-policy或--channel-config-policy参数，以指定链码背书策略。背书策略指定需要多少个属于不同渠道成员的peer根据给定的链码验证来交易。因为我们没有指定合格策略，asset-transfer (basic) 的定义会使用默认的背书策略，该政策要求在提交交易时，该交易必须得到channel中大多数成员的认可。这意味着，如果在channel中添加或删除组织，则背书政策会自动更新，以要求更多或更少的认可。在本教程中，默认策略需要2个中的大多数也就是2，并且交易需要由来自Org1和Org2的peer认可。如果要指定自定义认可策略，则可以使用 Endorsement Policies 操作指南来了解策略语法。 You need to approve a chaincode definition with an identity that has an admin role. As a result, the CORE_PEER_MSPCONFIGPATH variable needs to point to the MSP folder that contains an admin identity. You cannot approve a chaincode definition with a client user. The approval needs to be submitted to the ordering service, which will validate the admin signature and then distribute the approval to your peers. 你需要使用具有管理员角色的身份来批准的链码定义。即CORE_PEER_MSPCONFIGPATH变量需要指向包含管理员身份的MSP文件夹。你不能使用客户端用户的身份来批准链码。这个审批结果需要提交给排序服务，排序服务会验证管理员的签名，然后分发这个验证结果到你的peer节点。 We still need to approve the chaincode definition as Org1. Set the following environment variables to operate as the Org1 admin: 你还需要在组织Org1上批准这个链码定义，把环境变量修改为以组织Org1的管理员身份来操作： 1234export CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crtexport CORE_PEER_ADDRESS=localhost:7051 You can now approve the chaincode definition as Org1. 现在你可以以组织Org1的身份批准链码定义了。 1peer lifecycle chaincode approveformyorg -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --channelID mychannel --name basic --version 1.0 --package-id $CC_PACKAGE_ID --sequence 1 --tls --cafile $&#123;PWD&#125;&#x2F;organizations&#x2F;ordererOrganizations&#x2F;example.com&#x2F;orderers&#x2F;orderer.example.com&#x2F;msp&#x2F;tlscacerts&#x2F;tlsca.example.com-cert.pem We now have the majority we need to deploy the asset-transfer (basic) the chaincode to the channel. While only a majority of organizations need to approve a chaincode definition (with the default policies), all organizations need to approve a chaincode definition to start the chaincode on their peers. If you commit the definition before a channel member has approved the chaincode, the organization will not be able to endorse transactions. As a result, it is recommended that all channel members approve a chaincode before committing the chaincode definition. 现在我们已经有了将asset-transfer (basic) 的链码部署到渠道的大多数的批准。在将链码定义部署到channel上时，我们需要大多数组织的批准（使用默认的策略）；但是所有的组织都需批准链码定义才能在其peer启动这个链码。如果你在一个channel成员批准定义之前将链码定义提交到channel，那么这个组织将无法批准交易。结果，建议所有通道成员在提交链码定义之前批准链码。 Committing the chaincode definition to the channel（将链码定义提交到通道） After a sufficient number of organizations have approved a chaincode definition, one organization can commit the chaincode definition to the channel. If a majority of channel members have approved the definition, the commit transaction will be successful and the parameters agreed to in the chaincode definition will be implemented on the channel. 在有足够数量的组织批准链码定义之后，其中一个组织就可以把链码定义提交到通道中了。如果大多数通道成员已批准该定义，则提交定义的交易将会成功，并且链码定义中同意的参数将在该通道上实现。 You can use the peer lifecycle chaincode checkcommitreadiness command to check whether channel members have approved the same chaincode definition. The flags used for the checkcommitreadiness command are identical to the flags used to approve a chaincode for your organization. However, you do not need to include the --package-id flag. 你可以使用 peer lifecycle chaincode checkcommitreadiness命令来检查channel上的成员是否已经批准了相同的链码定义。用于checkcommitreadiness命令的标志与您的组织批准链码的标志相同；但是不需要包括--package-id标志。 1peer lifecycle chaincode checkcommitreadiness --channelID mychannel --name basic --version 1.0 --sequence 1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem --output json The command will produce a JSON map that displays if a channel member has approved the parameters that were specified in the checkcommitreadiness command: 这个命令会生成一个JSON来显示通道成员是否已经批准了定义。 123456&#123; &quot;Approvals&quot;: &#123; &quot;Org1MSP&quot;: true, &quot;Org2MSP&quot;: true &#125; &#125; Since both organizations that are members of the channel have approved the same parameters, the chaincode definition is ready to be committed to the channel. You can use the peer lifecycle chaincode commit command to commit the chaincode definition to the channel. The commit command also needs to be submitted by an organization admin. 因为channel上的两个成员都已经批准了相同的参数，因此链码定义已准备好提交给channel。你可以使用peer lifecycle chaincode commit 命令将链码定义提交到channel。commit命令依然需要由组织管理员来发起。 1peer lifecycle chaincode commit -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --channelID mychannel --name basic --version 1.0 --sequence 1 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem --peerAddresses localhost:7051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses localhost:9051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt The transaction above uses the --peerAddresses flag to target peer0.org1.example.com from Org1 and peer0.org2.example.com from Org2. The commit transaction is submitted to the peers joined to the channel to query the chaincode definition that was approved by the organization that operates the peer. The command needs to target the peers from a sufficient number of organizations to satisfy the policy for deploying a chaincode. Because the approval is distributed within each organization, you can target any peer that belongs to a channel member. 上面的交易使用--peerAddresses标志来指定Org1中的peer0.org1.example.com和Org2中的peer0.org2.example.com。 commit 交易会提交给已经加入通道的peer节点，用于peer节点查询同组织内其他节点批准的链码定义。该命令需要指明来自足够数量的组织中的peer节点，以满足部署链码的策略。因为批准操作已经在每个组织内部进行广播，所以你可以指定属于一个通道成员的任意的peer节点。 The chaincode definition endorsements by channel members are submitted to the ordering service to be added to a block and distributed to the channel. The peers on the channel then validate whether a sufficient number of organizations have approved the chaincode definition. The peer lifecycle chaincode commit command will wait for the validations from the peer before returning a response. 通道成员对链码定义的认可会提交给排序服务，以添加到区块并分发给渠道。然后通道上的peer节点验证是否有足够数量的组织批准了链码定义。peer lifecycle chaincode commit命令在返回相应之前会等待peer节点的验证。 You can use the peer lifecycle chaincode querycommitted command to confirm that the chaincode definition has been committed to the channel. 你可以使用 peer lifecycle chaincode querycommitted 命令来确认链码定义已经提交到通道。 1peer lifecycle chaincode querycommitted --channelID mychannel --name basic --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem If the chaincode was successful committed to the channel, the querycommitted command will return the sequence and version of the chaincode definition: 如果链码已经成功提交到通道，querycommitted 命令会返回该链码定义的序列号和版本号： 12Committed chaincode definition for chaincode &#x27;basic&#x27; on channel &#x27;mychannel&#x27;:Version: 1.0, Sequence: 1, Endorsement Plugin: escc, Validation Plugin: vscc, Approvals: [Org1MSP: true, Org2MSP: true] Invoking the chaincode（调用链码） After the chaincode definition has been committed to a channel, the chaincode will start on the peers joined to the channel where the chaincode was installed. The asset-transfer (basic) chaincode is now ready to be invoked by client applications. Use the following command create an initial set of assets on the ledger. Note that the invoke command needs target a sufficient number of peers to meet chaincode endorsement policy. 在链码定义提交到通道之后，链码可以由加入了通道并且安装了此链码的peer节点来启动。 asset-transfer (basic) 的链码已经可以由客户端程序进行调用。使用以下命令在账本上创建和初始化资产。请注意，invoke命令需要以足够数量的peer为目标，以满足链码的背书策略。 1peer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n basic --peerAddresses localhost:7051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses localhost:9051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;InitLedger&quot;,&quot;Args&quot;:[]&#125;&#x27; If the command is successful, you should be able to a response similar to the following: 如果命令执行成功，你会看到类似下面的响应： 12020-12-21 16:51:11.086 CST [chaincodeCmd] chaincodeInvokeOrQuery -&gt; INFO 001 Chaincode invoke successful. result: status:200 We can use a query function to read the set of cars that were created by the chaincode: 我们使用查询方法来查看我们通过链码创建的车： 1peer chaincode query -C mychannel -n basic -c &#x27;&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;&#x27; The response to the query should be the following list of assets: 下面的资产列表就是查询的响应结果： 1[&#123;&quot;ID&quot;:&quot;asset1&quot;,&quot;color&quot;:&quot;blue&quot;,&quot;size&quot;:5,&quot;owner&quot;:&quot;Tomoko&quot;,&quot;appraisedValue&quot;:300&#125;,&#123;&quot;ID&quot;:&quot;asset2&quot;,&quot;color&quot;:&quot;red&quot;,&quot;size&quot;:5,&quot;owner&quot;:&quot;Brad&quot;,&quot;appraisedValue&quot;:400&#125;,&#123;&quot;ID&quot;:&quot;asset3&quot;,&quot;color&quot;:&quot;green&quot;,&quot;size&quot;:10,&quot;owner&quot;:&quot;Jin Soo&quot;,&quot;appraisedValue&quot;:500&#125;,&#123;&quot;ID&quot;:&quot;asset4&quot;,&quot;color&quot;:&quot;yellow&quot;,&quot;size&quot;:10,&quot;owner&quot;:&quot;Max&quot;,&quot;appraisedValue&quot;:600&#125;,&#123;&quot;ID&quot;:&quot;asset5&quot;,&quot;color&quot;:&quot;black&quot;,&quot;size&quot;:15,&quot;owner&quot;:&quot;Adriana&quot;,&quot;appraisedValue&quot;:700&#125;,&#123;&quot;ID&quot;:&quot;asset6&quot;,&quot;color&quot;:&quot;white&quot;,&quot;size&quot;:15,&quot;owner&quot;:&quot;Michel&quot;,&quot;appraisedValue&quot;:800&#125;] Upgrading a smart contract（更新智能合约） You can use the same Fabric chaincode lifecycle process to upgrade a chaincode that has already been deployed to a channel. Channel members can upgrade a chaincode by installing a new chaincode package and then approving a chaincode definition with the new package ID, a new chaincode version, and with the sequence number incremented by one. The new chaincode can be used after the chaincode definition is committed to the channel. This process allows channel members to coordinate on when a chaincode is upgraded, and ensure that a sufficient number of channel members are ready to use the new chaincode before it is deployed to the channel. 您可以使用相同的Fabric链码生命周期流程来升级已经部署到通道的链码。通道成员可以通过以下方式升级链码：安装新的链码包，然后批准这个具有新packageID、新链码版本以及序列号加1的链码定义。在链码定义被提交给通道后新的链码就可以被使用。此过程允许通道成员在升级链码时进行协调，并确保在将新链码部署到通道之前，有足够数量的通道成员准备使用新链码。 Channel members can also use the upgrade process to change the chaincode endorsement policy. By approving a chaincode definition with a new endorsement policy and committing the chaincode definition to the channel, channel members can change the endorsement policy governing a chaincode without installing a new chaincode package. 通道成员也可以使用这个更新流程来修改链码的背书策略。通过批准具有新背书策略的链码定义并将其提交给渠道，渠道成员可以更改背书策略而无需安装新的链码包。 To provide a scenario for upgrading the asset-transfer (basic) chaincode that we just deployed,let’s assume that Org1 and Org2 would like to install a version of the chaincode that is written in another language. They will use the Fabric chaincode lifecycle to update the chaincode version and ensure that both organizations have installed the new chaincode before it becomes active on the channel. 为了提供一个我们刚才部署的asset-transfer (basic) 链码升级的情景，让我们假设Org1和Org2想要安装一个通过其他语言编写的链码版本。他们会使用Fabric链码生命周期来更新链码的版本并且在新链码可用于通道之前确保所有的组织已经安装了新的链码。 We are going to assume that Org1 and Org2 initially installed the GO version of the asset-transfer (basic) chaincode, but would be more comfortable working with a chaincode written in JavaScript. The first step is to package the JavaScript version of the asset-transfer (basic) chaincode. If you used the JavaScript instructions to package your chaincode when you went through the tutorial, you can install new chaincode binaries by following the steps for packaging a chaincode written in Go or TypeScript. 我们假设Org1和Org2最初安装了asset-transfer (basic) GO版本的链码，但使用JavaScript编写的链码会更舒适。第一步就是打包JavaScript版本的asset-transfer (basic) 链码。 Issue the following commands from the test-network directory to install the chaincode dependences. 在test-network 目录下运行下面的命令来安装链码的依赖。 123cd ../asset-transfer-basic/chaincode-javascriptnpm installcd ../../test-network 打包 You can then issue the following commands to package the JavaScript chaincode from the test-network directory. We will set the environment variables needed to use the peer CLI again in case you closed your terminal. 然后你可以在test-network 目录下运行下面的命令来打包JavaScript版本的链码。在运行命令之前先参考前面的内容来设置可以操作Org1的环境变量。 1peer lifecycle chaincode package basic_2.tar.gz --path ../asset-transfer-basic/chaincode-javascript/ --lang node --label basic_2.0 安装 We can now use the following command to install the new chaincode package on the Org1 peer. 你可以在Org1组织的peer节点通过下面的命令来安装一个新的链码包。 1peer lifecycle chaincode install basic_2.tar.gz The new chaincode package will create a new package ID. We can find the new package ID by querying our peer. 新的链码包会创建一个新的package ID，我们通过查询peer来获取新的package ID。 1peer lifecycle chaincode queryinstalled The queryinstalled command will return a list of the chaincode that have been installed on your peer similar to this output. queryinstalled 命令会返回你的peer已经安装的链码，输出类似如下： 123Installed chaincodes on peer:Package ID: basic_1.0:2c47b5b060a64aafa3c878b4bcb0ca680bdb2417ca8855b5440fa595562517d2, Label: basic_1.0Package ID: basic_2.0:59cb45985332d79a903ef39d710eeb23a1c63bddaf8cd999481071457d22acbd, Label: basic_2.0 You can use the package label to find the package ID of the new chaincode and save it as a new environment variable. This output is for example only – your package ID will be different, so DO NOT COPY AND PASTE! 你可以把新的 package ID保存为一个新的环境变量。下面的命令只是一个例子，不要直接copy。 1export NEW_CC_PACKAGE_ID&#x3D;basic_2.0:59cb45985332d79a903ef39d710eeb23a1c63bddaf8cd999481071457d22acbd 批准链码定义 Org1 can now approve a new chaincode definition（Org1现在可以批准这个新的链码定义）: 1peer lifecycle chaincode approveformyorg -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --channelID mychannel --name basic --version 2.0 --package-id $NEW_CC_PACKAGE_ID --sequence 2 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem The new chaincode definition uses the package ID of the JavaScript chaincode package and updates the chaincode version. Because the sequence parameter is used by the Fabric chaincode lifecycle to keep track of chaincode upgrades, Org1 also needs to increment the sequence number from 1 to 2. You can use the peer lifecycle chaincode querycommitted command to find the sequence of the chaincode that was last committed to the channel. 新的链码定义使用JavaScript版本的链码包的packageID以及新的链码版本。由于Fabric链码生命周期使用序列号来跟踪链码升级，因此Org1还需要将序列号从1递增到2。你可以使用 peer lifecycle chaincode querycommitted命令来查询链码上次提交到通道的序列号。 We now need to install the chaincode package and approve the chaincode definition as Org2 in order to upgrade the chaincode. Run the following commands to operate the peer CLI as the Org2 admin: 我们现在需要以Org2组织的身份来安装链码并且批准链码定义来更新链码，运行下面的命令来使用Org2组织的管理员进行操作： 12345export CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtexport CORE_PEER_TLS_ROOTCERT_FILE=$&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=$&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_ADDRESS=localhost:9051 其他组织安装链码 We can now use the following command to install the new chaincode package on the Org2 peer. 我们现在就可以使用下面的命令来安装新的链码包到Org2组织的peer上。 1peer lifecycle chaincode install basic_2.tar.gz 批准链码定义 You can now approve the new chaincode definition for Org2. 我们现在可以为Org2组织批准这个新的链码定义。 1peer lifecycle chaincode approveformyorg -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --channelID mychannel --name basic --version 2.0 --package-id $NEW_CC_PACKAGE_ID --sequence 2 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem Use the peer lifecycle chaincode checkcommitreadiness command to check if the chaincode definition with sequence 2 is ready to be committed to the channel: 使用peer lifecycle chaincode checkcommitreadiness 敏玲来检查序列号为2的链码定义是否已经准备好被提交到channel上： 1peer lifecycle chaincode checkcommitreadiness --channelID mychannel --name basic --version 2.0 --sequence 2 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem --output json The chaincode is ready to be upgraded if the command returns the following JSON: 如果这个命令返回以下内容，说明已经准备好更新了： 123456&#123; &quot;approvals&quot;: &#123; &quot;Org1MSP&quot;: true, &quot;Org2MSP&quot;: true &#125;&#125; The chaincode will be upgraded on the channel after the new chaincode definition is committed. Until then, the previous chaincode will continue to run on the peers of both organizations. Org2 can use the following command to upgrade the chaincode: 在新的链码定义提交后，通道上的链码将会升级。在此之前，先前的链码将继续在两个组织的peer上运行。Org2组织可以使用下面的命令来更新链码： 1peer lifecycle chaincode commit -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --channelID mychannel --name basic --version 2.0 --sequence 2 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem --peerAddresses localhost:7051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses localhost:9051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt A successful commit transaction will start the new chaincode right away. If the chaincode definition changed the endorsement policy, the new policy would be put in effect. 成功的提交的交易将立即启动新的链码。如果链码定义更改了背书策略，则新政策将生效。 You can use the docker ps command to verify that the new chaincode has started on your peers: 你现在可以使用 docker ps 命令来验证新的链码已经在你的peer节点启动。 12345678$docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES2e253d5141c3 dev-peer0.org2.example.com-basic_2.0-59cb45985332d79a903ef39d710eeb23a1c63bddaf8cd999481071457d22acbd-c00efc2e7c009601f23247ba3330c47fc5b737d476f8233da9b404c28681847b &quot;docker-entrypoint.s…&quot; 2 minutes ago Up 2 minutes dev-peer0.org2.example.com-basic_2.0-59cb45985332d79a903ef39d710eeb23a1c63bddaf8cd999481071457d22acbdcb7260fc3aa6 dev-peer0.org1.example.com-basic_2.0-59cb45985332d79a903ef39d710eeb23a1c63bddaf8cd999481071457d22acbd-ececda85b7ddf5cad9e5cbca808ffe76bc0b4b0d3067c345afa365a764b062ff &quot;docker-entrypoint.s…&quot; 2 minutes ago Up 2 minutes dev-peer0.org1.example.com-basic_2.0-59cb45985332d79a903ef39d710eeb23a1c63bddaf8cd999481071457d22acbdee12e6769e93 gliderlabs/logspout &quot;/bin/logspout&quot; 6 hours ago Up 6 hours 127.0.0.1:8000-&gt;80/tcp logspout628b12f2b3f0 hyperledger/fabric-peer:latest &quot;peer node start&quot; 6 hours ago Up 6 hours 7051/tcp, 0.0.0.0:9051-&gt;9051/tcp peer0.org2.example.come47cbd1b0b15 hyperledger/fabric-peer:latest &quot;peer node start&quot; 6 hours ago Up 6 hours 0.0.0.0:7051-&gt;7051/tcp peer0.org1.example.come67946f412a7 hyperledger/fabric-orderer:latest &quot;orderer&quot; 6 hours ago Up 6 hours 0.0.0.0:7050-&gt;7050/tcp orderer.example.com If you used the --init-required flag, you need to invoke the Init function before you can use the upgraded chaincode. Because we did not request the execution of Init, we can test our new JavaScript chaincode by creating a new car: 我们现在可以通过创建一个新的汽车来测试我们新的JavaScript版本的链码： 1peer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n basic --peerAddresses localhost:7051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses localhost:9051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;CreateAsset&quot;,&quot;Args&quot;:[&quot;asset8&quot;,&quot;blue&quot;,&quot;16&quot;,&quot;Kelley&quot;,&quot;750&quot;]&#125;&#x27; You can query all the cars on the ledger again to see the new car: 你可以查询账本上所有的车来看新创建的car： 1peer chaincode query -C mychannel -n basic -c &#x27;&#123;&quot;Args&quot;:[&quot;GetAllAssets&quot;]&#125;&#x27; You should see the following result from the JavaScript chaincode: 通过JavaScript版本的链码，你会看到下面的结果： 1[&#123;&quot;Key&quot;:&quot;asset1&quot;,&quot;Record&quot;:&#123;&quot;ID&quot;:&quot;asset1&quot;,&quot;color&quot;:&quot;blue&quot;,&quot;size&quot;:5,&quot;owner&quot;:&quot;Tomoko&quot;,&quot;appraisedValue&quot;:300&#125;&#125;,&#123;&quot;Key&quot;:&quot;asset2&quot;,&quot;Record&quot;:&#123;&quot;ID&quot;:&quot;asset2&quot;,&quot;color&quot;:&quot;red&quot;,&quot;size&quot;:5,&quot;owner&quot;:&quot;Brad&quot;,&quot;appraisedValue&quot;:400&#125;&#125;,&#123;&quot;Key&quot;:&quot;asset3&quot;,&quot;Record&quot;:&#123;&quot;ID&quot;:&quot;asset3&quot;,&quot;color&quot;:&quot;green&quot;,&quot;size&quot;:10,&quot;owner&quot;:&quot;Jin Soo&quot;,&quot;appraisedValue&quot;:500&#125;&#125;,&#123;&quot;Key&quot;:&quot;asset4&quot;,&quot;Record&quot;:&#123;&quot;ID&quot;:&quot;asset4&quot;,&quot;color&quot;:&quot;yellow&quot;,&quot;size&quot;:10,&quot;owner&quot;:&quot;Max&quot;,&quot;appraisedValue&quot;:600&#125;&#125;,&#123;&quot;Key&quot;:&quot;asset5&quot;,&quot;Record&quot;:&#123;&quot;ID&quot;:&quot;asset5&quot;,&quot;color&quot;:&quot;black&quot;,&quot;size&quot;:15,&quot;owner&quot;:&quot;Adriana&quot;,&quot;appraisedValue&quot;:700&#125;&#125;,&#123;&quot;Key&quot;:&quot;asset6&quot;,&quot;Record&quot;:&#123;&quot;ID&quot;:&quot;asset6&quot;,&quot;color&quot;:&quot;white&quot;,&quot;size&quot;:15,&quot;owner&quot;:&quot;Michel&quot;,&quot;appraisedValue&quot;:800&#125;&#125;,&#123;&quot;Key&quot;:&quot;asset8&quot;,&quot;Record&quot;:&#123;&quot;ID&quot;:&quot;asset8&quot;,&quot;Color&quot;:&quot;blue&quot;,&quot;Size&quot;:&quot;16&quot;,&quot;Owner&quot;:&quot;Kelley&quot;,&quot;AppraisedValue&quot;:&quot;750&quot;&#125;&#125;] Clean up（清理） When you are finished using the chaincode, you can also use the following commands to remove the Logspout tool. 当你使用链码结束之后，你可以通过下面的命令来移除Logspout tool。 12docker stop logspoutdocker rm logspout You can then bring down the test network by issuing the following command from the test-network directory: 你现在可以在test-network 目录下使用下面的命令来关闭测试网络： 1./network.sh down","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"HOW-TO","slug":"区块链/Hyperledger-Fabric/HOW-TO","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/HOW-TO/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"channel","slug":"channel","permalink":"https://guozhe001.github.io/tags/channel/"}]},{"title":"编写您的第一个Chaincode","slug":"blockchain/fabric/how_to/编写您的第一个Chaincode","date":"2024-11-22T06:32:06.494Z","updated":"2024-11-22T06:32:06.494Z","comments":true,"path":"2024/11/22/blockchain/fabric/how_to/编写您的第一个Chaincode/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/how_to/%E7%BC%96%E5%86%99%E6%82%A8%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AAChaincode/","excerpt":"","text":"官方文档 Asset Transfer Chaincode（资产交易智能合约） Our application is a basic sample chaincode to initialize a ledger with assets, create, read, update, and delete assets, check to see if an asset exists, and transfer assets from one owner to another. 我们的程序是一个基本简单的链码，利用资产初始化账本，创建、读取，更新以及更新资产，检查一个资产是否存在并且把资产从一个所有者交易给另一个所有者。 Choosing a Location for the Code（给代码选一个位置） If you haven’t been doing programming in Go, you may want to make sure that you have Go installed and your system properly configured. We assume you are using a version that supports modules. 如果你还没有使用过Go，你需要确认你的环境已经安装了 Go并配置好了环境变量。我们假设你使用的是支持模块的版本。 Now, you will want to create a directory for your chaincode application. To keep things simple, let’s use the following command: 现在你想要为你的链码程序创建一个目录，简单起见，我们使用下面的命令： 12// atcc is shorthand for asset transfer chaincodemkdir atcc &amp;&amp; cd atcc Now, let’s create the module and the source file that we’ll fill in with code: 现在让我们创建模块和源文件，并用代码填充它们： 12go mod init atcctouch atcc.go Housekeeping(整理工作) First, let’s start with some housekeeping. As with every chaincode, it implements the fabric-contract-api interface, so let’s add the Go import statements for the necessary dependencies for our chaincode. We’ll import the fabric contract api package and define our SmartContract. 首先让我们做一些整理工作。所有的链码都实现了fabric-contract-api interface，所以让我们为Go程序添加必要的依赖。我们会导入fabric合同API包来定义我们的智能合约。 123456789101112package mainimport ( &quot;fmt&quot; &quot;log&quot; &quot;github.com/hyperledger/fabric-contract-api-go/contractapi&quot;)// SmartContract provides functions for managing an Asset type SmartContract struct &#123; contractapi.Contract &#125; Next, let’s add a struct Asset to represent simple assets on the ledger. Note the JSON annotations, which will be used to marshal the asset to JSON which is stored on the ledger. 下一步让我们增加一个Asset 类来表示账本上的简单的资产。请注意JSON注释，该注释将用于将资产编组为存储在分类帐中的JSON。 12345678// Asset describes basic details of what makes up a simple asset type Asset struct &#123; ID string `json:&quot;ID&quot;` Color string `json:&quot;color&quot;` Size int `json:&quot;size&quot;` Owner string `json:&quot;owner&quot;` AppraisedValue int `json:&quot;appraisedValue&quot;` &#125; Initializing the Chaincode(初始化链码) Next, we’ll implement the InitLedger function to populate the ledger with some initial data. 接下来我们实现InitLedger 方法，这个方法使用一些初始化的数据来填充账本。 12345678910111213141516171819202122232425// InitLedger adds a base set of assets to the ledger func (s *SmartContract) InitLedger(ctx contractapi.TransactionContextInterface) error &#123; assets := []Asset&#123; &#123;ID: &quot;asset1&quot;, Color: &quot;blue&quot;, Size: 5, Owner: &quot;Tomoko&quot;, AppraisedValue: 300&#125;, &#123;ID: &quot;asset2&quot;, Color: &quot;red&quot;, Size: 5, Owner: &quot;Brad&quot;, AppraisedValue: 400&#125;, &#123;ID: &quot;asset3&quot;, Color: &quot;green&quot;, Size: 10, Owner: &quot;Jin Soo&quot;, AppraisedValue: 500&#125;, &#123;ID: &quot;asset4&quot;, Color: &quot;yellow&quot;, Size: 10, Owner: &quot;Max&quot;, AppraisedValue: 600&#125;, &#123;ID: &quot;asset5&quot;, Color: &quot;black&quot;, Size: 15, Owner: &quot;Adriana&quot;, AppraisedValue: 700&#125;, &#123;ID: &quot;asset6&quot;, Color: &quot;white&quot;, Size: 15, Owner: &quot;Michel&quot;, AppraisedValue: 800&#125;, &#125; for _, asset := range assets &#123; assetJSON, err := json.Marshal(asset) if err != nil &#123; return err &#125; err = ctx.GetStub().PutState(asset.ID, assetJSON) if err != nil &#123; return fmt.Errorf(&quot;failed to put to world state. %v&quot;, err) &#125; &#125; return nil &#125; Next, we write a function to create an asset on the ledger that does not yet exist. When writing chaincode, it is a good idea to check for the existence of something on the ledger prior to taking an action on it, as is demonstrated in the CreateAsset function below. 接下来，我们写一个创建一个账本上不存在的资产的方法。当编写链码时，最好先对分类帐进行检查，然后再对其进行操作，如下面的CreateAsset函数所示。 123456789101112131415161718192021222324// CreateAsset issues a new asset to the world state with given details. func (s *SmartContract) CreateAsset(ctx contractapi.TransactionContextInterface, id string, color string, size int, owner string, appraisedValue int) error &#123; exists, err := s.AssetExists(ctx, id) if err != nil &#123; return err &#125; if exists &#123; return fmt.Errorf(&quot;the asset %s already exists&quot;, id) &#125; asset := Asset&#123; ID: id, Color: color, Size: size, Owner: owner, AppraisedValue: appraisedValue, &#125; assetJSON, err := json.Marshal(asset) if err != nil &#123; return err &#125; return ctx.GetStub().PutState(id, assetJSON) &#125; Now that we have populated the ledger with some initial assets and created an asset, let’s write a function ReadAsset that allows us to read an asset from the ledger. 现在我们已经使用初始化资产和创建一个资产来填充了账本，让我们写一个 ReadAsset 方法来允许我们读取账本上的资产。 123456789101112131415161718// ReadAsset returns the asset stored in the world state with given id. func (s *SmartContract) ReadAsset(ctx contractapi.TransactionContextInterface, id string) (*Asset, error) &#123; assetJSON, err := ctx.GetStub().GetState(id) if err != nil &#123; return nil, fmt.Errorf(&quot;failed to read from world state: %v&quot;, err) &#125; if assetJSON == nil &#123; return nil, fmt.Errorf(&quot;the asset %s does not exist&quot;, id) &#125; var asset Asset err = json.Unmarshal(assetJSON, &amp;asset) if err != nil &#123; return nil, err &#125; return &amp;asset, nil &#125; Now that we have assets on our ledger we can interact with, let’s write a chaincode function UpdateAsset that allows us to update attributes of the asset that we are allowed to change. 现在我们已经在我们的账本上有资产并能够与他们交互了，让我们写一个链码方法 UpdateAsset 来使我们能够更新允许更改的资产的属性。 12345678910111213141516171819202122232425// UpdateAsset updates an existing asset in the world state with provided parameters. func (s *SmartContract) UpdateAsset(ctx contractapi.TransactionContextInterface, id string, color string, size int, owner string, appraisedValue int) error &#123; exists, err := s.AssetExists(ctx, id) if err != nil &#123; return err &#125; if !exists &#123; return fmt.Errorf(&quot;the asset %s does not exist&quot;, id) &#125; // overwriting original asset with new asset asset := Asset&#123; ID: id, Color: color, Size: size, Owner: owner, AppraisedValue: appraisedValue, &#125; assetJSON, err := json.Marshal(asset) if err != nil &#123; return err &#125; return ctx.GetStub().PutState(id, assetJSON) &#125; There may be cases where we need the ability to delete an asset from the ledger, so let’s write a DeleteAsset function to handle that requirement. 可能我本需要从账本上删除一个资产，所以让我们写一个 DeleteAsset 方法来处理这个需求。 123456789101112// DeleteAsset deletes an given asset from the world state. func (s *SmartContract) DeleteAsset(ctx contractapi.TransactionContextInterface, id string) error &#123; exists, err := s.AssetExists(ctx, id) if err != nil &#123; return err &#125; if !exists &#123; return fmt.Errorf(&quot;the asset %s does not exist&quot;, id) &#125; return ctx.GetStub().DelState(id) &#125; We said earlier that is was a good idea to check to see if an asset exists before taking an action on it, so let’s write a function called AssetExists to implement that requirement. 我们之前说在对一个资产进行操作之前，最好先检查这个资产是否存在，所以让我们写一个名为 AssetExists的方法来实现这个需求。 123456789// AssetExists returns true when asset with given ID exists in world state func (s *SmartContract) AssetExists(ctx contractapi.TransactionContextInterface, id string) (bool, error) &#123; assetJSON, err := ctx.GetStub().GetState(id) if err != nil &#123; return false, fmt.Errorf(&quot;failed to read from world state: %v&quot;, err) &#125; return assetJSON != nil, nil &#125; Next, we’ll write a function we’ll call TransferAsset that enables the transfer of an asset from one owner to another. 接着，我们写一个我们称作TransferAsset的方法，该函数可将资产从一个所有者转移到另一个所有者。 123456789101112131415// TransferAsset updates the owner field of asset with given id in world state. func (s *SmartContract) TransferAsset(ctx contractapi.TransactionContextInterface, id string, newOwner string) error &#123; asset, err := s.ReadAsset(ctx, id) if err != nil &#123; return err &#125; asset.Owner = newOwner assetJSON, err := json.Marshal(asset) if err != nil &#123; return err &#125; return ctx.GetStub().PutState(id, assetJSON) &#125; Let’s write a function we’ll call GetAllAssets that enables the querying of the ledger to return all of the assets on the ledger. 让我们写一个 GetAllAssets 方法来查询账本上的资产，这个方法返回账本上的所有资产。 123456789101112131415161718192021222324252627// GetAllAssets returns all assets found in world state func (s *SmartContract) GetAllAssets(ctx contractapi.TransactionContextInterface) ([]*Asset, error) &#123;// range query with empty string for startKey and endKey does an// open-ended query of all assets in the chaincode namespace. resultsIterator, err := ctx.GetStub().GetStateByRange(&quot;&quot;, &quot;&quot;) if err != nil &#123; return nil, err &#125; defer resultsIterator.Close() var assets []*Asset for resultsIterator.HasNext() &#123; queryResponse, err := resultsIterator.Next() if err != nil &#123; return nil, err &#125; var asset Asset err = json.Unmarshal(queryResponse.Value, &amp;asset) if err != nil &#123; return nil, err &#125; assets = append(assets, &amp;asset) &#125; return assets, nil &#125; Pulling it All Together（把这些代码放到一起） Finally, we need to add the main function, which will call the ContractChaincode.Start function. Here’s the whole chaincode program source. 最终我们需要添加一个调用 ContractChaincode.Start 方法的 main 方法。下面就是全部的链码程序源码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;log&quot; &quot;github.com/hyperledger/fabric-contract-api-go/contractapi&quot;)// SmartContract provides functions for managing an Asset type SmartContract struct &#123; contractapi.Contract &#125;// Asset describes basic details of what makes up a simple asset type Asset struct &#123; ID string `json:&quot;ID&quot;` Color string `json:&quot;color&quot;` Size int `json:&quot;size&quot;` Owner string `json:&quot;owner&quot;` AppraisedValue int `json:&quot;appraisedValue&quot;` &#125;// InitLedger adds a base set of assets to the ledger func (s *SmartContract) InitLedger(ctx contractapi.TransactionContextInterface) error &#123; assets := []Asset&#123; &#123;ID: &quot;asset1&quot;, Color: &quot;blue&quot;, Size: 5, Owner: &quot;Tomoko&quot;, AppraisedValue: 300&#125;, &#123;ID: &quot;asset2&quot;, Color: &quot;red&quot;, Size: 5, Owner: &quot;Brad&quot;, AppraisedValue: 400&#125;, &#123;ID: &quot;asset3&quot;, Color: &quot;green&quot;, Size: 10, Owner: &quot;Jin Soo&quot;, AppraisedValue: 500&#125;, &#123;ID: &quot;asset4&quot;, Color: &quot;yellow&quot;, Size: 10, Owner: &quot;Max&quot;, AppraisedValue: 600&#125;, &#123;ID: &quot;asset5&quot;, Color: &quot;black&quot;, Size: 15, Owner: &quot;Adriana&quot;, AppraisedValue: 700&#125;, &#123;ID: &quot;asset6&quot;, Color: &quot;white&quot;, Size: 15, Owner: &quot;Michel&quot;, AppraisedValue: 800&#125;, &#125; for _, asset := range assets &#123; assetJSON, err := json.Marshal(asset) if err != nil &#123; return err &#125; err = ctx.GetStub().PutState(asset.ID, assetJSON) if err != nil &#123; return fmt.Errorf(&quot;failed to put to world state. %v&quot;, err) &#125; &#125; return nil &#125;// CreateAsset issues a new asset to the world state with given details. func (s *SmartContract) CreateAsset(ctx contractapi.TransactionContextInterface, id string, color string, size int, owner string, appraisedValue int) error &#123; exists, err := s.AssetExists(ctx, id) if err != nil &#123; return err &#125; if exists &#123; return fmt.Errorf(&quot;the asset %s already exists&quot;, id) &#125; asset := Asset&#123; ID: id, Color: color, Size: size, Owner: owner, AppraisedValue: appraisedValue, &#125; assetJSON, err := json.Marshal(asset) if err != nil &#123; return err &#125; return ctx.GetStub().PutState(id, assetJSON) &#125;// ReadAsset returns the asset stored in the world state with given id. func (s *SmartContract) ReadAsset(ctx contractapi.TransactionContextInterface, id string) (*Asset, error) &#123; assetJSON, err := ctx.GetStub().GetState(id) if err != nil &#123; return nil, fmt.Errorf(&quot;failed to read from world state: %v&quot;, err) &#125; if assetJSON == nil &#123; return nil, fmt.Errorf(&quot;the asset %s does not exist&quot;, id) &#125; var asset Asset err = json.Unmarshal(assetJSON, &amp;asset) if err != nil &#123; return nil, err &#125; return &amp;asset, nil &#125;// UpdateAsset updates an existing asset in the world state with provided parameters. func (s *SmartContract) UpdateAsset(ctx contractapi.TransactionContextInterface, id string, color string, size int, owner string, appraisedValue int) error &#123; exists, err := s.AssetExists(ctx, id) if err != nil &#123; return err &#125; if !exists &#123; return fmt.Errorf(&quot;the asset %s does not exist&quot;, id) &#125; // overwriting original asset with new asset asset := Asset&#123; ID: id, Color: color, Size: size, Owner: owner, AppraisedValue: appraisedValue, &#125; assetJSON, err := json.Marshal(asset) if err != nil &#123; return err &#125; return ctx.GetStub().PutState(id, assetJSON) &#125; // DeleteAsset deletes an given asset from the world state. func (s *SmartContract) DeleteAsset(ctx contractapi.TransactionContextInterface, id string) error &#123; exists, err := s.AssetExists(ctx, id) if err != nil &#123; return err &#125; if !exists &#123; return fmt.Errorf(&quot;the asset %s does not exist&quot;, id) &#125; return ctx.GetStub().DelState(id) &#125;// AssetExists returns true when asset with given ID exists in world state func (s *SmartContract) AssetExists(ctx contractapi.TransactionContextInterface, id string) (bool, error) &#123; assetJSON, err := ctx.GetStub().GetState(id) if err != nil &#123; return false, fmt.Errorf(&quot;failed to read from world state: %v&quot;, err) &#125; return assetJSON != nil, nil &#125;// TransferAsset updates the owner field of asset with given id in world state. func (s *SmartContract) TransferAsset(ctx contractapi.TransactionContextInterface, id string, newOwner string) error &#123; asset, err := s.ReadAsset(ctx, id) if err != nil &#123; return err &#125; asset.Owner = newOwner assetJSON, err := json.Marshal(asset) if err != nil &#123; return err &#125; return ctx.GetStub().PutState(id, assetJSON) &#125;// GetAllAssets returns all assets found in world state func (s *SmartContract) GetAllAssets(ctx contractapi.TransactionContextInterface) ([]*Asset, error) &#123;// range query with empty string for startKey and endKey does an// open-ended query of all assets in the chaincode namespace. resultsIterator, err := ctx.GetStub().GetStateByRange(&quot;&quot;, &quot;&quot;) if err != nil &#123; return nil, err &#125; defer resultsIterator.Close() var assets []*Asset for resultsIterator.HasNext() &#123; queryResponse, err := resultsIterator.Next() if err != nil &#123; return nil, err &#125; var asset Asset err = json.Unmarshal(queryResponse.Value, &amp;asset) if err != nil &#123; return nil, err &#125; assets = append(assets, &amp;asset) &#125; return assets, nil &#125; func main() &#123; assetChaincode, err := contractapi.NewChaincode(&amp;SmartContract&#123;&#125;) if err != nil &#123; log.Panicf(&quot;Error creating asset-transfer-basic chaincode: %v&quot;, err) &#125; if err := assetChaincode.Start(); err != nil &#123; log.Panicf(&quot;Error starting asset-transfer-basic chaincode: %v&quot;, err) &#125; &#125; Chaincode access control Chaincode can utilize the client (submitter) certificate for access control decisions with ctx.GetStub().GetCreator(). Additionally the Fabric Contract API provides extension APIs that extract client identity from the submitter’s certificate that can be used for access control decisions, whether that is based on client identity itself, or the org identity, or on a client identity attribute. 链码可以通过 ctx.GetStub().GetCreator()利用客户端（提交者）证书进行访问控制决策。此外，Fabric Contract API还提供了扩展API，这些API从提交者的证书中提取客户端身份，可用于访问控制决策，不论是基于客户端身份本身，组织身份或客户端身份属性。 For example an asset that is represented as a key/value may include the client’s identity as part of the value (for example as a JSON attribute indicating that asset owner), and only this client may be authorized to make updates to the key/value in the future. The client identity library extension APIs can be used within chaincode to retrieve this submitter information to make such access control decisions. 例如，表示为键/值的资产可能包含客户的身份作为值的一部分（如作为表示该资产所有者的JSON属性），并且只有这个客户端可能有权限来在将来更新这些 key/value。客户端身份库扩展API可以在链码中使用，以检索此提交者信息以做出此类访问控制决策。","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"HOW-TO","slug":"区块链/Hyperledger-Fabric/HOW-TO","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/HOW-TO/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"chaincode","slug":"chaincode","permalink":"https://guozhe001.github.io/tags/chaincode/"}]},{"title":"Application","slug":"blockchain/fabric/关键概念/Application","date":"2024-11-22T06:32:06.494Z","updated":"2024-11-22T06:32:06.494Z","comments":true,"path":"2024/11/22/blockchain/fabric/关键概念/Application/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E5%85%B3%E9%94%AE%E6%A6%82%E5%BF%B5/Application/","excerpt":"","text":"官方文档：Application Basic Flow A PaperNet application invokes the commercial paper smart contract to submit an issue transaction request. An application has to follow six basic steps to submit a transaction: Select an identity from a wallet Connect to a gateway Access the desired network Construct a transaction request for a smart contract Submit the transaction to the network Process the response Wallet Think of a wallet holding the digital equivalents of your government ID, driving license or ATM card. The X.509 digital certificates within it will associate the holder with a organization, thereby entitling them to rights in a network channel. For example, Isabella might be an administrator in MagnetoCorp, and this could give her more privileges than a different user – Balaji from DigiBank. Moreover, a smart contract can retrieve this identity during smart contract processing using the transaction context. 钱包是保管了很多身份信息的钱包。 （个人理解：就好像谍战电影里面的间谍，打开一个抽屉里面有这个间谍的不同身份的护照。） Gateway The second key class is a Fabric Gateway. Most importantly, a gateway identifies one or more peers that provide access to a network。 in our case, PaperNet. See how issue.js connects to its gateway: 网关标识一个或多个提供对网络访问的节点。 1await gateway.connect(connectionProfile, connectionOptions); gateway.connect() has two important parameters: connectionProfile: the file system location of a connection profile that identifies a set of peers as a gateway to PaperNet 连接配置文件的文件系统位置，该文件将一组peer标识为PaperNet的gateway connectionOptions: a set of options used to control how issue.js interacts with PaperNet See how the client application uses a gateway to insulate itself from the network topology, which might change. The gateway takes care of sending the transaction proposal to the right peer nodes in the network using the connection profile and connection options. Network channel The peers defined in the gateway connectionProfile.yaml provide issue.js with access to PaperNet. Because these peers can be joined to multiple network channels, the gateway actually provides the application with access to multiple network channels! We can see here a powerful feature of Hyperledger Fabric – applications can participate in a network of networks, by connecting to multiple gateway peers, each of which is joined to multiple network channels. Applications will have different rights in different channels according to their wallet identity provided in gateway.connect(). Construct request The application is now ready to issue a commercial paper. To do this, it’s going to use CommercialPaperContract and again, its fairly straightforward to access this smart contract: Submit transaction Note that the submitTransaction API includes a process for listening for transaction commits. Listening for commits is required because without it, you will not know whether your transaction has successfully been orderered, validated, and committed to the ledger. Process response","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"Key Concepts","slug":"区块链/Hyperledger-Fabric/Key-Concepts","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/Key-Concepts/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"Application","slug":"Application","permalink":"https://guozhe001.github.io/tags/Application/"}]},{"title":"Fabric chaincode lifecycle","slug":"blockchain/fabric/关键概念/Fabric chaincode lifecycle","date":"2024-11-22T06:32:06.494Z","updated":"2024-11-22T06:32:06.494Z","comments":true,"path":"2024/11/22/blockchain/fabric/关键概念/Fabric chaincode lifecycle/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E5%85%B3%E9%94%AE%E6%A6%82%E5%BF%B5/Fabric%20chaincode%20lifecycle/","excerpt":"","text":"官方文档：Fabric chaincode lifecycle Install and define a chaincode Package the chaincode: This step can be completed by one organization or by each organization. Install the chaincode on your peers: Every organization that will use the chaincode to endorse a transaction or query the ledger needs to complete this step. Approve a chaincode definition for your organization: Every organization that will use the chaincode needs to complete this step. The chaincode definition needs to be approved by a sufficient number of organizations to satisfy the channel’s LifecycleEndorsment policy (a majority, by default) before the chaincode can be started on the channel. Commit the chaincode definition to the channel: The commit transaction needs to be submitted by one organization once the required number of organizations on the channel have approved. The submitter first collects endorsements from enough peers of the organizations that have approved, and then submits the transaction to commit the chaincode definition. Upgrade a chaincode Repackage the chaincode: You only need to complete this step if you are upgrading the chaincode binaries. Org1 and Org2 upgrade the chaincode binaries and repackage the chaincode. Both organizations use a different package label. Install the new chaincode package on your peers: Once again, you only need to complete this step if you are upgrading the chaincode binaries. Installing the new chaincode package will generate a package ID, which you will need to pass to the new chaincode definition. You also need to change the chaincode version, which is used by the lifecycle process to track if the chaincode binaries have been upgraded. Org1 and Org2 install the new package on their peers. The installation creates a new packageID. Approve a new chaincode definition: If you are upgrading the chaincode binaries, you need to update the chaincode version and the package ID in the chaincode definition. You can also update your chaincode endorsement policy without having to repackage your chaincode binaries. Channel members simply need to approve a definition with the new policy. The new definition needs to increment the sequence variable in the definition by one. Organization administrators from Org1 and Org2 approve the new chaincode definition for their respective organizations. The new definition references the new packageID and changes the chaincode version. Since this is the first update of the chaincode, the sequence is incremented from one to two. Commit the definition to the channel: When a sufficient number of channel members have approved the new chaincode definition, one organization can commit the new definition to upgrade the chaincode definition to the channel. There is no separate upgrade command as part of the lifecycle process. An organization administrator from Org1 or Org2 commits the new chaincode definition to the channel. Organizations install different chaincode packages Each organization can use a different packageID when they approve a chaincode definition. This allows channel members to install different chaincode binaries that use the same endorsement policy and read and write to data in the same chaincode namespace. 每个组织在批准链码定义时都可以使用不同的packageID。这允许通道成员安装使用相同背书策略的不同链代码二进制文件，并在同一链码名称空间中读取和写入数据。 Organizations can use this capability to install smart contracts that contain business logic that is specific to their organization. Each organization’s smart contract could contain additional validation that the organization requires before their peers endorse a transaction. Each organization can also write code that helps integrate the smart contract with data from their existing systems. 组织可以使用此功能来安装包含其组织的特殊的业务逻辑的智能合约。每个组织的智能合约都可以包含组织在其peer认可交易之前所需的其他验证。每个组织还可以编写代码将智能合约与他们现有系统中的数据集成在一起。 Org1 and Org2 each install versions of the MYCC chaincode containing business logic that is specific to their organization. Creating multiple chaincodes using one package You can use one chaincode package to create multiple chaincode instances on a channel by approving and committing multiple chaincode definitions. Each definition needs to specify a different chaincode name. This allows you to run multiple instances of a smart contract on a channel, but have the contract be subject to different endorsement policies. 您可以通过批准并提交多个链码定义，使用一个链码包在一个通道上创建多个链码实例。每个定义都需要指定一个不同的链码名称。这使您可以在一个通道上运行智能合约的多个实例，但是要让合约遵循不同的背书策略。 Org1 and Org2 use the MYCC_1 chaincode package to approve and commit two different chaincode definitions. As a result, both peers have two chaincode containers running on their peers. MYCC1 has an endorsement policy of 1 out of 2, while MYCC2 has an endorsement policy of 2 out of 2. 个人疑问：部署相的链码，使用不同的背书策略，这么做有什么用呢？ Migrate to the new Fabric lifecycle For information about migrating to the new lifecycle, check out Considerations for getting to v2.0. If you need to update your channel configurations to enable the new lifecycle, check out Enabling the new chaincode lifecycle. More information You can watch video below to learn more about the motivation of the new Fabric chaincode lifecycle and how it is implemented.","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"Key Concepts","slug":"区块链/Hyperledger-Fabric/Key-Concepts","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/Key-Concepts/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"Fabric chaincode lifecycle","slug":"Fabric-chaincode-lifecycle","permalink":"https://guozhe001.github.io/tags/Fabric-chaincode-lifecycle/"}]},{"title":"Hyperledger-Fabric模型","slug":"blockchain/fabric/关键概念/Hyperledger-Fabric模型","date":"2024-11-22T06:32:06.494Z","updated":"2024-11-22T06:32:06.495Z","comments":true,"path":"2024/11/22/blockchain/fabric/关键概念/Hyperledger-Fabric模型/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E5%85%B3%E9%94%AE%E6%A6%82%E5%BF%B5/Hyperledger-Fabric%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"Hyperledger-Fabric模型 This section outlines the key design features woven into Hyperledger Fabric that fulfill its promise of a comprehensive, yet customizable, enterprise blockchain solution: 本节概述了编织到Hyperledger Fabric中的关键设计功能，这些功能实现了其全面，可定制的企业区块链解决方案的承诺： Assets — Asset definitions enable the exchange of almost anything with monetary value over the network, from whole foods to antique cars to currency futures. 资产定义了允许通过网络交换的几乎所有具有货币价值的东西，从食品到古董车再到货币期货。 Chaincode — Chaincode execution is partitioned from transaction ordering, limiting the required levels of trust and verification across node types, and optimizing network scalability and performance. 链码执行从交易顺序中划分出来，从而限制了跨节点类型所需的信任和验证级别，并优化网络可伸缩和性能。 Ledger Features — The immutable, shared ledger encodes the entire transaction history for each channel, and includes SQL-like query capability for efficient auditing and dispute resolution. 不变的，共享的账本对每个通道的整个交易历史进行编码，并包括类似SQL的查询功能，以进行有效的审计和争议解决。 Privacy — Channels and private data collections enable private and confidential multi-lateral transactions that are usually required by competing businesses and regulated industries that exchange assets on a common network. 通道和隐私数据收集可实现私人和机密的多边交易，通常是在竞争企业和受管制的行业（在同一网络上交换资产）所需要。 Security &amp; Membership Services — Permissioned membership provides a trusted blockchain network, where participants know that all transactions can be detected and traced by authorized regulators and auditors. 获得许可的成员资格提供了一个受信任的区块链网络，参与者知道所有交易都可以由授权的监管机构和审计师检测和追踪。 Consensus — A unique approach to consensus enables the flexibility and scalability needed for the enterprise. 一种唯一的共识方法可以实现企业所需的灵活性和可伸缩性。 Assets Assets can range from the tangible (real estate and hardware) to the intangible (contracts and intellectual property). Hyperledger Fabric provides the ability to modify assets using chaincode transactions. 资产范围从有形资产（房地产和硬件）到无形资产（合同和知识产权）。Hyperledger Fabric提供了使用链码交易修改资产的功能。 Assets are represented in Hyperledger Fabric as a collection of key-value pairs, with state changes recorded as transactions on a Channel ledger. Assets can be represented in binary and/or JSON form. 资产在Hyperledger Fabric中表示为键值对的集合，状态更改记录为通道账本中的交易。资产可以二进制和/或JSON形式表示。 Chaincode Chaincode is software defining an asset or assets, and the transaction instructions for modifying the asset(s); in other words, it’s the business logic. Chaincode enforces the rules for reading or altering key-value pairs or other state database information. Chaincode functions execute against the ledger’s current state database and are initiated through a transaction proposal. Chaincode execution results in a set of key-value writes (write set) that can be submitted to the network and applied to the ledger on all peers. 链码是定义了一个或多个资产的软件，以及用于修改资产的交易指令；Chaincode强制执行用于读取或更改键值对或其他状态数据库信息的规则。链码功能针对账本的当前状态数据库执行，并通过交易提议启动。链码执行产生的一组键值写操作（写集），这些键值写操作可以提交给网络，并应用于所有peer的账本中。 Ledger Features The ledger is the sequenced, tamper-resistant record of all state transitions in the fabric. State transitions are a result of chaincode invocations (‘transactions’) submitted by participating parties. Each transaction results in a set of asset key-value pairs that are committed to the ledger as creates, updates, or deletes. 账本是Fabric中所有有序的、防篡改的状态转换。状态转换是参与方提交的链码调用（“交易”）的结果。每个交易都会产生一组资产键值对，这些键值对会在创建，更新或删除时提交到账本中。 The ledger is comprised of a blockchain (‘chain’) to store the immutable, sequenced record in blocks, as well as a state database to maintain current fabric state. There is one ledger per channel. Each peer maintains a copy of the ledger for each channel of which they are a member. 账本由区块链组成，以区块形式存储不可变的、有序的记录，以及用于维护当前结构状态的状态数据库。每个通道有一个账本。每个peer都为其所属的每个通道维护一个账本的副本。 Some features of a Fabric ledger（Fabric账本的一些功能）: Query and update ledger using key-based lookups, range queries, and composite key queries 使用基于键的查找，范围查询和组合键查询来查询和更新分类帐 Read-only queries using a rich query language (if using CouchDB as state database) 使用丰富查询语言的只读查询（如果使用CouchDB作为状态数据库） Read-only history queries — Query ledger history for a key, enabling data provenance scenarios 只读历史记录查询—为一个key查询史记录，从而启用数据出处场景 Transactions consist of the versions of keys/values that were read in chaincode (read set) and keys/values that were written in chaincode (write set) 交易由链码中读取的键/值的版本 (读取集)和用链码编写的键/值（写入集）所组成。 Transactions contain signatures of every endorsing peer and are submitted to ordering service 交易包含每个背书peer的签名，并提交给排序服务 Transactions are ordered into blocks and are “delivered” from an ordering service to peers on a channel 交易被排序并打包成区块，并从排序服务“交付”到通道上的peer节点 Peers validate transactions against endorsement policies and enforce the policies Peer根据背书策略验证交易并执行政策 Prior to appending a block, a versioning check is performed to ensure that states for assets that were read have not changed since chaincode execution time 在追加区块之前，执行版本检查，以确保自链码执行以来，已读取资产的状态未发生变化 There is immutability once a transaction is validated and committed 交易一旦经过验证并提交，便具有不变性 A channel’s ledger contains a configuration block defining policies, access control lists, and other pertinent information 通道的账本包含一个配置块，用于定义策略、访问控制列表和其他相关信息 Channels contain Membership Service Provider instances allowing for crypto materials to be derived from different certificate authorities 通道包含MSP实例，允许从不同的证书颁发机构生成加密材料 See the Ledger topic for a deeper dive on the databases, storage structure, and “query-ability.” 有关数据库，存储结构和“查询能力”的更深入了解，请参阅账本主题。 Privacy Hyperledger Fabric employs an immutable ledger on a per-channel basis, as well as chaincode that can manipulate and modify the current state of assets (i.e. update key-value pairs). A ledger exists in the scope of a channel — it can be shared across the entire network (assuming every participant is operating on one common channel) — or it can be privatized to include only a specific set of participants. Hyperledger Fabric在每个通道的基础上使用不变的账本，以及可以操纵和修改资产当前状态的链码。账本存在于通道范围内-可以在整个网络中共享（假设每个参与者都在一个公共频道上进行操作）也可以仅包括一组特定的参与者以将其私有化。 In the latter scenario, these participants would create a separate channel and thereby isolate/segregate their transactions and ledger. In order to solve scenarios that want to bridge the gap between total transparency and privacy, chaincode can be installed only on peers that need to access the asset states to perform reads and writes (in other words, if a chaincode is not installed on a peer, it will not be able to properly interface with the ledger). 在后一种情况下，这些参与者将创建一个单独的通道，从而隔离/分离他们的交易和账本。为了解决总体透明度和隐私之间存在间隙的场景，链码只能安装在需要访问资产状态以执行读写的peer节点上（换句话说，如果未在peer节点上安装链码，则它将无法与账本正确连接）。 When a subset of organizations on that channel need to keep their transaction data confidential, a private data collection (collection) is used to segregate this data in a private database, logically separate from the channel ledger, accessible only to the authorized subset of organizations. 当该渠道上的部分组织需要对其交易数据保密时，私有数据集合用于将这些数据隔离在私有数据库中，从逻辑上与通道账本隔离，并仅允许组织的授权子集访问。 Thus, channels keep transactions private from the broader network whereas collections keep data private between subsets of organizations on the channel. 因此，通道使交易对于更广泛的网络而言是不公开的，而集合则对通道上的组织子集之间的数据不公开。 To further obfuscate the data, values within chaincode can be encrypted (in part or in total) using common cryptographic algorithms such as AES before sending transactions to the ordering service and appending blocks to the ledger. Once encrypted data has been written to the ledger, it can be decrypted only by a user in possession of the corresponding key that was used to generate the cipher text. 为了进一步混淆数据，在将chaincode中的数据发送给排序服务和追加到账本区块上之前可以使用标准的加密算法（如AES）进行加密。加密数据一旦写入分类帐，则只有拥有用于生成密文的密钥的用户才能对其解密。 See the Private Data topic for more details on how to achieve privacy on your blockchain network. 有关如何在区块链网络上实现隐私的更多详细信息，请参阅私有数据主题。 Security &amp; Membership Services Hyperledger Fabric underpins a transactional network where all participants have known identities. Public Key Infrastructure is used to generate cryptographic certificates which are tied to organizations, network components, and end users or client applications. As a result, data access control can be manipulated and governed on the broader network and on channel levels. This “permissioned” notion of Hyperledger Fabric, coupled with the existence and capabilities of channels, helps address scenarios where privacy and confidentiality are paramount concerns. Hyperledger Fabric支持所有参与者都具有已知身份的交易网络。公钥基础结构用于生成与组织，网络组件以及最终用户或客户端应用程序绑定的加密证书。结果，可以在更广泛的网络和通道级别上操纵和控制数据访问控制。Hyperledger Fabric的“许可”概念以及通道的存在和功能，帮助解决隐私和机密至关重要的情况。 See the Membership Service Providers (MSP) topic to better understand cryptographic implementations, and the sign, verify, authenticate approach used in Hyperledger Fabric. Consensus In distributed ledger technology, consensus has recently become synonymous with a specific algorithm, within a single function. However, consensus encompasses more than simply agreeing upon the order of transactions, and this differentiation is highlighted in Hyperledger Fabric through its fundamental role in the entire transaction flow, from proposal and endorsement, to ordering, validation and commitment. In a nutshell, consensus is defined as the full-circle verification of the correctness of a set of transactions comprising a block. 在分布式分类帐技术中，共识最近已成为单一功能内特定算法的同义词。但是，共识不只是简单地约定交易顺序，Hyperledger Fabric通过在整个交易流程（从提案和认可，到排序，验证和提交）中的基本作用，突显了这种差异。简而言之，共识被定义为对包含一个区块的一组交易的正确性的全面验证。 Consensus is achieved ultimately when the order and results of a block’s transactions have met the explicit policy criteria checks. These checks and balances take place during the lifecycle of a transaction, and include the usage of endorsement policies to dictate which specific members must endorse a certain transaction class, as well as system chaincodes to ensure that these policies are enforced and upheld. Prior to commitment, the peers will employ these system chaincodes to make sure that enough endorsements are present, and that they were derived from the appropriate entities. Moreover, a versioning check will take place during which the current state of the ledger is agreed or consented upon, before any blocks containing transactions are appended to the ledger. This final check provides protection against double spend operations and other threats that might compromise data integrity, and allows for functions to be executed against non-static variables. 区块交易的顺序和结果满足明确的策略标准检查后，才能最终达成共识。这些检查和平衡发生在交易的生命周期中，并包括使用背书策略规定哪些特定成员必须背书某个交易类别，以及系统链码确保这些策略得到实施和维护。在作出承诺之前，peer将使用这些系统链码来确保存在足够的背书，并且背书来自适当的实体。此外，在将包含交易的任何块追加到账本之前，将进行版本控制检查，在此期间将对账本的当前状态进行被同意或同意。最终检查可以防止重复使用操作和其他可能危害数据完整性的威胁，并允许针对非静态变量执行功能。 In addition to the multitude of endorsement, validity and versioning checks that take place, there are also ongoing identity verifications happening in all directions of the transaction flow. Access control lists are implemented on hierarchical layers of the network (ordering service down to channels), and payloads are repeatedly signed, verified and authenticated as a transaction proposal passes through the different architectural components. To conclude, consensus is not merely limited to the agreed upon order of a batch of transactions; rather, it is an overarching characterization that is achieved as a byproduct of the ongoing verifications that take place during a transaction’s journey from proposal to commitment. 除了进行大量的背书，有效性和版本检查外，还在交易流程的各个方向上都在进行身份验证。访问控制列表是在网络的分层的层面实现的，当交易提议通过不同的架构组件时，有效载荷将被反复签名，验证和认证。总而言之，共识不仅限于一批交易的商定顺序；它更是一项总体特征，它是交易从提案到承诺过程中不断进行的验证的副产品。 Check out the Transaction Flow diagram for a visual representation of consensus. 查看交易流程图以直观表示共识。","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"Key Concepts","slug":"区块链/Hyperledger-Fabric/Key-Concepts","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/Key-Concepts/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"Model","slug":"Model","permalink":"https://guozhe001.github.io/tags/Model/"}]},{"title":"Fabric的网络","slug":"blockchain/fabric/关键概念/Fabric的网络","date":"2024-11-22T06:32:06.494Z","updated":"2024-11-22T06:32:06.494Z","comments":true,"path":"2024/11/22/blockchain/fabric/关键概念/Fabric的网络/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/%E5%85%B3%E9%94%AE%E6%A6%82%E5%BF%B5/Fabric%E7%9A%84%E7%BD%91%E7%BB%9C/","excerpt":"","text":"Blockchain network(Fabric的网络) 原始官方文档：https://hyperledger-fabric.readthedocs.io/en/release-2.2/network/network.html Creating the Network 从创建基础网络开始： 在orderer启动之后网络就形成了，在我们的示例网络N中，包括单个节点O4的ordered service是根据网络配置NC4配置的，该网络配置向组织R4提供管理权限。在网络级别，证书颁发机构CA4用于向R4组织的管理员和网络节点分配身份。 我们可以看到定义网络N的第一件事就是ordering service ，O4。将订购服务视为网络的初始管理点很有帮助。将ordering service视为网络的初始管理点很有帮助。按照事先约定，O4最初由组织R4中的管理员配置和启动，并托管在R4中。配置NC4包含描述网络管理功能的初始的策略集合。最初，将其设置为仅通过网络授予R4权限。这将改变，我们将在后面看到，但目前R4是网络的唯一成员。 Certificate Authorities（证书颁发机构） 您还可以看到证书颁发机构CA4，用于向管理员和网络节点颁发证书。CA4在我们的网络中起着关键作用，因为它颁发X.509证书，该证书可用于将组件标识为属于组织R4。由CA颁发的证书也可以用于签署交易，以表明组织认可交易结果–这是允许交易提交到分类帐的前提。让我们更详细地研究CA的这两个方面。 首先，区块链网络的不同组件使用证书将自己标识为来自特定组织。这就是为什么通常有不止一个CA支持一个区块链网络-不同的组织经常使用不同的CA。 证书到成员组织的映射是通过称为Membership Services Provider (MSP)的结构实现的。网络配置NC4使用MSP来标识由CA4分配的证书的属性，该证书将证书持有者与组织R4相关联。然后，NC4可以在策略中使用此MSP向R4的参与者授予对网络资源的特定权限。这种策略的一个示例是R4中的管理员可以向网络添加的新成员。 其次，稍后我们将看到CA颁发的证书如何成为交易生成和验证过程的核心。具体来说，X.509证书用于客户端应用程序交易建议和智能合约交易响应中以进行数字签名交易。随后，托管账本的网络节点在接受交易记录到账本之前会验证交易的签名是否有效。 让我们回顾一下示例区块链网络的基本结构：证书颁发机构CA4定义了一组用户，可以访问网络N；这些用户对网络N中资源的权限被网络配置NC4中包含的策略所描述。在我们配置并启动ordering service节点O4时，所有这些都变为现实。 Adding Network Administrators（添加网络管理员） NC4只配置了R4的用户在网络上的权限。在下一个阶段，我们将允许组织R1用户管理网络。让我们看看网络如何发展： 组织R4更新网络配置以使组织R1也成为管理员。此后，R1和R4在网络配置上享有同等的权利。 尽管订购者节点O4在R4的基础结构上运行，但R1拥有共享的管理权限，只要它可以访问网络即可。这意味着R1或R4可以更新网络配置NC4，以允许R2组织进行网络操作的子集。这样，即使R4在运行订购服务，R1也对其拥有完全的管理权限，并且R2具有创建新联合体的部分权限。 你在示例中看到的ordering service是网络中的单个节点，这是最简单的形式。ordering service通常是多节点的，可以配置为在不同组织的不同节点。例如，我们可能在R4中运行O4并将其连接到组织R1中单独的订购者节点O2。这样，我们将拥有一个多站点，多组织的管理结构。 我们将在本主题的稍后部分讨论ordering service，但是现在，仅将ordering service视为一个可为不同组织提供对网络受控访问的管理点。 Defining a Consortium(定义一个联盟) 尽管现在可以通过R1和R4管理网络，但是几乎没有什么事情可做。我们需要做的第一件事是定义一个联盟。这个词的字面意思是“拥有共同命运的团体”，因此对于区块链网络中的一组组织来说是一个合适的选择。 让我们看看联盟的定义： 网络管理员定义了一个联盟X1，该联盟包含两个成员，组织R1和R2。该联盟的定义存储在网络配置NC4中，并将在网络开发的下一阶段使用。CA1和CA2是这些组织的各自的证书颁发机构。 因为NC4配置的是只允许R1或R4可以创建新的联盟。该图显示了添加的新联盟X1，该联盟将R1和R2定义为其组成组织。我们还可以看到已经添加了CA2用以认证R2的用户。请注意，一个联盟可以有任意数量的组织成员–我们刚刚显示了两个，因为它是最简单的配置。 为什么联盟如此重要？我们可以看到一个联盟定义了网络中彼此需要共享交易的组织集合，在本例中R1和 R2。如果组织有共同的目标，将它们组合在一起真的很有意义，而这正上面的联盟定义。 该网络虽然由单个组织启动，但现在由较大的一组组织控制。现在，我们将使用联盟X1创建Hyperledger Fabric区块链的一个非常重要的部分-一个通道。 Creating a channel for a consortium(为联盟创建一个通道) channel是主要的通信机制，联盟的成员可以通过channel相互通信。网络中可以有多个通道，我们先从一个渠道开始。 让我们看看如何将第一个channel添加到网络中： 使用联盟定义X1为R1和R2创建了通道C1。通道由通道配置CC1进行治理，完全独立于网络配置。CC1由对C1拥有同等权利的R1和R2管理。 R4在CC1中没有任何权利。 通道C1为财团X1提供了专用的通信机制。我们可以看到通道C1已连接到ordersing service(O4)，但没有附加任何内容。在网络开发的下一阶段，我们将连接组件，例如客户端应用程序和peer节点。但是，渠道代表着未来连接的潜力。 即使通道C1是网络N的一部分，但也可以与它完全区分开。注意组织R3和R4不在此通道中，C1只用于R1和R2之间的交易处理。在上一步中，我们了解了R4如何授予R1创建新联盟的权限。值得一提的是R4还允许R1创建channel！在此图中，可能是组织R1或R4创建了通道C1。 再次注意通道C1对于网络配置NC4如何具有完全独立的配置CC1。CC1包含用于控制R1和R2在通道C1上的权限的策略-正如我们所看到的，R3和R4在此通道上没有权限。R3和R4只能在R1或R2将其添加适当策略到通道配置CC1中，才可以与C1交互。一个示例是定义谁可以向channel添加新组织。特别要注意的是，R4不能将自身添加到通道C1中-它必须并且只能由R1或R2授权。 为什么channel如此重要？channels之所以有用，是因为它们为联盟成员之间的私有通信和私有数据提供了一种机制。channel提供了隐私性保护，对于其他的channels和整个网络。Hyperledger Fabric在这方面很强大，因为它允许组织共享基础结构并同时保持私有状态。这里没有矛盾-网络中的不同联盟需要适当共享不同的信息和流程，而渠道则提供了一种有效的机制来做到这一点。通道可有效共享基础架构，同时保持数据和通信的隐私。 我们还可以看到，一旦创建了一个channel，它实际上就是“脱离网络”。从创建开始到未来，只有在channel配置中明确指定的组织才能对其进行控制。同样，从此时开始对网络配置NC4的任何更新都不会直接影响channel配置CC1；例如，如果联盟定义X1更改，它将不会影响通道C1的成员。通道之所以有用，是因为它们允许构成通道的组织之间进行私人通信。此外，通道中的数据与网络的其余部分（包括其他通道）完全隔离。 顺便说一句，还有一个特殊的系统通道（system channel）的定义，是为了给排序服务（ordering service）使用的。它的行为与常规channel完全相同，因此，有时也称为应用程序通道（application channels）。 Peers and Ledgers（节点与账单） 现在开始使用渠道将区块链网络和组织组件连接在一起。在网络开发的下一阶段，我们可以看到我们的网络N刚刚获得了两个新组件，即peer节点P1和账本实例L1。 peer节点P1已加入通道C1。 P1物理上存储账本L1的副本。 P1和O4可以使用通道C1相互通信。 peer节点是托管区块链账本副本的网络组件，最后，我们开始看到一些可识别的区块链组件。P1在网络中的目的纯粹是托管账本L1的副本，以供其他人访问。我们可以认为L1物理上托管在P1上，但逻辑上托管在通道C1上。当我们向channel添加更多peer时，我们会更清楚地看到这个想法。 P1配置的关键部分是CA1发出的X.509身份，该身份将P1与组织R1相关联。当R1组织的管理员将peer节点P1加入通道C1并且P1开始从排序节点O4拉取数据块的时候，O4使用通道配置CC1来确定P1在该通道上的权限。例如，CC1中的策略确定P1（或组织R1）是否可以在通道C1上读取（和/或）写入。 注意拥有peer的组织是如何将peer加入渠道的，尽管我们仅添加了一个peer，但我们将看到网络中的多个渠道上如何有多个peer节点。稍后我们将看到peer可以扮演的不同角色。 Applications and Smart Contract chaincode（应用程序和智能合约联链码） 现在，通道C1上有一个账本L1，我们可以开始连接客户端应用程序，以使用为操作账本提供服务的peer。 请注意网络已经增长了： 已经智能合约S5已经被部署到了P1，属于组织R1的客户端应用程序A1可以使用S5通过P1来访问账本L1。A1、P1和O4都加入了通道C1，如图所示，A1、P1和O4都加入了通道C1，即它们都可以利用该通道提供的通信设施。 在网络开发的下一阶段，我们可以看到客户端应用程序A1可以使用通道C1连接到特定的网络资源–在这种情况下，A1可以同时连接到peer节点P1和ordered节点O4。让我们在此之前查看渠道是如何成为网络和组织组件之间通信核心的。就像对peer节点和ordered节点一样，客户端应用程序也具有一个可以将其与组织关联起来的身份。在我们的例子中，客户端应用程序A1与组织R1关联，尽管它在Fabric区块链网络之外，但仍然可以通过渠道C1访问到区块链。 现在看来，A1可以直接通过P1访问分类帐L1，但实际上，所有访问都是通过称为智能合约链码S5的特殊程序进行管理的。将S5定义为账本的所有常见访问模式； S5提供了一套明确定义的方式，可用来查询或更新账本L1。 每个组织的开发人员都可以创建智能合约，然后发起在联盟之间共享的业务流程。智能合约用于生成可以分配到网络中每个节点的交易。我们稍后再讨论这个想法；当网络更大时，将更容易理解。现在，需要了解的重要一点是，到此为止，必须在智能合约上执行两次操作。目前为止，需要了解的重要一点是必须在智能合约上执行两次操作： 它必须已经安装（installed）在peer上 然后已经在通道上定义（defined） Hyperledger Fabric用户经常把术语智能合约（smart contract）和链码（chaincode）进行互换使用。通常，智能合约定义了交易逻辑（ transaction logic ），这个交易逻辑控制了现实世界状态中包含业务对象的生命周期。然后将其打包成链码，然后将其部署到区块链网络。可以将智能合约视为支配交易，而链码则是控制如何打包智能合约以进行部署。 Installing a chaincode package（安装链码包） 开发了智能合约S5之后，组织R1中的管理员必须创建一个链码包并将其安装到peer节点P1上。这是一个简单的操作；一旦完成，P1就完全了解S5。具体来说，P1可以看到S5的**实现（implementation）逻辑-就是用于访问账本L1的代码。我们将此与S5的接口（interface）**进行对比，后者仅描述S5的输入和输出，而与它的实现无关。 当一个组织在一个渠道中有多个peer时，它可以选择在哪些peer节点安装智能合约。它不需要在每个peer节点上安装智能合约。 Defining a chaincode（定义链码） 尽管链码已安装在各个组织的peer上，但它是在channel范围内管理和操作的。每个组织都需要批准链码定义（chaincode definition），这是一组参数，用于确定如何在渠道上使用链码。组织必须批准链码定义，才能使用已安装的智能合约来查询账本并认可交易。在我们的只有一个peer节点P1的例子中，组织R1中的管理员必须批准S5的链码定义（chaincode definition）。 需要足够数量的组织批准链码定义（chaincode definition）（默认情况下，大多数情况下为批准），然后才能将链码定义提交给渠道并用于与渠道账本进行交互。由于例子中的通道C1只有一个成员，因此R1的管理员可以将S5的链码定义提交给通道C1。提交链码的定义后，便可以由客户端应用程序A1调用S5！ 请注意，尽管通道上的每个组件现在都可以访问S5，但它们无法看到其程序逻辑。对于安装它的那些节点（我们的示例中是P1），它仍然是私有的。从概念上讲，这意味着已定义并提交给渠道的智能合约接口与已安装的智能合约实现相反。加强这个想法；安装智能合约我们可以将其视为物理托管（physically hosted）在peer上，而已在通道上定义的智能合约我们可以将其视为逻辑托管（ logically hosted）在通道上。 Endorsement policy（背书策略） 链码定义中提供的最重要的信息是背书策略。它描述了哪些组织必须批准交易然后其他组织才能将其接受到其账本副本上。在我们的示例网络中，只有R1或R2认可交易，才能将交易接受到账本L1上。 将链码定义提交给渠道会将背书策略放在渠道的账本上；它使通道的任何成员都可以访问它。您可以在交易流主题中阅读有关背书策略的更多信息。 Invoking a smart contract（调用智能合约） 将智能合约安装在peer节点上并在channel上定义后，即可由客户端应用程序调用。 客户端应用程序通过向由智能合约背书策略指定的组织所拥有的节点发起交易提案；智能合约使用交易提案作为它的输入来生成认可的交易响应，该响应由peer节点返回到客户端应用程序。 这些交易响应与交易提议打包在一起，形成一个完全认可的交易，可以分散到整个网络。现在了解应用程序如何调用智能合约以生成认可的交易即可，稍后我们将对其进行更详细的介绍。 在网络开发的这一阶段，我们可以看到组织R1正在完全参与网络。它的应用程序-从A1开始-可以通过智能合约S5访问账本L1，以生成将由R1认可的交易，由于它们符合认可策略因此被接受到账本中。 Network completed（网络完成） 回想一下，我们的目标是为联盟X1（组织R1和R2）创建渠道。网络开发的下一阶段将看到组织R2将其基础结构添加到网络中。 让我们来看看网络进化成什么样了： 通过增加组织R2的基础结构，网络得到了发展。具体来说，R2添加了peer节点P2，该peer节点托管账本L1的副本和链码S5。R2批准与R1相同的链码定义。P2也与应用程序A2一样加入了通道C1，A2和P2通过CA2进行身份认证。所有这些意味着应用程序A1和A2都可以使用peer节点P1或P2在C1上调用S5。 我们可以看到组织R2在通道C1上添加了一个peer节点P2。 P2还托管账本L1的副本和智能合约S5。我们可以看到R2还添加了可以通过通道C1连接到网络的客户端应用程序A2。为此，组织R2中的管理员已创建peer节点P2，并将其用与R1中的管理员相同的方式加入到通道C1。管理员还必须批准与R1相同的链码定义。 我们已经建立了第一个运营网络！在网络开发的现阶段，我们拥有一个渠道，在此通道上组织R1和R2可以彼此进行交易。具体来说，这意味着应用程序A1和A2可以使用智能合约S5和通道C1上的账本L1生成交易。 Generating and accepting transactions（生成和接受交易） 与始终托管着账本副本的peer节点相反，我们看到有两种不同的peer节点：拥有智能合约的peer和没有智能合约的peer。在我们的网络中，每个peer都托管着智能合约的副本，但是在较大的网络中，将有更多的peer节点不托管智能合约的副本。peer节点只能运行安装在其上的智能合约，但是它可以通过连接到通道来知道智能合约的接口。 您不应该将没有安装智能合约的peer节点视为劣等节点。具有智能合约的peer节点更具有特殊的功能-有助于**生成（generate ）交易。请注意，所有peer节点都可以验证（validate）并随后接受（accept）或拒绝（reject）交易到其账本L1的副本上。但是，只有安装了智能合约的peer节点才能参与交易认可（endorsement）**的过程，这对生成合法交易至关重要。 我们无需担心本主题中如何生成，分配和接受交易的确切细节–能够理解我们拥有一个区块链网络，组织R1和R2可以共享信息和流程作为账本接受（ledger-captured）的交易。我们将在其他主题中学习有关交易，账本，智能合约的更多信息。 Types of peers（peer节点的类型） 在Hyperledger Fabric中，尽管所有peer都相同，但它们可以根据网络的配置方式承担多个角色。现在，我们对典型的网络拓扑有了足够的了解，可以描述这些角色。 Committing peer：提交peer节点，通道中的每个peer节点都是提交peer节点。它接收包含已经生成的交易的块，随后将其验证，然后再将它们以追加的方式提交到peer节点的账本副本中。 Endorsing peer：背书节点，每一个安装了智能合约的peer节点都可以成为背书节点。但是要真正成为背书节点，客户端应用程序必须使用peer的智能合约来生成数字签名的事务响应。背书对等方一词是对此事实的明确引用。 智能合约的背书策略确定组织的peer应先对生成的交易进行数字签名，然后才能将其接受到提交peer的账本副本中。 上面是peer节点的的两种主要类型。peer还可以采用其他两种角色： Leader peer：领导节点，当一个组织在同一个channel中有多个peer节点时，领导节点负责将交易从排序节点分发到组织内的其他提交节点。一个peer可以选择参与静态或动态领导选择。 因此，从领导者的角度考虑两组peer是有帮助的-那些具有静态领导者选择的peer和那些具有动态领导者选择的peer。对于静态节点，可以将零个或多个peer配置为领导节点。对于动态节点集合，将由该集合选出一个peer作为领导者。此外，在动态集合中，如果领导节点失败了，则其余peer将重新选举领导节点。 这意味着同一个组织的peers可以让一个或多个领导节点连接到排序服务。这可以帮助提高处理大量事务的大型网络的弹性和可伸缩性。 Anchor peer:锚节点，如果peer需要与另一个组织中的peer进行通信，则可以使用该组织在通道配置中定义的锚节点。一个组织可以为其定义零个或多个锚节点，并且锚节点可以帮助处理许多不同的跨组织通信场景。 注意，一个peer可以同时是一个提交节点、背书节点、领导节点和锚节点！在一个组织中出于所有实际目的，仅锚节点是可选的，领导节点，背书节点和提交节点都至少有一个。 Adding organizations and peers to the channel（将组织和节点添加到渠道） 当组织R2加入通道时，它必须在其peer节点P2上安装智能合约S5。这很明显–如果应用程序A1或A2希望在peer节点P2上使用S5来生成交易，首先S5必须存在，安装智能合约可以做到让其存在。此时，peer节点P2具有智能合约和账本的物理副本；像P1一样，它可以在其账本L1的副本上生成和接受交易。 为了使用智能合约S5，R2必须批准与R1批准的相同的链码定义。由于链码定义已由组织R1提交给通道，因此R2组织批准链码定义并安装链码软件包后便可以使用链码了。提交交易只需发生一次。一个新的组织认可链码参数的行为被通道内的其他组织统一后便可以使用链码。由于链码定义的认可是在组织级别进行的，因此R2认可链码定义一次，然后将多个peer节点加入安装了链码包的渠道。然而，如果R2想要对链码定义进行修改的话，则R1和R2都需要在组织层面认可这个新的链码定义，然后需要其中一个组织将定义提交给渠道。 在我们的网络中，我们可以看到通道C1链接了两个客户端应用程序，两个peer节点和一个排序服务。由于只有一个通道，因此也只有一个逻辑账本可以与这些组件进行交互。节点P1和P2有相同的账本L1的副本。智能合约S5的副本通常使用相同的编程语言来实现，但如果不同，则他们在语义上必须等效。 我们可以看到，将对peer小心地添加到网络可以帮助支持增加的吞吐量，稳定性和弹性。例如，网络中更多的peer节点将允许更多的应用程序连接到它；在遇到计划内或计划外的停机时组织中的多个peer将提供额外的弹性。 这一切都意味着可以配置支持各种操作目标的复杂的拓扑网络，网络可以达到的规模不存在理论上的限制。此外，单个组织中的peer可以有效地发现并彼此通信的技术机制-gossip protocol-将容纳大量peer节点以支持此类拓扑。 仔细使用网络和通道策略可以使大型网络得到良好管理。组织可以自由地将peer节点添加到网络，只要它们符合网络约定的策略即可。网络和渠道策略在自治和控制之间建立了平衡，这是去中心化网络的特征。 Simplifying the visual vocabulary（简化视觉词汇） We’re now going to simplify the visual vocabulary used to represent our sample blockchain network. As the size of the network grows, the lines initially used to help us understand channels will become cumbersome. Imagine how complicated our diagram would be if we added another peer or client application, or another channel? 现在，我们将简化用于表示示例区块链网络的视觉词汇。随着网络规模的扩大，最初用于帮助我们了解渠道的线路将变得很繁琐。想想一些如果我们添加另一个peer节点或者一个客户端或者另一个channel我们的图片有多复杂？ That’s what we’re going to do in a minute, so before we do, let’s simplify the visual vocabulary. Here’s a simplified representation of the network we’ve developed so far: 这就是我们紧接着要做的事情，因此在我们这样做之前，让我们简化视觉词汇。这是到目前为止我们开发的网络的简化表示： The diagram shows the facts relating to channel C1 in the network N as follows: Client applications A1 and A2 can use channel C1 for communication with peers P1 and P2, and orderer O4. Peer nodes P1 and P2 can use the communication services of channel C1. Ordering service O4 can make use of the communication services of channel C1. Channel configuration CC1 applies to channel C1. 该图显示了与网络N中的通道C1有关的事实，如下所示：客户端程序A1和A2可以使用通道C1来与peer节点P1和P2和排序节点O4进行通信。peer节点P1和P2可以使用通道C1的通信服务。排序服务O4可以利用通道C1的通信服务。通道配置CC1适用于通道C1。 Note that the network diagram has been simplified by replacing channel lines with connection points, shown as blue circles which include the channel number. No information has been lost. This representation is more scalable because it eliminates crossing lines. This allows us to more clearly represent larger networks. We’ve achieved this simplification by focusing on the connection points between components and a channel, rather than the channel itself. 请注意，这个网络图已经通过用连接点替换通道线来简化了，显示为带有通道编号的蓝色圆圈。没有信息丢失。此表示形式更具伸缩性，因为它消除了交叉线。这使我们可以更清楚地表示更大的网络。通过专注于组件和通道之间的连接点，而不是通道本身，我们实现了这种简化。 Adding another consortium definition（添加另一个联盟定义） In this next phase of network development, we introduce organization R3. We’re going to give organizations R2 and R3 a separate application channel which allows them to transact with each other. This application channel will be completely separate to that previously defined, so that R2 and R3 transactions can be kept private to them. 在网络开发的下一阶段，我们介绍组织R3。我们将为组织R2和R3提供一个单独的应用程序渠道，使他们可以彼此进行交易。该应用程序通道将与先前定义的通道完全分开，因此可以使R2和R3的交易保持私有。 Let’s return to the network level and define a new consortium, X2, for R2 and R3: 让我们回到网络级别并且为R2和R3定义一个新的联盟X2： A network administrator from organization R1 or R4 has added a new consortium definition, X2, which includes organizations R2 and R3. This will be used to define a new channel for X2. R1或者R4的网络管理员已经添加了一个新的联盟定义X2，这个联盟定义包含了R2和R3两个组织。这将被用于为X2定义一个新的通道。 Notice that the network now has two consortia defined: X1 for organizations R1 and R2 and X2 for organizations R2 and R3. Consortium X2 has been introduced in order to be able to create a new channel for R2 and R3. 注意网络中现在已经有两个联盟定义，组织R1与R2的联盟X1和组织R2与R3的联盟X2。联盟X2已经被引进以便为R2和R3创建新的通道。 A new channel can only be created by those organizations specifically identified in the network configuration policy, NC4, as having the appropriate rights to do so, i.e. R1 or R4. This is an example of a policy which separates organizations that can manage resources at the network level versus those who can manage resources at the channel level. Seeing these policies at work helps us understand why Hyperledger Fabric has a sophisticated tiered policy structure. 新渠道只能由网络配置策略中明确标识的组织创建，网络中NC4具有适当权限的，即R1或R4。这是策略的示例，该策略将可以在网络级别管理资源的组织与可以在通道级别管理资源的组织区分开来。看到这些策略在起作用，有助于我们理解为什么Hyperledger Fabric具有复杂的分层策略结构。 In practice, consortium definition X2 has been added to the network configuration NC4. We discuss the exact mechanics of this operation elsewhere in the documentation. 实际上，联盟定义X2已添加到网络配置NC4。我们将在文档的其他地方讨论此操作的确切机制。 Adding a new channel（添加一个新的通道） Let’s now use this new consortium definition, X2, to create a new channel, C2. To help reinforce your understanding of the simpler channel notation, we’ve used both visual styles – channel C1 is represented with blue circular end points, whereas channel C2 is represented with red connecting lines: 让我们使用新的X2联盟定义来创建一个新的通道C2。为了帮助您进一步理解更简单的通道符号，我们使用了两种视觉样式-通道C1用蓝色圆形端点表示，而通道C2用红色连接线表示： A new channel C2 has been created for R2 and R3 using consortium definition X2. The channel has a channel configuration CC2, completely separate to the network configuration NC4, and the channel configuration CC1. Channel C2 is managed by R2 and R3 who have equal rights over C2 as defined by a policy in CC2. R1 and R4 have no rights defined in CC2 whatsoever. 使用联盟定义X2为R2和R3创建了一个新的通道C2。这个通道有一个通道配置CC2，完全独立于网络配置NC4和通道配置CC1。通道C2由R2和R3管理，它们具有CC2中的策略所定义的对C2相同的权限。 R1和R4在CC2中均未定义任何权限。 The channel C2 provides a private communications mechanism for the consortium X2. Again, notice how organizations united in a consortium are what form channels. The channel configuration CC2 now contains the policies that govern channel resources, assigning management rights to organizations R2 and R3 over channel C2. It is managed exclusively by R2 and R3; R1 and R4 have no power in channel C2. For example, channel configuration CC2 can subsequently be updated to add organizations to support network growth, but this can only be done by R2 or R3. 通道C2为联盟X2提供了专用通信机制。再次注意，组织是如何通过通道被联合起来的。通道配置CC2现在包含控制通道资源的策略，通过通道C2向组织R2和R3分配管理权限。它仅由R2和R3管理； R1和R4在通道C2中没有权限。例如，通道配置CC2随后可以更新以添加组织来支持网络增长，但这只能由R2或R3完成。 Note how the channel configurations CC1 and CC2 remain completely separate from each other, and completely separate from the network configuration, NC4. Again we’re seeing the de-centralized nature of a Hyperledger Fabric network; once channel C2 has been created, it is managed by organizations R2 and R3 independently to other network elements. Channel policies always remain separate from each other and can only be changed by the organizations authorized to do so in the channel. 请注意，通道配置CC1和CC2如何保持彼此完全独立，并与网络配置NC4完全独立。再次，我们看到了Hyperledger Fabric网络的去中心化性质；创建通道C2后，组织R2和R3会独立于其他网络元素来管理它。渠道策略始终保持彼此独立，并且只能由有权在通道中更改的组织进行更改。 As the network and channels evolve, so will the network and channel configurations. There is a process by which this is accomplished in a controlled manner – involving configuration transactions which capture the change to these configurations. Every configuration change results in a new configuration block transaction being generated, and later in this topic, we’ll see how these blocks are validated and accepted to create updated network and channel configurations respectively. 随着网络和通道的发展，网络和通道的配置也将随之发展。有一个过程可以通过受控的方式完成此过程-涉及配置事务，这些事务捕获对这些配置的更改。每次配置更改都会导致生成新的配置块事务，本主题后面的内容，我们将看到如何验证和接受这些区块，以分别创建更新的网络和通道配置。 Network and channel configurations（网络与通道配置） Throughout our sample network, we see the importance of network and channel configurations. These configurations are important because they encapsulate the policies agreed by the network members, which provide a shared reference for controlling access to network resources. Network and channel configurations also contain facts about the network and channel composition, such as the name of consortia and its organizations. 通过我们简单的网络，我们看到了网络和通道配置的重要性。这些配置之所以如此重要是因为他们封装了网络成员的认可策略，这些策略提供了对网络资源的共享的控制。网络和通道配置还包含有关网络和通道组成的事实，比如联盟以及组成联盟的组织。 For example, when the network is first formed using the ordering service node O4, its behaviour is governed by the network configuration NC4. The initial configuration of NC4 only contains policies that permit organization R4 to manage network resources. NC4 is subsequently updated to also allow R1 to manage network resources. Once this change is made, any administrator from organization R1 or R4 that connects to O4 will have network management rights because that is what the policy in the network configuration NC4 permits. Internally, each node in the ordering service records each channel in the network configuration, so that there is a record of each channel created, at the network level. 例如，当首先使用排序服务节点O4形成网络时，其行为由网络配置NC4控制。NC4的初始配置仅包含允许组织R4管理网络资源的策略。随后将NC4更新为还允许R1管理网络资源。一旦做了这个更新，组织R1和R4的管理员都拥有了网络管理权限了，因为这是在网络配置NC2的策略中指定的。在内部，排序服务中的每个节点都会记录网络配置中的每个通道，以便在网络级别上记录每个创建的通道。 It means that although ordering service node O4 is the actor that created consortia X1 and X2 and channels C1 and C2, the intelligence of the network is contained in the network configuration NC4 that O4 is obeying. As long as O4 behaves as a good actor, and correctly implements the policies defined in NC4 whenever it is dealing with network resources, our network will behave as all organizations have agreed. In many ways NC4 can be considered more important than O4 because, ultimately, it controls network access. 这意味着尽管排序服务节点O4是创建联盟X1和X2以及渠道C1和C2的参与者，网络的智能包含在O4遵循的网络配置NC4中。只要O4表现出色，并且在处理网络资源时正确执行NC4中定义的策略，我们的网络将按照所有组织的同意行事。在许多方面，NC4比O4更重要，因为它最终控制了网络访问。 The same principles apply for channel configurations with respect to peers. In our network, P1 and P2 are likewise good actors. When peer nodes P1 and P2 are interacting with client applications A1 or A2 they are each using the policies defined within channel configuration CC1 to control access to the channel C1 resources. 相同的原则适用于有关peer节点的通道配置。在我们的网络中，P1和P2同样是好角色。当peer节点P1和P2与客户端应用程序A1或A2交互时，它们每个都使用在通道配置CC1中定义的策略来控制对通道C1资源的访问。 For example, if A1 wants to access the smart contract chaincode S5 on peer nodes P1 or P2, each peer node uses its copy of CC1 to determine the operations that A1 can perform. For example, A1 may be permitted to read or write data from the ledger L1 according to policies defined in CC1. We’ll see later the same pattern for actors in channel and its channel configuration CC2. Again, we can see that while the peers and applications are critical actors in the network, their behaviour in a channel is dictated more by the channel configuration policy than any other factor. 例如，如果A1想要在peer节点P1或P2上访问智能合约S5，每个对等节点使用其CC1副本确定A1可以执行的操作。比如，根据CC1中的策略定义A1可以可能可以读写账本L1。稍后我们将在通道及其通道配置CC2中看到针对角色的相同模式。同样，我们可以看到，尽管peer节点和应用程序是网络中的关键角色，它们在通道中的行为受通道配置策略的支配，而不是其他任何因素。 Finally, it is helpful to understand how network and channel configurations are physically realized. We can see that network and channel configurations are logically singular – there is one for the network, and one for each channel. This is important; every component that accesses the network or the channel must have a shared understanding of the permissions granted to different organizations. 最后，了解物理上如何实现网络和通道配置将很有帮助。我们可以看到网络和通道配置在逻辑上是唯一的，网络有一个配置，每个通道也都有一个配置。这个很重要，访问网络或通道的每个组件都必须对授予不同组织的权限有共同的了解。 Even though there is logically a single configuration, it is actually replicated and kept consistent by every node that forms the network or channel. For example, in our network peer nodes P1 and P2 both have a copy of channel configuration CC1, and by the time the network is fully complete, peer nodes P2 and P3 will both have a copy of channel configuration CC2. Similarly ordering service node O4 has a copy of the network configuration, but in a multi-node configuration, every ordering service node will have its own copy of the network configuration. 即使从逻辑上讲只有一个配置，但实际上它被构成网络或通道的每个节点复制并保持一致。例如，在我们的网络peer节点P1和P2中都有一个通道配置CC1的副本，到网络完全完成时，peer节点P2和P3都将拥有通道配置CC2的副本。类似的排序服务节点O4有一个网络配置的副本，但是在多节点配置中，每个订购服务节点都将拥有自己的网络配置副本。 Both network and channel configurations are kept consistent using the same blockchain technology that is used for user transactions – but for configuration transactions. To change a network or channel configuration, an administrator must submit a configuration transaction to change the network or channel configuration. It must be signed by the organizations identified in the appropriate policy as being responsible for configuration change. This policy is called the mod_policy and we’ll discuss it later. 网络和通道配置使用与用户交易相同的区块链技术保持不可篡改，但是这里是用的是配置交易。要修改一个网络或者通道的配置，管理员必须提交一个配置交易来更改网络或者通道的配置。必须由适当策略中确定负责配置更改的组织签名。这项政策称为mod_policy，我们将在后面讨论。 Indeed, the ordering service nodes operate a mini-blockchain, connected via the system channel we mentioned earlier. Using the system channel ordering service nodes distribute network configuration transactions. These transactions are used to co-operatively maintain a consistent copy of the network configuration at each ordering service node. In a similar way, peer nodes in an application channel can distribute channel configuration transactions. Likewise, these transactions are used to maintain a consistent copy of the channel configuration at each peer node. 的确，排序服务节点运行着一个微型区块链，通过我们前面提到的系统通道连接。排序服务节点使用系统通道来分发网络配置交易。这些交易用于保持每个排序服务节点合作维护网络配置有一致的副本。以类似的方式，应用程序通道中的peer节点可以分发通道配置交易。同样，这些交易用于保持在每个peer节点上维护的通道配置的副本一致。 This balance between objects that are logically singular, by being physically distributed is a common pattern in Hyperledger Fabric. Objects like network configurations, that are logically single, turn out to be physically replicated among a set of ordering services nodes for example. We also see it with channel configurations, ledgers, and to some extent smart contracts which are installed in multiple places but whose interfaces exist logically at the channel level. It’s a pattern you see repeated time and again in Hyperledger Fabric, and enables Hyperledger Fabric to be both de-centralized and yet manageable at the same time. 物理是分布式的，逻辑上是单一的这种对象之间的平衡是Hyperledger Fabric中的常见模式。例如，逻辑上单一的对象（如网络配置）实际上是在一组排序服务节点之间进行物理复制的。我们会在通道配置、账本和在某种程度上安装在多个位置但逻辑上存在于通道级别的智能合约上看到相同的情况。您在Hyperledger Fabric中一次又一次地看到这种模式，并使Hyperledger Fabric既可以分散管理，又可以同时进行管理。 Adding another peer（添加另一个peer节点） Now that organization R3 is able to fully participate in channel C2, let’s add its infrastructure components to the channel. Rather than do this one component at a time, we’re going to add a peer, its local copy of a ledger, a smart contract and a client application all at once! 现在组织R3可以完全参与渠道C2了，让我们将其基础结构组件添加到渠道中。我们不会一次添加一个组件，而是一次添加一个peer以及其账本的本地副本、智能合约和客户端应用程序！ Let’s see the network with organization R3’s components added: 让我们看一下添加了组织R3组件的网络： The diagram shows the facts relating to channels C1 and C2 in the network N as follows: Client applications A1 and A2 can use channel C1 for communication with peers P1 and P2, and ordering service O4; client applications A3 can use channel C2 for communication with peer P3 and ordering service O4. Ordering service O4 can make use of the communication services of channels C1 and C2. Channel configuration CC1 applies to channel C1, CC2 applies to channel C2. 该图显示了与网络N中的通道C1和C2有关的事实，如下所示：客户端应用程序A1和A2可以使用通道C1来与peer节点P1和P2以及排序服务O4进行通信；客户端应用程序A3可以使用通道来与peer节点P3和排序服务O4进行通信。排序服务O4可以利用通道C1和C2的通信服务。通道配置CC1适用于通道C1，CC2适用于通道C2。 First of all, notice that because peer node P3 is connected to channel C2, it has a different ledger – L2 – to those peer nodes using channel C1. The ledger L2 is effectively scoped to channel C2. The ledger L1 is completely separate; it is scoped to channel C1. This makes sense – the purpose of the channel C2 is to provide private communications between the members of the consortium X2, and the ledger L2 is the private store for their transactions. 首先，请注意，由于peer节点P3连接到通道C2，他拥有一个与通道C1上的节点不一样的账本L2。账本L2的有效范围为通道C2。分类帐L1是完全独立的；它的作用域是通道C1。这是有道理的-通道C2的目的是在财团X2的成员之间提供私人通信，而分类帐L2是其交易的私人商店。 In a similar way, the smart contract S6, installed on peer node P3, and defined on channel C2, is used to provide controlled access to ledger L2. Application A3 can now use channel C2 to invoke the services provided by smart contract S6 to generate transactions that can be accepted onto every copy of the ledger L2 in the network. 以类似的方式，安装在peer节点P3上并定义在通道C2上的智能合约S6用于提供对账本L2的受控访问。应用程序A3现在可以使用通道C2来调用智能合约S6提供的服务来生成交易，以生成可以被接受到网络中账本L2的每个副本上的交易。 At this point in time, we have a single network that has two completely separate channels defined within it. These channels provide independently managed facilities for organizations to transact with each other. Again, this is de-centralization at work; we have a balance between control and autonomy. This is achieved through policies which are applied to channels which are controlled by, and affect, different organizations. 此时，我们有了一个网络，其中定义了两个完全独立的通道。这些通道为组织提供了相互独立管理的设施，以便彼此进行交易。同样，这是工作中的分权；我们在控制和自治之间取得平衡。这是通过将策略应用到受不同组织控制并影响不同组织的渠道来实现的。 Joining a peer to multiple channels（把一个peer节点加入到不同通道） In this final stage of network development, let’s return our focus to organization R2. We can exploit the fact that R2 is a member of both consortia X1 and X2 by joining it to multiple channels: 在网络开发的最后阶段，让我们把重点放回到组织R2。我们可以利用R2是X1和X2联盟的成员这一事实来将R2加入多个渠道： The diagram shows the facts relating to channels C1 and C2 in the network N as follows: Client applications A1 can use channel C1 for communication with peers P1 and P2, and ordering service O4; client application A2 can use channel C1 for communication with peers P1 and P2 and channel C2 for communication with peers P2 and P3 and ordering service O4; client application A3 can use channel C2 for communication with peer P3 and P2 and ordering service O4. Ordering service O4 can make use of the communication services of channels C1 and C2. Channel configuration CC1 applies to channel C1, CC2 applies to channel C2. 该图显示了与网络N中的通道C1和C2有关的下面的事实：客户端应用程序A1可以使用通道C1来与peer节点P1和P2以及排序服务O4进行通信；客户端应用程序A2可以使用通道C1来和peer节点P1和P2通信，并且使用C2来与peer节点P2和P3以及排序服务O4进行通信；客户端应用程序A3可以使用通道C2来与peer节点P3和P2以及排序服务O4进行通信。排序服务O4可以使用通道C1和C2上的通信服务。通道配置CC1服务于通道C1、CC2服务与通道C2。 We can see that R2 is a special organization in the network, because it is the only organization that is a member of two application channels! It is able to transact with organization R1 on channel C1, while at the same time it can also transact with organization R3 on a different channel, C2. 我们可以看到R2是网络上的一个特殊的组织，因为它是两个应用程序通道的成员的唯一组织！他可以在通道C1上与组织R1进行交易，同时它也可以在另一个不同的通道C2上与组织R3进行交易。 Notice how peer node P2 has smart contract S5 installed for channel C1 and smart contract S6 installed for channel C2. Peer node P2 is a full member of both channels at the same time via different smart contracts for different ledgers. 请注意，peer节点P2如何为通道C1安装了智能合约S5，并为通道C2安装了智能合约S6。peer节点P2通过不同账本的不同智能合约同时是两个渠道的正式成员。 This is a very powerful concept – channels provide both a mechanism for the separation of organizations, and a mechanism for collaboration between organizations. All the while, this infrastructure is provided by, and shared between, a set of independent organizations. 这是一个非常强大的概念-渠道既提供了组织分离的机制，也提供了组织之间协作的机制。一直以来，此基础结构（即通道）由一组独立的组织提供并在它们之间共享。 It is also important to note that peer node P2’s behaviour is controlled very differently depending upon the channel in which it is transacting. Specifically, the policies contained in channel configuration CC1 dictate the operations available to P2 when it is transacting in channel C1, whereas it is the policies in channel configuration CC2 that control P2’s behaviour in channel C2. 同样重要的是要注意，peer节点P2的行为受其进行交易的通道的控制非常不同。具体而言，通道配置CC1中包含的策略规定了P2在通道C1中进行交易时可使用的操作，而通道配置CC2中的策略控制渠道P2在渠道C2中的行为。 Again, this is desirable – R2 and R1 agreed the rules for channel C1, whereas R2 and R3 agreed the rules for channel C2. These rules were captured in the respective channel policies – they can and must be used by every component in a channel to enforce correct behaviour, as agreed. 同样，R2和R1同意通道C1的规则，而R2和R3同意了通道C2的规则是可取的。这些规则是在各自的通道的政策中获取的-渠道中的每个组件都可以并且必须使用它们来强制执行正确的行为，这已经达成共识。 Similarly, we can see that client application A2 is now able to transact on channels C1 and C2. And likewise, it too will be governed by the policies in the appropriate channel configurations. As an aside, note that client application A2 and peer node P2 are using a mixed visual vocabulary – both lines and connections. You can see that they are equivalent; they are visual synonyms. 同样，我们可以看到客户端应用程序A2现在能够在通道C1和C2上进行交易。同样，它也将由适当的通道配置中的策略控制。顺便提一句，请注意客户端应用程序A2和peer节点P2正在使用混合的可视词汇表（包括行和连接）。您可以看到它们是等效的。它们是视觉同义词。 The ordering service（排序服务） The observant reader may notice that the ordering service node appears to be a centralized component; it was used to create the network initially, and connects to every channel in the network. Even though we added R1 and R4 to the network configuration policy NC4 which controls the orderer, the node was running on R4’s infrastructure. In a world of de-centralization, this looks wrong! 细心的读者可能会注意到排序服务节点似乎是一个集中式组件，他被用于创建初始化网络，并且链接网络中的所有的通道。即使我们在控制排序者的网络配置策略NC4中添加了R1和R4，该节点仍在R4的基础架构上运行。在去中心化的世界中，这看起来是错误的！ Don’t worry! Our example network showed the simplest ordering service configuration to help you understand the idea of a network administration point. In fact, the ordering service can itself too be completely de-centralized! We mentioned earlier that an ordering service could be comprised of many individual nodes owned by different organizations, so let’s see how that would be done in our sample network. 不要担心！我们的示例网络显示了最简单的排序服务配置，以帮助您了解网络管理点的概念。事实上，排序服务自己也是完全去中心化的。前面我们提到过，排序服务可以由不同组织拥有的许多单个节点组成，因此让我们看看如何在示例网络中完成该工作。 Let’s have a look at a more realistic ordering service node configuration: 让我们看一个更接近现实的排序服务节点配置： A multi-organization ordering service. The ordering service comprises ordering service nodes O1 and O4. O1 is provided by organization R1 and node O4 is provided by organization R4. The network configuration NC4 defines network resource permissions for actors from both organizations R1 and R4. 多组织的排序服务。排序服务包含排序节点O1和O4。O1是由组织R1提供而节点O4是由组织R4提供。网络配置NC4为组织R1和R4的参与者定义了网络资源权限。 We can see that this ordering service completely de-centralized – it runs in organization R1 and it runs in organization R4. The network configuration policy, NC4, permits R1 and R4 equal rights over network resources. Client applications and peer nodes from organizations R1 and R4 can manage network resources by connecting to either node O1 or node O4, because both nodes behave the same way, as defined by the policies in network configuration NC4. In practice, actors from a particular organization tend to use infrastructure provided by their home organization, but that’s certainly not always the case. 我们看到排序服务已经是完全的去中心化了，他运行在组织R1和R4上。网络配置策略NC4，允许R1和R4在网络资源上享有同等的权利。组织R1和R4的客户端程序和peer节点可以通过O1和O4的任意一个来管理网络上的资源，因为两个节点的行为方式均与网络配置NC4中的策略所定义的方式相同。实际上，来自特定组织的参与者往往会使用其上级组织提供的基础架构，但这并非总是如此。 De-centralized transaction distribution（去中心化的交易分发） As well as being the management point for the network, the ordering service also provides another key facility – it is the distribution point for transactions. The ordering service is the component which gathers endorsed transactions from applications and orders them into transaction blocks, which are subsequently distributed to every peer node in the channel. At each of these committing peers, transactions are recorded, whether valid or invalid, and their local copy of the ledger updated appropriately. 排序服务不仅是网络的管理点，还提供了另一个关键功能–它是交易的分发点。排序服务是一个组件，这个组件从应用程序中收集认可交易并将其排序到交易块中，随后分发给通道中的每个peer节点。在每个提交节点中，交易会被记录（不论是成功还是失败），并在本地更新账本。 Notice how the ordering service node O4 performs a very different role for the channel C1 than it does for the network N. When acting at the channel level, O4’s role is to gather transactions and distribute blocks inside channel C1. It does this according to the policies defined in channel configuration CC1. In contrast, when acting at the network level, O4’s role is to provide a management point for network resources according to the policies defined in network configuration NC4. Notice again how these roles are defined by different policies within the channel and network configurations respectively. This should reinforce to you the importance of declarative policy based configuration in Hyperledger Fabric. Policies both define, and are used to control, the agreed behaviours by each and every member of a consortium. 请注意，排序服务节点O4如何对通道C1起到与对网络N完全不同的作用。在作用于通道级别时，O4的作用是在通道C1里面收集和分发区块的。它根据通道配置CC1中定义的策略执行此操作。作为对比，在网络级别执行操作时，O4的作用是根据网络配置NC4中定义的策略为网络资源提供管理点。再次注意，这些角色是如何分别由通道和网络配置中的不同策略定义的。这应该向您强调Hyperledger Fabric中基于声明策略的配置的重要性。策略既定义了联盟的每个成员，又用于控制联盟的每个成员的行为。 We can see that the ordering service, like the other components in Hyperledger Fabric, is a fully de-centralized component. Whether acting as a network management point, or as a distributor of blocks in a channel, its nodes can be distributed as required throughout the multiple organizations in a network. 我们看到像Hyperledger Fabric中的其他组件一样，排序服务是一个完全的去中心化的组件。无论是充当网络管理点，还是充当通道中的区块分配器，它的节点可以根据需要分布在网络中的多个组织中。 Changing policy（修改策略） Throughout our exploration of the sample network, we’ve seen the importance of the policies to control the behaviour of the actors in the system. We’ve only discussed a few of the available policies, but there are many that can be declaratively defined to control every aspect of behaviour. These individual policies are discussed elsewhere in the documentation. 在整个示例网络的探索过程中，我们已经了解了控制系统中参与者行为的策略的重要性。我们仅讨论了一些可用的策略，但是可以声明性地定义许多策略来控制行为的各个方面。这些单独的策略在文档的其他地方进行了讨论。 Most importantly of all, Hyperledger Fabric provides a uniquely powerful policy that allows network and channel administrators to manage policy change itself! The underlying philosophy is that policy change is a constant, whether it occurs within or between organizations, or whether it is imposed by external regulators. For example, new organizations may join a channel, or existing organizations may have their permissions increased or decreased. Let’s investigate a little more how change policy is implemented in Hyperledger Fabric. 最重要的是，Hyperledger Fabric 提供了独特而强大的策略，允许网络和通道管理员自行管理策略更改！基本理念是政策变化是一个持续不断的过程，不论它是在组织内部还是组织之间发生，还是由外部监管机构强加。例如，新组织可以加入通道，或者现有组织的权限可以增加或减少。让我们研究一下Hyperledger Fabric中更改策略的实现方式。 The key point of understanding is that policy change is managed by a policy within the policy itself. The modification policy, or mod_policy for short, is a first class policy within a network or channel configuration that manages change. Let’s give two brief examples of how we’ve already used mod_policy to manage change in our network! 理解的关键点是，策略更改由策略本身内的策略来管理。modification policy（修改策略）或者简称为mod_policy，是一个在网络或渠道配置中管理变更的头等仓的策略。让我们举两个简单的例子，说明我们是如何使用mod_policy来管理网络中的更改的！ The first example was when the network was initially set up. At this time, only organization R4 was allowed to manage the network. In practice, this was achieved by making R4 the only organization defined in the network configuration NC4 with permissions to network resources. Moreover, the mod_policy for NC4 only mentioned organization R4 – only R4 was allowed to change this configuration. 第一个示例是最初建立网络时。此时，只有组织R4允许管理网络。在实践中，这是通过使R4成为网络配置NC4中定义的唯一拥有网络资源权限的组织来实现的。此外，NC4的mod_policy仅提及组织R4 –仅允许R4更改此配置。 We then evolved the network N to also allow organization R1 to administer the network. R4 did this by adding R1 to the policies for channel creation and consortium creation. Because of this change, R1 was able to define the consortia X1 and X2, and create the channels C1 and C2. R1 had equal administrative rights over the channel and consortium policies in the network configuration. 然后，我们对网络N进行了演进，以也允许组织R1管理网络。R4通过将R1添加到用于通道创建和联盟创建的策略中来做到这一点。因为这个变更，R1可以定义联盟X1和X2，并且创建了通道C1和C2。网络配置中策略指明R1对通道和联盟具有同等的管理权限。 R4 however, could grant even more power over the network configuration to R1! R4 could add R1 to the mod_policy such that R1 would be able to manage change of the network policy too. 但是，R4可以通过网络配置向R1授予更多权利。R4可以将R1添加到mod_policy中，以便R1也能够管理网络策略的更改。 This second power is much more powerful than the first, because R1 now has full control over the network configuration NC4! This means that R1 can, in principle remove R4’s management rights from the network. In practice, R4 would configure the mod_policy such that R4 would need to also approve the change, or that all organizations in the mod_policy would have to approve the change. There’s lots of flexibility to make the mod_policy as sophisticated as it needs to be to support whatever change process is required. 第二个权利相比于第一个来说强大的多，因为R1现在可以完全控制网络配置NC4！这意味着R1原则上可以从网络中删除R4的管理权限。在实践中，R4将把mod_policy配置成为R4需要批准配置更改，或者mod_policy中的所有组织都必须批准更改。有足够的灵活性可以使mod_policy复杂到可以支持所需的任何更改过程。 This is mod_policy at work – it has allowed the graceful evolution of a basic configuration into a sophisticated one. All the time this has occurred with the agreement of all organization involved. The mod_policy behaves like every other policy inside a network or channel configuration; it defines a set of organizations that are allowed to change the mod_policy itself. 这就是mod_policy的作用，它使基本配置可以优雅地演变为复杂的配置。在所有相关组织达成一致之后，这种情况一直存在。mod_policy的行为与网络或通道配置中的所有其他策略相同；它定义了一组允许更改mod_policy本身的组织。 We’ve only scratched the surface of the power of policies and mod_policy in particular in this subsection. It is discussed at much more length in the policy topic, but for now let’s return to our finished network! 在本小节中，我们仅介绍了策略和mod_policy的功能。在策略主题中将对它进行更详细的讨论，但现在让我们回到完成的网络中！ Network fully formed（网络全面形成） Let’s recap what our network looks like using a consistent visual vocabulary. We’ve re-organized it slightly using our more compact visual syntax, because it better accommodates larger topologies: 让我们使用一致的视觉词汇来回顾一下我们的网络。我们使用更紧凑的视觉语法对其进行了稍微的重组，因为它可以更好地适应更大的拓扑： In this diagram we see that the Fabric blockchain network consists of two application channels and one ordering channel. The organizations R1 and R4 are responsible for the ordering channel, R1 and R2 are responsible for the blue application channel while R2 and R3 are responsible for the red application channel. Client applications A1 is an element of organization R1, and CA1 is it’s certificate authority. Note that peer P2 of organization R2 can use the communication facilities of the blue and the red application channel. Each application channel has its own channel configuration, in this case CC1 and CC2. The channel configuration of the system channel is part of the network configuration, NC4. 在我们看到的这个图片中，Fabirc区块链网络包含两个应用程序通道和一个排序通道。组织R1和R4负责排序通道，R1和R2负责蓝色应用程序通道，而R2和R3负责红色应用程序通道。客户端应用程序A1是组织R1的元素，而CA1是组织的证书颁发机构。注意属于组织R2的Peer节点P2可以同时使用红色和蓝色的应用程序通道的通信设施。每个应用程序通道都有自己的通道配置，例如CC1和CC2。系统通道的通道配置是网络配置（NC4）的一部分。 We’re at the end of our conceptual journey to build a sample Hyperledger Fabric blockchain network. We’ve created a four organization network with two channels and three peer nodes, with two smart contracts and an ordering service. It is supported by four certificate authorities. It provides ledger and smart contract services to three client applications, who can interact with it via the two channels. Take a moment to look through the details of the network in the diagram, and feel free to read back through the topic to reinforce your knowledge, or go to a more detailed topic. 我们构建简单的Hyperledger Fabric区块链网络的概念之旅已结束。我们创建了一个具有两个通道和三个peer节点，两个智能合约和一个排序服务的四个组织的网络。这个网络由四个证书颁发机构支持。这个网络对三个客户端应用程序提供账本和智能合约服务，他们可以通过两个通道与之交互。花一点时间浏览图中的网络详细信息，并随时阅读本主题以增强您的知识，或者转到更详细的主题。 Summary of network components（网络组件的摘要） Here’s a quick summary of the network components we’ve discussed（以下是我们讨论过的网络组件的简要摘要）： Ledger. One per channel. Comprised of the Blockchain and the World state（每个通道一个。由区块链和世界状态组成） Smart contract (aka chaincode)（Also Known As智能合约） Peer nodes（peer节点） Ordering service（排序服务） Channel（通道） Certificate Authority（证书颁发机构） Network summary（网络总结） In this topic, we’ve seen how different organizations share their infrastructure to provide an integrated Hyperledger Fabric blockchain network. We’ve seen how the collective infrastructure can be organized into channels that provide private communications mechanisms that are independently managed. We’ve seen how actors such as client applications, administrators, peers and orderers are identified as being from different organizations by their use of certificates from their respective certificate authorities. And in turn, we’ve seen the importance of policy to define the agreed permissions that these organizational actors have over network and channel resources. 在本主题中，我们已经看到了不同的组织如何共享其基础架构以提供集成Hyperledger Fabric区块链网络。我们已经看到了如何将集体基础结构组织为提供独立管理的私有通信机制的通道。我们已经了解了如何通过使用来自各自证书颁发机构的证书将诸如客户端应用程序，管理员，peer节点和排序者之类的参与者识别为来自不同组织。反过来，我们已经看到了定义这些组织参与者对网络和通道资源拥有的同意权限的政策的重要性。","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"Key Concepts","slug":"区块链/Hyperledger-Fabric/Key-Concepts","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/Key-Concepts/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"network","slug":"network","permalink":"https://guozhe001.github.io/tags/network/"}]},{"title":"Fabric关键问题20问","slug":"blockchain/fabric/Fabric关键问题20问","date":"2024-11-22T06:32:06.493Z","updated":"2024-11-22T06:32:06.493Z","comments":true,"path":"2024/11/22/blockchain/fabric/Fabric关键问题20问/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/Fabric%E5%85%B3%E9%94%AE%E9%97%AE%E9%A2%9820%E9%97%AE/","excerpt":"","text":"1、是否所有的背书节点都有相同的功能？一笔交易是不是任意的背书节点都可以验证，还是只能由支持此交易的背书节点验证？ 答：只有安装了相同的chaincode的peer节点才具有背书的功能。所以一个peer节点想要成为背书节点，必须安装对应的chaincode。 一笔交易肯定是由于调用了链码而产生的，所以这笔交易必须由其他的安装了相同链码的背书节点进行验证。 2、背书节点在验证的时候是否知道了交易的全部内容，如何保证数据的隐私的？ 答：背书节点在验证的时候可能并不知道交易的全部内容，Fabric有一个名为“transient”的存储，这个存储只在当前peer节点；如果有交易的话“transient”存储的数据会通过Gossip协议隐秘的传输给另一个peer节点。然后这两个peer节点都可以查询到“transient”存储的数据。而channel上的其他成员是无法看到这些数据的，因此并不是所有的背书节点都可以直到交易的全部内容。 2.1 这个问题会引出另一个新的问题，背书节点在缺少数据的情况下如何进行背书呢？这不就导致背书失败了吗？ 答：是的，拿不到“transient”存储的数据的背书节点会背书失败。但是由于我们可以设置chaincode和key的基于状态的背书策略，因此就算有部分背书节点背书失败了，只要能看到数据的背书节点做了背书并符合背书策略即可达成共识。 这个问题可以查看在Fabric中交易受保护的资产 3、区块数据的数据结构如果是数组的话，如何做到防篡改？ 答：暂时无法回答此问题，待完成。 4、主节点是干什么的？主节点可以交易吗？主节点和普通的peer节点有什么不一样？ 答：所谓的主节点应该是Order，目前了解到的只是负责交易的排序以及信息的转发。更多内容待学习。 5、链码是不是就是智能合约？ 答：链码就是智能合约，只有调用智能合约才可以更改channel上的账本。","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"}]},{"title":"Hyberledger-Fabric学习总结","slug":"blockchain/fabric/Hyberledger-Fabric学习总结","date":"2024-11-22T06:32:06.493Z","updated":"2024-11-22T06:32:06.493Z","comments":true,"path":"2024/11/22/blockchain/fabric/Hyberledger-Fabric学习总结/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/Hyberledger-Fabric%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/","excerpt":"","text":"Hyperledger-Fabric开发环境准备 Fabric测试网络使用 将智能合约部署到通道 Frbirc测试环境错误记录 编写您的第一个Chaincode [通过供应链金融练习Fabric](file://通过供应链金融练习Fabric/summary.md) [在Fabric中交易受保护的资产](file://在Fabric中交易受保护的资产.md) 在Fabric中使用私有数据 [背书策略](file://Endorsement policies背书策略.md) Fabric智能合约API学习 资料整理 hyperledger官网 hyperledger中文文档 hyperladger英文文档","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"}]},{"title":"Hyperledger-Frbirc测试环境错误记录","slug":"blockchain/fabric/Frbirc测试环境错误记录","date":"2024-11-22T06:32:06.493Z","updated":"2024-11-22T06:32:06.493Z","comments":true,"path":"2024/11/22/blockchain/fabric/Frbirc测试环境错误记录/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/Frbirc%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83%E9%94%99%E8%AF%AF%E8%AE%B0%E5%BD%95/","excerpt":"","text":"网络 测试网络其中一个组织的peer无法启动 错误描述 在运行./network.sh up时，只启动了一个组织的peer，另一个无法启动。导致在新建channel时报错如下： 1234562021-01-04 10:49:22.575 CST [comm.tls] ClientHandshake -&gt; ERRO 001 Client TLS handshake failed after 2.157125ms with error: EOF remoteaddress=[::1]:70512021-01-04 10:49:23.582 CST [comm.tls] ClientHandshake -&gt; ERRO 002 Client TLS handshake failed after 3.12316ms with error: EOF remoteaddress=[::1]:70512021-01-04 10:49:25.157 CST [comm.tls] ClientHandshake -&gt; ERRO 003 Client TLS handshake failed after 4.29759ms with error: EOF remoteaddress=[::1]:7051Error: error getting endorser client for channel: endorser client failed to connect to localhost:7051: failed to create new connection: context deadline exceededAfter 5 attempts, peer0.org1 has failed to join channel &#x27;mychannel&#x27;Create channel failed 因为这个问题导致的链码无法部署： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051(base) apple@WHOAMIdeMacBook-Pro:~/code/open-source/blockchain/hyperledger/fabric-samples/test-network$ ./network.sh deployCCdeploying chaincode on channel &#x27;mychannel&#x27;executing with the following- CHANNEL_NAME: mychannel- CC_NAME: basic- CC_SRC_PATH: NA- CC_SRC_LANGUAGE: go- CC_VERSION: 1.0- CC_SEQUENCE: 1- CC_END_POLICY: NA- CC_COLL_CONFIG: NA- CC_INIT_FCN: NA- DELAY: 3- MAX_RETRY: 5- VERBOSE: falseDetermining the path to the chaincodeasset-transfer-basicVendoring Go dependencies at ../asset-transfer-basic/chaincode-go/~/code/open-source/blockchain/hyperledger/fabric-samples/asset-transfer-basic/chaincode-go ~/code/open-source/blockchain/hyperledger/fabric-samples/test-network~/code/open-source/blockchain/hyperledger/fabric-samples/test-networkFinished vendoring Go dependencies+ peer lifecycle chaincode package basic.tar.gz --path ../asset-transfer-basic/chaincode-go/ --lang golang --label basic_1.0+ res=0Chaincode is packagedInstalling chaincode on peer0.org1...Using organization 1+ peer lifecycle chaincode install basic.tar.gz+ res=1Error: failed to retrieve endorser client for install: endorser client failed to connect to localhost:7051: failed to create new connection: context deadline exceededUsage: peer lifecycle chaincode install [flags]Flags: --connectionProfile string The fully qualified path to the connection profile that provides the necessary connection information for the network. Note: currently only supported for providing peer connection information -h, --help help for install --peerAddresses stringArray The addresses of the peers to connect to --tlsRootCertFiles stringArray If TLS is enabled, the paths to the TLS root cert files of the peers to connect to. The order and number of certs specified should match the --peerAddresses flagGlobal Flags: --cafile string Path to file containing PEM-encoded trusted certificate(s) for the ordering endpoint --certfile string Path to file containing PEM-encoded X509 public key to use for mutual TLS communication with the orderer endpoint --clientauth Use mutual TLS when communicating with the orderer endpoint --connTimeout duration Timeout for client to connect (default 3s) --keyfile string Path to file containing PEM-encoded private key to use for mutual TLS communication with the orderer endpoint -o, --orderer string Ordering service endpoint --ordererTLSHostnameOverride string The hostname override to use when validating the TLS connection to the orderer --tls Use TLS when communicating with the orderer endpoint --tlsHandshakeTimeShift duration The amount of time to shift backwards for certificate expiration checks during TLS handshakes with the orderer endpointChaincode installation on peer0.org1 has failedDeploying chaincode failed 错误原因和解决方案 可能是因为bin和config目录中的版本与启动时指定的版本不一致，./network.sh up命令使用的应该是最新的版本，确认bin和config目录下的也应该是最新的版本。可以重新替换这两个目录的代码。 链码 调用链码 1peer chaincode invoke -o localhost:8050 --ordererTLSHostnameOverride orderer.supply.com --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem -C coreandfirstchannel -n supply --peerAddresses localhost:8051 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/core.supply.com/peers/peer0.core.supply.com/tls/ca.crt --peerAddresses localhost:8053 --tlsRootCertFiles $&#123;PWD&#125;/organizations/peerOrganizations/f1.supply.com/peers/peer0.f1.supply.com/tls/ca.crt -c &#x27;&#123;&quot;function&quot;:&quot;IssueVoucher&quot;,&quot;Args&quot;:[&quot;asset001&quot;, &quot;100&quot;, &quot;一级供应商&quot;]&#125;&#x27; 成功信息如下： 12020-12-28 18:37:54.285 CST [chaincodeCmd] chaincodeInvokeOrQuery -&gt; INFO 001 Chaincode invoke successful. result: status:200 错误信息如下： 1Error: could not assemble transaction: proposal response was not successful, error code 500, msg Incorrect number of params. Expected 2, received 1 - proposal response: version:1 response:&lt;status:200 &gt; payload:&quot;\\n \\177\\017\\350[\\344G6\\010V\\331\\332\\377\\354\\216&amp;\\035\\317&amp;\\251[N`\\023\\036\\033\\237\\237A\\005\\3670\\260\\022\\266\\002\\n\\237\\002\\0227\\n\\n_lifecycle\\022)\\n&#x27;\\n!namespaces/fields/supply/Sequence\\022\\002\\010\\016\\022\\343\\001\\n\\006supply\\022\\330\\001\\n\\003\\n\\0011\\032\\320\\001\\n\\0011\\032\\312\\001&#123;\\&quot;ID\\&quot;:\\&quot;1\\&quot;,\\&quot;issuer\\&quot;:\\&quot;\\346\\240\\270\\345\\277\\203\\344\\274\\201\\344\\270\\232\\&quot;,\\&quot;owner\\&quot;:\\&quot;\\346\\240\\270\\345\\277\\203\\344\\274\\201\\344\\270\\232\\&quot;,\\&quot;amount\\&quot;:100,\\&quot;createDate\\&quot;:\\&quot;2020-12-28T10:02:30.578872398Z\\&quot;,\\&quot;endDate\\&quot;:\\&quot;2021-06-28T10:02:30.578872527Z\\&quot;,\\&quot;contractHash\\&quot;:\\&quot;test\\&quot;,\\&quot;invoiceHash\\&quot;:\\&quot;test\\&quot;&#125;\\032\\003\\010\\310\\001\\&quot;\\r\\022\\006supply\\032\\0033.0&quot; endorsement:&lt;endorser:&quot;\\n\\016GylCoreOrg1MSP\\022\\222\\006-----BEGIN CERTIFICATE-----\\nMIICFjCCAbygAwIBAgIQU43L5gjtXO+uCpRP2jG2AjAKBggqhkjOPQQDAjBxMQsw\\nCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy\\nYW5jaXNjbzEYMBYGA1UEChMPY29yZS5zdXBwbHkuY29tMRswGQYDVQQDExJjYS5j\\nb3JlLnN1cHBseS5jb20wHhcNMjAxMjI1MDkxNzAwWhcNMzAxMjIzMDkxNzAwWjBa\\nMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2Fu\\nIEZyYW5jaXNjbzEeMBwGA1UEAxMVcGVlcjAuY29yZS5zdXBwbHkuY29tMFkwEwYH\\nKoZIzj0CAQYIKoZIzj0DAQcDQgAErf3R+7XpNQpmTsMO+iM4WS7IrOoafiPbAS7Q\\nbuFFR3Qs4riIczgSmjh9rOA6I1q2q0CstLhfWDbqpf+8fXPUlKNNMEswDgYDVR0P\\nAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAguznqsTisa64dNvOR\\nvPwP0KGklWohNpbSe7VgIghx4L8wCgYIKoZIzj0EAwIDSAAwRQIhALIw1VMzezCg\\n9LONbO4+V+weY42HQLbShkTP/gCFnGRYAiARyLLSDJIC2wwzSvOHNdm+aDRtbqGC\\nNJenP9hmEbYsTw==\\n-----END CERTIFICATE-----\\n&quot; signature:&quot;0E\\002!\\000\\251\\370K6S\\020\\373\\242\\321\\000\\211\\312\\0001\\333\\365&gt;\\314\\324\\231\\020&gt;u;+\\243\\303dD\\023\\221\\237\\002 z \\224\\236R\\355Z\\251\\202\\363\\035\\304\\365\\212\\277\\235\\375?\\376\\030\\371\\236\\220\\354iG6\\244\\334M\\315\\331&quot; &gt; 原因是因为下图，只有一个组织的链码更新到了最新的版本。 ![截屏2020-12-28 18.03.06](/Users/apple/Desktop/截屏2020-12-28 18.03.06.png) **解决方案：**原因是因为设置环境变量CC_PACKAGE_ID时只设置了一个组织的peer，导致旧的环境变量还在生效，重新操作一遍问题解决。 调用chaincode时报错VSCC error如下： 12342021-01-07 06:44:40.479 UTC [vscc] Validate -&gt; ERRO 62f VSCC error: stateBasedValidator.Validate failed, err validation of endorsement policy for chaincode secured_supply in tx 12:0 failed: implicit policy evaluation failed - 1 sub-policies were satisfied, but this policy requires 3 of the &#x27;Endorsement&#x27; sub-policies to be satisfied2021-01-07 06:44:40.479 UTC [committer.txvalidator] validateTx -&gt; ERRO 630 Dispatch for transaction txId = 101fe5e0aaaafbabcf31a5ce66fa48b92ab834456ba73cdb29730679bd637847 returned error: validation of endorsement policy for chaincode secured_supply in tx 12:0 failed: implicit policy evaluation failed - 1 sub-policies were satisfied, but this policy requires 3 of the &#x27;Endorsement&#x27; sub-policies to be satisfied2021-01-07 06:44:40.479 UTC [committer.txvalidator] Validate -&gt; INFO 631 [alljoinchannel] Validated block [12] in 2ms 错误原因： 背景是我的测试环境有四个组织安装了相同的链码，链码的背书策略是默认的\u0012 /Channel/Application/Endorsement所以要求大多数背书，而我只让一个组织签名，所以导致错误。 查询chaincode是否可以被提交时报错 再所有的组织都批准了链码之后，查询批准结果返回的全部是false。 123456789(base) w:supply-finance apple$ peer lifecycle chaincode checkcommitreadiness --channelID alljoinchannel --name secured_supply --version 2.0 --sequence 2 --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --output json&#123; &quot;approvals&quot;: &#123; &quot;GylCoreOrg1MSP&quot;: false, &quot;GylFOrg1MSP&quot;: false, &quot;GylSOrg1MSP&quot;: false, &quot;GylSOrg2MSP&quot;: false &#125;&#125; 错误原因及解决方案： 因为批准的时候制定了签名策略，但是查询的时候没有指定；在查询时指定背书策略即可。 123456789(base) w:supply-finance apple$ peer lifecycle chaincode checkcommitreadiness --channelID alljoinchannel --name secured_supply --version 2.0 --sequence 2 --signature-policy &quot;OR(&#x27;GylCoreOrg1MSP.peer&#x27;,&#x27;GylFOrg1MSP.peer&#x27;,&#x27;GylSOrg1MSP.peer&#x27;,&#x27;GylSOrg2MSP.peer&#x27;)&quot; --tls --cafile $&#123;PWD&#125;/organizations/ordererOrganizations/supply.com/orderers/orderer.supply.com/msp/tlscacerts/tlsca.supply.com-cert.pem --output json&#123; &quot;approvals&quot;: &#123; &quot;GylCoreOrg1MSP&quot;: true, &quot;GylFOrg1MSP&quot;: true, &quot;GylSOrg1MSP&quot;: true, &quot;GylSOrg2MSP&quot;: true &#125;&#125; signature set did not satisfy policy 签名集合与策略不一致 122021-01-05 09:40:29.461 UTC [vscc] Validate -&gt; ERRO 3212 VSCC error: stateBasedValidator.Validate failed, err validation of key asset001 (coll&#x27;&#x27;:ns&#x27;secured_supply&#x27;) in tx 59:0 failed: signature set did not satisfy policy2021-01-05 09:40:29.461 UTC [committer.txvalidator] validateTx -&gt; ERRO 3213 Dispatch for transaction txId = 7d13143d4a24fe370528b0e47e6e8a71d7a8b660798c424769a57b67a9cb69ae returned error: validation of key asset001 (coll&#x27;&#x27;:ns&#x27;secured_supply&#x27;) in tx 59:0 failed: signature set did not satisfy policy 又遇到了签名和背书策略不一致的问题。 Troubleshooting网站 1234567Why are my transactions returning an endorsement policy error: signature set did not satisfy policy?问题情况When I invoke a smart contract to submit a transaction, the transaction returns the following endorsement policy failure:returned error: VSCC error: endorsement policy failure, err: signature set did not satisfy policy问题原因If you have recently joined a channel and installed the smart contract, this error occurs if you have not added your organization to the endorsement policy. Because your organization is not on the list of organizations who can endorse a transaction from the smart contract, the endorsement from your peers is rejected by the channel. If you encounter this problem, you can change the endorsement policy by upgrading the smart contract. For more information, see Specifying an endorsement policy and Upgrading a smart contract. 错误原因一级解决方案 这个错误的背景是channel、chaincode和key的背书策略都不一样，具体如下： channel：默认的，需要大多数签名 chaincode：指定了OR(‘GylCoreOrg1MSP.member’,‘GylFOrg1MSP.member’,‘GylSOrg1MSP.member’,‘GylSOrg2MSP.member’) key：设置了SetStateValidationParameter，只需要拥有者的签名 具体的解决方案需要确认链码的编写是否有问题。","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"}]},{"title":"Geth源码学习之Transaction","slug":"blockchain/ethereum/source_code/Geth源码学习之Transaction","date":"2024-11-22T06:32:06.493Z","updated":"2024-11-22T06:32:06.493Z","comments":true,"path":"2024/11/22/blockchain/ethereum/source_code/Geth源码学习之Transaction/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/source_code/Geth%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%B9%8BTransaction/","excerpt":"","text":"学习github.com/ethereum/go-ethereum/core/types.transaction.go源码Version: 1.10.2-unstable: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545// Copyright 2014 The go-ethereum Authors// This file is part of the go-ethereum library.//// The go-ethereum library is free software: you can redistribute it and/or modify// it under the terms of the GNU Lesser General Public License as published by// the Free Software Foundation, either version 3 of the License, or// (at your option) any later version.//// The go-ethereum library is distributed in the hope that it will be useful,// but WITHOUT ANY WARRANTY; without even the implied warranty of// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the// GNU Lesser General Public License for more details.//// You should have received a copy of the GNU Lesser General Public License// along with the go-ethereum library. If not, see &lt;http://www.gnu.org/licenses/&gt;.package typesimport ( &quot;bytes&quot; &quot;container/heap&quot; &quot;errors&quot; &quot;io&quot; &quot;math/big&quot; &quot;sync/atomic&quot; &quot;time&quot; &quot;github.com/ethereum/go-ethereum/common&quot; &quot;github.com/ethereum/go-ethereum/crypto&quot; &quot;github.com/ethereum/go-ethereum/rlp&quot;)var ( ErrInvalidSig = errors.New(&quot;invalid transaction v, r, s values&quot;) ErrUnexpectedProtection = errors.New(&quot;transaction type does not supported EIP-155 protected signatures&quot;) ErrInvalidTxType = errors.New(&quot;transaction type not valid in this context&quot;) ErrTxTypeNotSupported = errors.New(&quot;transaction type not supported&quot;) errEmptyTypedTx = errors.New(&quot;empty typed transaction bytes&quot;))// Transaction types.const ( LegacyTxType = iota AccessListTxType)// Transaction is an Ethereum transaction.type Transaction struct &#123; inner TxData // Consensus contents of a transaction 交易中需要共识的内容 time time.Time // Time first seen locally (spam avoidance) 第一次收到交易的时间 // caches hash atomic.Value // 交易的hash size atomic.Value // 交易的大小 from atomic.Value // 交易的发起者&#125;// NewTx creates a new transaction.func NewTx(inner TxData) *Transaction &#123; tx := new(Transaction) tx.setDecoded(inner.copy(), 0) return tx&#125;// TxData is the underlying data of a transaction.//// This is implemented by LegacyTx and AccessListTx.type TxData interface &#123; txType() byte // returns the type ID copy() TxData // creates a deep copy and initializes all fields chainID() *big.Int //链ID accessList() AccessList data() []byte // 交易中的数据 gas() uint64 // 交易的消耗了多少gas gasPrice() *big.Int //交易的gas价格 value() *big.Int // 交易中带的以太币的数量 nonce() uint64 // 对于发送交易的人来说，这是第几笔交易 to() *common.Address // 交易发送给谁 rawSignatureValues() (v, r, s *big.Int) // 获取签名相关信息 setSignatureValues(chainID, v, r, s *big.Int) // 设置签名相关信息&#125;// EncodeRLP implements rlp.Encoderfunc (tx *Transaction) EncodeRLP(w io.Writer) error &#123; if tx.Type() == LegacyTxType &#123; return rlp.Encode(w, tx.inner) &#125; // It&#x27;s an EIP-2718 typed TX envelope. buf := encodeBufferPool.Get().(*bytes.Buffer) defer encodeBufferPool.Put(buf) buf.Reset() if err := tx.encodeTyped(buf); err != nil &#123; return err &#125; return rlp.Encode(w, buf.Bytes())&#125;// encodeTyped writes the canonical encoding of a typed transaction to w.// 将交易中的inner数据写入到入参wfunc (tx *Transaction) encodeTyped(w *bytes.Buffer) error &#123; w.WriteByte(tx.Type()) return rlp.Encode(w, tx.inner)&#125;// MarshalBinary returns the canonical encoding of the transaction.// For legacy transactions, it returns the RLP encoding. For EIP-2718 typed// transactions, it returns the type and payload.func (tx *Transaction) MarshalBinary() ([]byte, error) &#123; if tx.Type() == LegacyTxType &#123; return rlp.EncodeToBytes(tx.inner) &#125; var buf bytes.Buffer err := tx.encodeTyped(&amp;buf) return buf.Bytes(), err&#125;// DecodeRLP implements rlp.Decoderfunc (tx *Transaction) DecodeRLP(s *rlp.Stream) error &#123; kind, size, err := s.Kind() switch &#123; case err != nil: return err case kind == rlp.List: // It&#x27;s a legacy transaction. var inner LegacyTx err := s.Decode(&amp;inner) if err == nil &#123; tx.setDecoded(&amp;inner, int(rlp.ListSize(size))) &#125; return err case kind == rlp.String: // It&#x27;s an EIP-2718 typed TX envelope. var b []byte if b, err = s.Bytes(); err != nil &#123; return err &#125; inner, err := tx.decodeTyped(b) if err == nil &#123; tx.setDecoded(inner, len(b)) &#125; return err default: return rlp.ErrExpectedList &#125;&#125;// UnmarshalBinary decodes the canonical encoding of transactions.// It supports legacy RLP transactions and EIP2718 typed transactions.// 将字节数组b解码设置到交易的inner字段func (tx *Transaction) UnmarshalBinary(b []byte) error &#123; if len(b) &gt; 0 &amp;&amp; b[0] &gt; 0x7f &#123; // It&#x27;s a legacy transaction. var data LegacyTx err := rlp.DecodeBytes(b, &amp;data) if err != nil &#123; return err &#125; tx.setDecoded(&amp;data, len(b)) return nil &#125; // It&#x27;s an EIP2718 typed transaction envelope. inner, err := tx.decodeTyped(b) if err != nil &#123; return err &#125; tx.setDecoded(inner, len(b)) return nil&#125;// decodeTyped decodes a typed transaction from the canonical format.func (tx *Transaction) decodeTyped(b []byte) (TxData, error) &#123; if len(b) == 0 &#123; return nil, errEmptyTypedTx &#125; switch b[0] &#123; case AccessListTxType: var inner AccessListTx err := rlp.DecodeBytes(b[1:], &amp;inner) return &amp;inner, err default: return nil, ErrTxTypeNotSupported &#125;&#125;// setDecoded sets the inner transaction and size after decoding.func (tx *Transaction) setDecoded(inner TxData, size int) &#123; tx.inner = inner tx.time = time.Now() if size &gt; 0 &#123; tx.size.Store(common.StorageSize(size)) &#125;&#125;func sanityCheckSignature(v *big.Int, r *big.Int, s *big.Int, maybeProtected bool) error &#123; if isProtectedV(v) &amp;&amp; !maybeProtected &#123; return ErrUnexpectedProtection &#125; var plainV byte if isProtectedV(v) &#123; chainID := deriveChainId(v).Uint64() plainV = byte(v.Uint64() - 35 - 2*chainID) &#125; else if maybeProtected &#123; // Only EIP-155 signatures can be optionally protected. Since // we determined this v value is not protected, it must be a // raw 27 or 28. plainV = byte(v.Uint64() - 27) &#125; else &#123; // If the signature is not optionally protected, we assume it // must already be equal to the recovery id. plainV = byte(v.Uint64()) &#125; if !crypto.ValidateSignatureValues(plainV, r, s, false) &#123; return ErrInvalidSig &#125; return nil&#125;func isProtectedV(V *big.Int) bool &#123; if V.BitLen() &lt;= 8 &#123; v := V.Uint64() return v != 27 &amp;&amp; v != 28 &amp;&amp; v != 1 &amp;&amp; v != 0 &#125; // anything not 27 or 28 is considered protected return true&#125;// Protected says whether the transaction is replay-protected.func (tx *Transaction) Protected() bool &#123; switch tx := tx.inner.(type) &#123; case *LegacyTx: return tx.V != nil &amp;&amp; isProtectedV(tx.V) default: return true &#125;&#125;// Type returns the transaction type.func (tx *Transaction) Type() uint8 &#123; return tx.inner.txType()&#125;// ChainId returns the EIP155 chain ID of the transaction. The return value will always be// non-nil. For legacy transactions which are not replay-protected, the return value is// zero.func (tx *Transaction) ChainId() *big.Int &#123; return tx.inner.chainID()&#125;// Data returns the input data of the transaction.func (tx *Transaction) Data() []byte &#123; return tx.inner.data() &#125;// AccessList returns the access list of the transaction.func (tx *Transaction) AccessList() AccessList &#123; return tx.inner.accessList() &#125;// Gas returns the gas limit of the transaction.func (tx *Transaction) Gas() uint64 &#123; return tx.inner.gas() &#125;// GasPrice returns the gas price of the transaction.func (tx *Transaction) GasPrice() *big.Int &#123; return new(big.Int).Set(tx.inner.gasPrice()) &#125;// Value returns the ether amount of the transaction.func (tx *Transaction) Value() *big.Int &#123; return new(big.Int).Set(tx.inner.value()) &#125;// Nonce returns the sender account nonce of the transaction.func (tx *Transaction) Nonce() uint64 &#123; return tx.inner.nonce() &#125;// To returns the recipient address of the transaction.// For contract-creation transactions, To returns nil.func (tx *Transaction) To() *common.Address &#123; // Copy the pointed-to address. ito := tx.inner.to() if ito == nil &#123; return nil &#125; cpy := *ito return &amp;cpy&#125;// Cost returns gas * gasPrice + value.// 这个交易的发起者总共需要支付多少以太币func (tx *Transaction) Cost() *big.Int &#123; total := new(big.Int).Mul(tx.GasPrice(), new(big.Int).SetUint64(tx.Gas())) total.Add(total, tx.Value()) return total&#125;// RawSignatureValues returns the V, R, S signature values of the transaction.// The return values should not be modified by the caller.func (tx *Transaction) RawSignatureValues() (v, r, s *big.Int) &#123; return tx.inner.rawSignatureValues()&#125;// GasPriceCmp compares the gas prices of two transactions.// 比较当前交易和其他交易的gas价格func (tx *Transaction) GasPriceCmp(other *Transaction) int &#123; return tx.inner.gasPrice().Cmp(other.inner.gasPrice())&#125;// GasPriceIntCmp compares the gas price of the transaction against the given price.// 比较当前交易和其他交易的gas价格func (tx *Transaction) GasPriceIntCmp(other *big.Int) int &#123; return tx.inner.gasPrice().Cmp(other)&#125;// Hash returns the transaction hash.// 获取交易的hash，如果已经存在则直接返回，如果不存在则计算func (tx *Transaction) Hash() common.Hash &#123; if hash := tx.hash.Load(); hash != nil &#123; return hash.(common.Hash) &#125; var h common.Hash if tx.Type() == LegacyTxType &#123; h = rlpHash(tx.inner) &#125; else &#123; h = prefixedRlpHash(tx.Type(), tx.inner) &#125; tx.hash.Store(h) return h&#125;// Size returns the true RLP encoded storage size of the transaction, either by// encoding and returning it, or returning a previously cached value.func (tx *Transaction) Size() common.StorageSize &#123; if size := tx.size.Load(); size != nil &#123; return size.(common.StorageSize) &#125; c := writeCounter(0) rlp.Encode(&amp;c, &amp;tx.inner) tx.size.Store(common.StorageSize(c)) return common.StorageSize(c)&#125;// WithSignature returns a new transaction with the given signature.// This signature needs to be in the [R || S || V] format where V is 0 or 1.// 对交易进行签名，并返回一个新的签名后的交易func (tx *Transaction) WithSignature(signer Signer, sig []byte) (*Transaction, error) &#123; r, s, v, err := signer.SignatureValues(tx, sig) if err != nil &#123; return nil, err &#125; cpy := tx.inner.copy() cpy.setSignatureValues(signer.ChainID(), v, r, s) return &amp;Transaction&#123;inner: cpy, time: tx.time&#125;, nil&#125;// Transactions implements DerivableList for transactions.type Transactions []*Transaction// Len returns the length of s.func (s Transactions) Len() int &#123; return len(s) &#125;// EncodeIndex encodes the i&#x27;th transaction to w. Note that this does not check for errors// because we assume that *Transaction will only ever contain valid txs that were either// constructed by decoding or via public API in this package.// 将指定下标i的交易的inner数据解码写入w中func (s Transactions) EncodeIndex(i int, w *bytes.Buffer) &#123; tx := s[i] if tx.Type() == LegacyTxType &#123; rlp.Encode(w, tx.inner) &#125; else &#123; tx.encodeTyped(w) &#125;&#125;// TxDifference returns a new set which is the difference between a and b.func TxDifference(a, b Transactions) Transactions &#123; keep := make(Transactions, 0, len(a)) remove := make(map[common.Hash]struct&#123;&#125;) for _, tx := range b &#123; remove[tx.Hash()] = struct&#123;&#125;&#123;&#125; &#125; for _, tx := range a &#123; if _, ok := remove[tx.Hash()]; !ok &#123; keep = append(keep, tx) &#125; &#125; return keep&#125;// TxByNonce implements the sort interface to allow sorting a list of transactions// by their nonces. This is usually only useful for sorting transactions from a// single account, otherwise a nonce comparison doesn&#x27;t make much sense.// 实现了排序的交易列表，排序的方式是nonce，只有同一个地址的nonce的比较才有意义，不同地址的nonce比较没有意义type TxByNonce Transactionsfunc (s TxByNonce) Len() int &#123; return len(s) &#125;func (s TxByNonce) Less(i, j int) bool &#123; return s[i].Nonce() &lt; s[j].Nonce() &#125;func (s TxByNonce) Swap(i, j int) &#123; s[i], s[j] = s[j], s[i] &#125;// TxByPriceAndTime implements both the sort and the heap interface, making it useful// for all at once sorting as well as individually adding and removing elements.type TxByPriceAndTime Transactionsfunc (s TxByPriceAndTime) Len() int &#123; return len(s) &#125;func (s TxByPriceAndTime) Less(i, j int) bool &#123; // If the prices are equal, use the time the transaction was first seen for // deterministic sorting // 先按照价格排序，如果价格相等再按照时间排序 cmp := s[i].GasPrice().Cmp(s[j].GasPrice()) if cmp == 0 &#123; return s[i].time.Before(s[j].time) &#125; return cmp &gt; 0&#125;func (s TxByPriceAndTime) Swap(i, j int) &#123; s[i], s[j] = s[j], s[i] &#125;func (s *TxByPriceAndTime) Push(x interface&#123;&#125;) &#123; *s = append(*s, x.(*Transaction))&#125;func (s *TxByPriceAndTime) Pop() interface&#123;&#125; &#123; old := *s n := len(old) x := old[n-1] *s = old[0 : n-1] return x&#125;// TransactionsByPriceAndNonce represents a set of transactions that can return// transactions in a profit-maximizing sorted order, while supporting removing// entire batches of transactions for non-executable accounts.type TransactionsByPriceAndNonce struct &#123; txs map[common.Address]Transactions // Per account nonce-sorted list of transactions heads TxByPriceAndTime // Next transaction for each unique account (price heap) signer Signer // Signer for the set of transactions&#125;// NewTransactionsByPriceAndNonce creates a transaction set that can retrieve// price sorted transactions in a nonce-honouring way.//// Note, the input map is reowned so the caller should not interact any more with// if after providing it to the constructor.func NewTransactionsByPriceAndNonce(signer Signer, txs map[common.Address]Transactions) *TransactionsByPriceAndNonce &#123; // Initialize a price and received time based heap with the head transactions heads := make(TxByPriceAndTime, 0, len(txs)) for from, accTxs := range txs &#123; // Ensure the sender address is from the signer if acc, _ := Sender(signer, accTxs[0]); acc != from &#123; delete(txs, from) continue &#125; heads = append(heads, accTxs[0]) txs[from] = accTxs[1:] &#125; heap.Init(&amp;heads) // Assemble and return the transaction set return &amp;TransactionsByPriceAndNonce&#123; txs: txs, heads: heads, signer: signer, &#125;&#125;// Peek returns the next transaction by price.func (t *TransactionsByPriceAndNonce) Peek() *Transaction &#123; if len(t.heads) == 0 &#123; return nil &#125; return t.heads[0]&#125;// Shift replaces the current best head with the next one from the same account.func (t *TransactionsByPriceAndNonce) Shift() &#123; acc, _ := Sender(t.signer, t.heads[0]) if txs, ok := t.txs[acc]; ok &amp;&amp; len(txs) &gt; 0 &#123; t.heads[0], t.txs[acc] = txs[0], txs[1:] heap.Fix(&amp;t.heads, 0) &#125; else &#123; heap.Pop(&amp;t.heads) &#125;&#125;// Pop removes the best transaction, *not* replacing it with the next one from// the same account. This should be used when a transaction cannot be executed// and hence all subsequent ones should be discarded from the same account.func (t *TransactionsByPriceAndNonce) Pop() &#123; heap.Pop(&amp;t.heads)&#125;// Message is a fully derived transaction and implements core.Message//// NOTE: In a future PR this will be removed.type Message struct &#123; to *common.Address from common.Address nonce uint64 amount *big.Int gasLimit uint64 gasPrice *big.Int data []byte accessList AccessList checkNonce bool&#125;func NewMessage(from common.Address, to *common.Address, nonce uint64, amount *big.Int, gasLimit uint64, gasPrice *big.Int, data []byte, accessList AccessList, checkNonce bool) Message &#123; return Message&#123; from: from, to: to, nonce: nonce, amount: amount, gasLimit: gasLimit, gasPrice: gasPrice, data: data, accessList: accessList, checkNonce: checkNonce, &#125;&#125;// AsMessage returns the transaction as a core.Message.func (tx *Transaction) AsMessage(s Signer) (Message, error) &#123; msg := Message&#123; nonce: tx.Nonce(), gasLimit: tx.Gas(), gasPrice: new(big.Int).Set(tx.GasPrice()), to: tx.To(), amount: tx.Value(), data: tx.Data(), accessList: tx.AccessList(), checkNonce: true, &#125; var err error msg.from, err = Sender(s, tx) return msg, err&#125;func (m Message) From() common.Address &#123; return m.from &#125;func (m Message) To() *common.Address &#123; return m.to &#125;func (m Message) GasPrice() *big.Int &#123; return m.gasPrice &#125;func (m Message) Value() *big.Int &#123; return m.amount &#125;func (m Message) Gas() uint64 &#123; return m.gasLimit &#125;func (m Message) Nonce() uint64 &#123; return m.nonce &#125;func (m Message) Data() []byte &#123; return m.data &#125;func (m Message) AccessList() AccessList &#123; return m.accessList &#125;func (m Message) CheckNonce() bool &#123; return m.checkNonce &#125; 对比etherscan.io的显示的Transaction字段：","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"source_code","slug":"区块链/ethereum/source-code","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/source-code/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"swarm","slug":"swarm","permalink":"https://guozhe001.github.io/tags/swarm/"}]},{"title":"Geth源码学习之block","slug":"blockchain/ethereum/source_code/Geth源码学习之block","date":"2024-11-22T06:32:06.493Z","updated":"2024-11-22T06:32:06.493Z","comments":true,"path":"2024/11/22/blockchain/ethereum/source_code/Geth源码学习之block/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/source_code/Geth%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%B9%8Bblock/","excerpt":"","text":"学习github.com/ethereum/go-ethereum/core/types.block.go源码Version: 1.10.2-unstable: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411// Copyright 2014 The go-ethereum Authors// This file is part of the go-ethereum library.//// The go-ethereum library is free software: you can redistribute it and/or modify// it under the terms of the GNU Lesser General Public License as published by// the Free Software Foundation, either version 3 of the License, or// (at your option) any later version.//// The go-ethereum library is distributed in the hope that it will be useful,// but WITHOUT ANY WARRANTY; without even the implied warranty of// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the// GNU Lesser General Public License for more details.//// You should have received a copy of the GNU Lesser General Public License// along with the go-ethereum library. If not, see &lt;http://www.gnu.org/licenses/&gt;.// Package types contains data types related to Ethereum consensus.package typesimport ( &quot;encoding/binary&quot; &quot;fmt&quot; &quot;io&quot; &quot;math/big&quot; &quot;reflect&quot; &quot;sync/atomic&quot; &quot;time&quot; &quot;github.com/ethereum/go-ethereum/common&quot; &quot;github.com/ethereum/go-ethereum/common/hexutil&quot; &quot;github.com/ethereum/go-ethereum/rlp&quot;)var ( EmptyRootHash = common.HexToHash(&quot;56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421&quot;) EmptyUncleHash = rlpHash([]*Header(nil)))// A BlockNonce is a 64-bit hash which proves (combined with the// mix-hash) that a sufficient amount of computation has been carried// out on a block.type BlockNonce [8]byte // 挖矿就是找这个nonce，nonce是一个64位的数字// EncodeNonce converts the given integer to a block nonce.// 把十进制的数字i转换成BlockNoncefunc EncodeNonce(i uint64) BlockNonce &#123; var n BlockNonce binary.BigEndian.PutUint64(n[:], i) return n&#125;// Uint64 returns the integer value of a block nonce.// 与EncodeNonce相反，把BlockNonce转换成十进制数字func (n BlockNonce) Uint64() uint64 &#123; return binary.BigEndian.Uint64(n[:])&#125;// MarshalText encodes n as a hex string with 0x prefix.// 返回一个带有0x前缀的十六进制的字符串func (n BlockNonce) MarshalText() ([]byte, error) &#123; return hexutil.Bytes(n[:]).MarshalText()&#125;// UnmarshalText implements encoding.TextUnmarshaler.// 把一个带有0x前缀的十六进制字符串赋值给nfunc (n *BlockNonce) UnmarshalText(input []byte) error &#123; return hexutil.UnmarshalFixedText(&quot;BlockNonce&quot;, input, n[:])&#125;//go:generate gencodec -type Header -field-override headerMarshaling -out gen_header_json.go// Header represents a block header in the Ethereum blockchain.// 区块的头type Header struct &#123; ParentHash common.Hash `json:&quot;parentHash&quot; gencodec:&quot;required&quot;` // 父区块的hash UncleHash common.Hash `json:&quot;sha3Uncles&quot; gencodec:&quot;required&quot;` // 叔区块数组的hash Coinbase common.Address `json:&quot;miner&quot; gencodec:&quot;required&quot;` // 谁挖出的此块 Root common.Hash `json:&quot;stateRoot&quot; gencodec:&quot;required&quot;` // TxHash common.Hash `json:&quot;transactionsRoot&quot; gencodec:&quot;required&quot;` // 交易的hash，使用mpt结构的交易的根hash ReceiptHash common.Hash `json:&quot;receiptsRoot&quot; gencodec:&quot;required&quot;` // 回执（交易响应）的hash，使用mpt结构的回执的根hash Bloom Bloom `json:&quot;logsBloom&quot; gencodec:&quot;required&quot;` // 使用交易回执算出的Bloom过滤器 Difficulty *big.Int `json:&quot;difficulty&quot; gencodec:&quot;required&quot;` // 当前区块的难度 Number *big.Int `json:&quot;number&quot; gencodec:&quot;required&quot;` // 当前区块的高度 GasLimit uint64 `json:&quot;gasLimit&quot; gencodec:&quot;required&quot;` // 当前区块的总的gas上限 GasUsed uint64 `json:&quot;gasUsed&quot; gencodec:&quot;required&quot;` // 当前区块的总共使用的gas Time uint64 `json:&quot;timestamp&quot; gencodec:&quot;required&quot;` // 当前区块的生成时间 Extra []byte `json:&quot;extraData&quot; gencodec:&quot;required&quot;` // 额外的数据 MixDigest common.Hash `json:&quot;mixHash&quot;` // 使用header中的上面的字段算出来的ethash和nonce算出来的hash值 Nonce BlockNonce `json:&quot;nonce&quot;` // 当前区块的nonce&#125;// field type overrides for gencodectype headerMarshaling struct &#123; Difficulty *hexutil.Big Number *hexutil.Big GasLimit hexutil.Uint64 GasUsed hexutil.Uint64 Time hexutil.Uint64 Extra hexutil.Bytes Hash common.Hash `json:&quot;hash&quot;` // adds call to Hash() in MarshalJSON&#125;// Hash returns the block hash of the header, which is simply the keccak256 hash of its// RLP encoding.// 计算区块头h的hash，使用keccak256hash算法func (h *Header) Hash() common.Hash &#123; return rlpHash(h)&#125;var headerSize = common.StorageSize(reflect.TypeOf(Header&#123;&#125;).Size())// Size returns the approximate memory used by all internal contents. It is used// to approximate and limit the memory consumption of various caches.func (h *Header) Size() common.StorageSize &#123; return headerSize + common.StorageSize(len(h.Extra)+(h.Difficulty.BitLen()+h.Number.BitLen())/8)&#125;// SanityCheck checks a few basic things -- these checks are way beyond what// any &#x27;sane&#x27; production values should hold, and can mainly be used to prevent// that the unbounded fields are stuffed with junk data to add processing// overhead// 检查区块头的字段func (h *Header) SanityCheck() error &#123; if h.Number != nil &amp;&amp; !h.Number.IsUint64() &#123; return fmt.Errorf(&quot;too large block number: bitlen %d&quot;, h.Number.BitLen()) &#125; if h.Difficulty != nil &#123; if diffLen := h.Difficulty.BitLen(); diffLen &gt; 80 &#123; return fmt.Errorf(&quot;too large block difficulty: bitlen %d&quot;, diffLen) &#125; &#125; if eLen := len(h.Extra); eLen &gt; 100*1024 &#123; return fmt.Errorf(&quot;too large block extradata: size %d&quot;, eLen) &#125; return nil&#125;// EmptyBody returns true if there is no additional &#x27;body&#x27; to complete the header// that is: no transactions and no uncles.// 检查是否有额外的body数据，没有交易并且没有数块即代表为没有bodyfunc (h *Header) EmptyBody() bool &#123; return h.TxHash == EmptyRootHash &amp;&amp; h.UncleHash == EmptyUncleHash&#125;// EmptyReceipts returns true if there are no receipts for this header/block.// 检查回执是否为空func (h *Header) EmptyReceipts() bool &#123; return h.ReceiptHash == EmptyRootHash&#125;// Body is a simple (mutable, non-safe) data container for storing and moving// a block&#x27;s data contents (transactions and uncles) together.// 区块中的body信息，包括交易列表和叔块header列表type Body struct &#123; Transactions []*Transaction Uncles []*Header&#125;// Block represents an entire block in the Ethereum blockchain.// 区块type Block struct &#123; header *Header // 块头 uncles []*Header // 数块头 transactions Transactions // 交易列表 // caches hash atomic.Value // 区块hash size atomic.Value // 区块大小 // Td is used by package core to store the total difficulty // of the chain up to and including the block. td *big.Int // total difficulty 当前网络的总难度 // These fields are used by package eth to track // inter-peer block relay. ReceivedAt time.Time // 接收到的时间 ReceivedFrom interface&#123;&#125; // 提交区块的Peer&#125;// DeprecatedTd is an old relic for extracting the TD of a block. It is in the// code solely to facilitate upgrading the database from the old format to the// new, after which it should be deleted. Do not use!func (b *Block) DeprecatedTd() *big.Int &#123; return b.td&#125;// [deprecated by eth/63]// StorageBlock defines the RLP encoding of a Block stored in the// state database. The StorageBlock encoding contains fields that// would otherwise need to be recomputed.type StorageBlock Block// &quot;external&quot; block encoding. used for eth protocol, etc.type extblock struct &#123; Header *Header Txs []*Transaction Uncles []*Header&#125;// [deprecated by eth/63]// &quot;storage&quot; block encoding. used for database.type storageblock struct &#123; Header *Header Txs []*Transaction Uncles []*Header TD *big.Int&#125;// NewBlock creates a new block. The input data is copied,// changes to header and to the field values will not affect the// block.//// The values of TxHash, UncleHash, ReceiptHash and Bloom in header// are ignored and set to values derived from the given txs, uncles// and receipts.func NewBlock(header *Header, txs []*Transaction, uncles []*Header, receipts []*Receipt, hasher TrieHasher) *Block &#123; b := &amp;Block&#123;header: CopyHeader(header), td: new(big.Int)&#125; // TODO: panic if len(txs) != len(receipts) if len(txs) == 0 &#123; b.header.TxHash = EmptyRootHash &#125; else &#123; b.header.TxHash = DeriveSha(Transactions(txs), hasher) b.transactions = make(Transactions, len(txs)) copy(b.transactions, txs) &#125; if len(receipts) == 0 &#123; b.header.ReceiptHash = EmptyRootHash &#125; else &#123; b.header.ReceiptHash = DeriveSha(Receipts(receipts), hasher) b.header.Bloom = CreateBloom(receipts) &#125; if len(uncles) == 0 &#123; b.header.UncleHash = EmptyUncleHash &#125; else &#123; b.header.UncleHash = CalcUncleHash(uncles) b.uncles = make([]*Header, len(uncles)) for i := range uncles &#123; b.uncles[i] = CopyHeader(uncles[i]) &#125; &#125; return b&#125;// NewBlockWithHeader creates a block with the given header data. The// header data is copied, changes to header and to the field values// will not affect the block.func NewBlockWithHeader(header *Header) *Block &#123; return &amp;Block&#123;header: CopyHeader(header)&#125;&#125;// CopyHeader creates a deep copy of a block header to prevent side effects from// modifying a header variable.func CopyHeader(h *Header) *Header &#123; cpy := *h if cpy.Difficulty = new(big.Int); h.Difficulty != nil &#123; cpy.Difficulty.Set(h.Difficulty) &#125; if cpy.Number = new(big.Int); h.Number != nil &#123; cpy.Number.Set(h.Number) &#125; if len(h.Extra) &gt; 0 &#123; cpy.Extra = make([]byte, len(h.Extra)) copy(cpy.Extra, h.Extra) &#125; return &amp;cpy&#125;// DecodeRLP decodes the Ethereumfunc (b *Block) DecodeRLP(s *rlp.Stream) error &#123; var eb extblock _, size, _ := s.Kind() if err := s.Decode(&amp;eb); err != nil &#123; return err &#125; b.header, b.uncles, b.transactions = eb.Header, eb.Uncles, eb.Txs b.size.Store(common.StorageSize(rlp.ListSize(size))) return nil&#125;// EncodeRLP serializes b into the Ethereum RLP block format.func (b *Block) EncodeRLP(w io.Writer) error &#123; return rlp.Encode(w, extblock&#123; Header: b.header, Txs: b.transactions, Uncles: b.uncles, &#125;)&#125;// [deprecated by eth/63]func (b *StorageBlock) DecodeRLP(s *rlp.Stream) error &#123; var sb storageblock if err := s.Decode(&amp;sb); err != nil &#123; return err &#125; b.header, b.uncles, b.transactions, b.td = sb.Header, sb.Uncles, sb.Txs, sb.TD return nil&#125;// TODO: copiesfunc (b *Block) Uncles() []*Header &#123; return b.uncles &#125;func (b *Block) Transactions() Transactions &#123; return b.transactions &#125;func (b *Block) Transaction(hash common.Hash) *Transaction &#123; for _, transaction := range b.transactions &#123; if transaction.Hash() == hash &#123; return transaction &#125; &#125; return nil&#125;func (b *Block) Number() *big.Int &#123; return new(big.Int).Set(b.header.Number) &#125;func (b *Block) GasLimit() uint64 &#123; return b.header.GasLimit &#125;func (b *Block) GasUsed() uint64 &#123; return b.header.GasUsed &#125;func (b *Block) Difficulty() *big.Int &#123; return new(big.Int).Set(b.header.Difficulty) &#125;func (b *Block) Time() uint64 &#123; return b.header.Time &#125;func (b *Block) NumberU64() uint64 &#123; return b.header.Number.Uint64() &#125;func (b *Block) MixDigest() common.Hash &#123; return b.header.MixDigest &#125;func (b *Block) Nonce() uint64 &#123; return binary.BigEndian.Uint64(b.header.Nonce[:]) &#125;func (b *Block) Bloom() Bloom &#123; return b.header.Bloom &#125;func (b *Block) Coinbase() common.Address &#123; return b.header.Coinbase &#125;func (b *Block) Root() common.Hash &#123; return b.header.Root &#125;func (b *Block) ParentHash() common.Hash &#123; return b.header.ParentHash &#125;func (b *Block) TxHash() common.Hash &#123; return b.header.TxHash &#125;func (b *Block) ReceiptHash() common.Hash &#123; return b.header.ReceiptHash &#125;func (b *Block) UncleHash() common.Hash &#123; return b.header.UncleHash &#125;func (b *Block) Extra() []byte &#123; return common.CopyBytes(b.header.Extra) &#125;func (b *Block) Header() *Header &#123; return CopyHeader(b.header) &#125;// Body returns the non-header content of the block.func (b *Block) Body() *Body &#123; return &amp;Body&#123;b.transactions, b.uncles&#125; &#125;// Size returns the true RLP encoded storage size of the block, either by encoding// and returning it, or returning a previsouly cached value.func (b *Block) Size() common.StorageSize &#123; if size := b.size.Load(); size != nil &#123; return size.(common.StorageSize) &#125; c := writeCounter(0) rlp.Encode(&amp;c, b) b.size.Store(common.StorageSize(c)) return common.StorageSize(c)&#125;// SanityCheck can be used to prevent that unbounded fields are// stuffed with junk data to add processing overheadfunc (b *Block) SanityCheck() error &#123; return b.header.SanityCheck()&#125;type writeCounter common.StorageSizefunc (c *writeCounter) Write(b []byte) (int, error) &#123; *c += writeCounter(len(b)) return len(b), nil&#125;func CalcUncleHash(uncles []*Header) common.Hash &#123; if len(uncles) == 0 &#123; return EmptyUncleHash &#125; return rlpHash(uncles)&#125;// WithSeal returns a new block with the data from b but the header replaced with// the sealed one.func (b *Block) WithSeal(header *Header) *Block &#123; cpy := *header return &amp;Block&#123; header: &amp;cpy, transactions: b.transactions, uncles: b.uncles, &#125;&#125;// WithBody returns a new block with the given transaction and uncle contents.func (b *Block) WithBody(transactions []*Transaction, uncles []*Header) *Block &#123; block := &amp;Block&#123; header: CopyHeader(b.header), transactions: make([]*Transaction, len(transactions)), uncles: make([]*Header, len(uncles)), &#125; copy(block.transactions, transactions) for i := range uncles &#123; block.uncles[i] = CopyHeader(uncles[i]) &#125; return block&#125;// Hash returns the keccak256 hash of b&#x27;s header.// The hash is computed on the first call and cached thereafter.// 获取当前区块的hash，如果已经有了直接返回，否则计算当前区块的hash再返回func (b *Block) Hash() common.Hash &#123; if hash := b.hash.Load(); hash != nil &#123; return hash.(common.Hash) &#125; v := b.header.Hash() b.hash.Store(v) return v&#125;type Blocks []*Block 对比etherscan.io的显示的Block字段：","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"source_code","slug":"区块链/ethereum/source-code","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/source-code/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"swarm","slug":"swarm","permalink":"https://guozhe001.github.io/tags/swarm/"}]},{"title":"Geth源码学习之共识与奖励","slug":"blockchain/ethereum/source_code/Geth源码学习之共识与奖励","date":"2024-11-22T06:32:06.493Z","updated":"2024-11-22T06:32:06.493Z","comments":true,"path":"2024/11/22/blockchain/ethereum/source_code/Geth源码学习之共识与奖励/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/source_code/Geth%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%85%B1%E8%AF%86%E4%B8%8E%E5%A5%96%E5%8A%B1/","excerpt":"","text":"计算挖矿奖励 12345678910111213141516171819202122232425262728293031323334353637383940// AccumulateRewards credits the coinbase of the given block with the mining// reward. The total reward consists of the static block reward and rewards for// included uncles. The coinbase of each uncle block is also rewarded.func accumulateRewards(config *params.ChainConfig, state *state.StateDB, header *types.Header, uncles []*types.Header) &#123; // Select the correct block reward based on chain progression // 根据不同的阶段，获取静态的区块奖励 blockReward := FrontierBlockReward if config.IsByzantium(header.Number) &#123; blockReward = ByzantiumBlockReward &#125; if config.IsConstantinople(header.Number) &#123; blockReward = ConstantinopleBlockReward &#125; // Accumulate the rewards for the miner and any included uncles reward := new(big.Int).Set(blockReward) r := new(big.Int) for _, uncle := range uncles &#123; r.Add(uncle.Number, big8) // r = uncle.Number + 8 r.Sub(r, header.Number) // r = r - header.Number r.Mul(r, blockReward) // r = r * blockReward r.Div(r, big8) // r = r / 8 state.AddBalance(uncle.Coinbase, r) // 挖出叔父区块的miner获得静态的（2个）奖励 //叔父区块number 当前区块number r.Add(uncle.Number, big8) r.Sub(r, header.Number) r.Mul(r, blockReward) r.Div(r, big8) 挖出叔父区块的奖励 blockReward //1 2 9 7 14 1.75 八分之七 2 //1 3 9 6 12 1.5 八分之六 2 //1 4 9 5 10 1.25 八分之五 2 //1 5 9 4 8 1 八分之四 2 //1 6 9 3 6 0.75 八分之三 2 //1 7 9 2 4 0.5 八分之二 2 //1 8 9 1 2 0.25 八分之一 2 //1 9 9 0 0 0 八分之零 2 //1 10 9 -1 -2 -0.25 八分之零 2 // 叔块距离当前区块越远，能够得到的奖励越少，最多不超过8个区块 // 不会出现负数的原因应该是在添加叔父区块时有判断，只有距离在8个区块之内的区块才能算是叔父区块，其他的不让添加 r.Div(blockReward, big32) // 当前挖到区块的miner每添加一个叔块获得1/32的静态（2个）的奖励 reward.Add(reward, r) &#125; state.AddBalance(header.Coinbase, reward)&#125; 解析源码中叔父区块的挖矿者获得的奖励 blockReward=2,不会出现负数的原因应该是在添加叔父区块时有判断，只有距离在8个区块之内的区块才能算是叔父区块，其他的不让添加 叔父区块number 当前区块number r.Add(uncle.Number, big8) r.Sub(r, header.Number) r.Mul(r, blockReward) r.Div(r, big8) 挖出叔父区块的奖励 blockReward 1 2 9 7 14 1.75 八分之七 2 1 3 9 6 12 1.5 八分之六 2 1 4 9 5 10 1.25 八分之五 2 1 5 9 4 8 1 八分之四 2 1 6 9 3 6 0.75 八分之三 2 1 7 9 2 4 0.5 八分之二 2 1 8 9 1 2 0.25 八分之一 2 1 9 9 0 0 0 八分之零 2 1 10 9 -1 -2 -0.25 八分之零 2 块头验证 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798// VerifyHeader checks whether a header conforms to the consensus rules of the// stock Ethereum ethash engine.func (ethash *Ethash) VerifyHeader(chain consensus.ChainHeaderReader, header *types.Header, seal bool) error &#123; // If we&#x27;re running a full engine faking, accept any input as valid if ethash.config.PowMode == ModeFullFake &#123; return nil &#125; // Short circuit if the header is known, or its parent not number := header.Number.Uint64() // 根据区块号和区块头的hash获取区块信息，只有区块高度为number的区块头的hash等于指定hash才返回数据，否则返回nil if chain.GetHeader(header.Hash(), number) != nil &#123; return nil &#125; // 获取父区块，父区块不能为nil parent := chain.GetHeader(header.ParentHash, number-1) if parent == nil &#123; return consensus.ErrUnknownAncestor &#125; // Sanity checks passed, do a proper verification return ethash.verifyHeader(chain, header, parent, false, seal, time.Now().Unix())&#125;// verifyHeader checks whether a header conforms to the consensus rules of the// stock Ethereum ethash engine.// See YP section 4.3.4. &quot;Block Header Validity&quot;func (ethash *Ethash) verifyHeader(chain consensus.ChainHeaderReader, header, parent *types.Header, uncle bool, seal bool, unixNow int64) error &#123; // Ensure that the header&#x27;s extra-data section is of a reasonable size // 块头的扩展数据的字符长度不能超过32 if uint64(len(header.Extra)) &gt; params.MaximumExtraDataSize &#123; return fmt.Errorf(&quot;extra-data too long: %d &gt; %d&quot;, len(header.Extra), params.MaximumExtraDataSize) &#125; // Verify the header&#x27;s timestamp if !uncle &#123; // 如果块头的时间超过了当前时间+15秒，抛异常； if header.Time &gt; uint64(unixNow+allowedFutureBlockTimeSeconds) &#123; return consensus.ErrFutureBlock &#125; &#125; // 如果块头的时间小于父区块的时间，也抛异常 if header.Time &lt;= parent.Time &#123; return errOlderBlockTime &#125; // Verify the block&#x27;s difficulty based on its timestamp and parent&#x27;s difficulty // 根据父区块的难度和当前区块的时间获取期望的难度 expected := ethash.CalcDifficulty(chain, header.Time, parent) // 如果当前区块的难度和计算的难度不一致，则抛异常 if expected.Cmp(header.Difficulty) != 0 &#123; return fmt.Errorf(&quot;invalid difficulty: have %v, want %v&quot;, header.Difficulty, expected) &#125; // Verify that the gas limit is &lt;= 2^63-1 // 区块的gas总量不能超过2^63-1 cap := uint64(0x7fffffffffffffff) if header.GasLimit &gt; cap &#123; return fmt.Errorf(&quot;invalid gasLimit: have %v, max %v&quot;, header.GasLimit, cap) &#125; // Verify that the gasUsed is &lt;= gasLimit // 使用的gas不能超过gas上限 if header.GasUsed &gt; header.GasLimit &#123; return fmt.Errorf(&quot;invalid gasUsed: have %d, gasLimit %d&quot;, header.GasUsed, header.GasLimit) &#125; // Verify that the gas limit remains within allowed bounds // 当前区块的gas上限与父区块的gas上限相减取绝对值 diff := int64(parent.GasLimit) - int64(header.GasLimit) if diff &lt; 0 &#123; diff *= -1 &#125; limit := parent.GasLimit / params.GasLimitBoundDivisor // 此处的整体意思是每次gas费的上限增加不能超过上一个区块的gas上限的1024分之一；也不能少于区块的gas最小上限5000 // 转账最少都需要21000的gas费，gas费怎么会少于5000呢？ if uint64(diff) &gt;= limit || header.GasLimit &lt; params.MinGasLimit &#123; return fmt.Errorf(&quot;invalid gas limit: have %d, want %d += %d&quot;, header.GasLimit, parent.GasLimit, limit) &#125; // Verify that the block number is parent&#x27;s +1 // 这个校验没有用吧，因为上面的父区块的获取方式是在当前区块高度的基础上-1；所以只要能获取到父区块父区块的高度肯定比当前区块少1 // 因为这个方法中的父区块是传入的，而不是在当前方法查询的，所以有这个判断是没问题的，但是可以把这个放在gasLimit的前面，如果这个父区块不是当前区块的父区块就没有必要验证gasLimit了 if diff := new(big.Int).Sub(header.Number, parent.Number); diff.Cmp(big.NewInt(1)) != 0 &#123; return consensus.ErrInvalidNumber &#125; // Verify the engine specific seal securing the block if seal &#123; // 验证nonce是否符合难度 if err := ethash.verifySeal(chain, header, false); err != nil &#123; return err &#125; &#125; // If all checks passed, validate any special fields for hard forks if err := misc.VerifyDAOHeaderExtraData(chain.Config(), header); err != nil &#123; return err &#125; if err := misc.VerifyForkHashes(chain.Config(), header, uncle); err != nil &#123; return err &#125; return nil&#125; 难度计算 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677 // calcDifficultyByzantium is the difficulty adjustment algorithm. It returns // the difficulty that a new block should have when created at time given the // parent block&#x27;s time and difficulty. The calculation uses the Byzantium rules. // Specification EIP-649: https://eips.ethereum.org/EIPS/eip-649 // 数字3000000是为了计算难度炸弹，目前的区块高度是12184295；2^(12184295-3000000)/100000 = 2^91 = 2.47588e+27！！！ calcDifficultyByzantium = makeDifficultyCalculator(big.NewInt(3000000))// makeDifficultyCalculator creates a difficultyCalculator with the given bomb-delay.// the difficulty is calculated with Byzantium rules, which differs from Homestead in// how uncles affect the calculationfunc makeDifficultyCalculator(bombDelay *big.Int) func(time uint64, parent *types.Header) *big.Int &#123; // Note, the calculations below looks at the parent number, which is 1 below // the block number. Thus we remove one from the delay given bombDelayFromParent := new(big.Int).Sub(bombDelay, big1) return func(time uint64, parent *types.Header) *big.Int &#123; // https://github.com/ethereum/EIPs/issues/100. // algorithm: // diff = (parent_diff + // (parent_diff / 2048 * max((2 if len(parent.uncles) else 1) - ((timestamp - parent.timestamp) // 9), -99)) // ) + 2^(periodCount - 2) bigTime := new(big.Int).SetUint64(time) bigParentTime := new(big.Int).SetUint64(parent.Time) // holds intermediate values to make the algo easier to read &amp; audit x := new(big.Int) y := new(big.Int) // (2 if len(parent_uncles) else 1) - (block_timestamp - parent_timestamp) // 9 x.Sub(bigTime, bigParentTime) x.Div(x, big9) if parent.UncleHash == types.EmptyUncleHash &#123; x.Sub(big1, x) &#125; else &#123; x.Sub(big2, x) &#125; // max((2 if len(parent_uncles) else 1) - (block_timestamp - parent_timestamp) // 9, -99) // 最多减少的难度不能超过99个单元，一个单元 = parent_diff / 2048；即最多减少的难度不能大于99*parent_diff / 2048 if x.Cmp(bigMinus99) &lt; 0 &#123; x.Set(bigMinus99) &#125; // parent_diff + (parent_diff / 2048 * max((2 if len(parent.uncles) else 1) - ((timestamp - parent.timestamp) // 9), -99)) y.Div(parent.Difficulty, params.DifficultyBoundDivisor) x.Mul(y, x) x.Add(parent.Difficulty, x) // minimum difficulty can ever be (before exponential factor) // 最小难度不能少于131072，即100000000000000000 if x.Cmp(params.MinimumDifficulty) &lt; 0 &#123; x.Set(params.MinimumDifficulty) &#125; // calculate a fake block number for the ice-age delay // Specification: https://eips.ethereum.org/EIPS/eip-1234 // 如果已经过了bombDelayFromParent区块高度，则计算直到父区块为止过去了多少个区块了 fakeBlockNumber := new(big.Int) if parent.Number.Cmp(bombDelayFromParent) &gt;= 0 &#123; fakeBlockNumber = fakeBlockNumber.Sub(parent.Number, bombDelayFromParent) &#125; // for the exponential factor // 每隔100000（十万）个区块，periodCount增加1，即每隔十万个区块难度炸弹的难度翻一倍 periodCount := fakeBlockNumber periodCount.Div(periodCount, expDiffPeriod) // the exponential factor, commonly referred to as &quot;the bomb&quot; // diff = diff + 2^(periodCount - 2) // 难度再加上难度炸弹的难度 if periodCount.Cmp(big1) &gt; 0 &#123; y.Sub(periodCount, big2) y.Exp(big2, y, nil) x.Add(x, y) &#125; return x &#125;&#125;","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"source_code","slug":"区块链/ethereum/source-code","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/source-code/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"swarm","slug":"swarm","permalink":"https://guozhe001.github.io/tags/swarm/"}]},{"title":"Mac安装swarm-bee","slug":"blockchain/ethereum/storage/Mac安装swarm-bee","date":"2024-11-22T06:32:06.493Z","updated":"2024-11-22T06:32:06.493Z","comments":true,"path":"2024/11/22/blockchain/ethereum/storage/Mac安装swarm-bee/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/storage/Mac%E5%AE%89%E8%A3%85swarm-bee/","excerpt":"","text":"安装swarm-clef 安装 1brew tap ethersphere/tap 1brew install swarm-clef 启动 1brew services start swarm-clef 安装swarm-bee 安装 1brew install swarm-bee 启动 1brew services start swarm-bee 查看日志验证启动情况 1tail -f /usr/local/var/log/swarm-bee/bee.log 常用命令记录 启动和停止 123456# 启动brew services start swarm-bee# 停止brew services stop swarm-bee# 重启brew services restart swarm-bee 文件路径 日志文件： 1tail -f /usr/local/var/log/swarm-bee/bee.log 配置文件： 1vi /usr/local/etc/swarm-bee/bee.yaml 密钥文件 1ll ~/.bee/keys","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"storage","slug":"区块链/ethereum/storage","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/storage/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"swarm","slug":"swarm","permalink":"https://guozhe001.github.io/tags/swarm/"}]},{"title":"ubuntu安装swarm-bee","slug":"blockchain/ethereum/storage/ubuntu安装swarm-bee","date":"2024-11-22T06:32:06.493Z","updated":"2024-11-22T06:32:06.493Z","comments":true,"path":"2024/11/22/blockchain/ethereum/storage/ubuntu安装swarm-bee/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/storage/ubuntu%E5%AE%89%E8%A3%85swarm-bee/","excerpt":"","text":"安装swarm-clef 安装 访问https://github.com/ethersphere/bee-clef/releases并下载最新版本的安装程序 1sudo dpkg -i bee-clef_0.4.9_amd64.deb 修改配置sudo vi /etc/bee/bee.yaml 修改点如下： 123456full-node: trueswap-endpoint: wss:&#x2F;&#x2F;goerli.infura.io&#x2F;ws&#x2F;v3&#x2F;your-api-keyresolver-options: [&quot;https:&#x2F;&#x2F;mainnet.infura.io&#x2F;v3&#x2F;&lt;&lt;your-api-key&gt;&gt;&quot;]db-open-files-limit: 2000debug-api-enable: truedebug-api-addr: 127.0.0.1:1635 查看状态 1systemctl status bee-clef 查看日志 1journalctl -f -u bee-clef.service 安装swarm-bee 安装 访问https://github.com/ethersphere/bee/releases并下载最新的安装程序 1sudo dpkg -i bee_0.5.3_amd64.deb 常用命令记录 启动和停止 123456# 启动sudo systemctl start bee# 停止sudo systemctl stop bee# 重启sudo systemctl restart bee 查看状态 1systemctl status bee 查看日志 1journalctl --lines=100 --follow --unit bee 文件路径 Bee-clef# Configuration files are stored in /etc/bee-clef/ Key material and other data is stored in /var/lib/bee-clef/ 1ll /var/lib/bee-clef/ Bee# Configuration files are stored in /etc/bee/ State, chunks and other data is stored in /var/lib/bee/ 1sudo vi /etc/bee/bee.yaml 导出钱包 把bee-clef的钱包导出，然后就可以导入到自己的钱包（如metamask）。 运行命令 1bee-clef-keys 1234# 运行命令后的输出结果# bee-clef-keysKey exported to /root/bee-clef-key-1617347363.jsonPass exported to /root/bee-clef-password-1617347363.txt","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"storage","slug":"区块链/ethereum/storage","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/storage/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"swarm","slug":"swarm","permalink":"https://guozhe001.github.io/tags/swarm/"}]},{"title":"Oracle-预言机","slug":"blockchain/ethereum/概念学习/Oracle-预言机","date":"2024-11-22T06:32:06.493Z","updated":"2024-11-22T06:32:06.493Z","comments":true,"path":"2024/11/22/blockchain/ethereum/概念学习/Oracle-预言机/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/%E6%A6%82%E5%BF%B5%E5%AD%A6%E4%B9%A0/Oracle-%E9%A2%84%E8%A8%80%E6%9C%BA/","excerpt":"","text":"为什么需要预言机？ EVM和智能合约没有内在的随机性来源 外部数据只能作为交易的数据载荷引入（而不能通过智能合约去查询） 为什么EVM和智能合约没有内在的随机性来源？ 因为Pow共识，如果一个在EVM和智能合约内部真的有随机性的数据，并且智能合约使用了这些数据。那么极有可能无法达成共识，因为挖矿的矿工获得的随机数和其他验证者获得的随机数会不一样。 为什么外部数据只能作为交易的数据载荷引入？ 如果在合约内部使用随机数，比如区块的高度，hash函数等伪随机数，那么矿工只打包有利于自己的随机结果即可。而从外部传入随机数据矿工就无法控制了。 预言机的应用场景和示例 理想情况下，预言机提供了一种无信任（即无需信任提供的数据的人或组织）的方式来获取链外信息。 应用场景 有些预言机是提供特定的私有数据源的数据，例如： 大学毕业证书 政府ID 护照 征信报告 以上这些这些数据是掌握在大学、政府部门等，你只能信任他们。（不信任也没办法，你无法证明他们提供的数据不正确） 其他可能由预言机提供的数据示例包括： 物理随机数源或熵源：如在彩票智能合约中公平地选出获胜者 与自然灾害相关的参数触发器：触发大型自然灾害债券智能合约 汇率数据：例如让加密货币与法币精确挂钩 资本市场数据：例如为一揽子代币化资产或证券定价（数字货币基金） 指标引用数据：例如将利率纳入智能金融衍生品合约 统计与准统计数据：安全标识、国家代码、货币代号等 时间和间隔数据：基于精准的SI（国际单位制）时间度量的事件触发器 天气数据：例如给予天气预报的保险费计算器 政治事件：预测市场走势 运动事件：预测市场走势以及体育博彩相关的合约 地理定位数据：例如供应链跟踪 损坏程度核验：保险合约 其他区块链上发生的事件：可互操作函数 以太币市场价格：例如gas价格预言机 航班统计数据：例如用于团体和俱乐部的机票合同 预言机的设计模式 预言机的关键功能 根据定义，所有预言机都提供了一些关键功能。这些能力包括： 从链外的数据源收集数据 使用签名消息在链上传输数据 将数据放入智能合约的存储空间，使数据可用 实现预言机的三种主要方式 设置预言机的三种主要方式可以分为请求/响应、发布于订阅和立即读取。 立即读取 这种预言机提供及时决策所需的数据 这种预言机的例子包括那些持有组织数据或有组织发布数据（例如学术证书、拨号代码、机构会员资格、机场标识符、自主ID等）的预言机 这种预言机存储中的数据也可以通过区块链启用应用程序（Geth）直接在本地查找，不需要消耗gas 这种预言机存储的数据和实际组织提供的数据可能不一样。（为了保密只需要在合约存储hash即可） 发布与订阅 在这种预言机中，要对预期改变的数据提供有效的广播服务，预言机要么由链上的智能合约轮询，要么由链外的守护进程监视和更新 这种预言机的示例包括价格推送、天气预报、经济或社会统计、交通数据等 以太坊时间日志应用程序特别容易注意预言机更新 但是如果使用智能合约去轮询可能会产生大量的gas支出 请求与响应 这是数据空间太大而无法存储在智能合约中的情况，并且用户每次只需要整个数据集的一小部分。它也是数据提供商业务的适用模型 请求与响应预言机的步骤可以总结如下： 接收来自DApp的查询 解析查询 检查是否提供了付款和数据访问权限 从链外数据源检索相关数据（并在必要时加密） 使用包含的数据对交易进行签名 将交易广播到网络 安排任何进一步必要的交易，例如通知等 数据认证 两种常见的数据认证方法： 真实性证明（authenticity proof） 可信执行环境（Trusted Execution Environment，TEE） 真实性证明 真实性证明是用密码学证据证明数据没有被篡改过。 TLSNotary： 可信执行环境 使用Intel SGX来保证对HTTPS查询的响应可以被验证为可信的。 SGK提供了完整性保证：使得在安全区中运行的应用程序收到CPU保护。不被其他进程篡改 SGK提供了机密性：保证应用程序在安全区中运行时，其状态对其他进程来说是不可知的 SGK通过生成应用程序确定在安全区中运行的数字签名，让证明成为可能，只要验证这个签名就能够确认程序在SGK安全区内安全地运行 计算性的预言机 智能合约因为有gas费限制的原因，并不适合做非常复杂的计算。部分提供计算性预言机如下： Provable Cryptlet truebit 去中心化预言机 ChainLink NEST Protocol Solidity中的预言机客户端接口 轮询ETH/USD价格 123456789101112131415161718192021222324252627282930pragma solidity ^0.4.22;import &quot;github.com&#x2F;provable-things&#x2F;ethereum-api&#x2F;provableAPI_0.4.25.sol&quot;;contract ExampleContract is usingProvable &#123; string public ETHUSD; event LogConstructorInitiated(string nextStep); event LogPriceUpdated(string price); event LogNewProvableQuery(string description); function ExampleContract() payable &#123; LogConstructorInitiated(&quot;Constructor was initiated. Call &#39;updatePrice()&#39; to send the Provable Query.&quot;); &#125; function __callback(bytes32 myid, string result) &#123; if (msg.sender !&#x3D; provable_cbAddress()) revert(); ETHUSD &#x3D; result; LogPriceUpdated(result); updatePrice(); &#125; function updatePrice() payable &#123; if (provable_getPrice(&quot;URL&quot;) &gt; this.balance) &#123; LogNewProvableQuery(&quot;Provable query was NOT sent, please add some ETH to cover for the query fee&quot;); &#125; else &#123; LogNewProvableQuery(&quot;Provable query was sent, standing by for the answer..&quot;); provable_query(60, &quot;URL&quot;, &quot;json(https:&#x2F;&#x2F;api.pro.coinbase.com&#x2F;products&#x2F;ETH-USD&#x2F;ticker).price&quot;); &#125; &#125;","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"概念学习","slug":"区块链/ethereum/概念学习","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/%E6%A6%82%E5%BF%B5%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"智能合约","slug":"智能合约","permalink":"https://guozhe001.github.io/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"},{"name":"Oracle","slug":"Oracle","permalink":"https://guozhe001.github.io/tags/Oracle/"}]},{"title":"背书策略（Endorsement policies）","slug":"blockchain/fabric/how_to/Endorsement policies背书策略","date":"2024-11-22T06:32:06.493Z","updated":"2024-11-22T06:32:06.493Z","comments":true,"path":"2024/11/22/blockchain/fabric/how_to/Endorsement policies背书策略/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/fabric/how_to/Endorsement%20policies%E8%83%8C%E4%B9%A6%E7%AD%96%E7%95%A5/","excerpt":"","text":"背书策略 官方文档：Endorsement policies 。。。省略部分 Setting chaincode-level endorsement policies(设置链码级别的背书策略) Chaincode-level endorsement policies are agreed to by channel members when they approve a chaincode definition for their organization. A sufficient number of channel members need to approve a chaincode definition to meet the Channel/Application/LifecycleEndorsement policy, which by default is set to a majority of channel members, before the definition can be committed to the channel. Once the definition has been committed, the chaincode is ready to use. Any invoke of the chaincode that writes data to the ledger will need to be validated by enough channel members to meet the endorsement policy. 通道成员在为其组织批准链码定义时，会同意链码级认可策略。需要足够数量的通道成员批准链码定义才能满足Channel / Application / LifecycleEndorsement策略，该策略默认情况下设置为大多数通道成员，然后才能将链码定义提交给通道。提交定义后，便可以使用链码了。任何将数据写入账本的链码的调用都需要由足够的通道成员来验证，以满足背书策略。 You can specify an endorsement policy for a chaincode using the Fabric SDKs. For an example, visit the How to install and start your chaincode in the Node.js SDK documentation. You can also create an endorsement policy from your CLI when you approve and commit a chaincode definition with the Fabric peer binaries by using the --signature-policy flag. 你可以使用Fabric SDKs来为链码指定背书策略，访问How to install and start your chaincode来查看使用Node.js SDK的文档。你也可以通过CLI在批准和提交链码定义时来创建背书策略，使用Fabric的peer可执行程序时使用 --signature-policy 标志来实现这个功能。 For example： 1peer lifecycle chaincode approveformyorg --channelID mychannel --signature-policy &quot;AND(&#x27;Org1.member&#x27;, &#x27;Org2.member&#x27;)&quot; --name mycc --version 1.0 --package-id mycc_1:3a8c52d70c36313cfebbaf09d8616e7a6318ababa01c7cbe40603c373bcfe173 --sequence 1 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem --waitForEvent The above command approves the chaincode definition of mycc with the policy AND('Org1.member', 'Org2.member') which would require that a member of both Org1 and Org2 sign the transaction. After a sufficient number of channel members approve a chaincode definition for mycc, the definition and endorsement policy can be committed to the channel using the command below: 上面的命令使用 AND('Org1.member', 'Org2.member') 策略来批准mycc的链码定义，这个策略要求Org1和Org2的成员都需要对一笔交易进行签名。在有足够的通道成员批准了mycc的链码定义之后，这个定义和背书策略就可以使用下面的命令被提交到通道了： 1peer lifecycle chaincode commit -o orderer.example.com:7050 --channelID mychannel --signature-policy &quot;AND(&#x27;Org1.member&#x27;, &#x27;Org2.member&#x27;)&quot; --name mycc --version 1.0 --sequence 1 --init-required --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem --waitForEvent --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses peer0.org2.example.com:9051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt Notice that, if the identity classification is enabled (see Membership Service Providers (MSP)), one can use the PEER role to restrict endorsement to only peers. 请注意，如果启用了身份分类（请参阅 Membership Service Providers (MSP)），则可以使用PEER角色将背书限制为仅peer节点。 For example: 1peer lifecycle chaincode approveformyorg --channelID mychannel --signature-policy &quot;AND(&#x27;Org1.peer&#x27;, &#x27;Org2.peer&#x27;)&quot; --name mycc --version 1.0 --package-id mycc_1:3a8c52d70c36313cfebbaf09d8616e7a6318ababa01c7cbe40603c373bcfe173 --sequence 1 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem --waitForEvent In addition to the specifying an endorsement policy from the CLI or SDK, a chaincode can also use policies in the channel configuration as endorsement policies. You can use the --channel-config-policy flag to select a channel policy with format used by the channel configuration and by ACLs. 除了从CLI或SDK中指定背书策略以外，链码还可以使用通道配置中的策略作为背书策略。你可以使用--channel-config-policy标志来选择一个通道策略，其格式由通道配置和ACL使用。 For example: 1peer lifecycle chaincode approveformyorg --channelID mychannel --channel-config-policy Channel/Application/Admins --name mycc --version 1.0 --package-id mycc_1:3a8c52d70c36313cfebbaf09d8616e7a6318ababa01c7cbe40603c373bcfe173 --sequence 1 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem --waitForEvent If you do not specify a policy, the chaincode definition will use the Channel/Application/Endorsement policy by default, which requires that a transaction be validated by a majority of channel members. This policy depends on the membership of the channel, so it will be updated automatically when organizations are added or removed from a channel. One advantage of using channel policies is that they can be written to be updated automatically with channel membership. 如果你不指定背书策略，链码定义会使用默认的 Channel/Application/Endorsement策略，这个策略要求交易必须经过大多数通道成员的验证。该策略取决于通道成员，因此从通道中添加或删除组织时，它将自动更新。使用通道策略的一个优势是，可以将其编写为根据通道成员数量自动更新。 If you specify an endorsement policy using the --signature-policy flag or the SDK, you will need to update the policy when organizations join or leave the channel. A new organization added to the channel after the chaincode has been defined will be able to query a chaincode (provided the query has appropriate authorization as defined by channel policies and any application level checks enforced by the chaincode) but will not be able to execute or endorse the chaincode. Only organizations listed in the endorsement policy syntax will be able sign transactions. 如果你使用 --signature-policy 标志或者SDK指定了背书策略，你需要在组织加入或者离开通道时更新这个策略。一个新的组织在链码被定义好之后加入这个通道，这个组织可以查询这个链码（提供查询具有通道策略和链码强制执行的任何应用程序级别检查所定义的适当授权），但是不能够执行或认可链码。只有组织在认可策略语法的列表中之后，组织才能签署交易。 个人验证 chaincode如果不设置背书策略，则默认的背书策略是：\u0012 /Channel/Application/Endorsement 123456789101112131415apple$ peer lifecycle chaincode querycommitted --channelID alljoinchannel --name secured_supply --output json&#123; &quot;sequence&quot;: 6, &quot;version&quot;: &quot;3.0&quot;, &quot;endorsement_plugin&quot;: &quot;escc&quot;, &quot;validation_plugin&quot;: &quot;vscc&quot;, &quot;validation_parameter&quot;: &quot;EiAvQ2hhbm5lbC9BcHBsaWNhdGlvbi9FbmRvcnNlbWVudA==&quot;, &quot;collections&quot;: &#123;&#125;, &quot;approvals&quot;: &#123; &quot;GylCoreOrg1MSP&quot;: true, &quot;GylFOrg1MSP&quot;: true, &quot;GylSOrg1MSP&quot;: true, &quot;GylSOrg2MSP&quot;: true &#125;&#125; 设置背书策略为--signature-policy &quot;OR('GylCoreOrg1MSP.peer','GylFOrg1MSP.peer','GylSOrg1MSP.peer','GylSOrg2MSP.peer')&quot;，再次查询链码定义： 123456789101112131415apple$ peer lifecycle chaincode querycommitted --channelID alljoinchannel --name secured_supply --output json&#123; &quot;sequence&quot;: 7, &quot;version&quot;: &quot;3.0&quot;, &quot;endorsement_plugin&quot;: &quot;escc&quot;, &quot;validation_plugin&quot;: &quot;vscc&quot;, &quot;validation_parameter&quot;: &quot;CmUSFBISCAESAggAEgIIARICCAISAggDGhQSEgoOR3lsQ29yZU9yZzFNU1AQAxoREg8KC0d5bEZPcmcxTVNQEAMaERIPCgtHeWxTT3JnMU1TUBADGhESDwoLR3lsU09yZzJNU1AQAw==&quot;, &quot;collections&quot;: &#123;&#125;, &quot;approvals&quot;: &#123; &quot;GylCoreOrg1MSP&quot;: true, &quot;GylFOrg1MSP&quot;: true, &quot;GylSOrg1MSP&quot;: true, &quot;GylSOrg2MSP&quot;: true &#125;&#125; 解码之后： 12345e\u0012\u0014\u0012\u0012\b\u0001\u0012\u0002\b\u0012\u0002\b\u0001\u0012\u0002\b\u0002\u0012\u0002\b\u0003\u001a\u0014\u0012\u0012\u000eGylCoreOrg1MSP\u0010\u0003\u001a\u0011\u0012\u000f GylFOrg1MSP\u0010\u0003\u001a\u0011\u0012\u000f GylSOrg1MSP\u0010\u0003\u001a\u0011\u0012\u000f GylSOrg2MSP\u0010\u0003 Endorsement policy syntax（背书策略的语法） As you can see above, policies are expressed in terms of principals (“principals” are identities matched to a role). Principals are described as 'MSP.ROLE', where MSP represents the required MSP ID and ROLE represents one of the four accepted roles: member, admin, client, and peer. 正如您在上面看到的那样，策略是根据主体表达的（“主体”是与角色匹配的身份）。主体被描述为'MSP.ROLE'，其中MSP代表所需的MSP ID,ROLE 代表四个公认的角色之一：member, admin, client，和 peer。 Here are a few examples of valid principals: 'Org0.admin': any administrator of the Org0 MSP 'Org1.member': any member of the Org1 MSP 'Org1.client': any client of the Org1 MSP 'Org1.peer': any peer of the Org1 MSP The syntax of the language is: 1EXPR(E[, E...]) Where EXPR is either AND, OR, or OutOf, and E is either a principal (with the syntax described above) or another nested call to EXPR. EXPR 可以为AND, OR, or OutOf，E可以是一个具有上面语法的主体，也可以是对另一个EXPR的嵌套调用。 For example: AND('Org1.member', 'Org2.member', 'Org3.member') requests one signature from each of the three principals. OR('Org1.member', 'Org2.member') requests one signature from either one of the two principals. OR('Org1.member', AND('Org2.member', 'Org3.member')) requests either one signature from a member of the Org1 MSP or one signature from a member of the Org2 MSP and one signature from a member of the Org3 MSP. OutOf(1, 'Org1.member', 'Org2.member'), which resolves to the same thing as OR('Org1.member', 'Org2.member'). Similarly, OutOf(2, 'Org1.member', 'Org2.member') is equivalent to AND('Org1.member', 'Org2.member'), and OutOf(2, 'Org1.member', 'Org2.member', 'Org3.member') is equivalent to OR(AND('Org1.member', 'Org2.member'), AND('Org1.member', 'Org3.member'), AND('Org2.member', 'Org3.member')). 例如： AND('Org1.member', 'Org2.member', 'Org3.member') 三个主体都需要进行签名。 OR('Org1.member', 'Org2.member') 只需要两个主体的其中一个提供签名。 OR('Org1.member', AND('Org2.member', 'Org3.member')) 需要Org1提供签名，或者需要Org2和Org3同时提供签名。 OutOf(1, 'Org1.member', 'Org2.member'), 和 OR('Org1.member', 'Org2.member')做的事情一样。 相似的, OutOf(2, 'Org1.member', 'Org2.member') 与 AND('Org1.member', 'Org2.member')相同 OutOf(2, 'Org1.member', 'Org2.member', 'Org3.member') 与 OR(AND('Org1.member', 'Org2.member'), AND('Org1.member', 'Org3.member'), AND('Org2.member', 'Org3.member'))相同。","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"区块链/Hyperledger-Fabric","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/"},{"name":"HOW-TO","slug":"区块链/Hyperledger-Fabric/HOW-TO","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Hyperledger-Fabric/HOW-TO/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Hyperledger-Fabric","slug":"Hyperledger-Fabric","permalink":"https://guozhe001.github.io/tags/Hyperledger-Fabric/"},{"name":"Endorsement policies","slug":"Endorsement-policies","permalink":"https://guozhe001.github.io/tags/Endorsement-policies/"}]},{"title":"TOKEN-代币","slug":"blockchain/ethereum/概念学习/以太坊中的token","date":"2024-11-22T06:32:06.493Z","updated":"2024-11-22T06:32:06.493Z","comments":true,"path":"2024/11/22/blockchain/ethereum/概念学习/以太坊中的token/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/%E6%A6%82%E5%BF%B5%E5%AD%A6%E4%B9%A0/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E4%B8%AD%E7%9A%84token/","excerpt":"","text":"什么是TOKEN（代币） 通常是指私人发行的，类似硬币形状的物体，具备少量价值；如游戏币 以太坊上的代币是指基于区块链的一种抽象的资产，可以被持有并且用来代表资产、现金等 代币有哪些使用方式 货币 资产 访问权限 权益（股东权益） 投票权 收藏品 身份 。。。 代币标准 ERC20 ERC20接口定义 ERC20-OpenZeppelin implementation ERC20-ConsenSys implementation ERC20是一个token标准，体现到合约上是一个接口规范。接口如下（不同编译版本的solidity的接口可能语法不一样，但是描述的是一样的）： 我的0.8.0版本接口定义： 123456789101112131415161718192021&#x2F;&#x2F; SPDX-License-Identifier: GPL-3.0pragma solidity&#x3D;0.8.0;interface ERC20Interface &#123; function balanceOf(address _owner) external view returns (uint256 balance); function transfer(address _to, uint256 _value) external returns (bool success); function transferFrom(address _from, address _to, uint256 _value) external returns (bool success); function approve(address _spender, uint256 _value) external returns (bool success); function allowance(address _owner, address _spender) external view returns (uint256 remaining); event Transfer(address indexed _from, address indexed _to, uint256 _value); event Approval(address indexed _owner, address indexed _spender, uint256 _value);&#125; ERC20-[ConsenSys定义] 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&#x2F;&#x2F; Abstract contract for the full ERC 20 Token standard&#x2F;&#x2F; https:&#x2F;&#x2F;github.com&#x2F;ethereum&#x2F;EIPs&#x2F;blob&#x2F;master&#x2F;EIPS&#x2F;eip-20.mdpragma solidity ^0.4.21;contract EIP20Interface &#123; &#x2F;* This is a slight change to the ERC20 base standard. function totalSupply() constant returns (uint256 supply); is replaced with: uint256 public totalSupply; This automatically creates a getter function for the totalSupply. This is moved to the base contract since public getter functions are not currently recognised as an implementation of the matching abstract function by the compiler. *&#x2F; &#x2F;&#x2F;&#x2F; total amount of tokens uint256 public totalSupply; &#x2F;&#x2F;&#x2F; @param _owner The address from which the balance will be retrieved &#x2F;&#x2F;&#x2F; @return The balance function balanceOf(address _owner) public view returns (uint256 balance); &#x2F;&#x2F;&#x2F; @notice send &#96;_value&#96; token to &#96;_to&#96; from &#96;msg.sender&#96; &#x2F;&#x2F;&#x2F; @param _to The address of the recipient &#x2F;&#x2F;&#x2F; @param _value The amount of token to be transferred &#x2F;&#x2F;&#x2F; @return Whether the transfer was successful or not function transfer(address _to, uint256 _value) public returns (bool success); &#x2F;&#x2F;&#x2F; @notice send &#96;_value&#96; token to &#96;_to&#96; from &#96;_from&#96; on the condition it is approved by &#96;_from&#96; &#x2F;&#x2F;&#x2F; @param _from The address of the sender &#x2F;&#x2F;&#x2F; @param _to The address of the recipient &#x2F;&#x2F;&#x2F; @param _value The amount of token to be transferred &#x2F;&#x2F;&#x2F; @return Whether the transfer was successful or not function transferFrom(address _from, address _to, uint256 _value) public returns (bool success); &#x2F;&#x2F;&#x2F; @notice &#96;msg.sender&#96; approves &#96;_spender&#96; to spend &#96;_value&#96; tokens &#x2F;&#x2F;&#x2F; @param _spender The address of the account able to transfer the tokens &#x2F;&#x2F;&#x2F; @param _value The amount of tokens to be approved for transfer &#x2F;&#x2F;&#x2F; @return Whether the approval was successful or not function approve(address _spender, uint256 _value) public returns (bool success); &#x2F;&#x2F;&#x2F; @param _owner The address of the account owning tokens &#x2F;&#x2F;&#x2F; @param _spender The address of the account able to transfer the tokens &#x2F;&#x2F;&#x2F; @return Amount of remaining tokens allowed to spent function allowance(address _owner, address _spender) public view returns (uint256 remaining); &#x2F;&#x2F; solhint-disable-next-line no-simple-event-func-name event Transfer(address indexed _from, address indexed _to, uint256 _value); event Approval(address indexed _owner, address indexed _spender, uint256 _value);&#125; ERC721 ERC721是NFT（Non-Fungible Token）的标准。直接看官方接口定义ERC721和openzeppelin的实现 ERC777 一种兼容ERC20的代币标准，这个标准在转账的时候会检查接收方支不支持接收当前代币（即有没有实现某个接口）；如果没有实现转账会失败，这可以防止代币转入一个不支持的合约中","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"概念学习","slug":"区块链/ethereum/概念学习","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/%E6%A6%82%E5%BF%B5%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"token","slug":"token","permalink":"https://guozhe001.github.io/tags/token/"}]},{"title":"与swarm-bee交互","slug":"blockchain/ethereum/storage/与swarm-bee交互","date":"2024-11-22T06:32:06.493Z","updated":"2024-11-22T06:32:06.493Z","comments":true,"path":"2024/11/22/blockchain/ethereum/storage/与swarm-bee交互/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/storage/%E4%B8%8Eswarm-bee%E4%BA%A4%E4%BA%92/","excerpt":"","text":"状态检查 主页 1curl localhost:1633 检查运行是否正常 1curl -s http://localhost:1635/health 查看当前bee节点的地址 1sudo bee-get-addr 1curl -s localhost:1635/addresses | jq .ethereum 查看链接了多少个peer 1curl -s http://localhost:1635/peers | jq &#x27;.peers | length&#x27; 查看网络拓扑 1curl -X GET http://localhost:1635/topology | jq 上传文件 上传文件，返回的是一个hash值 12curl -F file=@bee.jpg http://localhost:1633/files&#123;&quot;reference&quot;:&quot;02a03340405f30c1027b885ee39903fb394ba8909e98029dd6c14371437edafc&quot;&#125; 1curl --data-binary @bee.jpg -H &quot;Content-Type: video/jpg&quot; &quot;http://localhost:1633/files?name=bee.jpg&quot; 下载文件 12curl -OJ http://localhost:1633/files/042d4fe94b946e2cb51196a8c136b8cc335156525bf1ad7e86356c2402291dd4https://gateway.ethswarm.org/files/042d4fe94b946e2cb51196a8c136b8cc335156525bf1ad7e86356c2402291dd4 特别注意：不要传一些重要数据到swarm除非已经加密，因为上传上去之后的所有文件都是公开的，只要知道hash就能下载。 上传文件夹 比如有一个前端vue项目，需要上传到swarm 项目构建 1npm run build 把需要上传的文件夹dist打包 12cd disttar -cf ../hello-swarm.tar . 把hello-swarm.tar包上传到swarm 12345curl \\ -X POST \\ -H &quot;Content-Type: application/x-tar&quot; \\ -H &quot;Swarm-Index-Document: index.html&quot; \\ --data-binary @hello-swarm.tar http://localhost:1633/dirs {“reference”:“b2afd8fa4995be121ba6e6cf544d035e07a2b4b775648b5549b14f82e15c5bea”} 访问主页： http://localhost:1633/bzz/b2afd8fa4995be121ba6e6cf544d035e07a2b4b775648b5549b14f82e15c5bea/index.html 支票信息API 查询当前bee节点的余额 1curl localhost:1635/chequebook/balance | jq 查看每个节点（当前bee节点连接的）的余额 1curl localhost:1635/balances | jq 查看结算信息 1curl localhost:1635/settlements | jq 查看支票信息 1curl localhost:1635/chequebook/cheque | jq 支票兑换(地址是上一个命令中显示的地址) 1curl -XPOST http://localhost:1635/chequebook/cashout/d7881307e793e389642ea733451db368c4c9b9e23f188cca659c8674d183a56b 查看支票的兑换状态 1curl http://localhost:1635/chequebook/cashout/d7881307e793e389642ea733451db368c4c9b9e23f188cca659c8674d183a56b | jq gBZZ提现 1curl -XPOST http://localhost:1635/chequebook/withdraw\\?amount\\=1000 | jq 管理支票脚本 下载官方的脚本 1wget -O cashout.sh https://gist.githubusercontent.com/ralph-pichler/3b5ccd7a5c5cd0500e6428752b37e975/raw/cashout.sh 添加可执行权限 1chmod +x cashout.sh 列出所有的没有兑换的支票信息 1./cashout.sh 当超过5BZZ时兑换所有支票： 1./cashout.sh cashout-all 5","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"storage","slug":"区块链/ethereum/storage","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/storage/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"swarm","slug":"swarm","permalink":"https://guozhe001.github.io/tags/swarm/"}]},{"title":"Alpaca项目评估报告","slug":"blockchain/ethereum/audit/Alpaca项目评估报告","date":"2024-11-22T06:32:06.492Z","updated":"2024-11-22T06:32:06.492Z","comments":true,"path":"2024/11/22/blockchain/ethereum/audit/Alpaca项目评估报告/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/audit/Alpaca%E9%A1%B9%E7%9B%AE%E8%AF%84%E4%BC%B0%E6%8A%A5%E5%91%8A/","excerpt":"","text":"https://defisafety.com/2021/06/11/alpaca-finance-bsc/ 项目安全评估结果 Alpaca Finance项目合约审计完善、代码开源，策略基本透明；虽然有一些审计的问题并未部署到生产环境，但是如果不做借贷是比较安全的。 并且Alpaca Finance项目的AlpacaToken代币是随着区块的增加而铸造的，因此不会出现像AutoShark那样被闪电贷攻击铸造很多SHARK代币。 评估维度 评估结果 审计报告 合约代码由多家审计公司审计，发现的严重问题基本修复，未修复的问题也不影响非借贷类使用者。 智能合约 完全开源，部署的智能合约与审计修复后的智能合约代码基本一致；其中有一个DebtToken合约在授信转账后未更新授信额度的问题部署的合约与源码不一致，但是如果不做借贷进行farm并且不授权给其他地址则没有问题。 安全漏洞 未发现合约后门。AlpacaToken有一个owner可以锁定的方法，但是被锁定的地址可以通过调用解锁方法来释放；所以不能让合约持有AlpacaToken，不然被锁定了就提不出来了；这可能也是Alpaca团队预防被合约攻击的一种手段 资金投向 存入的资金在本平台被其他人借出并最终投向了pancakeswap和wault.finance 审计报告 Alpaca主项目共有两个审计公司做了代码审计，分别如下： PeckShield Certik Alpaca的Grazing Range 合约也有两个审计公司做了代码审计，分别如下： SlowMist Valix/Inspex 审计报告分析 由多家审计公司进行审计是加分项 审计报告中发现的严重级别的问题都已经修正 合约代码 是否开源 合约代码开源，并在官方文档提供代码链接bsc-alpaca-contract 合约代码检查 GrazingRange.sol合约 审计报告提供的fix后的源码 部署的智能合约GrazingRange的代码，也是修复后的代码 AlpacaToken合约 ATC-03 | Lack of State Update in已经修复 审计报告 合约源码 1234567function manualMint(address _to, uint256 _amount) public onlyOwner &#123; require(manualMinted.add(_amount) &lt;&#x3D; MANUAL_MINT_LIMIT, &quot;mint limit exceeded&quot;); manualMinted &#x3D; manualMinted.add(_amount); mint(_to, _amount);&#125; DebtToken合约 DTC-01 | Lack of Allowance Check In 源码已经修复，但是生产环境部署的是未修复代码； 此问题如果有影响必须满足两个条件： A地址参与此项目的借贷farm A地址把获取到的debttoken授信一部分给其他地址B 满足以上两个条件之后获得授信的地址B就可以转移所有的A的debttoken。 审计报告问题 合约源码 12345678function transferFrom(address from, address to, uint256 amount) public override returns (bool) &#123; require(okHolders[from], &quot;debtToken::transferFrom:: unapproved holder in from&quot;); require(okHolders[to], &quot;debtToken::transferFrom:: unapproved holder in to&quot;); _transfer(from, to, amount); _approve(from, _msgSender(), allowance(from, _msgSender()).sub(amount, &quot;BEP20: transfer amount exceeds allowance&quot;)); return true;&#125; 线上部署合约代码DebtToken 1234567function transferFrom(address from, address to, uint256 amount) public override returns (bool) &#123; require(okHolders[from], &quot;debtToken::transferFrom:: unapproved holder in from&quot;); require(okHolders[to], &quot;debtToken::transferFrom:: unapproved holder in to&quot;); _transfer(from, to, amount); return true;&#125; Vault合约 PeckShield审计报告的3.1Possible Drain of Vault Funds With Double Returns Of Excess Tokens问题 合约源码 ![image-20210616145054787](/Users/apple/Library/Application Support/typora-user-images/image-20210616145054787.png) 生产环境部署的合约代码，其他代码与源码不完全一致，但是此问题已经修复 PeckShield审计报告的3.4 Proper Leftover Return After Liquidation问题 此问题是在清算时剩余的金额没有返还给用户，而是给了清算人。 审计报告提供的问题代码: 合约源码 生产环境部署的代码 安全漏洞 检查合约如下，均未发现明显的管理员或owner有权利转移别人资产的方法： GrazingRange WaultSwapWorker AlpacaToken PancakeswapV2Worker Vault AlpacaToken代码检查 AlpacaToken中有一个只允许owner调用的可以锁住任何人资产的方法，但是提供了unlock方法，被锁住的地址可以调用解锁。 此方法是一个小风险，虽然资产没有被转移还能由自己解锁，但是尚不清楚为什么要给owner锁住某个地址的资产的权限。 1234567891011121314151617181920212223242526272829function lock(address _account, uint256 _amount) external onlyOwner &#123; require(_account !&#x3D; address(0), &quot;no lock to address(0)&quot;); require(_amount &lt;&#x3D; balanceOf(_account), &quot;no lock over balance&quot;); _transfer(_account, address(this), _amount); _locks[_account] &#x3D; _locks[_account].add(_amount); _totalLock &#x3D; _totalLock.add(_amount); if (_lastUnlockBlock[_account] &lt; startReleaseBlock) &#123; _lastUnlockBlock[_account] &#x3D; startReleaseBlock; &#125; emit Lock(_account, _amount);&#125;function unlock() external &#123; require(_locks[msg.sender] &gt; 0, &quot;no locked ALPACAs&quot;); uint256 amount &#x3D; canUnlockAmount(msg.sender); _transfer(address(this), msg.sender, amount); _locks[msg.sender] &#x3D; _locks[msg.sender].sub(amount); _lastUnlockBlock[msg.sender] &#x3D; block.number; _totalLock &#x3D; _totalLock.sub(amount);&#125;","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"合约审计","slug":"区块链/ethereum/合约审计","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/%E5%90%88%E7%BA%A6%E5%AE%A1%E8%AE%A1/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"solidity","slug":"solidity","permalink":"https://guozhe001.github.io/tags/solidity/"},{"name":"项目评估","slug":"项目评估","permalink":"https://guozhe001.github.io/tags/%E9%A1%B9%E7%9B%AE%E8%AF%84%E4%BC%B0/"}]},{"title":"CERTIK针对SOLO.TOP的审计报告学习","slug":"blockchain/ethereum/audit/CERTIK针对SOLO.TOP的审计报告学习","date":"2024-11-22T06:32:06.492Z","updated":"2024-11-22T06:32:06.492Z","comments":true,"path":"2024/11/22/blockchain/ethereum/audit/CERTIK针对SOLO.TOP的审计报告学习/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/audit/CERTIK%E9%92%88%E5%AF%B9SOLO.TOP%E7%9A%84%E5%AE%A1%E8%AE%A1%E6%8A%A5%E5%91%8A%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"学习结论 审计报告内容比较简单，审计发现的代码问题因给的代码较少难以做进一步的判断 从审计报告中看项目的代码是比较健康的，审计发现的问题也都做了修复 代码未开源无法判定其他风险 基本信息 SOLO.TOP Audit Report 审计结果 共发现12个问题，其中2个是Minor级别，其余的都是information级别。 审计种类 Gas优化 数学计算 逻辑问题 流程控制 代码样式 魔法数字 编译错误","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"合约审计","slug":"区块链/ethereum/合约审计","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/%E5%90%88%E7%BA%A6%E5%AE%A1%E8%AE%A1/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"solidity","slug":"solidity","permalink":"https://guozhe001.github.io/tags/solidity/"},{"name":"智能合约","slug":"智能合约","permalink":"https://guozhe001.github.io/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"},{"name":"审计报告","slug":"审计报告","permalink":"https://guozhe001.github.io/tags/%E5%AE%A1%E8%AE%A1%E6%8A%A5%E5%91%8A/"}]},{"title":"CoinWind审计报告学习","slug":"blockchain/ethereum/audit/CoinWind审计报告学习","date":"2024-11-22T06:32:06.492Z","updated":"2024-11-22T06:32:06.492Z","comments":true,"path":"2024/11/22/blockchain/ethereum/audit/CoinWind审计报告学习/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/audit/CoinWind%E5%AE%A1%E8%AE%A1%E6%8A%A5%E5%91%8A%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"学习结论 审计报告不严谨，如“成都链安”的审计报告存在拼写错误（错误见中文版“审计类型及结果”），“灵踪安全”的审计报告是一个模板但是未替换模板的内容（错误见中文版&quot;引用文档&quot;）。 代码未开源，无法从官网、审计报告以及搜索引擎获得项目的源码，审计报告中只存在部分代码片段。（个人使用此网站进行审批时调用的合约也无法完全反编译） 成都链安的审计结论说的很中立：“项目中管理权限 owner 和 governance 对整 个项目有较高的控制权，建议做好权限管控。” 报告中显示有个只允许owner调用的提现的方法，因为代码不全无法根据上下文判断这个是不是后门。如下图 因为代码未开源且owner和管理员有较高的权限，注意风险 基本信息 官网：https://coinwind.pro/ 审计平台：灵踪安全、成都链安 成都链安 审计报告：英文、中文 审计报告中列出了一些审计的代码片段，最终结果为pass “owner 和 governance ”权限较高 灵踪安全 审计报告：英文、中文 审计报告中提到的问题没有对应的代码片段，读了之后并没有办法理解是什么问题 从灵踪安全的角度来说发现了5个问题并且项目方已经解决","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"合约审计","slug":"区块链/ethereum/合约审计","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/%E5%90%88%E7%BA%A6%E5%AE%A1%E8%AE%A1/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"solidity","slug":"solidity","permalink":"https://guozhe001.github.io/tags/solidity/"},{"name":"智能合约","slug":"智能合约","permalink":"https://guozhe001.github.io/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"},{"name":"审计报告","slug":"审计报告","permalink":"https://guozhe001.github.io/tags/%E5%AE%A1%E8%AE%A1%E6%8A%A5%E5%91%8A/"}]},{"title":"certik针对pancakeswap的审计报告学习","slug":"blockchain/ethereum/audit/certik针对pancakeswap的审计报告学习","date":"2024-11-22T06:32:06.492Z","updated":"2024-11-22T06:32:06.492Z","comments":true,"path":"2024/11/22/blockchain/ethereum/audit/certik针对pancakeswap的审计报告学习/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/audit/certik%E9%92%88%E5%AF%B9pancakeswap%E7%9A%84%E5%AE%A1%E8%AE%A1%E6%8A%A5%E5%91%8A%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"审计报告总结 共发现9个问题，其中5个是information级别，其他更严重级别的问题pancakeswap团队已经修复或者跟certik沟通表示没有影响 通过审计报告看项目还是很健康的。 审计项目地址 https://www.certik.org/projects/pancakeswap 审计发现的问题 暂时忽略代码格式之类的问题，主要列出中级以上的问题。 SBR-01: Incorrect Delegation Flow 问题比较简单直接看修复提交的代码：在burn时需要把此账户的授权的地址修改为0地址，其实就是把授权移除；这个问题应该是个手误。 commit SCF-01 addressList Inaccuracy Description: The first linked if block pushes a new address to the addressList array in the case the userInfo mapping lookup yields 0 on the amount member. This case is possible even after the user has already been added to the array, either by invoking emergencyWithdraw or withdrawing the full amount held by the user. Recommendation: We advise that the push mechanism is revised to ensure that the user does not already exist in the array. Alleviation: The PancakeSwap team altered the condition for pushing new items to the addressList array, however duplicates can still exist. After conversing with the team, we were informed that the array is not utilized on-chain and is meant to aid off-chain processes in an airdrop mechanism which will eliminate duplicate addresses. As such, this issue can be safely ignored. We would like to note that this is not an optimal mechanism to conduct this, as it would be better to instead rely on emitted events and blockchain analysis rather than contract storage 修复后的代码如下： certik提出的问题意思是，在存款时通过用户的amount是否为0判断地址是否存在addressList中不严谨，因为可能之前存过一次然后全部提现了，这样就会导致amount为0并且在addressList中存在。 pancakeswap团队通过遍历addressList来判断地址是否存在于addressList中。 commit 个人理解 通过遍历addressList的方式来查找某个地址是否在这个列表中不太可取，因为这增加了gas费。 如果别人想要攻击一直存入很小的amount来增加addressList的大小会导致存款的方法的gas费特别高。 SCF-03 Incorrect Reset Mechanism Description: The emergencyWithdraw function is meant to “reset” a user’s state and withdraw his deposited tokens. In this case, the rewardPending variable of the user struct is not zeroed out. Recommendation: As the rewardPending member is cumulative, it is possible to exploit this behavior and artificially increase the pending rewards of a user. We advise that either a manual 0 assignment statement is introduced in the emergencyWithdraw function or a delete operation is conducted on the full struct located at userInfo[msg.sender]. Alleviation: The emergencyWithdraw function was properly fixed to zero out all members of the UserInfo struct 修复后代码如下 此问题是说在转账之后应该吧user结构里面的值都更新为0，团队已经做了修复。 1234567891011&#x2F;&#x2F; Withdraw without caring about rewards. EMERGENCY ONLY.function emergencyWithdraw() public &#123; UserInfo storage user &#x3D; userInfo[msg.sender]; syrup.safeTransfer(address(msg.sender), user.amount); emit EmergencyWithdraw(msg.sender, user.amount); user.amount &#x3D; 0; user.rewardDebt &#x3D; 0; user.rewardPending &#x3D; 0; &#x2F;&#x2F; 此行为修复行&#125; 个人理解 最好是先修改user结构中的值在进行转账，这样应该是最佳开发实践。","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"合约审计","slug":"区块链/ethereum/合约审计","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/%E5%90%88%E7%BA%A6%E5%AE%A1%E8%AE%A1/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"solidity","slug":"solidity","permalink":"https://guozhe001.github.io/tags/solidity/"},{"name":"智能合约","slug":"智能合约","permalink":"https://guozhe001.github.io/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"},{"name":"审计报告","slug":"审计报告","permalink":"https://guozhe001.github.io/tags/%E5%AE%A1%E8%AE%A1%E6%8A%A5%E5%91%8A/"}]},{"title":"Geth源码学习之MPT","slug":"blockchain/ethereum/source_code/Geth源码学习之MPT","date":"2024-11-22T06:32:06.492Z","updated":"2024-11-22T06:32:06.493Z","comments":true,"path":"2024/11/22/blockchain/ethereum/source_code/Geth源码学习之MPT/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/source_code/Geth%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%B9%8BMPT/","excerpt":"","text":"数据结构mpt学习/go-ethereum/trie/trie.go： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601// Copyright 2014 The go-ethereum Authors// This file is part of the go-ethereum library.//// The go-ethereum library is free software: you can redistribute it and/or modify// it under the terms of the GNU Lesser General Public License as published by// the Free Software Foundation, either version 3 of the License, or// (at your option) any later version.//// The go-ethereum library is distributed in the hope that it will be useful,// but WITHOUT ANY WARRANTY; without even the implied warranty of// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the// GNU Lesser General Public License for more details.//// You should have received a copy of the GNU Lesser General Public License// along with the go-ethereum library. If not, see &lt;http://www.gnu.org/licenses/&gt;.// Package trie implements Merkle Patricia Tries.package trieimport ( &quot;bytes&quot; &quot;errors&quot; &quot;fmt&quot; &quot;sync&quot; &quot;github.com/ethereum/go-ethereum/common&quot; &quot;github.com/ethereum/go-ethereum/crypto&quot; &quot;github.com/ethereum/go-ethereum/log&quot;)var ( // emptyRoot is the known root hash of an empty trie. emptyRoot = common.HexToHash(&quot;56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421&quot;) // emptyState is the known hash of an empty state trie entry. emptyState = crypto.Keccak256Hash(nil))// LeafCallback is a callback type invoked when a trie operation reaches a leaf// node. It&#x27;s used by state sync and commit to allow handling external references// between account and storage tries.type LeafCallback func(path []byte, leaf []byte, parent common.Hash) error// Trie is a Merkle Patricia Trie.// The zero value is an empty trie with no database.// Use New to create a trie that sits on top of a database.//// Trie is not safe for concurrent use.type Trie struct &#123; db *Database root node // Keep track of the number leafs which have been inserted since the last // hashing operation. This number will not directly map to the number of // actually unhashed nodes unhashed int&#125;// newFlag returns the cache flag value for a newly created node.func (t *Trie) newFlag() nodeFlag &#123; return nodeFlag&#123;dirty: true&#125;&#125;// New creates a trie with an existing root node from db.//// If root is the zero hash or the sha3 hash of an empty string, the// trie is initially empty and does not require a database. Otherwise,// New will panic if db is nil and returns a MissingNodeError if root does// not exist in the database. Accessing the trie loads nodes from db on demand.// 无论root是zero hash还是一个空字符串，都需要传入Database，否则会panicfunc New(root common.Hash, db *Database) (*Trie, error) &#123; if db == nil &#123; panic(&quot;trie.New called without a database&quot;) &#125; trie := &amp;Trie&#123; db: db, &#125; // 如果root不为zero hash并且也不是一个空字符串，则从数据库中获取节点数据 if root != (common.Hash&#123;&#125;) &amp;&amp; root != emptyRoot &#123; rootnode, err := trie.resolveHash(root[:], nil) if err != nil &#123; return nil, err &#125; trie.root = rootnode &#125; return trie, nil&#125;// NodeIterator returns an iterator that returns nodes of the trie. Iteration starts at// the key after the given start key.func (t *Trie) NodeIterator(start []byte) NodeIterator &#123; return newNodeIterator(t, start)&#125;// Get returns the value for key stored in the trie.// The value bytes must not be modified by the caller.func (t *Trie) Get(key []byte) []byte &#123; res, err := t.TryGet(key) if err != nil &#123; log.Error(fmt.Sprintf(&quot;Unhandled trie error: %v&quot;, err)) &#125; return res&#125;// TryGet returns the value for key stored in the trie.// The value bytes must not be modified by the caller.// If a node was not found in the database, a MissingNodeError is returned.func (t *Trie) TryGet(key []byte) ([]byte, error) &#123; value, newroot, didResolve, err := t.tryGet(t.root, keybytesToHex(key), 0) if err == nil &amp;&amp; didResolve &#123; t.root = newroot &#125; return value, err&#125;func (t *Trie) tryGet(origNode node, key []byte, pos int) (value []byte, newnode node, didResolve bool, err error) &#123; switch n := (origNode).(type) &#123; case nil: return nil, nil, false, nil case valueNode: return n, n, false, nil case *shortNode: // 如果key的长度小于n.key的长度，则说明这个key不是当前node的子节点也不是当前node本身 // 如果key的len(n.key)的前缀与n.key不一样，也说明这个key不在当前node的子节点中 if len(key)-pos &lt; len(n.Key) || !bytes.Equal(n.Key, key[pos:pos+len(n.Key)]) &#123; // key not found in trie return nil, n, false, nil &#125; // 到这里时，key的len(n.key)长度的前缀与n.key相同，说明key在node的子节点，（而不是当前节点本身） value, newnode, didResolve, err = t.tryGet(n.Val, key, pos+len(n.Key)) if err == nil &amp;&amp; didResolve &#123; n = n.copy() n.Val = newnode &#125; return value, n, didResolve, err case *fullNode: value, newnode, didResolve, err = t.tryGet(n.Children[key[pos]], key, pos+1) if err == nil &amp;&amp; didResolve &#123; n = n.copy() n.Children[key[pos]] = newnode &#125; return value, n, didResolve, err case hashNode: child, err := t.resolveHash(n, key[:pos]) if err != nil &#123; return nil, n, true, err &#125; value, newnode, _, err := t.tryGet(child, key, pos) return value, newnode, true, err default: panic(fmt.Sprintf(&quot;%T: invalid node: %v&quot;, origNode, origNode)) &#125;&#125;// TryGetNode attempts to retrieve a trie node by compact-encoded path. It is not// possible to use keybyte-encoding as the path might contain odd nibbles.func (t *Trie) TryGetNode(path []byte) ([]byte, int, error) &#123; item, newroot, resolved, err := t.tryGetNode(t.root, compactToHex(path), 0) if err != nil &#123; return nil, resolved, err &#125; if resolved &gt; 0 &#123; t.root = newroot &#125; if item == nil &#123; return nil, resolved, nil &#125; return item, resolved, err&#125;func (t *Trie) tryGetNode(origNode node, path []byte, pos int) (item []byte, newnode node, resolved int, err error) &#123; // If we reached the requested path, return the current node if pos &gt;= len(path) &#123; // Although we most probably have the original node expanded, encoding // that into consensus form can be nasty (needs to cascade down) and // time consuming. Instead, just pull the hash up from disk directly. var hash hashNode if node, ok := origNode.(hashNode); ok &#123; hash = node &#125; else &#123; hash, _ = origNode.cache() &#125; if hash == nil &#123; return nil, origNode, 0, errors.New(&quot;non-consensus node&quot;) &#125; blob, err := t.db.Node(common.BytesToHash(hash)) return blob, origNode, 1, err &#125; // Path still needs to be traversed, descend into children switch n := (origNode).(type) &#123; case nil: // Non-existent path requested, abort return nil, nil, 0, nil case valueNode: // Path prematurely ended, abort return nil, nil, 0, nil case *shortNode: if len(path)-pos &lt; len(n.Key) || !bytes.Equal(n.Key, path[pos:pos+len(n.Key)]) &#123; // Path branches off from short node return nil, n, 0, nil &#125; item, newnode, resolved, err = t.tryGetNode(n.Val, path, pos+len(n.Key)) if err == nil &amp;&amp; resolved &gt; 0 &#123; n = n.copy() n.Val = newnode &#125; return item, n, resolved, err case *fullNode: item, newnode, resolved, err = t.tryGetNode(n.Children[path[pos]], path, pos+1) if err == nil &amp;&amp; resolved &gt; 0 &#123; n = n.copy() n.Children[path[pos]] = newnode &#125; return item, n, resolved, err case hashNode: child, err := t.resolveHash(n, path[:pos]) if err != nil &#123; return nil, n, 1, err &#125; item, newnode, resolved, err := t.tryGetNode(child, path, pos) return item, newnode, resolved + 1, err default: panic(fmt.Sprintf(&quot;%T: invalid node: %v&quot;, origNode, origNode)) &#125;&#125;// Update associates key with value in the trie. Subsequent calls to// Get will return value. If value has length zero, any existing value// is deleted from the trie and calls to Get will return nil.//// The value bytes must not be modified by the caller while they are// stored in the trie.func (t *Trie) Update(key, value []byte) &#123; if err := t.TryUpdate(key, value); err != nil &#123; log.Error(fmt.Sprintf(&quot;Unhandled trie error: %v&quot;, err)) &#125;&#125;// TryUpdate associates key with value in the trie. Subsequent calls to// Get will return value. If value has length zero, any existing value// is deleted from the trie and calls to Get will return nil.//// The value bytes must not be modified by the caller while they are// stored in the trie.//// If a node was not found in the database, a MissingNodeError is returned.// 这个方法是更新t，如果value不为0则意味着插入一个新的节点或者更新原来的节点的值func (t *Trie) TryUpdate(key, value []byte) error &#123; t.unhashed++ k := keybytesToHex(key) if len(value) != 0 &#123; _, n, err := t.insert(t.root, nil, k, valueNode(value)) if err != nil &#123; return err &#125; t.root = n &#125; else &#123; _, n, err := t.delete(t.root, nil, k) if err != nil &#123; return err &#125; t.root = n &#125; return nil&#125;// insert 向节点n中插入（或更新）key等于key，value等于value的数据// 返回值bool表示是否更新// node是更新后的新的nodefunc (t *Trie) insert(n node, prefix, key []byte, value node) (bool, node, error) &#123; // 如果key的长度为0 if len(key) == 0 &#123; // 判断n是不是valueNode类型，如果是 if v, ok := n.(valueNode); ok &#123; // 返回n中的value和传入的value是否相同 return !bytes.Equal(v, value.(valueNode)), value, nil &#125; // 如果key的长度为0并且n不是valueNode类型，直接返回 return true, value, nil &#125; switch n := n.(type) &#123; case *shortNode: // 计算key和n.key的公共前缀长度 matchlen := prefixLen(key, n.Key) // If the whole key matches, keep this short node as is // and only update the value. // 如果前缀的长度等于整个key的长度，则表示这个是最终的节点了，直接插入值 if matchlen == len(n.Key) &#123; dirty, nn, err := t.insert(n.Val, append(prefix, key[:matchlen]...), key[matchlen:], value) if !dirty || err != nil &#123; return false, n, err &#125; return true, &amp;shortNode&#123;n.Key, nn, t.newFlag()&#125;, nil &#125; // Otherwise branch out at the index where they differ. // 如果key和n.key的前缀长度不等于n.key的长度，说明需要在现在的基础上扩展一个branchNode，（即fullNode） branch := &amp;fullNode&#123;flags: t.newFlag()&#125; var err error // node节点的值放在branchNode中 _, branch.Children[n.Key[matchlen]], err = t.insert(nil, append(prefix, n.Key[:matchlen+1]...), n.Key[matchlen+1:], n.Val) if err != nil &#123; return false, nil, err &#125; // 新的key和value也放在branchNode中 _, branch.Children[key[matchlen]], err = t.insert(nil, append(prefix, key[:matchlen+1]...), key[matchlen+1:], value) if err != nil &#123; return false, nil, err &#125; // Replace this shortNode with the branch if it occurs at index 0. // 如果key和n.key没有公共前缀，则使用branchNode替代当前的extensionNode（即shortNode） if matchlen == 0 &#123; return true, branch, nil &#125; // Otherwise, replace it with a short node leading up to the branch. // 其他情况则使用新的branchNode替换shortNode的value return true, &amp;shortNode&#123;key[:matchlen], branch, t.newFlag()&#125;, nil case *fullNode: // 如果是fullNode，则根据key的第一个字符获得应该插入的节点，然后插入到这个节点 dirty, nn, err := t.insert(n.Children[key[0]], append(prefix, key[0]), key[1:], value) if !dirty || err != nil &#123; return false, n, err &#125; n = n.copy() n.flags = t.newFlag() n.Children[key[0]] = nn return true, n, nil case nil: return true, &amp;shortNode&#123;key, value, t.newFlag()&#125;, nil case hashNode: // We&#x27;ve hit a part of the trie that isn&#x27;t loaded yet. Load // the node and insert into it. This leaves all child nodes on // the path to the value in the trie. rn, err := t.resolveHash(n, prefix) if err != nil &#123; return false, nil, err &#125; dirty, nn, err := t.insert(rn, prefix, key, value) if !dirty || err != nil &#123; return false, rn, err &#125; return true, nn, nil default: panic(fmt.Sprintf(&quot;%T: invalid node: %v&quot;, n, n)) &#125;&#125;// Delete removes any existing value for key from the trie.func (t *Trie) Delete(key []byte) &#123; if err := t.TryDelete(key); err != nil &#123; log.Error(fmt.Sprintf(&quot;Unhandled trie error: %v&quot;, err)) &#125;&#125;// TryDelete removes any existing value for key from the trie.// If a node was not found in the database, a MissingNodeError is returned.func (t *Trie) TryDelete(key []byte) error &#123; t.unhashed++ k := keybytesToHex(key) _, n, err := t.delete(t.root, nil, k) if err != nil &#123; return err &#125; t.root = n return nil&#125;// delete returns the new root of the trie with key deleted.// It reduces the trie to minimal form by simplifying// nodes on the way up after deleting recursively.// 返回值bool代表是否删除// 返回值node代表删除后的nodefunc (t *Trie) delete(n node, prefix, key []byte) (bool, node, error) &#123; switch n := n.(type) &#123; case *shortNode: matchlen := prefixLen(key, n.Key) // 如果key和n.key的公共前缀长度小于n.key的长度，说明key这个节点不再当前的n节点，因此直接返回不删除 if matchlen &lt; len(n.Key) &#123; return false, n, nil // don&#x27;t replace n on mismatch &#125; // 如果key和n.key的公共前缀长度等于key的长度，说明当前的n就是需要删除的目标，直接删除 if matchlen == len(key) &#123; return true, nil, nil // remove n entirely for whole matches &#125; // The key is longer than n.Key. Remove the remaining suffix // from the subtrie. Child can never be nil here since the // subtrie must contain at least two other values with keys // longer than n.Key. // 到这里说明如果的长度大于n.key的长度，如果key存在与当前节点下那么当前节点的value肯定是一个branchNode，如果是一个branchNode则里面的值肯定不止一个，不然没有必要是branchNode。 dirty, child, err := t.delete(n.Val, append(prefix, key[:len(n.Key)]...), key[len(n.Key):]) if !dirty || err != nil &#123; return false, n, err &#125; switch child := child.(type) &#123; case *shortNode: // Deleting from the subtrie reduced it to another // short node. Merge the nodes to avoid creating a // shortNode&#123;..., shortNode&#123;...&#125;&#125;. Use concat (which // always creates a new slice) instead of append to // avoid modifying n.Key since it might be shared with // other nodes. // 如果删除之后的返回child是shortNode类型，说明原来的branchNode一共有两个值，删除之后现在只剩下一个值，就不需要再有child了，直接把当前的节点的值改为child的值 return true, &amp;shortNode&#123;concat(n.Key, child.Key...), child.Val, t.newFlag()&#125;, nil default: return true, &amp;shortNode&#123;n.Key, child, t.newFlag()&#125;, nil &#125; case *fullNode: dirty, nn, err := t.delete(n.Children[key[0]], append(prefix, key[0]), key[1:]) if !dirty || err != nil &#123; return false, n, err &#125; n = n.copy() n.flags = t.newFlag() n.Children[key[0]] = nn // Check how many non-nil entries are left after deleting and // reduce the full node to a short node if only one entry is // left. Since n must&#x27;ve contained at least two children // before deletion (otherwise it would not be a full node) n // can never be reduced to nil. // 检查删除后的branchNode有多少个非nil的为止，如果只有一个则把它缩短为shortNode。 // 在删除元素之前，节点n肯定至少包含两个子节点，因为如果不包含两个子节点他就不是一个fullNode，因此n不会减少为nil // When the loop is done, pos contains the index of the single // value that is left in n or -2 if n contains at least two // values. pos := -1 // 遍历n的所有子节点 for i, cld := range &amp;n.Children &#123; // 如果子节点不为nil if cld != nil &#123; // 第一次到这里时，pos肯定等于-1，所以&quot;pos == -1&quot;是true if pos == -1 &#123; pos = i &#125; else &#123; // 有第二个子节点不为nil，并且pos已经不是-1时才会进入到这里，因此说明删除后的n还有至少两个子节点不为nil pos = -2 break &#125; &#125; &#125; // 如果pos&gt;=0说明删除后的n只剩下一个子节点有值 if pos &gt;= 0 &#123; // pos != 16说明删除后的branchNode的最后一个child为nil if pos != 16 &#123; // If the remaining entry is a short node, it replaces // n and its key gets the missing nibble tacked to the // front. This avoids creating an invalid // shortNode&#123;..., shortNode&#123;...&#125;&#125;. Since the entry // might not be loaded yet, resolve it just for this // check. cnode, err := t.resolve(n.Children[pos], prefix) if err != nil &#123; return false, nil, err &#125; if cnode, ok := cnode.(*shortNode); ok &#123; k := append([]byte&#123;byte(pos)&#125;, cnode.Key...) return true, &amp;shortNode&#123;k, cnode.Val, t.newFlag()&#125;, nil &#125; &#125; // Otherwise, n is replaced by a one-nibble short node // containing the child. // 到这里说明pos等于16，说明前面的16个child都是nil，把当前节点缩短为shortNode return true, &amp;shortNode&#123;[]byte&#123;byte(pos)&#125;, n.Children[pos], t.newFlag()&#125;, nil &#125; // n still contains at least two values and cannot be reduced. return true, n, nil case valueNode: return true, nil, nil case nil: return false, nil, nil case hashNode: // We&#x27;ve hit a part of the trie that isn&#x27;t loaded yet. Load // the node and delete from it. This leaves all child nodes on // the path to the value in the trie. rn, err := t.resolveHash(n, prefix) if err != nil &#123; return false, nil, err &#125; dirty, nn, err := t.delete(rn, prefix, key) if !dirty || err != nil &#123; return false, rn, err &#125; return true, nn, nil default: panic(fmt.Sprintf(&quot;%T: invalid node: %v (%v)&quot;, n, n, key)) &#125;&#125;// concat 拼接func concat(s1 []byte, s2 ...byte) []byte &#123; r := make([]byte, len(s1)+len(s2)) copy(r, s1) copy(r[len(s1):], s2) return r&#125;func (t *Trie) resolve(n node, prefix []byte) (node, error) &#123; if n, ok := n.(hashNode); ok &#123; return t.resolveHash(n, prefix) &#125; return n, nil&#125;// resolveHash 根据hashNode从数据库中获取node数据，如果获取不到则返回MissingNodeError错误func (t *Trie) resolveHash(n hashNode, prefix []byte) (node, error) &#123; hash := common.BytesToHash(n) if node := t.db.node(hash); node != nil &#123; return node, nil &#125; return nil, &amp;MissingNodeError&#123;NodeHash: hash, Path: prefix&#125;&#125;// Hash returns the root hash of the trie. It does not write to the// database and can be used even if the trie doesn&#x27;t have one.// 返回trie的root的hash，这个hash不进行持久化func (t *Trie) Hash() common.Hash &#123; hash, cached, _ := t.hashRoot() t.root = cached return common.BytesToHash(hash.(hashNode))&#125;// Commit writes all nodes to the trie&#x27;s memory database, tracking the internal// and external (for account tries) references.func (t *Trie) Commit(onleaf LeafCallback) (root common.Hash, err error) &#123; if t.db == nil &#123; panic(&quot;commit called on trie with nil database&quot;) &#125; if t.root == nil &#123; return emptyRoot, nil &#125; // Derive the hash for all dirty nodes first. We hold the assumption // in the following procedure that all nodes are hashed. rootHash := t.Hash() h := newCommitter() defer returnCommitterToPool(h) // Do a quick check if we really need to commit, before we spin // up goroutines. This can happen e.g. if we load a trie for reading storage // values, but don&#x27;t write to it. if _, dirty := t.root.cache(); !dirty &#123; return rootHash, nil &#125; var wg sync.WaitGroup if onleaf != nil &#123; h.onleaf = onleaf h.leafCh = make(chan *leaf, leafChanSize) wg.Add(1) go func() &#123; defer wg.Done() h.commitLoop(t.db) &#125;() &#125; var newRoot hashNode newRoot, err = h.Commit(t.root, t.db) if onleaf != nil &#123; // The leafch is created in newCommitter if there was an onleaf callback // provided. The commitLoop only _reads_ from it, and the commit // operation was the sole writer. Therefore, it&#x27;s safe to close this // channel here. close(h.leafCh) wg.Wait() &#125; if err != nil &#123; return common.Hash&#123;&#125;, err &#125; t.root = newRoot return rootHash, nil&#125;// hashRoot calculates the root hash of the given triefunc (t *Trie) hashRoot() (node, node, error) &#123; if t.root == nil &#123; return hashNode(emptyRoot.Bytes()), nil, nil &#125; // If the number of changes is below 100, we let one thread handle it h := newHasher(t.unhashed &gt;= 100) defer returnHasherToPool(h) hashed, cached := h.hash(t.root, true) t.unhashed = 0 return hashed, cached, nil&#125;// Reset drops the referenced root node and cleans all internal state.func (t *Trie) Reset() &#123; t.root = nil t.unhashed = 0&#125;","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"source_code","slug":"区块链/ethereum/source-code","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/source-code/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"swarm","slug":"swarm","permalink":"https://guozhe001.github.io/tags/swarm/"}]},{"title":"审计智能合约需要关注哪些内容","slug":"blockchain/ethereum/audit/审计智能合约需要关注哪些内容","date":"2024-11-22T06:32:06.492Z","updated":"2024-11-22T06:32:06.492Z","comments":true,"path":"2024/11/22/blockchain/ethereum/audit/审计智能合约需要关注哪些内容/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/audit/%E5%AE%A1%E8%AE%A1%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E9%9C%80%E8%A6%81%E5%85%B3%E6%B3%A8%E5%93%AA%E4%BA%9B%E5%86%85%E5%AE%B9/","excerpt":"","text":"最近学习了CERTIK、灵踪安全、成都链安、Trail of Bits 等公司的合约审计报告；在此做一个总结，通过学习审计报告中的关注点来尽量避免在以后的合约开发过程中踩这些坑。 虽然列出的内容很多，但是背后的逻辑与思想并没有完全了解与吃透，后续还需要继续学习与消化。 合约审计的维度 合约审计主要包括下面这些大类 代码规范审计 代码漏洞审计 测试与验证审计 业务逻辑审计 合约审计的方式 形式化验证 静态分析 动态分析 典型案例测试 人工审核 代码规范审计 编译器版本安全审计 老版本的编译器可能会导致各种已知的安全问题，建议开发者在代码中指定合约代码采用最新的编译器版本，并消除编译器告警。 弃用项审计 Solidity智能合约开发语言处于快速迭代中，部分关键字已被新版本的编译器弃用，如throw、years等，为了消除其可能导致的隐患，合约开发者不应该使用当前编译器版本已弃用的关键字。 冗余代码审计 智能合约中的冗余代码会降低代码可读性，并可能需要消耗更多的gas用于合约部署，建议消除冗余代码。 SafeMath 功能审计 检查合约中是否正确使用SafeMath库内的函数进行数学运算，或者进行其他防溢出的检查。 require/assert 使用审计 Solidity使用状态恢复异常来处理错误。这种机制将会撤消对当前调用(及其所有子调用)中的状态所做的所有更改，并向调用者标记错误。函数assert和require可用于检查条件并在条件不满足时抛出异常。 assert函数只能用于测试内部错误，并检查非变量。 require函数用于确认条件有效性，例如输入变量，或合约状态变量是否满足条件，或验证外部合约调用的返回值。 gas 消耗审计 可见性规范审计 fallback 函数使用审计 代码样式 魔法数字 编译错误 代码封装 集中化 可升级性 监控 代码漏洞审计 整型溢出审计 整型溢出是很多语言都存在的安全问题，它们在智能合约中尤其危险。Solidity最多能处理256位的数字(2**256-1)，最大数字增加1会溢出得到0。同样，当数字为uint类型时，0减去1会下溢得到最大数字值。溢出情况会导致不正确的结果，特别是如果其可能的结果未被预期，可能会影响程序的可靠性和安全性。 重入攻击审计 重入漏洞是最典型的智能合约漏洞，曾导致了The DAO被攻击。该漏洞原因是Solidity中的call.value()函数在被用来发送ETH的时候会消耗它接收到的所有gas，当调用call.value()函数发送ETH的逻辑顺序存在错误时，就会存在重入攻击的风险。 伪随机数生成审计 智能合约中可能会使用到随机数，在solidity下常见的是用block区块信息作为随机因子生成，但是这样使用是不安全的，区块信息是可以被矿工控制或被攻击者在交易时获取到，这类随机数在一定程度上是可预测或可碰撞的，比较典型的例子就是fomo3d的airdrop随机数可以被碰撞。 交易顺序依赖审计 在交易打包执行过程中，面对相同难度的交易时，矿工往往会选择gas费用高的优先打包，因此用户可以指定更高的gas费用，使自己的交易优先被打包执行。 拒绝服务攻击审计 拒绝服务攻击，即Denial of Service，可以使目标无法提供正常的服务。在智能合约中也会存在此类问题，由于智能合约的不可更改性，该类攻击可能使得合约永远无法恢复正常工作状态。导致智能合约拒绝服务的原因有很多种，包括在作为交易接收方时的恶意revert、代码设计缺陷导致gas耗尽等等。 函数调用权限审计 智能合约如果存在高权限功能，如：铸币、自毁、change owner等，需要对函数调用做权限限制，避免权限泄露导致的安全问题。 call/delegatecall 安全审计 Solidity中提供了call/delegatecall函数来进行函数调用，如果使用不当，会造成call注入漏洞，例如call的参数如果可控，则可以控制本合约进行越权操作或调用其他合约的危险函数 返回值安全审计 在Solidity中存在transfer()、send()、call.value()等方法中，transfer转账失败交易会回滚，而send和call.value转账失败会return false，如果未对返回做正确判断，则可能会执行到未预期的逻辑;另外在HRC20 Token的transfer/transferFrom功能实现中，也要避免转账失败returnfalse的情况，以免造成假充值漏洞。 tx.origin 使用安全审计 在智能合约的复杂调用中，tx.origin表示交易的初始创建者地址，如果使用tx.origin进行权限判断，可能会出现错误;另外，如果合约需要判断调用方是否为合约地址时则需要使用tx.origin，不能使用extcodesize。 重放攻击审计 重放攻击是指如果两份合约使用了相同的代码实现，并且身份鉴权在传参中，当用户在向一份合 约中执行一笔交易，交易信息可以被复制并且向另一份合约重放执行该笔交易。 变量覆盖审计 智能合约中存在着复杂的变量类型，例如结构体、动态数组等，如果使用不当，对其赋值后，可能导致覆盖已有状态变量的值，造成合约执行逻辑异常。 其他的攻击与安全检查的点 下面这些审计的点后续再做持续的学习与解释补充 重排攻击 注入攻击 条件竞争攻击 时间戳依赖攻击 冗余的回调函数 函数状态变量的显式可见性 逻辑缺陷 未声明的存储指针 算术精度误差 假充值漏洞 变量覆盖 设计缺陷 潜在后门 代币发行 代理升级 委托调用插槽共享 用户资金安全 迁移管理 测试和验证 自动化测试与验证工具： Slither Echidna 测试和验证关注点 代码自动化测试覆盖率 代码测试用例通过率 业务逻辑审计 根据白皮书和被审计公司的业务逻辑进行的审计，包括： 业务逻辑审计 业务实现审计","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"合约审计","slug":"区块链/ethereum/合约审计","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/%E5%90%88%E7%BA%A6%E5%AE%A1%E8%AE%A1/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"solidity","slug":"solidity","permalink":"https://guozhe001.github.io/tags/solidity/"},{"name":"智能合约","slug":"智能合约","permalink":"https://guozhe001.github.io/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"},{"name":"审计报告","slug":"审计报告","permalink":"https://guozhe001.github.io/tags/%E5%AE%A1%E8%AE%A1%E6%8A%A5%E5%91%8A/"}]},{"title":"如何在ubantu上启动go-ethereum客户端","slug":"blockchain/ethereum/how_to/ubantu系统安装go-ethereum客户端","date":"2024-11-22T06:32:06.492Z","updated":"2024-11-22T06:32:06.492Z","comments":true,"path":"2024/11/22/blockchain/ethereum/how_to/ubantu系统安装go-ethereum客户端/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/how_to/ubantu%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85go-ethereum%E5%AE%A2%E6%88%B7%E7%AB%AF/","excerpt":"","text":"环境准备 安装git:sudo apt install git 安装go:sudo apt install golang-go go-ethereum（Geth）客户端下载和编译 clone源码： 1https://gitee.com/guozhe001/go-ethereum.git 从源码构建geth 需要科学上网 12cd go-ethereummake geth 编译结果如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530env GO111MODULE=on go run build/ci.go install ./cmd/geth&gt;&gt;&gt; /usr/lib/go-1.13/bin/go build -ldflags -X main.gitCommit=54c0d573d75ab9baa239db3f071d6cb4d1ec6aad -X main.gitDate=20210325 -trimpath -v -o /home/guozhe/code/go-ethereum/build/bin/geth ./cmd/gethgo: downloading github.com/holiman/uint256 v1.1.1go: downloading github.com/peterh/liner v1.1.1-0.20190123174540-a2c9a5303de7go: downloading golang.org/x/sys v0.0.0-20210124154548-22da62e12c0cgo: downloading github.com/edsrzf/mmap-go v1.0.0go: downloading github.com/prometheus/tsdb v0.7.1go: downloading github.com/hashicorp/golang-lru v0.5.5-0.20210104140557-80c98217689dgo: downloading github.com/golang/protobuf v1.4.3go: downloading github.com/holiman/bloomfilter/v2 v2.0.3go: downloading github.com/rs/cors v1.7.0go: downloading github.com/tyler-smith/go-bip39 v1.0.1-0.20181017060643-dbb3b84ba2efgo: extracting github.com/rs/cors v1.7.0go: downloading github.com/olekukonko/tablewriter v0.0.2-0.20190409134802-7e037d187b0cgo: extracting github.com/edsrzf/mmap-go v1.0.0go: extracting github.com/holiman/uint256 v1.1.1go: downloading github.com/karalabe/usb v0.0.0-20190919080040-51dc0efba356go: extracting github.com/golang/protobuf v1.4.3go: downloading github.com/golang/snappy v0.0.3-0.20201103224600-674baa8c7fc3go: extracting golang.org/x/sys v0.0.0-20210124154548-22da62e12c0cgo: downloading github.com/status-im/keycard-go v0.0.0-20190316090335-8537d3370df4go: extracting github.com/prometheus/tsdb v0.7.1go: downloading github.com/deckarep/golang-set v0.0.0-20180603214616-504e848d77eago: extracting github.com/peterh/liner v1.1.1-0.20190123174540-a2c9a5303de7go: downloading github.com/rjeczalik/notify v0.9.1go: extracting github.com/tyler-smith/go-bip39 v1.0.1-0.20181017060643-dbb3b84ba2efgo: downloading golang.org/x/text v0.3.3go: extracting github.com/hashicorp/golang-lru v0.5.5-0.20210104140557-80c98217689dgo: downloading github.com/naoina/go-stringutil v0.1.0go: downloading google.golang.org/protobuf v1.23.0go: extracting github.com/holiman/bloomfilter/v2 v2.0.3go: downloading github.com/dop251/goja v0.0.0-20200721192441-a695b0cdd498go: extracting github.com/olekukonko/tablewriter v0.0.2-0.20190409134802-7e037d187b0cgo: downloading github.com/syndtr/goleveldb v1.0.1-0.20210305035536-64b5b1c73954go: extracting github.com/karalabe/usb v0.0.0-20190919080040-51dc0efba356go: downloading github.com/pkg/errors v0.8.1go: extracting github.com/golang/snappy v0.0.3-0.20201103224600-674baa8c7fc3go: downloading github.com/mattn/go-isatty v0.0.5-0.20180830101745-3fb116b82035go: extracting github.com/status-im/keycard-go v0.0.0-20190316090335-8537d3370df4go: downloading github.com/shirou/gopsutil v2.20.5+incompatiblego: extracting github.com/deckarep/golang-set v0.0.0-20180603214616-504e848d77eago: extracting github.com/rjeczalik/notify v0.9.1go: downloading github.com/davecgh/go-spew v1.1.1go: extracting github.com/naoina/go-stringutil v0.1.0go: downloading github.com/huin/goupnp v1.0.1-0.20210310174557-0ca763054c88go: extracting google.golang.org/protobuf v1.23.0go: downloading github.com/fatih/color v1.7.0go: extracting github.com/syndtr/goleveldb v1.0.1-0.20210305035536-64b5b1c73954go: downloading github.com/graph-gophers/graphql-go v0.0.0-20201113091052-beb923fada29go: extracting github.com/dop251/goja v0.0.0-20200721192441-a695b0cdd498go: downloading github.com/jackpal/go-nat-pmp v1.0.2-0.20160603034137-1fa385a6f458go: extracting github.com/pkg/errors v0.8.1go: extracting github.com/davecgh/go-spew v1.1.1go: downloading github.com/jedisct1/go-minisign v0.0.0-20190909160543-45766022959ego: extracting github.com/mattn/go-isatty v0.0.5-0.20180830101745-3fb116b82035go: extracting github.com/huin/goupnp v1.0.1-0.20210310174557-0ca763054c88go: downloading github.com/google/uuid v1.1.5go: downloading github.com/go-sourcemap/sourcemap v2.1.2+incompatiblego: extracting github.com/shirou/gopsutil v2.20.5+incompatiblego: downloading github.com/go-stack/stack v1.8.0go: extracting github.com/fatih/color v1.7.0go: downloading golang.org/x/net v0.0.0-20200822124328-c89045814202go: extracting github.com/graph-gophers/graphql-go v0.0.0-20201113091052-beb923fada29go: extracting github.com/jackpal/go-nat-pmp v1.0.2-0.20160603034137-1fa385a6f458go: downloading gopkg.in/olebedev/go-duktape.v3 v3.0.0-20200619000410-60c24ae608a6go: extracting github.com/jedisct1/go-minisign v0.0.0-20190909160543-45766022959ego: downloading github.com/mattn/go-runewidth v0.0.4go: extracting github.com/go-sourcemap/sourcemap v2.1.2+incompatiblego: downloading github.com/opentracing/opentracing-go v1.1.0go: extracting golang.org/x/text v0.3.3go: extracting github.com/google/uuid v1.1.5go: downloading github.com/gorilla/websocket v1.4.2go: downloading github.com/VictoriaMetrics/fastcache v1.5.7go: downloading github.com/dlclark/regexp2 v1.2.0go: downloading github.com/influxdata/influxdb v1.8.3go: extracting github.com/go-stack/stack v1.8.0go: extracting golang.org/x/net v0.0.0-20200822124328-c89045814202go: downloading golang.org/x/sync v0.0.0-20200317015054-43a5402ce75ago: extracting gopkg.in/olebedev/go-duktape.v3 v3.0.0-20200619000410-60c24ae608a6go: extracting github.com/VictoriaMetrics/fastcache v1.5.7go: downloading github.com/cespare/xxhash v1.1.0go: extracting github.com/opentracing/opentracing-go v1.1.0go: extracting github.com/gorilla/websocket v1.4.2go: extracting github.com/dlclark/regexp2 v1.2.0go: extracting github.com/mattn/go-runewidth v0.0.4go: extracting golang.org/x/sync v0.0.0-20200317015054-43a5402ce75ago: extracting github.com/cespare/xxhash v1.1.0go: downloading github.com/cespare/xxhash/v2 v2.1.1go: extracting github.com/cespare/xxhash/v2 v2.1.1go: extracting github.com/influxdata/influxdb v1.8.3go: finding gopkg.in/urfave/cli.v1 v1.20.0go: finding github.com/peterh/liner v1.1.1-0.20190123174540-a2c9a5303de7go: finding github.com/dop251/goja v0.0.0-20200721192441-a695b0cdd498go: finding github.com/VictoriaMetrics/fastcache v1.5.7go: finding github.com/davecgh/go-spew v1.1.1go: finding github.com/deckarep/golang-set v0.0.0-20180603214616-504e848d77eago: finding github.com/jedisct1/go-minisign v0.0.0-20190909160543-45766022959ego: finding github.com/go-stack/stack v1.8.0go: finding github.com/edsrzf/mmap-go v1.0.0go: finding github.com/fjl/memsize v0.0.0-20190710130421-bcb5799ab5e5go: finding github.com/shirou/gopsutil v2.20.5+incompatiblego: finding github.com/naoina/toml v0.1.2-0.20170918210437-9fafd6967416go: finding github.com/mattn/go-colorable v0.1.0go: finding github.com/mattn/go-isatty v0.0.5-0.20180830101745-3fb116b82035go: finding github.com/holiman/bloomfilter/v2 v2.0.3go: finding github.com/fatih/color v1.7.0go: finding github.com/golang/protobuf v1.4.3go: finding github.com/golang/snappy v0.0.3-0.20201103224600-674baa8c7fc3go: finding github.com/cespare/xxhash/v2 v2.1.1go: finding github.com/syndtr/goleveldb v1.0.1-0.20210305035536-64b5b1c73954go: finding github.com/olekukonko/tablewriter v0.0.2-0.20190409134802-7e037d187b0cgo: finding github.com/hashicorp/golang-lru v0.5.5-0.20210104140557-80c98217689dgo: finding github.com/naoina/go-stringutil v0.1.0go: finding github.com/dlclark/regexp2 v1.2.0go: finding github.com/prometheus/tsdb v0.7.1go: finding golang.org/x/sys v0.0.0-20210124154548-22da62e12c0cgo: finding github.com/google/uuid v1.1.5go: finding github.com/karalabe/usb v0.0.0-20190919080040-51dc0efba356go: finding github.com/rjeczalik/notify v0.9.1go: finding github.com/mattn/go-runewidth v0.0.4go: finding github.com/go-sourcemap/sourcemap v2.1.2+incompatiblego: finding github.com/pkg/errors v0.8.1go: finding golang.org/x/text v0.3.3go: finding github.com/holiman/uint256 v1.1.1go: finding github.com/gballet/go-libpcsclite v0.0.0-20190607065134-2772fd86a8ffgo: finding github.com/gorilla/websocket v1.4.2go: finding github.com/status-im/keycard-go v0.0.0-20190316090335-8537d3370df4go: finding github.com/rs/cors v1.7.0go: finding github.com/tyler-smith/go-bip39 v1.0.1-0.20181017060643-dbb3b84ba2efgo: finding google.golang.org/protobuf v1.23.0go: finding github.com/huin/goupnp v1.0.1-0.20210310174557-0ca763054c88go: finding github.com/jackpal/go-nat-pmp v1.0.2-0.20160603034137-1fa385a6f458go: finding github.com/influxdata/influxdb v1.8.3go: finding github.com/graph-gophers/graphql-go v0.0.0-20201113091052-beb923fada29go: finding golang.org/x/time v0.0.0-20190308202827-9d24e82272b4go: finding gopkg.in/olebedev/go-duktape.v3 v3.0.0-20200619000410-60c24ae608a6go: finding golang.org/x/net v0.0.0-20200822124328-c89045814202go: finding golang.org/x/sync v0.0.0-20200317015054-43a5402ce75ago: finding github.com/opentracing/opentracing-go v1.1.0unicodeunicode/utf8vendor/golang.org/x/crypto/cryptobyte/asn1crypto/internal/subtlemath/bitsgolang.org/x/sys/internal/unsafeheadercontainer/listinternal/nettracevendor/golang.org/x/crypto/internal/subtleencodinggolang.org/x/net/html/atomcrypto/subtleruntime/internal/sysgolang.org/x/text/encoding/internal/identifiergolang.org/x/text/internal/utf8internalruntime/cgogoogle.golang.org/protobuf/internal/flagsunicode/utf16runtime/internal/atomiccontainer/ringvendor/golang.org/x/crypto/curve25519internal/raceinternal/cpugoogle.golang.org/protobuf/internal/fieldnumsync/atomicgoogle.golang.org/protobuf/internal/gennamegithub.com/ethereum/go-ethereum/internal/web3extruntime/internal/mathinternal/testloggoogle.golang.org/protobuf/internal/setinternal/bytealgmathruntimeinternal/reflectlitesyncgoogle.golang.org/protobuf/internal/pragmainternal/singleflightmath/randerrorssortinternal/oserroriogithub.com/ethereum/go-ethereum/common/bitutilgithub.com/hashicorp/golang-lru/simplelruvendor/golang.org/x/net/dns/dnsmessagestrconvsyscallcontainer/heapgolang.org/x/text/internal/tagbyteshashgithub.com/ethereum/go-ethereum/ethdbcrypto/internal/randutilstringstext/tabwritergithub.com/go-sourcemap/sourcemap/internal/base64vlqcrypto/hmachash/fnvhash/crc32golang.org/x/crypto/pbkdf2vendor/golang.org/x/crypto/hkdfgolang.org/x/crypto/hkdfcrypto/rc4github.com/dop251/goja/tokencryptoreflectgolang.org/x/crypto/ripemd160github.com/syndtr/goleveldb/leveldb/comparergolang.org/x/text/transformvendor/golang.org/x/text/transformbufiopathgithub.com/influxdata/influxdb/pkg/escapeencoding/base32htmlregexp/syntaxgolang.org/x/text/runesgolang.org/x/text/encodinggolang.org/x/text/encoding/internalgolang.org/x/text/encoding/unicodegolang.org/x/text/encoding/charmapgolang.org/x/text/encoding/japanesegolang.org/x/text/encoding/traditionalchinesegolang.org/x/text/encoding/koreangolang.org/x/text/encoding/simplifiedchinesegithub.com/ethereum/go-ethereum/common/fdlimitinternal/syscall/unixgithub.com/mattn/go-isattytimeregexpcontextgithub.com/naoina/toml/astgithub.com/ethereum/go-ethereum/common/mclockinternal/pollgithub.com/ethereum/go-ethereum/common/prquegolang.org/x/sync/errgrouposinternal/fmtsortencoding/binarycrypto/md5github.com/cespare/xxhash/v2encoding/base64crypto/sha1crypto/sha256golang.org/x/crypto/sha3crypto/ciphervendor/golang.org/x/crypto/poly1305crypto/sha512crypto/ed25519/internal/edwards25519github.com/golang/snappyvendor/golang.org/x/sys/cpugolang.org/x/sys/unixfmtruntime/debugpath/filepathgithub.com/mattn/go-runewidthos/signalgoogle.golang.org/protobuf/internal/detrandgithub.com/mattn/go-colorablenetencoding/pemcrypto/aescrypto/desvendor/golang.org/x/crypto/internal/chacha20golang.org/x/crypto/scryptio/ioutilos/execvendor/golang.org/x/crypto/chacha20poly1305golang.org/x/sys/cpudatabase/sql/driverencoding/jsonencoding/hexgithub.com/ethereum/go-ethereum/eventgithub.com/go-stack/stacklognet/urlgithub.com/VictoriaMetrics/fastcachegithub.com/syndtr/goleveldb/leveldb/utilmath/biggithub.com/syndtr/goleveldb/leveldb/storageencoding/csvgithub.com/pkg/errorscompress/flategithub.com/hashicorp/golang-lruvendor/golang.org/x/net/http2/hpackencoding/gobmimemime/quotedprintableflagvendor/golang.org/x/text/unicode/normnet/http/internalgithub.com/peterh/linervendor/golang.org/x/text/unicode/bidigithub.com/olekukonko/tablewritergithub.com/ethereum/go-ethereum/crypto/blake2bencoding/xmlgolang.org/x/net/htmlgolang.org/x/text/internal/languagegithub.com/syndtr/goleveldb/leveldb/cachegithub.com/syndtr/goleveldb/leveldb/filtergithub.com/status-im/keycard-go/derivationpathgolang.org/x/text/unicode/normgoogle.golang.org/protobuf/internal/errorsgo/tokengoogle.golang.org/protobuf/internal/versiongithub.com/karalabe/usbgoogle.golang.org/protobuf/encoding/protowiregithub.com/davecgh/go-spew/spewgithub.com/syndtr/goleveldb/leveldb/errorsgithub.com/shirou/gopsutil/internal/commongoogle.golang.org/protobuf/reflect/protoreflectgithub.com/tyler-smith/go-bip39/wordlistsgithub.com/syndtr/goleveldb/leveldb/iteratorgithub.com/syndtr/goleveldb/leveldb/journalgithub.com/syndtr/goleveldb/leveldb/optcompress/gzipgithub.com/fjl/memsizevendor/golang.org/x/text/secure/bidiruletext/template/parseruntime/traceos/usergithub.com/ethereum/go-ethereum/console/promptgolang.org/x/time/rateruntime/pprofgithub.com/ethereum/go-ethereum/eth/tracers/internal/tracersgolang.org/x/text/internal/language/compactgo/scannergithub.com/graph-gophers/graphql-go/errorsgithub.com/syndtr/goleveldb/leveldb/memdbgithub.com/syndtr/goleveldb/leveldb/tabletestingtext/scannergithub.com/graph-gophers/graphql-go/loggithub.com/opentracing/opentracing-go/loggithub.com/rjeczalik/notifygithub.com/prometheus/tsdb/fileutilgithub.com/edsrzf/mmap-gogo/astgoogle.golang.org/protobuf/reflect/protoregistrygolang.org/x/text/languagegoogle.golang.org/protobuf/internal/strsgoogle.golang.org/protobuf/internal/mapsortgoogle.golang.org/protobuf/internal/fieldsortgithub.com/huin/goupnp/scpdvendor/golang.org/x/net/idnagoogle.golang.org/protobuf/runtime/protoifacegoogle.golang.org/protobuf/internal/descfmtgithub.com/deckarep/golang-setgithub.com/shirou/gopsutil/cpugoogle.golang.org/protobuf/internal/encoding/textgoogle.golang.org/protobuf/internal/descoptsgithub.com/graph-gophers/graphql-go/internal/commongithub.com/influxdata/influxdb/modelsgithub.com/dlclark/regexp2/syntaxgithub.com/syndtr/goleveldb/leveldbgithub.com/dop251/goja/filegithub.com/go-sourcemap/sourcemapgithub.com/fatih/colorgithub.com/ethereum/go-ethereum/internal/jsre/depsgoogle.golang.org/protobuf/internal/encoding/messagesetgithub.com/naoina/go-stringutilgithub.com/shirou/gopsutil/memtext/templategithub.com/ethereum/go-ethereum/common/hexutilcrypto/ellipticencoding/asn1crypto/randgithub.com/ethereum/go-ethereum/common/mathgithub.com/ethereum/go-ethereum/rlpcrypto/dsagithub.com/holiman/uint256google.golang.org/protobuf/protogithub.com/graph-gophers/graphql-go/internal/schemagithub.com/graph-gophers/graphql-go/internal/querygolang.org/x/text/encoding/htmlindexgithub.com/dop251/goja/astgolang.org/x/text/internalgo/parsergo/printergoogle.golang.org/protobuf/internal/encoding/defvalgolang.org/x/text/internal/colltabgithub.com/holiman/bloomfilter/v2crypto/ed25519crypto/rsagithub.com/ethereum/go-ethereum/crypto/bn256/cloudflaregithub.com/tyler-smith/go-bip39golang.org/x/net/html/charsetgithub.com/graph-gophers/graphql-go/internal/exec/packergithub.com/graph-gophers/graphql-go/introspectiongithub.com/graph-gophers/graphql-go/internal/validationgithub.com/dop251/goja/parsergolang.org/x/text/casesgolang.org/x/crypto/ed25519crypto/x509/pkixgithub.com/ethereum/go-ethereum/commonvendor/golang.org/x/crypto/cryptobytegithub.com/naoina/tomlgopkg.in/urfave/cli.v1html/templatecrypto/ecdsagithub.com/ethereum/go-ethereum/crypto/secp256k1github.com/jedisct1/go-minisigngithub.com/graph-gophers/graphql-go/internal/exec/resolvablegithub.com/dlclark/regexp2golang.org/x/text/collatego/formatgithub.com/ethereum/go-ethereum/les/vfluxgoogle.golang.org/protobuf/encoding/prototextgoogle.golang.org/protobuf/internal/filedescgithub.com/graph-gophers/graphql-go/internal/exec/selectedgithub.com/ethereum/go-ethereum/ethdb/memorydbgithub.com/ethereum/go-ethereum/crypto/bls12381github.com/ethereum/go-ethereum/crypto/bn256google.golang.org/protobuf/internal/encoding/taggoogle.golang.org/protobuf/internal/impllog/syslogvendor/golang.org/x/net/http/httpproxygithub.com/ethereum/go-ethereum/p2p/enrgithub.com/jackpal/go-nat-pmpgithub.com/ethereum/go-ethereum/p2p/netutilnet/textprotogithub.com/gballet/go-libpcsclitegithub.com/google/uuidcrypto/x509gopkg.in/olebedev/go-duktape.v3github.com/ethereum/go-ethereum/logvendor/golang.org/x/net/http/httpgutsmime/multipartgithub.com/ethereum/go-ethereum/signer/storagegithub.com/ethereum/go-ethereum/les/flowcontrolgithub.com/ethereum/go-ethereum/metricscrypto/tlsgithub.com/ethereum/go-ethereum/ethdb/leveldbgoogle.golang.org/protobuf/internal/filetypegithub.com/dop251/gojagoogle.golang.org/protobuf/runtime/protoimplgithub.com/golang/protobuf/protogoogle.golang.org/protobuf/types/descriptorpbnet/http/httptracenet/httpgithub.com/golang/protobuf/protoc-gen-go/descriptorgithub.com/ethereum/go-ethereum/accounts/usbwallet/trezorgithub.com/fjl/memsize/memsizeuigithub.com/ethereum/go-ethereum/metrics/prometheusgithub.com/rs/corsexpvargithub.com/influxdata/influxdb/clientnet/http/pprofgithub.com/huin/goupnp/soapgithub.com/huin/goupnp/httpugithub.com/opentracing/opentracing-gogithub.com/gorilla/websocketgithub.com/opentracing/opentracing-go/extgithub.com/ethereum/go-ethereum/metrics/expgithub.com/graph-gophers/graphql-go/tracegithub.com/huin/goupnp/ssdpgithub.com/ethereum/go-ethereum/metrics/influxdbgithub.com/graph-gophers/graphql-go/internal/execgithub.com/ethereum/go-ethereum/internal/debuggithub.com/huin/goupnpgithub.com/graph-gophers/graphql-gogithub.com/ethereum/go-ethereum/rpcgithub.com/huin/goupnp/dcps/internetgateway1github.com/huin/goupnp/dcps/internetgateway2github.com/ethereum/go-ethereum/internal/jsregithub.com/ethereum/go-ethereum/p2p/natgithub.com/ethereum/go-ethereum/cryptogithub.com/ethereum/go-ethereum/crypto/eciesgithub.com/ethereum/go-ethereum/p2p/enodegithub.com/ethereum/go-ethereum/paramsgithub.com/ethereum/go-ethereum/accounts/abigithub.com/ethereum/go-ethereum/p2p/rlpxgithub.com/ethereum/go-ethereum/internal/flagsgithub.com/ethereum/go-ethereum/core/typesgithub.com/ethereum/go-ethereum/p2p/discover/v4wiregithub.com/ethereum/go-ethereum/les/utilsgithub.com/ethereum/go-ethereum/p2p/dnsdiscgithub.com/ethereum/go-ethereum/p2p/nodestategithub.com/ethereum/go-ethereum/p2p/discover/v5wiregithub.com/ethereum/go-ethereum/les/vflux/clientgithub.com/ethereum/go-ethereum/les/vflux/servergithub.com/ethereum/go-ethereumgithub.com/ethereum/go-ethereum/eth/gaspricegithub.com/ethereum/go-ethereum/core/forkidgithub.com/ethereum/go-ethereum/core/bloombitsgithub.com/ethereum/go-ethereum/core/rawdbgithub.com/ethereum/go-ethereum/core/vmgithub.com/ethereum/go-ethereum/p2p/discovergithub.com/ethereum/go-ethereum/accountsgithub.com/ethereum/go-ethereum/ethclientgithub.com/ethereum/go-ethereum/accounts/scwalletgithub.com/ethereum/go-ethereum/accounts/keystoregithub.com/ethereum/go-ethereum/accounts/usbwalletgithub.com/ethereum/go-ethereum/p2pgithub.com/ethereum/go-ethereum/consolegithub.com/ethereum/go-ethereum/triegithub.com/ethereum/go-ethereum/core/state/snapshotgithub.com/ethereum/go-ethereum/core/stategithub.com/ethereum/go-ethereum/consensusgithub.com/ethereum/go-ethereum/consensus/miscgithub.com/ethereum/go-ethereum/core/state/prunergithub.com/ethereum/go-ethereum/consensus/cliquegithub.com/ethereum/go-ethereum/consensus/ethashgithub.com/ethereum/go-ethereum/coregithub.com/ethereum/go-ethereum/eth/filtersgithub.com/ethereum/go-ethereum/eth/protocols/ethgithub.com/ethereum/go-ethereum/eth/fetchergithub.com/ethereum/go-ethereum/lightgithub.com/ethereum/go-ethereum/eth/protocols/snapgithub.com/ethereum/go-ethereum/eth/downloadergithub.com/ethereum/go-ethereum/minergithub.com/ethereum/go-ethereum/internal/ethapigithub.com/ethereum/go-ethereum/signer/coregithub.com/ethereum/go-ethereum/accounts/externalgithub.com/ethereum/go-ethereum/nodegithub.com/ethereum/go-ethereum/accounts/abi/bindgithub.com/ethereum/go-ethereum/contracts/checkpointoracle/contractgithub.com/ethereum/go-ethereum/accounts/abi/bind/backendsgithub.com/ethereum/go-ethereum/contracts/checkpointoraclegithub.com/ethereum/go-ethereum/eth/ethconfiggithub.com/ethereum/go-ethereum/graphqlgithub.com/ethereum/go-ethereum/les/checkpointoraclegithub.com/ethereum/go-ethereum/ethgithub.com/ethereum/go-ethereum/lesgithub.com/ethereum/go-ethereum/ethstatsgithub.com/ethereum/go-ethereum/eth/tracersgithub.com/ethereum/go-ethereum/cmd/utilsgithub.com/ethereum/go-ethereum/cmd/gethDone building.Run &quot;./build/bin/geth&quot; to launch geth. 通过查看geth版本来确认geth是否已经安装正确： 12345678910$ ./build/bin/geth versionGethVersion: 1.10.2-unstableGit Commit: 54c0d573d75ab9baa239db3f071d6cb4d1ec6aadGit Commit Date: 20210325Architecture: amd64Go Version: go1.13.8Operating System: linuxGOPATH=GOROOT=go 首次同步以太坊区块数据 查看go-ethereum的readme文档，默认是fast方式同步数据，直接运行geth console即可，因为数据比较大我单独挂载了一个磁盘，所以指定了数据存放的目录--datadir /data/ethereum/node 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354$ ./build/bin/geth console --datadir /data/ethereum/node/INFO [03-27|16:25:39.409] Starting Geth on Ethereum mainnet...INFO [03-27|16:25:39.409] Bumping default cache on mainnet provided=1024 updated=4096INFO [03-27|16:25:39.411] Maximum peer count ETH=50 LES=0 total=50INFO [03-27|16:25:39.411] Smartcard socket not found, disabling err=&quot;stat /run/pcscd/pcscd.comm: no such file or directory&quot;INFO [03-27|16:25:39.412] Set global gas cap cap=25000000INFO [03-27|16:25:39.412] Allocated trie memory caches clean=614.00MiB dirty=1024.00MiBINFO [03-27|16:25:39.412] Allocated cache and file handles database=/data/ethereum/node/geth/chaindata cache=2.00GiB handles=524288INFO [03-27|16:25:39.504] Opened ancient database database=/data/ethereum/node/geth/chaindata/ancient readonly=falseINFO [03-27|16:25:39.504] Writing default main-net genesis blockINFO [03-27|16:25:39.645] Persisted trie from memory database nodes=12356 size=1.78MiB time=48.710818ms gcnodes=0 gcsize=0.00B gctime=0s livenodes=1 livesize=0.00BINFO [03-27|16:25:39.645] Initialised chain configuration config=&quot;&#123;ChainID: 1 Homestead: 1150000 DAO: 1920000 DAOSupport: true EIP150: 2463000 EIP155: 2675000 EIP158: 2675000 Byzantium: 4370000 Constantinople: 7280000 Petersburg: 7280000 Istanbul: 9069000, Muir Glacier: 9200000, Berlin: 12244000, YOLO v3: &lt;nil&gt;, Engine: ethash&#125;&quot;INFO [03-27|16:25:39.645] Disk storage enabled for ethash caches dir=/data/ethereum/node/geth/ethash count=3INFO [03-27|16:25:39.645] Disk storage enabled for ethash DAGs dir=/home/guozhe/.ethash count=2INFO [03-27|16:25:39.646] Initialising Ethereum protocol network=1 dbversion=&lt;nil&gt;WARN [03-27|16:25:39.646] Upgrade blockchain database version from=&lt;nil&gt; to=8INFO [03-27|16:25:39.646] Loaded most recent local header number=0 hash=&quot;d4e567…cb8fa3&quot; td=17179869184 age=51y11mo3wINFO [03-27|16:25:39.646] Loaded most recent local full block number=0 hash=&quot;d4e567…cb8fa3&quot; td=17179869184 age=51y11mo3wINFO [03-27|16:25:39.646] Loaded most recent local fast block number=0 hash=&quot;d4e567…cb8fa3&quot; td=17179869184 age=51y11mo3wWARN [03-27|16:25:39.646] Failed to load snapshot, regenerating err=&quot;missing or corrupted snapshot&quot;INFO [03-27|16:25:39.646] Rebuilding state snapshotINFO [03-27|16:25:39.646] Deleted state snapshot leftovers kind=accounts wiped=0 elapsed=&quot;47.755µs&quot;INFO [03-27|16:25:39.647] Deleted state snapshot leftovers kind=storage wiped=0 elapsed=&quot;17.809µs&quot;INFO [03-27|16:25:39.647] Compacting snapshot account areaINFO [03-27|16:25:39.647] Regenerated local transaction journal transactions=0 accounts=0INFO [03-27|16:25:39.650] Wiper running, state snapshotting paused accounts=0 slots=0 storage=0.00B elapsed=&quot;361.935µs&quot;INFO [03-27|16:25:39.676] Allocated fast sync bloom size=2.00GiBWARN [03-27|16:25:39.677] Error reading unclean shutdown markers error=&quot;leveldb: not found&quot;INFO [03-27|16:25:39.677] Starting peer-to-peer node instance=Geth/v1.10.2-unstable-54c0d573-20210325/linux-amd64/go1.13.8INFO [03-27|16:25:39.741] Initialized state bloom items=12356 errorrate=0.000 elapsed=64.036msINFO [03-27|16:25:39.817] New local node record seq=1 id=0d81eb9b177ba542 ip=127.0.0.1 udp=30303 tcp=30303INFO [03-27|16:25:39.817] Started P2P networking self=enode://dbb9a7d3a1ca59a200c1fa920b2cc467c342182b0f818c491028da1c564391f2cb91f0ce88bb7826264e609aa407dd8544224c0dd3d1a3f6bc449fd063dbdde7@127.0.0.1:30303INFO [03-27|16:25:39.818] IPC endpoint opened url=/data/ethereum/node/geth.ipcWARN [03-27|16:25:39.858] Served eth_coinbase reqid=3 t=&quot;12.338µs&quot; err=&quot;etherbase must be explicitly specified&quot;Welcome to the Geth JavaScript console!instance: Geth/v1.10.2-unstable-54c0d573-20210325/linux-amd64/go1.13.8at block: 0 (Thu Jan 01 1970 08:00:00 GMT+0800 (CST)) datadir: /data/ethereum/node modules: admin:1.0 debug:1.0 eth:1.0 ethash:1.0 miner:1.0 net:1.0 personal:1.0 rpc:1.0 txpool:1.0 web3:1.0To exit, press ctrl-d&gt; INFO [03-27|16:25:39.924] Compacting snapshot storage areaINFO [03-27|16:25:39.924] Compacted snapshot area in database elapsed=277.624msINFO [03-27|16:25:39.924] Resuming state snapshot generation root=&quot;d7f897…0f0544&quot; accounts=0 slots=0 storage=0.00B elapsed=&quot;9.119µs&quot;INFO [03-27|16:25:39.996] Generated state snapshot accounts=8893 slots=0 storage=409.64KiB elapsed=71.524msINFO [03-27|16:25:46.015] New local node record seq=2 id=0d81eb9b177ba542 ip=115.171.250.78 udp=52360 tcp=30303INFO [03-27|16:25:50.847] Looking for peers peercount=0 tried=8 static=0INFO [03-27|16:25:56.124] Block synchronisation startedINFO [03-27|16:26:01.068] Looking for peers peercount=0 tried=4 static=0WARN [03-27|16:26:05.414] Dropping unsynced node during sync id=46e8efbdd811cf2e conn=dyndial addr=207.148.3.150:30303 type=Geth/v1.9.25-stable-...INFO [03-27|16:26:11.068] Looking for peers peercount=2 tried=15 static=0WARN [03-27|16:26:12.135] Dropping unsynced node during sync id=53455744030e83cc conn=dyndial addr=108.61.176.254:30303 type=Geth/v1.9.25-stable-... 查看/data/ethereum/node目录 123456$ ll总用量 1drwxrwxrwx 1 root root 472 3月 27 16:28 geth/srwxrwxrwx 1 root root 1 3月 27 16:25 geth.ipc=drwxrwxrwx 1 root root 0 3月 27 16:25 keystore/ 调用geth的json-rpc接口 1curl -X POST -H &quot;Content-Type: application/json&quot; --data &#x27;&#123;&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;method&quot;:&quot;web3_clientVersion&quot;,&quot;params&quot;:[],&quot;id&quot;:1&#125;&#x27; http://localhost:8545","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"HOW-TO","slug":"区块链/ethereum/HOW-TO","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/HOW-TO/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"}]},{"title":"以太坊使用MetaMask钱包发起交易","slug":"blockchain/ethereum/how_to/以太坊使用MetaMask钱包发起交易","date":"2024-11-22T06:32:06.492Z","updated":"2024-11-22T06:32:06.492Z","comments":true,"path":"2024/11/22/blockchain/ethereum/how_to/以太坊使用MetaMask钱包发起交易/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/how_to/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E4%BD%BF%E7%94%A8MetaMask%E9%92%B1%E5%8C%85%E5%8F%91%E8%B5%B7%E4%BA%A4%E6%98%93/","excerpt":"","text":"钱包软件 MetaMask：可以链接测试网络rinkeby，然后在ropsten，rinkeby获取相应的测试以太币。 发起交易 发起交易和普通的银行转帐一样，需要指定地址（银行账户）和转账数额；交易时会有手续费（Gas Fee），钱包会显示当前的价格，自己可以设置Gas Fee的上限。 交易的结构 可以在https://ropsten.etherscan.io/或者https://www.rinkeby.io/#explorer查看交易详情。 好玩的是，可以自己给自己转账，如下是我自己的测试账户给自己转账的交易截图。（WARN：请勿给截图中的地址转账，这是测试账号）： 需要说明的只有Nonce那一行： Nonce： 表示的是当前的账户的第一次交易，截图的1表示是第二个交易（交易序号从0开始） Position：表示当前的交易在区块中的序号。 区块中的交易列表 区块的结构","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"HOW-TO","slug":"区块链/ethereum/HOW-TO","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/HOW-TO/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"MetaMask","slug":"MetaMask","permalink":"https://guozhe001.github.io/tags/MetaMask/"}]},{"title":"以太坊合约开发最佳安全指南与反模式","slug":"blockchain/ethereum/how_to/以太坊合约开发最佳安全指南与反模式","date":"2024-11-22T06:32:06.492Z","updated":"2024-11-22T06:32:06.492Z","comments":true,"path":"2024/11/22/blockchain/ethereum/how_to/以太坊合约开发最佳安全指南与反模式/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/how_to/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E5%90%88%E7%BA%A6%E5%BC%80%E5%8F%91%E6%9C%80%E4%BD%B3%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97%E4%B8%8E%E5%8F%8D%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"安全 以太坊智能合约 —— 最佳安全开发指南： 最佳实践中所体现出的这些特性，其实是所有软件开发中都需要的；而在智能合约代码中尤其重要是因为合约一旦部署无法再做任何更改。 最小化/简单化 代码重用 代码质量 可读性和可审计性 测试覆盖率 安全风险和反模式 有漏洞合约的例子 重入 最有名的例子就是The DAO，code： 12345678910111213function getBalance(address user) constant returns(uint) &#123; return userBalances[user];&#125;function addToBalance() &#123; userBalances[msg.sender] +&#x3D; msg.amount;&#125;function withdrawBalance() &#123; amountToWithdraw &#x3D; userBalances[msg.sender]; if (!(msg.sender.call.value(amountToWithdraw)())) &#123; throw; &#125; userBalances[msg.sender] &#x3D; 0;&#125; 防范技术 使用transfer方法转账，因为transfer方法转账时只会带2300gas，这些gas不足以让其他合约再做其他的操作 在转账之前先修改状态（检查-修改-交互） 算数溢出 1234567891011121314151617181920212223242526&#x2F;&#x2F; SPDX-License-Identifier: GPL-3.0pragma solidity&#x3D;0.8.0;contract TimeLock &#123; mapping(address &#x3D;&gt; uint) public balances; mapping(address &#x3D;&gt; uint) public lockTime; function deposit() public payable &#123; balances[msg.sender] +&#x3D; msg.value; lockTime[msg.sender] &#x3D; block.timestamp + 1 weeks; &#125; function increaseLockTime(uint _secondsToIncrease) public &#123; lockTime[msg.sender] +&#x3D; _secondsToIncrease; &#125; function withdraw() public &#123; require(lockTime[msg.sender] &lt; block.timestamp); require(balances[msg.sender] &gt; 0); balances[msg.sender] &#x3D; 0; payable(msg.sender).transfer(balances[msg.sender]); &#125;&#125; 防范技术 使用SafeMath库 意外的以太币 有两种方式在合约没有payable方法时也能够强制给合约转入以太币： self-destruct：在一个合约使用selfdestruct函数将代码清除时，可以把需要自毁的合约中的以太币转入到指定的地址 预先发送的以太币：合约的地址是根据创建这个合约的账户地址和交易nonce通过Keccak256计算出来的，所以其实是可以预先给一个合约发送以太币的 这会导致什么问题呢？ 好像有人给我的合约发送以太币并不是什么坏事，不是吗？ 1234567891011121314151617181920212223242526272829303132&#x2F;&#x2F; SPDX-License-Identifier: GPL-3.0pragma solidity&#x3D;0.8.0;contract EtherGame &#123; uint public constant three &#x3D; 3; uint public constant six &#x3D; 6; uint public constant nine &#x3D; 9; uint public constant finalAmount &#x3D; 10; mapping(address &#x3D;&gt; uint) public redeemableEther; function play() public payable &#123; require(msg.value &#x3D;&#x3D; 0.5 ether); uint currentBalance &#x3D; address(this).balance + msg.value; require(currentBalance &lt;&#x3D; finalAmount); if (currentBalance &#x3D;&#x3D; three || currentBalance &#x3D;&#x3D; six || currentBalance &#x3D;&#x3D; nine) &#123; redeemableEther[msg.sender] +&#x3D; currentBalance; &#125; &#125; function getRedeem() public &#123; require(address(this).balance &#x3D;&#x3D; finalAmount); uint transferValue &#x3D; redeemableEther[msg.sender]; require(transferValue &gt; 0); redeemableEther[msg.sender] &#x3D; 0; payable(msg.sender).transfer(transferValue); &#125;&#125; 防范技术 慎用this.balance;如上面的合约可以改为： 1234567891011121314151617181920212223242526272829303132333435&#x2F;&#x2F; SPDX-License-Identifier: GPL-3.0pragma solidity&#x3D;0.8.0;contract EtherGame &#123; uint public constant three &#x3D; 3; uint public constant six &#x3D; 6; uint public constant nine &#x3D; 9; uint public constant finalAmount &#x3D; 10; uint public depositedWei; mapping(address &#x3D;&gt; uint) public redeemableEther; function play() public payable &#123; require(msg.value &#x3D;&#x3D; 0.5 ether); uint currentBalance &#x3D; depositedWei + msg.value; require(currentBalance &lt;&#x3D; finalAmount); if (currentBalance &#x3D;&#x3D; three || currentBalance &#x3D;&#x3D; six || currentBalance &#x3D;&#x3D; nine) &#123; redeemableEther[msg.sender] +&#x3D; currentBalance; &#125; depositedWei +&#x3D; msg.value; &#125; function getRedeem() public &#123; require(depositedWei &#x3D;&#x3D; finalAmount); uint transferValue &#x3D; redeemableEther[msg.sender]; require(transferValue &gt; 0); redeemableEther[msg.sender] &#x3D; 0; payable(msg.sender).transfer(transferValue); &#125;&#125; DELEGATECALL DELEGATECALL调用是使用当前的上下文调用目标合约，并且会以主调用合约的状态来运行。也就是目标合约的状态存储槽的数据会变成主调用合约的状态存储槽的数据。 防范技术 DELEGATECALL调用时要非常仔细的注意调用的上下文，并且尽可能的构建无状态的库合约 默认的可见性 函数的默认可见性是public 状态变量默认可见性是internal 所以如果一个函数忘记了写可见性关键字，则所有人（包括外部账户和合约账户）都可以调用这个函数。 防范技术 为合约中的所有函数都明确指定可见性是最佳实践。 无序错觉 以太坊内部几乎没有随机性，如果合约通过判断未来的区块大小、hash、gas上限、时间戳等来进行状态的变更；这些变量都可能被矿工所控制。 防范技术 使用外部的oracle最为随机源来保证随机性。如RANDAO 外部合约引用 如果一个合约要引用其他的外部合约，如何引用是一个问题；如果在构造方法中通过输入地址来引用，则会有可能因为输错地址而导致引用错误。 蜜罐合约： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&#x2F;** *Submitted for verification at Etherscan.io on 2018-02-09*&#x2F;pragma solidity ^0.4.19;contract Private_Bank&#123; mapping (address &#x3D;&gt; uint) public balances; uint public MinDeposit &#x3D; 1 ether; Log TransferLog; function Private_Bank(address _log) &#123; TransferLog &#x3D; Log(_log); &#125; function Deposit() public payable &#123; if(msg.value &gt;&#x3D; MinDeposit) &#123; balances[msg.sender]+&#x3D;msg.value; TransferLog.AddMessage(msg.sender,msg.value,&quot;Deposit&quot;); &#125; &#125; function CashOut(uint _am) &#123; if(_am&lt;&#x3D;balances[msg.sender]) &#123; if(msg.sender.call.value(_am)()) &#123; balances[msg.sender]-&#x3D;_am; TransferLog.AddMessage(msg.sender,_am,&quot;CashOut&quot;); &#125; &#125; &#125; function() public payable&#123;&#125;&#125;contract Log&#123; struct Message &#123; address Sender; string Data; uint Val; uint Time; &#125; Message[] public History; Message LastMsg; function AddMessage(address _adr,uint _val,string _data) public &#123; LastMsg.Sender &#x3D; _adr; LastMsg.Time &#x3D; now; LastMsg.Val &#x3D; _val; LastMsg.Data &#x3D; _data; History.push(LastMsg); &#125;&#125; 防范技术 在构造函数中使用new的方法来引用其他合约 在引用其他合约时对外部合约地址进行硬编码（就算硬编码也不能100%完全的不输错，但是这很容易审查） 短地址/参数攻击 漏洞的细节 当我们向智能合约传递参数时，这些参数需要依照ABI规范进行编码。不过发送的实际数据长度小于标准的参数编码长度也是可以的。在这种情况下，EVM会在数据的末尾补0来使数据长度达到要求。 防范技术 所有的外部应用在把输入参数发送到区块链之前都应该对他们进行校验。 未检查的调用返回值 在使用call或者send进行外部调用时，这两个方法会返回一个bool类型的结果，如果不检查这个结果就继续往下进行，有可能导致call或send的调用失败，而之后的代码执行成功。（很像本应该在同一个事物中执行的两个操作，第一个操作失败了，第二个操作却成功了，最终导致有问题。） 12345678910111213141516171819202122232425262728293031&#x2F;&#x2F; SPDX-License-Identifier: GPL-3.0pragma solidity&#x3D;0.8.0;contract Lotto &#123; address public winner; bool public payedOut &#x3D; false; uint public winAmount; function play() public payable &#123; winAmount +&#x3D; msg.value; if(msg.sender &#x3D;&#x3D; address(0x2560be5793F9AA00963e163A1287807Feb897e2F)) &#123; winner &#x3D; msg.sender; &#125; &#125; function sendToWinner() public &#123; require(!payedOut); payable(winner).send(winAmount); payedOut &#x3D; true; &#125; function withdrawLeftOver() public &#123; require(payedOut); payable(msg.sender).transfer(winAmount); &#125;&#125; 防范技术 尽可能的使用transfer函数而不是send，因为transfer函数会在外部调用失败时revert。 竞争条件/预先交易 在目前Pow的共识方式下，以太坊网络上的所有的交易都是由矿工从交易池中选择部分交易打包成区块的，而矿工在打包区块的时候会优先打包gas费多的交易。因此如果一个人监听了交易池中某个合约（如猜谜语）的交易，那么他在看到别人猜中的答案时马上发布一个gas费更高的同样答案的交易就很有可能会提前被确认。 防范技术 能够发起这种攻击的人有两种： 普通用户通过提高交易费的方式进行攻击 矿工自己对交易进行攻击 第一种防范方法是设置gas费的上限，这样就能一定程度的避免用户通过提交交易费来进行提前确认。但是这种方式无法防范矿工。 第二种防范方法是（提交-揭示），即先提交一个答案的hash，然后再提交答案。 拒绝服务 基于可被外部操纵的映射或数组的循环 12345678910111213141516171819202122232425262728&#x2F;&#x2F; SPDX-License-Identifier: GPL-3.0contract DistributeTokens &#123; address public owner; address[] investors; uint[] investorTokens; function inverst() public payable &#123; investors.push(msg.sender); investorTokens.push(msg.value * 5); &#125; modifier onlyOwner() &#123; require(address(msg.sender) &#x3D;&#x3D; owner); _; &#125; function distribute() public onlyOwner &#123; for (uint i &#x3D; 0; i &lt; investors.length; i++) &#123; transferToken(investors[i], investorTokens[i]); &#125; &#125;&#125; 主人的操作 如果一个合约只能由合约的主人做一些操作才能进入下一个状态，那么如果合约的主人失去了行为能力或者丢失了私钥那么这个合约就永远无法进入下一个状态了。 12345678910111213141516171819202122232425262728293031&#x2F;&#x2F; SPDX-License-Identifier: GPL-3.0pragma solidity&#x3D;0.8.0;contract ICO &#123; bool public isFinalized &#x3D; false; address public owner; constructor () &#123; owner&#x3D; msg.sender; &#125; mapping(address &#x3D;&gt; uint) public monery; function giveMe() public payable &#123; monery[msg.sender] +&#x3D; msg.value; &#125; function finalize() public &#123; require(msg.sender &#x3D;&#x3D; owner); isFinalized &#x3D; true; &#125; function withdraw() public &#123; require(isFinalized); payable(msg.sender).transfer(monery[msg.sender]); &#125;&#125; 基于外部调用来修改状态 如果一个合约只有把余额转移到外部的某个账户时才能够更改状态，那么外部的那个账户如果没有fallback之类的用于接收以太币的函数的话，当前的函数永远都无法进入下一个状态。 防范技术 第一个例子，合约不应该基于一个可以被外部用户人为操纵的数据结构来执行循环。推荐使用取回模式，让每个取款人单独的调用withdraw函数来取回他们各自的代币。 第二个例子，将主人设定为多重签名合约；或者是使用时间锁（require(msg.sender ==owner || block.timestamp &gt; unlockTime)）。 区块时间戳操纵 下面的代码，如果时间戳是15的倍数则能取走当前合约的所有余额。但是时间戳是可以被矿工轻微的调整的。 123456789101112131415161718192021&#x2F;&#x2F; SPDX-License-Identifier: GPL-3.0pragma solidity&#x3D;0.8.0;contract Roulette &#123; uint public pastBlockTime; constructor() payable &#123; &#125; fallback() external payable &#123; require(msg.value &#x3D;&#x3D; 10 ether); require(block.timestamp !&#x3D; pastBlockTime); pastBlockTime &#x3D; block.timestamp; if (pastBlockTime % 15 &#x3D;&#x3D; 0) &#123; payable(msg.sender).transfer(address(this).balance); &#125; &#125;&#125; 防范技术 区块的时间戳不应该被用来作为无序数据或生成随机数，也就是说，他们不应该用来作为游戏的获胜条件或者用来判断一个重要的状态变动。 如果合约需要感知时间的逻辑，如解锁合约（基于时间锁），在ICO开始几周之后来结束它或者强制指定一个过期时间。有些情况推荐使用block.number和平均区块时间来估算时间条件。 小心使用构造函数 在Solidity v0.4.22之前，和合约名称相同的函数就是构造函数。如果合约修改了名称但是忘了改构造函数的名称，那么这个函数就变成了一个普通的函数。 123456789101112131415161718192021&#x2F;&#x2F; SPDX-License-Identifier: GPL-3.0pragma solidity&#x3D;0.4.1;contract OwnerWallet &#123; address public owner; function ownerWallet() &#123; owner &#x3D; msg.sender; &#125; function () public payable &#123; &#125; function withdraw() public &#123; require(msg.sender &#x3D;&#x3D; owner); msg.sender.transfer(this.balance); &#125;&#125; 防范技术 Solidity v0.4.22之后的版本的构造函数是通过constructor关键字生命，Solidity的版本变化较快，尽量选择较新的稳定版本。 未初始化的存储指针 EVM是用存储（storaege）或内存（memory）来保存数据的。函数中轭局部变量默认在存储中还是在内存中，取决于他们的类型。 // TODO 存储指针这一块还没有搞懂，后续再补充。 浮点数和精度 下面的合约buyTokens方法在支付的以太币小于1ether时，得到的token会是0；或者说会把小于1ether的部分全部舍去导致出错。 1234567891011121314151617181920212223242526&#x2F;&#x2F; SPDX-License-Identifier: GPL-3.0pragma solidity&#x3D;0.8.0;contract FunWithNumbers &#123; uint constant public tokensPerEth &#x3D; 10; uint constant public weiPerEth &#x3D; 1e18; mapping(address &#x3D;&gt; uint) public balances; function buyTokens() public payable &#123; uint tokens &#x3D; msg.value &#x2F; weiPerEth * tokensPerEth; balances[msg.sender] &#x3D; tokens; &#125; function sellTokens(uint tokens) public &#123; require(tokens &lt; balances[msg.sender]); balances[msg.sender] -&#x3D; tokens; payable(msg.sender).transfer(tokens &#x2F; tokensPerEth * weiPerEth); &#125;&#125; Tx.Origin 通过tx.origin变量来判断用户授权的合约一般是易受钓鱼攻击的，这种攻击是通过欺骗用户向有漏洞的合约发送需要授权的操作来实现的。 123456789101112131415161718192021&#x2F;&#x2F; SPDX-License-Identifier: GPL-3.0pragma solidity &#x3D; 0.8.0;contract Phishable &#123; address public owner; constructor () &#123; owner &#x3D; msg.sender; &#125; receive() external payable&#123; &#125; function withdrawAll(address _recipient) public &#123; require(tx.origin &#x3D;&#x3D; owner); payable(_recipient).transfer(address(this).balance); &#125;&#125; 攻击合约如下,如果有人通过做游戏等方式让Phishable合约的owner给AccackContract合约转一小部分以太币，那么这个owner会损失Phishable合约中的所有以太币。 123456789101112131415161718192021222324&#x2F;&#x2F; SPDX-License-Identifier: GPL-3.0pragma solidity &#x3D; 0.8.0;import &quot;Phishable.sol&quot;;contract AccackContract &#123; Phishable phishableContract; address attacker; constructor(Phishable _phishableContract, address _attackerAddress) &#123; phishableContract &#x3D; _phishableContract; attacker &#x3D; _attackerAddress; &#125; fallback() external payable &#123; phishableContract.withdrawAll(_attackerAddress); &#125;&#125; 防范技术 智能合约中不应该使用tx.origin来进行验证授权。 tx.origin的使用场景：如果某人想要拒绝外部合约调用当前合约，他们可以实现一个类似require(tx.origin == msg.sender);这样的检查；这样可以防止当前合约被其他中间合约调用，也就是仅允许外部账户调用当前合约。","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"HOW-TO","slug":"区块链/ethereum/HOW-TO","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/HOW-TO/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"solidity","slug":"solidity","permalink":"https://guozhe001.github.io/tags/solidity/"},{"name":"智能合约","slug":"智能合约","permalink":"https://guozhe001.github.io/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"}]},{"title":"使用solidity开发以太坊智能合约","slug":"blockchain/ethereum/how_to/如何开发以太坊智能合约","date":"2024-11-22T06:32:06.492Z","updated":"2024-11-22T06:32:06.492Z","comments":true,"path":"2024/11/22/blockchain/ethereum/how_to/如何开发以太坊智能合约/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/how_to/%E5%A6%82%E4%BD%95%E5%BC%80%E5%8F%91%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/","excerpt":"","text":"一些开发合约相关资料 合约开发语言：soliditylang；中文版 开发工具：remix-project 开发网络：ganache，hardhat，scaffold-eth:以太坊开发all in one solc版本列表 环境搭建（MAC） 安装solidity 1brew install solidity 安装truffle truffle是集成安装、部署、测试合约为一体的开发框架；如果没有node环境需要先安装node:brew install node 1npm install truffle -g 合约开发 初始化项目路径 1truffle init 初始化npm环境 在初始化的过程中会让你输入一些参数的值，可以一路按回车全部使用默认值即可 1npm init 安装npm依赖库 1npm install dotenv truffle-wallet-provider ethereumjs-wallet 配置网络 123456789101112131415161718192021222324module.exports = &#123; networks: &#123; localnode: &#123; network_id: &quot;*&quot;, host: &quot;localhost&quot;, port: &quot;8545&quot; &#125; &#125;, mocha: &#123; // timeout: 100000 &#125;, compilers: &#123; solc: &#123; version: &quot;0.8.0+commit.c7dfd78e&quot;, // Fetch exact version from solc-bin (default: truffle&#x27;s version) &#125; &#125;, db: &#123; enabled: false &#125;&#125;; 开发合约 按照《精通以太坊》书本的例子写了一个“水龙头”的合约，只有两个函数，一个提取以太币（withdraw），一个接收以太币（receive）。合约的代码放在项目的contracts目录下。 12345678910111213141516171819202122&#x2F;&#x2F; SPDX-License-Identifier: GPL-3.0pragma solidity &gt;&#x3D;0.7.0 &lt;0.8.0;&#x2F;&#x2F; my first contractcontract Faucet &#123; &#x2F;&#x2F; Give out ether to anyone who asks function withdraw(uint withdraw_amount) public &#123; &#x2F;&#x2F; limit withdrawal amount require(withdraw_amount &lt;&#x3D; 1 * 1000 * 1000 * 1000 * 1000); msg.sender.transfer(withdraw_amount); &#125; &#x2F;&#x2F; Accept any incoming amount 一个默认的函数 &#x2F;&#x2F; fallback () external payable &#123;&#125; &#x2F;&#x2F; 推荐使用receive()函数来接收以太币 receive() external payable&#123;&#125;&#125; 编译合约 1truffle compile 部署合约 参考migrations/1_initial_migration.js文件，新建一个``migrations/2_initial_migration.js；(*注意：2_initial_migration.js这个名字不能以0`开头，否则部署的时候会忽略。。。*)修改文件内容如下： 123456const Faucet = artifacts.require(&quot;Faucet&quot;);module.exports = function (deployer) &#123; deployer.deploy(Faucet);&#125;; 然后部署到本地的测试网络（要在本地启动truffle的ethereum测试网络）： 1truffle migrate --network localnode 执行完成之后的日志如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172(base) w:Faucet apple$ truffle migrate --network localnodeCompiling your contracts...===========================&gt; Compiling ./contracts/Faucet.sol&gt; Artifacts written to /Users/apple/code/open-source/my-projects/etherum/Faucet/build/contracts&gt; Compiled successfully using: - solc: 0.8.0+commit.c7dfd78e.Emscripten.clangStarting migrations...======================&gt; Network name: &#x27;localnode&#x27;&gt; Network id: 1337&gt; Block gas limit: 6721975 (0x6691b7)1_initial_migration.js====================== Replacing &#x27;Migrations&#x27; ---------------------- &gt; transaction hash: 0xaf813946c7470d83c7fb1e8b535efebcfdd90540c72ee9092ae9e04775bf56bc &gt; Blocks: 0 Seconds: 0 &gt; contract address: 0x4445151f84Fd5E71aB93f0d9A1AC93fd7a454c10 &gt; block number: 1 &gt; block timestamp: 1615445677 &gt; account: 0xc0F680767D4Ae17C7adaF8C6d0b4805Bc207805e &gt; balance: 99.99511424 &gt; gas used: 244288 (0x3ba40) &gt; gas price: 20 gwei &gt; value sent: 0 ETH &gt; total cost: 0.00488576 ETH &gt; Saving migration to chain. &gt; Saving artifacts ------------------------------------- &gt; Total cost: 0.00488576 ETH2_initial_migration.js====================== Replacing &#x27;Faucet&#x27; ------------------ &gt; transaction hash: 0xcb451bc9f9347fa9983e5182ccc4453f1a3c7ac74b5c7785679913a7325f7715 &gt; Blocks: 0 Seconds: 0 &gt; contract address: 0x6B7d6480BC95EF2C51d2Ae247bDd2aC3bBA5690c &gt; block number: 3 &gt; block timestamp: 1615445677 &gt; account: 0xc0F680767D4Ae17C7adaF8C6d0b4805Bc207805e &gt; balance: 99.9888339 &gt; gas used: 271504 (0x42490) &gt; gas price: 20 gwei &gt; value sent: 0 ETH &gt; total cost: 0.00543008 ETH &gt; Saving migration to chain. &gt; Saving artifacts ------------------------------------- &gt; Total cost: 0.00543008 ETHSummary=======&gt; Total deployments: 2&gt; Final cost: 0.01031584 ETH 使用truffle部署智能合约到ropsten测试网络 可以在https://infura.io/网站建立账号，可以把它看成一个geth节点，然后他提供了rpc接口。 首次执行部署，报错说HDWalletProvider没有定义 123456789101112131415161718192021$ truffle migrate --network ropstenCompiling your contracts...===========================&gt; Compiling ./contracts/GZToken.sol&gt; Compiling ./contracts/Token2.sol&gt; Compiling ./contracts/Token3.sol&gt; Artifacts written to /Users/apple/code/open-source/my-projects/etherum/Faucet/build/contracts&gt; Compiled successfully using: - solc: 0.8.0+commit.c7dfd78e.Emscripten.clangReferenceError: HDWalletProvider is not defined at Object.provider (/Users/apple/code/open-source/my-projects/etherum/Faucet/truffle-config.js:62:21) at Object.getProvider (/usr/local/lib/node_modules/truffle/build/webpack:/packages/provider/index.js:20:1) at Object.create (/usr/local/lib/node_modules/truffle/build/webpack:/packages/provider/index.js:13:1) at TruffleConfig.get [as provider] (/usr/local/lib/node_modules/truffle/build/webpack:/packages/config/dist/configDefaults.js:204:1) at Object.detect (/usr/local/lib/node_modules/truffle/build/webpack:/packages/environment/environment.js:19:1) at Object.run (/usr/local/lib/node_modules/truffle/build/webpack:/packages/core/lib/commands/migrate.js:206:1) at Command.run (/usr/local/lib/node_modules/truffle/build/webpack:/packages/core/lib/command.js:136:1)Truffle v5.2.3 (core: 5.2.3)Node v14.16.0 解决方案： 添加依赖： 12npm install truffle-hdwallet-providernpm install dotenv 在与truffle-config.js相同的目录下添加.evn文件，然后写入你的助记词，如： 1mnemonic&#x3D;topic foster find apple famous have bonus month remain middle funny smart 注意在gitignore文件中把这个文件（.evn）忽略，避免上传到github 修改truffle-config.js：在最上面添加： 12345678// 在使用infura作为rpc-api的提供方时，因为infura不管理我们的私钥所以要在本地有一个钱包用于签名var HDWalletProvider = require(&quot;truffle-hdwallet-provider&quot;);// 默认读取项目根目录下的.env文件,用process.env.调用const result = require(&#x27;dotenv&#x27;).config();if (result.error) &#123; throw result.error;&#125; 修改ropsten的配置如下： 12345678ropsten: &#123; provider: () =&gt; new HDWalletProvider(process.env.mnemonic, `https://ropsten.infura.io/v3/your-id`), network_id: 3, // Ropsten&#x27;s id gas: 5500000, // Ropsten has a lower block limit than mainnet confirmations: 2, // # of confs to wait between deployments. (default: 0) timeoutBlocks: 200, // # of blocks before a deployment times out (minimum/default: 50) skipDryRun: true // Skip dry run before migrations? (default: false for public nets ) &#125;, 重新部署： 123456789101112131415161718192021222324252627282930313233343536373839404142$truffle migrate --network ropstenCompiling your contracts...===========================&gt; Compiling ./contracts/GZToken.sol&gt; Compiling ./contracts/Token3.sol&gt; Artifacts written to /Users/apple/code/open-source/my-projects/etherum/Faucet/build/contracts&gt; Compiled successfully using: - solc: 0.8.0+commit.c7dfd78e.Emscripten.clangStarting migrations...======================&gt; Network name: &#x27;ropsten&#x27;&gt; Network id: 3&gt; Block gas limit: 8000000 (0x7a1200)1_initial_migration.js====================== Deploying &#x27;Migrations&#x27; ----------------------Error: *** Deployment Failed ***&quot;Migrations&quot; -- insufficient funds for gas * price + value. at /usr/local/lib/node_modules/truffle/build/webpack:/packages/deployer/src/deployment.js:365:1 at processTicksAndRejections (internal/process/task_queues.js:93:5) at Migration._deploy (/usr/local/lib/node_modules/truffle/build/webpack:/packages/migrate/Migration.js:74:1) at Migration._load (/usr/local/lib/node_modules/truffle/build/webpack:/packages/migrate/Migration.js:61:1) at Migration.run (/usr/local/lib/node_modules/truffle/build/webpack:/packages/migrate/Migration.js:212:1) at Object.runMigrations (/usr/local/lib/node_modules/truffle/build/webpack:/packages/migrate/index.js:150:1) at Object.runFrom (/usr/local/lib/node_modules/truffle/build/webpack:/packages/migrate/index.js:110:1) at Object.run (/usr/local/lib/node_modules/truffle/build/webpack:/packages/migrate/index.js:87:1) at runMigrations (/usr/local/lib/node_modules/truffle/build/webpack:/packages/core/lib/commands/migrate.js:263:1) at Object.run (/usr/local/lib/node_modules/truffle/build/webpack:/packages/core/lib/commands/migrate.js:228:1) at Command.run (/usr/local/lib/node_modules/truffle/build/webpack:/packages/core/lib/command.js:136:1)Truffle v5.2.3 (core: 5.2.3)Node v14.16.0 原因是没有足够的汽油费，去https://faucet.ropsten.be/获取即可。 在此重新部署： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105$ truffle migrate --network ropstenCompiling your contracts...===========================&gt; Compiling ./contracts/Token3.sol&gt; Artifacts written to /Users/apple/code/open-source/my-projects/etherum/Faucet/build/contracts&gt; Compiled successfully using: - solc: 0.8.0+commit.c7dfd78e.Emscripten.clangStarting migrations...======================&gt; Network name: &#x27;ropsten&#x27;&gt; Network id: 3&gt; Block gas limit: 8000000 (0x7a1200)1_initial_migration.js====================== Deploying &#x27;Migrations&#x27; ---------------------- &gt; transaction hash: 0x212e4eee81d5fc3024db8d6787b36a51f070f832b94961605de18675d8f597d3 &gt; Blocks: 2 Seconds: 13 &gt; contract address: 0x0d4f7ff83b66e1E3377aacE5EFA70d9E036890c2 &gt; block number: 9941219 &gt; block timestamp: 1617088554 &gt; account: 0x2560be5793F9AA00963e163A1287807Feb897e2F &gt; balance: 0.99508824 &gt; gas used: 245588 (0x3bf54) &gt; gas price: 20 gwei &gt; value sent: 0 ETH &gt; total cost: 0.00491176 ETH Pausing for 2 confirmations... ------------------------------ &gt; confirmation number: 2 (block: 9941221) &gt; Saving migration to chain. &gt; Saving artifacts ------------------------------------- &gt; Total cost: 0.00491176 ETH2_initial_migration.js====================== Deploying &#x27;Faucet&#x27; ------------------ &gt; transaction hash: 0x40ead4c9b0fa1efb90d551e43587c10457e0c99deeaf4f804222645395435090 &gt; Blocks: 2 Seconds: 21 &gt; contract address: 0xE18C40cEf01bEedA140033892b4638CFBc464BbD &gt; block number: 9941227 &gt; block timestamp: 1617088603 &gt; account: 0x2560be5793F9AA00963e163A1287807Feb897e2F &gt; balance: 0.9887139 &gt; gas used: 272804 (0x429a4) &gt; gas price: 20 gwei &gt; value sent: 0 ETH &gt; total cost: 0.00545608 ETH Pausing for 2 confirmations... ------------------------------ &gt; confirmation number: 1 (block: 9941229) &gt; confirmation number: 2 (block: 9941230) &gt; Saving migration to chain. &gt; Saving artifacts ------------------------------------- &gt; Total cost: 0.00545608 ETH3_initial_migration.js====================== Deploying &#x27;GZToken&#x27; ------------------- &gt; transaction hash: 0xf28b9b32e6cbf0b12a44249dd4c6eb914706820daafc671e43cabb4541d5396b &gt; Blocks: 2 Seconds: 25 &gt; contract address: 0xB8DfEe0D9aC703E75EE3D031148227B3BbB26524 &gt; block number: 9941234 &gt; block timestamp: 1617088662 &gt; account: 0x2560be5793F9AA00963e163A1287807Feb897e2F &gt; balance: 0.9713052 &gt; gas used: 841622 (0xcd796) &gt; gas price: 20 gwei &gt; value sent: 0 ETH &gt; total cost: 0.01683244 ETH Pausing for 2 confirmations... ------------------------------ &gt; confirmation number: 1 (block: 9941235) &gt; confirmation number: 2 (block: 9941236) &gt; Saving migration to chain. &gt; Saving artifacts ------------------------------------- &gt; Total cost: 0.01683244 ETHSummary=======&gt; Total deployments: 3&gt; Final cost: 0.02720028 ETH 调用合约的报错汇总： 12Received unexpected error: out of gas 1intrinsic gas too low: have 0, want 21420 (supplied gas 0) 上面这些全部都是因为gas费设置的太少导致的。 与合约交互 在remix中调用合约 在remix网页中部署完成合约之后，在下面可以看到withdraw函数，输入提现的金额然后点击transact按钮，就可以调起MetaMask调用智能合约。 使用truffle的命令调用合约 启动truffle的console控制台： 1truffle console --network localnode 打开之后双击两次tab键会有命令提示，我们查看一下部署的Faucet合约的地址： 12truffle(localnode)&gt; Faucet.address&#x27;0x6B7d6480BC95EF2C51d2Ae247bDd2aC3bBA5690c&#x27; 查看我们合约的账户余额： 12truffle(localnode)&gt; web3.eth.getBalance(Faucet.address)&#x27;0&#x27; truffle develop develop Open a console with a local development blockchain 123456789101112131415161718192021222324252627282930313233343536373839truffle(develop)&gt; Faucet.deployed().then(i =&gt; &#123;FaucetDeployed = i&#125;)// 发送给合约1个ethtruffle(develop)&gt; FaucetDeployed.send(web3.utils.toWei(&quot;1&quot;, &quot;ether&quot;)).then(res =&gt; &#123; console.log(res.logs[0].event, res.logs[0].args) &#125;)Deposit Result &#123; &#x27;0&#x27;: &#x27;0xAC3509D2d2746B6fEC873087AAB9394d03472131&#x27;, &#x27;1&#x27;: BN &#123; negative: 0, words: [ 56885248, 2993385, 222, &lt;1 empty item&gt; ], length: 3, red: null &#125;, __length__: 2, to: &#x27;0xAC3509D2d2746B6fEC873087AAB9394d03472131&#x27;, amount: BN &#123; negative: 0, words: [ 56885248, 2993385, 222, &lt;1 empty item&gt; ], length: 3, red: null &#125;&#125;// 从合约提取0.1ethtruffle(develop)&gt; FaucetDeployed.withdraw(web3.utils.toWei(&quot;0.1&quot;, &quot;ether&quot;)).then(res =&gt; &#123; console.log(res.logs[0].event, res.logs[0].args) &#125;)Withdrawal Result &#123; &#x27;0&#x27;: &#x27;0xAC3509D2d2746B6fEC873087AAB9394d03472131&#x27;, &#x27;1&#x27;: BN &#123; negative: 0, words: [ 25821184, 13721111, 22, &lt;1 empty item&gt; ], length: 3, red: null &#125;, __length__: 2, to: &#x27;0xAC3509D2d2746B6fEC873087AAB9394d03472131&#x27;, amount: BN &#123; negative: 0, words: [ 25821184, 13721111, 22, &lt;1 empty item&gt; ], length: 3, red: null &#125;&#125; 与Gas费相关的注意事项 如果在执行过程中gas费耗尽，会触发如下一系列事件： 抛出“out of gas”异常 状态被恢复到执行开始之前 所有在这次执行过程中的gas开销都会被作为交易费用，以太坊不会因为交易中止而退回gas或以太币。 如何把合约函数调用的gas费消耗最小化 避免动态尺寸的数组 例如对数组的每个元素进行操作，或者通过遍历的方式查找数组中的某个值。 避免调用其他合约 调用其他合约，特别是那些gas消耗未知的合约，可能会产生高昂的gas开销。 估计gas开销","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"HOW-TO","slug":"区块链/ethereum/HOW-TO","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/HOW-TO/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"solidity","slug":"solidity","permalink":"https://guozhe001.github.io/tags/solidity/"},{"name":"智能合约","slug":"智能合约","permalink":"https://guozhe001.github.io/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"}]},{"title":"调用erc20合约的转账方法","slug":"blockchain/ethereum/how_to/如何调用erc20合约的转账方法","date":"2024-11-22T06:32:06.492Z","updated":"2024-11-22T06:32:06.492Z","comments":true,"path":"2024/11/22/blockchain/ethereum/how_to/如何调用erc20合约的转账方法/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/how_to/%E5%A6%82%E4%BD%95%E8%B0%83%E7%94%A8erc20%E5%90%88%E7%BA%A6%E7%9A%84%E8%BD%AC%E8%B4%A6%E6%96%B9%E6%B3%95/","excerpt":"","text":"solidity编译器的版本选择 12345678# 选择solc的指定版本solc-select use 0.8.0# 如果没有制定版本先安装solc-select install 0.8.0# 生成制定合约的abisolc --abi GZToken.sol 使用go-ethereum的abigen工具生成go源文件 123cd /Users/apple/code/open-source/blockchain/ethereum/go-ethereum/cmd/abigen# 制定bin和abi文件生成go文件go run main.go --abi=WETH.abi --bin=WETH.bin --pkg=contract --out=WETH.go 报错记录 replacement transaction underpriced 使用相同的nonce再次发起交易时，gasPrice必须大于上次交易gasPrice10%以上。 交易一直是pending状态，无法确认 invalid sender 在调用json rpc接口时，返回以上的错误，原因是因为chainId与实际的chainId不一致。 交易发送出去但是交易状态是失败，点击详情提示：a status code indicating if the top-level call succeeded or failed 其中一个原因可能是abi错误，然后生成的methodId不正确导致，可以在应用页面调用一次这个方法，确认真实的方法和参数。 这是个坑人的问题，合约源码与真实的链上部署的不一致，如solo.top项目的bank合约，deposit提供的源码与页面调用的参数就不一致。 提供的智能合约代码如下： 从页面调用的方法如下：","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"HOW-TO","slug":"区块链/ethereum/HOW-TO","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/HOW-TO/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"solidity","slug":"solidity","permalink":"https://guozhe001.github.io/tags/solidity/"},{"name":"智能合约","slug":"智能合约","permalink":"https://guozhe001.github.io/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"}]},{"title":"如何搭建一个私有以太坊网络","slug":"blockchain/ethereum/how_to/如何搭建私有以太坊网络","date":"2024-11-22T06:32:06.492Z","updated":"2024-11-22T06:32:06.492Z","comments":true,"path":"2024/11/22/blockchain/ethereum/how_to/如何搭建私有以太坊网络/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/how_to/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89%E4%BB%A5%E5%A4%AA%E5%9D%8A%E7%BD%91%E7%BB%9C/","excerpt":"","text":"本文档是参考官方文档实践的记录，如有不当支持欢迎指正。参考文档： https://geth.ethereum.org/docs/interface/private-network 环境准备 安装geth等工具 参考文档：Install on Ubuntu via PPAs 创建工作目录 创建工作目录gethpoa，并在此目录下创建另外两个node节点目录。完成之后的目录结构如下：创建账户 12345678910111213141516$geth --datadir data account newINFO [04-07|16:48:50.857] Maximum peer count ETH=50 LES=0 total=50INFO [04-07|16:48:50.857] Smartcard socket not found, disabling err=&quot;stat /run/pcscd/pcscd.comm: no such file or directory&quot;Your new account is locked with a password. Please give a password. Do not forget this password.Password:Repeat password:Your new key was generatedPublic address of the key: 0x4852C36DeC855E487D46ddDD015A92612dE5Bf20Path of the secret key file: data/keystore/UTC--2022-04-07T08-48-58.777243596Z--4852c36dec855e487d46dddd015a92612de5bf20- You can share your public address with anyone. Others need it to interact with you.- You must NEVER share the secret key with anyone! The key controls access to your funds!- You must BACKUP your key file! Without the key, it&#x27;s impossible to access account funds!- You must REMEMBER your password! Without the password, it&#x27;s impossible to decrypt the key! 执行完以上操作之后的目录结构如下： 12345678910$ tree gethpoa/gethpoa/├── node1│ └── data│ └── keystore│ └── UTC--2022-04-07T11-43-40.475412645Z--7adc4a5a65ab33595ade0ed15903e8c406f69230└── node2 └── data └── keystore └── UTC--2022-04-07T08-50-53.751660870Z--0691e168e8cc151a76a04705290702631a86c948 使用puppeth创建创世区块的配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394$ puppeth+-----------------------------------------------------------+| Welcome to puppeth, your Ethereum private network manager || || This tool lets you create a new Ethereum network down to || the genesis block, bootnodes, miners and ethstats servers || without the hassle that it would normally entail. || || Puppeth uses SSH to dial in to remote servers, and builds || its network components out of Docker containers using the || docker-compose toolset. |+-----------------------------------------------------------+# 首先指定一个名称Please specify a network name to administer (no spaces, hyphens or capital letters please)&gt; blockpoaSweet, you can set this via --network=blockpoa next time!INFO [04-07|19:55:26.726] Administering Ethereum network name=blockpoaINFO [04-07|19:55:26.732] No remote machines to gather stats from# 然后会提示选择要做的操作，我这里选择配置一个新的创世区块What would you like to do? (default = stats) 1. Show network stats 2. Configure new genesis 3. Track new remote server 4. Deploy network components&gt; 2# 创建创世区块配置还是导入已有的创世区块配置？ What would you like to do? (default = create) 1. Create new genesis from scratch 2. Import already existing genesis&gt; 1# 选择共识引擎，这里选择CliqueWhich consensus engine to use? (default = clique) 1. Ethash - proof-of-work 2. Clique - proof-of-authority&gt; 2# 多少秒出一个区块，默认时15秒How many seconds should blocks take? (default = 15)&gt; 3# 哪些账户允许打包区块？当我选两个账户时报错：signed recently, must wait for others，因此这里只选了一个账户可以打包。Which accounts are allowed to seal? (mandatory at least one)&gt; 0x7adC4A5a65ab33595adE0ed15903e8c406f69230&gt; 0x# 哪些账户需要预先初始化一部分资金？Which accounts should be pre-funded? (advisable at least one)&gt; 0x7adC4A5a65ab33595adE0ed15903e8c406f69230&gt; 0x0691e168E8cC151a76a04705290702631A86C948&gt; 0x# 这些地址需要初始化1wei的资金吗？选择的yes，其实对这块不太了解为什么Should the precompile-addresses (0x1 .. 0xff) be pre-funded with 1 wei? (advisable yes)&gt; yes# 指定网络ID，我这里直接随机Specify your chain/network ID if you want an explicit one (default = random)&gt;INFO [04-07|19:59:20.325] Configured new genesis block# 经过以上的配置，已经配置好了，现在再次让我选择要做什么操作。我这里选择2:管理已经存在的创世区块配置What would you like to do? (default = stats) 1. Show network stats 2. Manage existing genesis 3. Track new remote server 4. Deploy network components&gt; 2# 选择管理现有的创世区块配置之后，会出现下面三个选项，分别是修改，导出和删除；我这里选择导出创世区块的配置。 1. Modify existing configurations 2. Export genesis configurations 3. Remove genesis configuration&gt; 2# 选择导出之后会询问导出到哪个文件夹，选择默认的当前文件夹； 下面有两个是报错，从字面意思理解是这两个配置不支持poa的共识协议，所以这次忽略。Which folder to save the genesis specs into? (default = current) Will create blockpoa.json, blockpoa-aleth.json, blockpoa-harmony.json, blockpoa-parity.json&gt;INFO [04-07|19:59:47.758] Saved native genesis chain spec path=blockpoa.jsonERROR[04-07|19:59:47.758] Failed to create Aleth chain spec err=&quot;unsupported consensus engine&quot;ERROR[04-07|19:59:47.758] Failed to create Parity chain spec err=&quot;unsupported consensus engine&quot;INFO [04-07|19:59:47.761] Saved genesis chain spec client=harmony path=blockpoa-harmony.jsonWhat would you like to do? (default = stats) 1. Show network stats 2. Manage existing genesis 3. Track new remote server 4. Deploy network components 配置完成之后的创世区块配置json文件如下： 12345678910111213141516171819202122232425262728293031323334353637383940&#123; &quot;config&quot;: &#123; &quot;chainId&quot;: 3030, &quot;homesteadBlock&quot;: 0, &quot;eip150Block&quot;: 0, &quot;eip150Hash&quot;: &quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;, &quot;eip155Block&quot;: 0, &quot;eip158Block&quot;: 0, &quot;byzantiumBlock&quot;: 0, &quot;constantinopleBlock&quot;: 0, &quot;petersburgBlock&quot;: 0, &quot;istanbulBlock&quot;: 0, &quot;clique&quot;: &#123; &quot;period&quot;: 3, &quot;epoch&quot;: 30000 &#125; &#125;, &quot;nonce&quot;: &quot;0x0&quot;, &quot;timestamp&quot;: &quot;0x624ed1f0&quot;, &quot;extraData&quot;: &quot;0x00000000000000000000000000000000000000000000000000000000000000007adc4a5a65ab33595ade0ed15903e8c406f692300000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000&quot;, &quot;gasLimit&quot;: &quot;0x47b760&quot;, &quot;difficulty&quot;: &quot;0x1&quot;, &quot;mixHash&quot;: &quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;, &quot;coinbase&quot;: &quot;0x0000000000000000000000000000000000000000&quot;, &quot;alloc&quot;: &#123; &quot;0000000000000000000000000000000000000000&quot;: &#123; &quot;balance&quot;: &quot;0x1&quot; &#125;, &quot;0691e168e8cc151a76a04705290702631a86c948&quot;: &#123; &quot;balance&quot;: &quot;0x200000000000000000000000000000000000000000000000000000000000000&quot; &#125;, &quot;7adc4a5a65ab33595ade0ed15903e8c406f69230&quot;: &#123; &quot;balance&quot;: &quot;0x200000000000000000000000000000000000000000000000000000000000000&quot; &#125; &#125;, &quot;number&quot;: &quot;0x0&quot;, &quot;gasUsed&quot;: &quot;0x0&quot;, &quot;parentHash&quot;: &quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;, &quot;baseFeePerGas&quot;: null&#125; 导出创世区块配置之后的目录结构如下： 123456789101112$ tree gethpoa/gethpoa/├── blockpoa-harmony.json├── blockpoa.json├── node1│ └── data│ └── keystore│ └── UTC--2022-04-07T11-43-40.475412645Z--7adc4a5a65ab33595ade0ed15903e8c406f69230└── node2 └── data └── keystore └── UTC--2022-04-07T08-50-53.751660870Z--0691e168e8cc151a76a04705290702631a86c948 初始化创世区块配置 初始化创世区块配置(分别在每个节点目录下执行此命令) 123456789101112$ geth --datadir data init ../blockpoa.jsonINFO [04-07|20:22:34.955] Maximum peer count ETH=50 LES=0 total=50INFO [04-07|20:22:34.955] Smartcard socket not found, disabling err=&quot;stat /run/pcscd/pcscd.comm: no such file or directory&quot;INFO [04-07|20:22:34.957] Set global gas cap cap=50,000,000INFO [04-07|20:22:34.957] Allocated cache and file handles database=/home/guozhe/work/blockchain/gethpoa/node1/data/geth/chaindata cache=16.00MiB handles=16INFO [04-07|20:22:34.975] Writing custom genesis blockINFO [04-07|20:22:34.984] Persisted trie from memory database nodes=357 size=50.70KiB time=1.847678ms gcnodes=0 gcsize=0.00B gctime=0s livenodes=1 livesize=0.00BINFO [04-07|20:22:34.986] Successfully wrote genesis state database=chaindata hash=9d6e3d..f10d54INFO [04-07|20:22:34.986] Allocated cache and file handles database=/home/guozhe/work/blockchain/gethpoa/node1/data/geth/lightchaindata cache=16.00MiB handles=16INFO [04-07|20:22:35.004] Writing custom genesis blockINFO [04-07|20:22:35.012] Persisted trie from memory database nodes=357 size=50.70KiB time=2.258964ms gcnodes=0 gcsize=0.00B gctime=0s livenodes=1 livesize=0.00BINFO [04-07|20:22:35.013] Successfully wrote genesis state database=lightchaindata hash=9d6e3d..f10d54 启动引导节点 创建一个目录bnode,然后进入到此目录执行bootnode -genkey boot.key命令生成boot.key。执行完成之后，工作目录下会有boot.key文件，整体目录结构如下: 1234567891011121314$ tree gethpoa/gethpoa/├── blockpoa-harmony.json├── blockpoa.json├── bnode│ └── boot.key├── node1│ └── data│ └── keystore│ └── UTC--2022-04-07T11-43-40.475412645Z--7adc4a5a65ab33595ade0ed15903e8c406f69230└── node2 └── data └── keystore └── UTC--2022-04-07T08-50-53.751660870Z--0691e168e8cc151a76a04705290702631a86c948 使用bootnode和刚才生成的boot.key启动引导节点: 提示信息说bootnode是开发工具，如果是生产环境的话使用一个正常的节点作为引导节点。 12345$ bootnode -nodekey boot.keyenode://5b0427c6efd2b8c1e107061527a7bfc39b74ab42db1561f8da8302622b0504d7f3afe3e7ba74b7561ddc00c256d4cacea756ff983080cb78bd8f56fd89959e88@127.0.0.1:0?discport=30301Note: you&#x27;re using cmd/bootnode, a developer tool.We recommend using a regular node as bootstrap node for production deployments.INFO [04-07|17:04:08.597] New local node record seq=1,649,322,248,596 id=1ae5556065ce551c ip=&lt;nil&gt; udp=0 tcp=0 启动成员节点 在node1和node2目录下创建password.txt文件，然后把账户密钥的密码保存到此文件中。然后分别在两个目录下运行下面的命令 1234567# node1目录下执行$geth --datadir data --networkid 3030 --bootnodes enode://5b0427c6efd2b8c1e107061527a7bfc39b74ab42db1561f8da8302622b0504d7f3afe3e7ba74b7561ddc00c256d4cacea756ff983080cb78bd8f56fd89959e88@127.0.0.1:0?discport=30301 --ipcdisable --syncmode full --http --allow-insecure-unlock --http.addr 0.0.0.0 --unlock 0x7adc4a5a65ab33595ade0ed15903e8c406f69230 --password password.txt --mine console# node2目录下执行geth --datadir data --networkid 3030 --bootnodes enode://5b0427c6efd2b8c1e107061527a7bfc39b74ab42db1561f8da8302622b0504d7f3afe3e7ba74b7561ddc00c256d4cacea756ff983080cb78bd8f56fd89959e88@127.0.0.1:0?discport=30301 --port 30304 --ipcdisable --syncmode full --http --allow-insecure-unlock --http.addr 0.0.0.0 --http.port 8546 console 如果关掉终端之后需要重启网络的话，直接执行上面两个命令即可，不用再启用引导节点 验证 配置matemask 配置网络，把刚才生成的账户导入到matemask。 发送一个交易 后台日志： 1INFO [04-07|20:41:00.283] Submitted transaction hash=0xce38e66cbc6267110fc31a4f07fbfd740c784439ba87666c5fddf1c036136f46 from=0x7adC4A5a65ab33595adE0ed15903e8c406f69230 nonce=0 recipient=0x2560be5793F9AA00963e163A1287807Feb897e2F value=111,000,000,000,000,000,000 错误处理 因为没有启用rpcapi接口，因此使用matemask无法配置私有网络 解决方法，启用rpcapi功能 如果您需要在其他的机器上连此node节点，则命令选项需要添加--http.addr 0.0.0.0选项。 Do not forget --http.addr 0.0.0.0, if you want to access RPC from other containers and/or hosts. By default, geth binds to the local interface and RPC endpoints are not accessible from the outside. 1geth &lt;other-flags&gt; --http --http.addr 0.0.0.0 发送ETH失败，日志报错：err=“header not found” 如果在matemask上面发送ETH之后日志报下面的错误，检查一下网络配置是否正确。我出现这个错误是因为网络ID配置不正确导致。 1WARN [04-07|20:39:29.911] Served eth_getTransactionCount conn=192.168.31.153:64458 reqid=5607614675047 duration=&quot;84.518µs&quot; err=&quot;header not found&quot; WARN [04-05|14:46:19.861] Block sealing failed err=“signed recently, must wait for others” 我配置两个节点作为签名节点时报此错误，然后只保留一个签名节点可以正常打包区块也不报次错误了。目前原因尚不清楚。 Fatal: Account unlock with HTTP access is forbidden! --http和--unlock两个选项不能同时启用，应该是考虑到安全的问题。 也可以使用--allow-insecure-unlock选项：Allow insecure account unlocking when account-related RPCs are exposed by http。但是生产环境不建议使用此选项。 错误记录：WARN [04-05|13:28:32.568] Block sealing failed err=“unauthorized signer” 如果运行一个签名的节点时出现上面的错误，可以查看genesis.json文件中的extradata是否包含启动时解锁的用户地址，如果不包含则使用包含的账户地址进行启动签名者节点。 后续工作 因为现在启动节点都是在终端执行命令启动的，终端一旦关闭网络也就关了。可以有两种方案： 使用docker启动 使用后台运行的方式执行启动命令 个人更倾向于使用第一种，后面有时间再用docker启动。","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"HOW-TO","slug":"区块链/ethereum/HOW-TO","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/HOW-TO/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"私有以太坊网络","slug":"私有以太坊网络","permalink":"https://guozhe001.github.io/tags/%E7%A7%81%E6%9C%89%E4%BB%A5%E5%A4%AA%E5%9D%8A%E7%BD%91%E7%BB%9C/"}]},{"title":"以太坊官方文档【private-network】学习","slug":"blockchain/ethereum/how_to/如何用go-ethereum运营一个私有区块链网络","date":"2024-11-22T06:32:06.492Z","updated":"2024-11-22T06:32:06.492Z","comments":true,"path":"2024/11/22/blockchain/ethereum/how_to/如何用go-ethereum运营一个私有区块链网络/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/how_to/%E5%A6%82%E4%BD%95%E7%94%A8go-ethereum%E8%BF%90%E8%90%A5%E4%B8%80%E4%B8%AA%E7%A7%81%E6%9C%89%E5%8C%BA%E5%9D%97%E9%93%BE%E7%BD%91%E7%BB%9C/","excerpt":"","text":"本文档是官方文档private-network的翻译 运营一个私有区块链网络 维护自己的私有网络比较麻烦，因为很多在官方网络中习以为常的配置都需要手动设置。 本指南解释了如何设置多个 Geth 节点的私有网络。如果一个以太坊网络的节点没有连接到主网络，则它就是一个私有网络。在这种情况下，私有仅意味着保留或隔离，而不是受保护或安全。 选择一个网络ID 网络 ID 是一个整数，用于隔离以太坊对等网络。只有当所有对等节点使用相同的创世块和网络 ID 时，区块链节点之间才会发生连接。使用 --networkid命令行选项设置 geth 使用的网络 ID。 主网络的ID是1。如果您提供自己的不同于主网络的自定义网络 ID，您的节点将不会连接到其他节点，而是形成了一个私有网络。 如果你计划在互联网上能够连接到你的私有链，最好选择一个没有被用到的网络ID。您可以在 https://chainid.network 找到由社区运行的以太坊网络注册表。 选择一个共识算法 While the main network uses proof-of-work to secure the blockchain, Geth also supports the the ‘clique’ proof-of-authority consensus algorithm as an alternative for private networks. We strongly recommend ‘clique’ for new private network deployments because it is much less resource intensive than proof-of-work. The clique system is also used for several public Ethereum testnets such as Rinkeby and Görli. 虽然主网络使用工作量证明来保护区块链，但 Geth 还支持“clique”权威证明共识算法作为私有网络的替代方案。我们强烈建议将“clique”用于新的专用网络部署，因为它比工作量证明占用的资源要少得多。clique 共识算法还用于多个公共以太坊测试网，例如 Rinkeby 和 Görli。 Here are the key differences between the two consensus algorithms available in Geth: 以下是 Geth 中可用的两种共识算法之间的主要区别： Ethash consensus, being a proof-of-work algorithm, is a system that allows open participation by anyone willing to dedicate resources to mining. While this is a great property to have for a public network, the overall security of the blockchain strictly depends on the total amount of resources used to secure it. As such, proof-of-work is a poor choice for private networks with few miners. The Ethash mining ‘difficulty’ is adjusted automatically so that new blocks are created approximately 12 seconds apart. As more mining resources are deployed on the network, creating a new block becomes harder so that the average block time matches the target block time. Ethash是一个工作量证明的共识算法，是一个允许任何愿意将资源用于挖矿的人公开参与的系统。虽然这对于公共网络来说是一个很好的属性，但区块链的整体安全性严格取决于用于保护它的资源总量。因此，对于矿工很少的私有网络来说，工作量证明是一个糟糕的选择。Ethash 挖矿“难度”会自动调整，以便每隔大约 12 秒创建新块。随着网络上部署的挖矿资源越来越多，创建新区块变得更加困难，以使平均区块时间与目标区块时间相匹配。 Clique consensus is a proof-of-authority system where new blocks can be created by authorized ‘signers’ only. The clique consenus protocol is specified in EIP-225. The initial set of authorized signers is configured in the genesis block. Signers can be authorized and de-authorized using a voting mechanism, thus allowing the set of signers to change while the blockchain operates. Clique can be configured to target any block time (within reasonable limits) since it isn’t tied to the difficulty adjustment. Clique 是一种权威证明的共识系统，新区块只能由授权的“签名者”创建。Clique共识协议是在EIP-225中指定的。初始授权签名者集合在创世块中配置。可以使用投票机制对签名者进行授权和取消授权，从而允许签名者集在区块链运行时更改。Clique 可以配置为针对任何出块时间（在合理范围内），因为它与难度调整无关。 创建创世区块 Every blockchain starts with the genesis block. When you run Geth with default settings for the first time, it commits the main net genesis to the database. For a private network, you usually want a different genesis block. 每个区块链都是从创世区块开始的。当你使用默认设置第一次运行Geth时，它会将主网络创世提交到数据库。对于一个私有网络来说，你通常想要一个不一样的创世区块， The genesis block is configured using the genesis.json file. When creating a genesis block, you need to decide on a few initial parameters for your blockchain: 创世区块使用 genesis.json文件进行配置。在创建创世区块时，您需要为区块链确定一些初始参数： Ethereum platform features enabled at launch (config). Enabling protocol features while the blockchain is running requires scheduling a hard fork. 启动时启用的以太坊平台功能（config）。在区块链运行时启用协议功能需要安排硬分叉。 Initial block gas limit (gasLimit). Your choice here impacts how much EVM computation can happen within a single block. We recommend using the main Ethereum network as a guideline to find a good amount. The block gas limit can be adjusted after launch using the --miner.gastarget command-line flag. 初始的区块gas上限 (gasLimit)。您在此处的选择会影响单个区块内可以发生多少 EVM 计算。我们建议使用以太坊主网络作为找到合适gas数量的指南。启动后可以使用 --miner.gastarget 命令行参数来调整gas上限。 Initial allocation of ether (alloc). This determines how much ether is available to the addresses you list in the genesis block. Additional ether can be created through mining as the chain progresses. 初始分配以太(alloc)。这决定了您在创世区块中列出的地址可以使用多少以太币(单位是wei)。随着链的进展，可以通过挖掘创建额外的以太币。 Clique共识协议的配置样例 This is an example of a genesis.json file for a proof-of-authority network. The config section ensures that all known protocol changes are available and configures the ‘clique’ engine to be used for consensus. 这是权威证明网络的 genesis.json 文件示例。config 部分确保所有已知的协议更改都可用，并配置“clique”共识引擎以用于达成共识。 Note that the initial signer set must be configured through the extradata field. This field is required for clique to work. 请注意，必须通过 extradata 字段配置初始签名者集。该字段是 clique 工作所必需的。 First create the signer account keys using the geth account command (run this command multiple times to create more than one signer key). 首先使用 geth account 命令创建签名者帐户密钥（多次运行此命令以创建多个签名者密钥）。 1234567891011121314151617$ geth account new --datadir dataINFO [04-02|16:37:33.521] Maximum peer count ETH=50 LES=0 total=50INFO [04-02|16:37:33.521] Smartcard socket not found, disabling err=&quot;stat /run/pcscd/pcscd.comm: no such file or directory&quot;Your new account is locked with a password. Please give a password. Do not forget this password.Password:Repeat password:Your new key was generatedPublic address of the key: 0x72a43a99415943087ca78B0f56864BB872172A0BPath of the secret key file: data/keystore/UTC--2022-04-02T08-37-39.509059069Z--72a43a99415943087ca78b0f56864bb872172a0b- You can share your public address with anyone. Others need it to interact with you.- You must NEVER share the secret key with anyone! The key controls access to your funds!- You must BACKUP your key file! Without the key, it&#x27;s impossible to access account funds!1234567890- You must REMEMBER your password! Without the password, it&#x27;s impossible to decrypt the key! Take note of the Ethereum address printed by this command. 记录此命令输出的以太坊地址。 此命令会自动创建data目录，data目录下面有个名为keystore的目录用于保存密钥文件。 123$ ll data/keystore/total 4-rw------- 1 guozhe guozhe 491 Apr 2 16:38 UTC--2022-04-02T08-38-00.725585452Z--b64337679d907ec8e7f8acecc4996f511b63aca3 To create the initial extradata for your network, collect the signer addresses and encode extradata as the concatenation of 32 zero bytes, all signer addresses, and 65 further zero bytes. In the example below, extradata contains a single initial signer address, 0x7df9a875a174b3bc565e6424a0050ebc1b2d1d82. 要为您的网络创建初始额外数据，请收集签名者地址并将额外数据编码为： 32 个零字节+所有签名者地址+另外 65 个零字节。在下面的示例中，extradata 包含一个初始签名者地址 0x7df9a875a174b3bc565e6424a0050ebc1b2d1d82。 您可以使用 period 配置选项来设置链的目标出块时间。 123456789101112131415161718192021222324&#123; &quot;config&quot;: &#123; &quot;chainId&quot;: 15, &quot;homesteadBlock&quot;: 0, &quot;eip150Block&quot;: 0, &quot;eip155Block&quot;: 0, &quot;eip158Block&quot;: 0, &quot;byzantiumBlock&quot;: 0, &quot;constantinopleBlock&quot;: 0, &quot;petersburgBlock&quot;: 0, &quot;clique&quot;: &#123; &quot;period&quot;: 5, &quot;epoch&quot;: 30000 &#125; &#125;, &quot;difficulty&quot;: &quot;1&quot;, &quot;gasLimit&quot;: &quot;8000000&quot;, &quot;extradata&quot;: &quot;0x000000000000000000000000000000000000000000000000000000000000000072a43a99415943087ca78B0f56864BB872172A0B2a63a0155852B1B6756E336036E957925adCa7eC0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000&quot;, &quot;alloc&quot;: &#123; &quot;72a43a99415943087ca78B0f56864BB872172A0B&quot;: &#123; &quot;balance&quot;: &quot;30000000000000000000000000&quot; &#125;, &quot;2a63a0155852B1B6756E336036E957925adCa7eC&quot;: &#123; &quot;balance&quot;: &quot;40000000000000000000000000&quot; &#125;, &quot;556136F8c1853fB7A393994Ee6058a8d2Ec5999C&quot;: &#123; &quot;balance&quot;: &quot;50000000000000000000000000000000000000000000&quot; &#125; &#125;&#125; 初始化 Geth 数据库 To create a blockchain node that uses this genesis block, run the following command. This imports and sets the canonical genesis block for your chain. 要创建使用此创世区块的区块链节点，请运行以下命令。这会为您的链导入并设置规范的创世块。 1geth init --datadir data genesis.json Future runs of geth using this data directory will use the genesis block you have defined. 以后使用此数据目录运行 geth 将使用您定义的创世块。 1geth --datadir data --networkid 15 调度硬分叉 As Ethereum protocol development progresses, new Ethereum features become available. To enable these features on your private network, you must schedule a hard fork. 随着以太坊协议开发的进展，新的以太坊功能变得可用。要在您的专用网络上启用这些功能，您必须安排一次硬分叉。 First, choose any future block number where the hard fork will activate. Continuing from the genesis.json example above, let’s assume your network is running and its current block number is 35421. To schedule the ‘Istanbul’ fork, we pick block 40000 as the activation block number and modify our genesis.json file to set it: 首先，选择硬分叉将激活的任何未来区块号。继续上面的 genesis.json 示例，假设您的网络正在运行，并且它的当前块号是 35421。为了安排“伊斯坦布尔”分叉，我们选择块 40000 作为激活块号并修改我们的 genesis.json 文件以设置它： 12345678&#123; &quot;config&quot;: &#123; ... &quot;istanbulBlock&quot;: 40000, ... &#125;, ...&#125; In order to update to the new fork, first ensure that all Geth instances on your private network actually support the Istanbul fork (i.e. ensure you have the latest version of Geth installed). Now shut down all nodes and re-run the init command to enable the new chain configuration: 为了更新到新的分叉，首先确保您的私有网络上的所有 Geth 实例实际上都支持伊斯坦布尔分叉（即确保您安装了最新版本的 Geth）。现在关闭所有节点并重新运行 init 命令以启用新的链配置： 1geth init --datadir data genesis.json 启动网络 Once your node is initialized to the desired genesis state, it is time to set up the peer-to-peer network. Any node can be used as an entry point. We recommend dedicating a single node as the rendezvous point which all other nodes use to join. This node is called the ‘bootstrap node’. 一旦你的节点被初始化为所需的创始状态，那么就该设置点对点网络了。任何节点都可以用作入口点。我们建议将单个节点用作所有其他节点用来加入的集合点。该节点称为“引导节点”。 First, determine the IP address of the machine your bootstrap node will run on. If you are using a cloud service such as Amazon EC2, you’ll find the IP of the virtual machine in the management console. Please also ensure that your firewall configuration allows both UDP and TCP traffic on port 30303. 首先，确定运行您的引导节点的服务器的IP地址。如果你使用例如亚马逊EC2之类的云服务器，你需要在虚拟机管理页面查看机器的IP地址。还请确保您的防火墙配置允许端口 30303 上的 UDP 和 TCP 流量。 The bootstrap node needs to know about its own IP address in order to be able to relay it others. The IP is set using the --nat flag (insert your own IP instead of the example address below). 引导节点需要知道他自己的IP地址，以便能够将其中继给其他节点.使用--nat设置IP地址。 1geth --datadir data --networkid 15 --nat extip:172.16.254.4 Now extract the ‘node record’ of the bootnode using the JS console. 现在使用 JS 控制台提取引导节点的“节点记录”。 1geth attach data/geth.ipc --exec admin.nodeInfo.enr This command should print a base64 string such as the following example. Other nodes will use the information contained in the bootstrap node record to connect to your peer-to-peer network. 这个命令应该会输出一个像下面例子一样的base64编码的字符串。其他节点将使用引导节点记录中包含的信息连接到您的对等网络。 1&quot;enr:-Je4QEiMeOxy_h0aweL2DtZmxnUMy-XPQcZllrMt_2V1lzynOwSx7GnjCf1k8BAsZD5dvHOBLuldzLYxpoD5UcqISiwDg2V0aMfGhGlQhqmAgmlkgnY0gmlwhKwQ_gSJc2VjcDI1NmsxoQKX_WLWgDKONsGvxtp9OeSIv2fRoGwu5vMtxfNGdut4cIN0Y3CCdl-DdWRwgnZf&quot; Setting up peer-to-peer networking depends on your requirements. If you connect nodes across the Internet, please ensure that your bootnode and all other nodes have public IP addresses assigned, and both TCP and UDP traffic can pass the firewall. 设置对等网络取决于您的要求。如果您通过 Internet 连接节点，请确保您的引导节点和所有其他节点都分配了公共 IP 地址，并且 TCP 和 UDP 流量都可以通过防火墙。 If Internet connectivity is not required or all member nodes connect using well-known IPs, we strongly recommend setting up Geth to restrict peer-to-peer connectivity to an IP subnet. Doing so will further isolate your network and prevents cross-connecting with other blockchain networks in case your nodes are reachable from the Internet. Use the --netrestrict flag to configure a whitelist of IP networks: 如果不需要 Internet 连接或所有成员节点都使用已知 IP 连接，我们强烈建议设置 Geth 以限制对 IP 子网的对等连接。这样做将进一步隔离您的网络并防止与其他区块链网络交叉连接，以防您的节点可以从 Internet 访问。使用--netrestrict 标志配置 IP 网络白名单： 1geth &lt;other-flags&gt; --netrestrict 172.16.254.0/24 With the above setting, Geth will only allow connections from the 172.16.254.0/24 subnet, and will not attempt to connect to other nodes outside of the set IP range. 使用上述设置，Geth 将只允许来自 172.16.254.0/24 子网的连接，而不会试图连接到设定的 IP 范围之外的其他节点。 运行成员节点 Before running a member node, you have to initialize it with the same genesis file as used for the bootstrap node. 在运行一个成员节点之前，你必须使用与引导节点相同的创世文件进行初始化。 With the bootnode operational and externally reachable (you can try telnet to ensure it’s indeed reachable), you can start more Geth nodes and connect them via the bootstrap node using the --bootnodes flag. 随着 bootnode 可操作且外部可访问（您可以尝试 telnet 以确保它确实可访问），您可以启动更多 Geth 节点并使用 --bootnodes 标志通过引导节点连接它们。 To create a member node running on the same machine as the bootstrap node, choose a separate data directory (example: data-2) and listening port (example: 30305): 要创建与引导节点在同一台机器上运行的成员节点，请选择单独的数据目录（例如：data-2）和监听端口（例如：30305）： 下面的命令中部分，需要替换成引导节点的信息，具体信息可以在引导节点的日志中获取，比如我的如下： 1INFO [04-05|13:13:46.760] Started P2P networking self&#x3D;enode:&#x2F;&#x2F;ded53747cabc10400ffd59fb329c2cb3d048ea8eacc078641177abab7054afd71a3c7404f9461257ef678af0875c93f4d70792c02a27bbb449ad844bf176ab5d@127.0.0.1:30303 1geth --datadir data-2 --networkid 15 --port 30305 --bootnodes &lt;bootstrap-node-record&gt; With the member node running, you can check whether it is connected to the bootstrap node or any other node in your network by attaching a console and running admin.peers. It may take up to a few seconds for the nodes to get connected. 在成员节点运行时，你可以通过连接控制台和运行admin.peers来检查它是否连接到引导节点或网络中的任何其他节点。节点可能需要几秒钟的时间来连接。 1geth attach data-2/geth.ipc --exec admin.peers Clique: 启动一个签名者 To set up Geth for signing blocks in proof-of-authority mode, a signer account must be available. The account must be unlocked to mine blocks. The following command will prompt for the account password, then start signing blocks: 要设置Geth在权威证明模式下签署区块，必须有一个签名者账户。该账户必须被解锁以挖掘区块。下面的命令将提示输入账户密码，然后开始签署区块。 1geth &lt;other-flags&gt; --unlock 0x7df9a875a174b3bc565e6424a0050ebc1b2d1d82 --mine You can further configure mining by changing the default gas limit blocks converge to (with --miner.gastarget) and the price transactions are accepted at (with --miner.gasprice). 你可以通过改变区块的默认气体上限（用--miner.gastarget）和接受交易的价格（用–miner.gasprice）来进一步配置挖矿。 Ethash: Running A Miner For proof-of-work in a simple private network, a single CPU miner instance is enough to create a stable stream of blocks at regular intervals. To start a Geth instance for mining, run it with all the usual flags and add the following to configure mining: geth --mine --miner.threads=1 --miner.etherbase=0x0000000000000000000000000000000000000000 This will start mining bocks and transactions on a single CPU thread, crediting all block rewards to the account specified by --miner.etherbase.","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"HOW-TO","slug":"区块链/ethereum/HOW-TO","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/HOW-TO/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"私有区块链网络","slug":"私有区块链网络","permalink":"https://guozhe001.github.io/tags/%E7%A7%81%E6%9C%89%E5%8C%BA%E5%9D%97%E9%93%BE%E7%BD%91%E7%BB%9C/"}]},{"title":"北京大学肖臻老师《区块链技术与应用》学习笔记","slug":"blockchain/1北京大学肖臻老师《区块链技术与应用》学习总结","date":"2024-11-22T06:32:06.491Z","updated":"2024-11-22T06:32:06.491Z","comments":true,"path":"2024/11/22/blockchain/1北京大学肖臻老师《区块链技术与应用》学习总结/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/1%E5%8C%97%E4%BA%AC%E5%A4%A7%E5%AD%A6%E8%82%96%E8%87%BB%E8%80%81%E5%B8%88%E3%80%8A%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8%E3%80%8B%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/","excerpt":"","text":"3 数据结构 hash printers （hash指针） hash指针既可以找到块的位置，也可以验证hash的正确性 Block chain is a linked list using hash pointers 每一个区块都包含前一个区块的hash指针 后面一个区块的hash指针是通过前一个区块的值算出来的。 通过上面的数据结构可以实现：tamper-evident-log 只要记住最后一个块的hash值，就可以保证整个链的值无法篡改。 我们也可以只保存其中的部分区块，区块的前面的部分我们不必保存，如果需要的时候找别人要；然后验证要的区块的hash值是否是当前区块的hash值即可 Merkle tree 上图： 最下面的一层是数据块，data blocks；每个数据块都是交易（tx） 上面的那些都是hash pointers 最上面的节点是根hash值（root hash） Merkle tree数据结构的好处： 只要记住root hash就可以检测出节点的修改 每个区块分成块头（block header）和块身（block body） 默克尔证明（Merkle proof）：指一笔交易到跟节点的路径 这种证明也叫做：proof of membership或proof of inclusion（证明节点存在于Merkle tree之中） proof of non-membership（证明节点存不在于Merkle tree之中） 排序所有交易节点的hash值（Sorted Merkle tree），然后计算需要证明的交易的hash值，找到此hash值应该出现的位置，如果应该出现的位置的两边的节点的hash满足Merkle proof，则说明需要证明的节点不在此Merkle tree之中。 只要不是有环的数据结构，都可以使用hash指针 4 BTC 协议 如何发行数字货币 央行发行数字货币，如果只使用私钥签名，可以吗？ 无法防止double spending attack：花两次攻击 中心化方案： 如果央行给发行的货币打上编号并且记录货币当前属于谁，那么可以解决double spending attack； 但是每次花钱都要去央行验证货币是否是真的，并且属于当前花钱的人，花钱之后再变更钱的归属。 去中心化方案 每个交易（如A给B转账）中都包含输入和输出两个部分 输入部分需要说明币的来源 输入部分需要包含付款人的公钥（因为付款时有付款人的签名，带上公钥为了供别人校验） 输出部分要给出收款人公钥的hash 铸币交易（coinbase tx）里面有A的公钥的hash，这样就知道铸币交易的钱是给谁的。 上图中的数据结构有两种hash指针 第一种是链接块的hash指针（即前一个区块的hash指针） 第二种hash指针是说明币的来源 问题：是否可以检测dobule spending？ 如果币的来源是不合法的（验证不合法的方式是币的来源是否存在与UTXO），是不会添加到区块链中，可以检测dobule spending 问题：在A给B转账时，所有人都需要知道A的公钥，为了验证A的签名；那么怎么才能知道A的公钥呢？ 在交易的输入部分，付款人需要给出自己的公钥 在比特币的系统里，地址是通过公钥推算出来的，地址相当于银行账号，A需要给B转钱需要B的地址；比特币系统里面是没有功能查询某个人的地址 BitCoin Script：交易脚本，把A的输入部分和上一步的输出脚本拼在一起执行，如果不报错说明交易是合法的。 每一个块包含不止一个交易，每个块包含Block header和Block body 哈希指针包含的hash，是通过Block header做hash的值 Block header包含： version：用的哪个比特币协议的版本 hash of previous block header：上一个区块头的hash Merkle root hash：整个Tree的root hash值 target：挖矿的目标target（满足H(block header + nonce) &lt;= target） 随机数nonce Block body包含： transaction list 系统中的节点分为全节点和轻节点 full node 全节点是保存区块链的所有信息的，验证每一个交易，所以全节点也叫做fully validating node light node 轻节点无法独立验证交易的合法性 问题：每个账户都可以发布交易，谁来决定哪个交易写到区块中？顺序是什么样的？ 挖矿决定谁有记账权，有记账权的节点可以申请写入区块，顺序由拥有记账权的节点定 账本的内容要取得分布式的共识 distributed consensus（分布式共识） distributed hash table 需要取得共识的内容是什么？ FLP impossibility result： 在一个异步的系统里，即使只有一个成员是有问题的，也不可能取得共识 CAP Theorem（定理） CAP： 一致性 （Consistency） 可用性 （Availability） 分区容错性 （Partition tolerance） 这三个特性分布式系统中最多同时满足两个 分布式的一个协议：Paxos，能够保证Consistency 比特币中的共识协议Consensus in BitCoin 假设系统中大部分的节点是好的，小部分有恶意。 直接投票选择哪些交易是合法的，如果超过半数就接受可以吗？ membership，谁有投票权 hyperledger fabric（联盟链）：可以投票决定 sybil attack（女巫攻击）：超级计算机一直制造账户，参与投票，直到制造的恶意账户超过半数。 比特币的投票，按照算力值 谁先获得下面公式中的nonce，谁就能获得记账权，并且给予初块奖励 Puzzle friendly: H(block header) &lt;= target longest valid chain 最长合法链 如果不在最长合法链上，新的区块也不会被接受； 上面的图片是分叉攻击（forking attack） block reward 初块奖励 一次性能造多少币？ 刚发布的时候50 BTC，21万个区块之后可以铸造25个比特币 50 BTC -&gt; 25 BTC -&gt; 12.5 BTC coinbase transaction mining（挖矿）：争夺记账权 digital gold：数字黄金 miner：矿工 5-BTC 实现 transaction-based ledger：基于交易的账本模式 每个区块记录的是交易信息，包括转账交易和铸币交易 UTXO：Unspent Transaction Output（还没有被花出去的输出） UTXO数据结构，以便快速检测double spending；如果想花掉的币不存在UTXO中，说明不存在或已经花出 total inputs = total outputs 比特币的第二个激励机制：transaction fee 其他的模式：account-based ledger，在这种模式中，系统要显示的记录账户的余额，以太坊是基于此种模式记账。 每次尝试nonce可以看作是Bernoulli trial：a random experiment with binary outcome 所有的尝试的集合构成了Bernoulli Process：a sequence of independent Bernoulli trials 尝试计算nonce是memoryless的：即无论以前尝试过多少次下一次的概率还是一样 可以使用Poisson Process近似 出块时间服从指数分布：exponential distribution BitCoin is secured by mining 比特币的安全性 问题：能不能把别人的钱转给自己？ 不可以，因为你没有别人的私钥，无法签名。（比特币在花每一笔钱的时候都要制定币的来源，即某次交易的output，这个output中有币的所有人的公钥，在花钱的时候币的所有人需要用自己的私钥做签名，然后别人通过当前交易的input和币来源的output来验证这个交易的合法性。） 问题：能不能double spending？ 不可以，因为第二次花的时候在UTXO里面不存在，会验证不通过。 6-BTC-网络 application layer：BitCoin Block chain network layer：P2P Overlay Network 设计原则：simple, robust, but not efficient 7-BTC-挖矿难度 如何调整挖矿难度：调整挖矿难度就是调整目标空间在整个输出空间中所占的比例。 挖矿即是算出满足：H(block header) &lt;= target的nonce值 sha-256: 可能的值是2的256次方 difficulty = difficulty_1_target/target 问题：为什么要调整挖矿难度？ 为了保证出块时间平均10分钟 问题：出块时间太短会有什么问题？ 两个节点同时发布区块，可能会出现分叉 平均出块时间过短可能导致上图的很多分叉，这会分散诚实节点的算力 平均出块时间不论设置的多长，都不可以无限的减小下去 如果分叉过多就无法防止51% attack 以太坊的共识协议：ghost 什么时候调整难度？ 每2016个区块之后调整一次 如何调整挖矿难度： 调整的target值 **公式：**target = target_current * (actual time)/(expected time) 当actual time大于expected time，说明难度太大， (actual time)/(expected time)得出的值就大于1，最终算出来的target会比当前的target大，也就是变得容易 调整难度 next_difficulty = previous_diffculty * (2 weeks)/ (time to mine last 2016 blocks) 调整难度与目标域值（target）成反比 expected time = 2016 * 10min actual time = time spent mining the last 2016 blocks 目标域值调整最大不会超过4倍，最小不会小于1/4 怎么让所有的矿工都调整域值呢？ 代码里自动调，如果恶意节点修改了源码不调整，他发布的区块的检查区块合法性就通不过。 8-BTC-挖矿 全节点 一直在线 在本地硬盘上维护完整的区块链信息 在内存里维护UTXO，以便快速验证交易的正确性 监听比特币网络上的交易信息，验证每个交易的合法性 决定哪些交易会被打包到区块里 监听别的矿工挖出来的区块，验证其合法性 挖矿 决定沿着哪条链挖下去？ 当出现等长的分叉的时候，选择哪个分叉？ 缺省情况下是沿着最先听到的区块 轻节点 不是一直在线 不用保存整个区块链，只要保存每个区块的块头 不用保存全部交易，只保存与自己相关的交易 无法检验大多数交易的合法性，只能检测与自己相关的那些交易的合法性 无法检测网上发布的区块的正确性 可以验证挖矿的难度 只能检测哪个是最长链，不知道哪个是最长合法链 挖矿具有特性： memoryless或叫做progress free 挖矿的设备 第一代，CPU 闲置的cpu、内存、硬盘 第二代，GPU 为了通用并行计算而设计的 也存在浪费 第三代，ASIC：Application Specific Integrated Circuit 挖矿的设备的趋势是从通用到专业 puzzle mining puzzle:挖矿时求解的puzzle merge mining：使用别的币的mining puzzle Alternative mining puzzle: 抗ASIC芯片 矿池 （share almost valid block） 假如一个矿池占了51%的比例，他能发动哪些攻击呢？ forking attack Boycott（封锁） 9-BTC-比特币脚本 比特币脚本是stack-based的脚本，包括下面三种类型 P2PK（Pay to Public Key） P2PH（Pay to Public Key Hash） P2SH（Pay to Script Hash）对多重签名的支持 redeemScript： 当一个需要联合签名的账号B（如需要5个中的三个签名）需要支付时，需要至少有三个签名才可以，那么在B支付给C时需要验证B的币来来源的output和当前的交易的input做验证。如果需要验证成功则需要在上一步交易的output中包含这些公钥信息。 当一个账号A支付给另一个需要联合签名的账号B时，如果需要A支付时提供B的所有的账户的公钥信息，会导致A支付时特别麻烦。 redeemScript就是解决上面的问题而存在的，详情参考深入理解比特币脚本 Proof of Burn 燃烧证明，在输出脚本中添加return，使这个output在验证时永远报错，也就是这个输出的币永远也花不出去。 自问：如果A在给B付款时，output中面包含return语句，那么B虽然真实收到了款，但是永远花不出去。B能够在接收时验证吗？还是只能等到花钱时才能发现这个问题呢？ **自答：**因为B需要验证这比交易有没有写入区块链中，所以A会把交易发给B，此时B需要检查output是否包含return，如果包含则认为这比交易无效；假如B是商家并在交易刚发生时不验证，把货发送给A，那么B就收到一笔花不出去的钱。 digital commitment 发布交易不需要记账权，发布区块才需要记账权 10-BTC-分叉 fork state fork forking attack（deliberate fork） protocol fork（协议分叉） hard fork soft fork hard fork 系统中只有有一部分节点不更新软件，就会出现永久性的分叉 eg：block size limit block size不超过1M，计算出7tx/sec（每秒7笔交易）；如果new nodes把软件升级为区块大小最多可以4M，那么旧的节点如果不一起升级继续沿着旧链挖就会导致硬分叉；旧节点认为超过1M大小的区块为非法的。 只要old nodes不更新软件，分叉就不会变更 soft fork 只要系统中有半数中的节点更新软件，就不会出现永久性的分叉；只会出现临时性的分叉 接着使用调整区块大小的例子，如果调整为限制不超过0.5M，那么新节点产生的区块旧节点也认可；但是旧节点产生的区块新节点不认可，如果新节点占多数时就会迫使旧节点升级。 软分叉的例子（P2SH：Pay to Script Hash） 11-BTC-问答 如果转账的时候地址写错了怎么办？ 答：没有办法取消一经发布的交易 Proof of Burn，如果OP_RETURN无条件的返回错误，这笔交易是如何写入到区块链里的呢？ 答：因为OP_RETURN是写在当前交易的输出脚本里，所以当前交易的验证不会验证这个脚本 你怎么知道哪个矿工最先找到的同一个nonce？ 答：不可以偷答案，因为区块里面的coinbase tx指向的收款账户是真正计算出nonce的账户，这个信息如果被修改了，交易就不会验证通过。 transaction fee，如何确定交易费给哪个矿工，给多少？ 只要total inputs &gt; total outputs，之间的差额就是交易费 12-BTC-比特币中的匿名性 BitCoin and anonymity pseudonymity 什么情况下会破坏匿名性？ 在多个inputs的时候，多个输入可能是同一个人 什么情况下别人能直到比特币账户对应现实中的某个人呢？ 资金的转入转出，购买比特币或者比特币套现；比特币支付的时候也可以 silk road：eBay for illegal drugs 采取什么方法提高匿名性？ 零知识证明 零知识证明是指一方（证明者）向另一方（验证着）证明一个陈述是正确的，而无需透露除该陈述是正确的外的任何信息。 **我的理解：**如比特币的转账（A转给B）签名就是零知识证明，因为这个签名证明了这个交易是A转出去的，却不需要让A提供其他信息。 13-BTC-思考 为什么比特币系统能够绕过被证明的分布式系统的不可能的结论？ 比特币并没有绕过 14-ETH-以太坊概述 memory hard mining puzzle ASIC resistance：挖矿时需要访问内存 proof of work -&gt; proof of stake：目标是从工作量证明过度到权益证明 smart contract: 智能合约 BitCoin: decentralized currency（去中心化的货币） Ethereum: decentralized contract（去中心化的合同） 15-ETH-账户 以太坊是一个accounting-based ledger（基于账户的去中心化的账本） 天然防御double spending attack 记录交易次数（nonce），以防御replay attack（重放攻击） 账户类型 externally owned account（外部账户） 记录： balance nonce Smart contract account（智能合约账户） 记录： balance nonce code storage 智能合约账户有以下几个特点： 合约账户无法主动发起一个交易 创建合约账户的时候会返回一个地址，可以调用这个地址 16-ETH-以太坊中的状态树 维护的功能是账户地址到账户状态的映射：addr -&gt; state 问题：如果把所有账户直接组成一个merkle tree 可以吗？ 不可以，因为修改账户时成了串行 问题：为什么比特币可以把所有交易组成一个merkle tree呢？ 因为比特币只有一个人拥有记账权，所以这个有记账权的人随意记录即可 即使以太坊使用sorted merkle tree，在有新的账户出现时也会大量的更新merkle tree中的hash值。 数据结构：trie（retrieval-检索） 数据结构：Patricia tree（trie） 树的高度变短 如果插入新的单词，原来压缩的节点可能需要扩展开 数据结构：MPT（Merkle Patricia tree） 把Patricia tree的指针改为Hash Pointer就成了MPT 数据结构：Modified MPT 下面状态树的例子中的节点有三种： Extention Node：如果路径出现压缩，就会出现此节点 Branch Node：分支节点 Leaf Node：最终的节点 16-ETH-交易树和收据树 用处： 提供Merkle proof 数据结构：bloom filter **用途：**支持查找某个元素是否在一个比较大的集合中 **实现：**把集合中的所有的hash值映射到一个小的数组中，然后把数组中的对应位置的值由0改为1。 有可能出现误报（一个值的hash映射的数组中的位置，如果是1只能说明可能存在，因为存在hash碰撞） 不会出现漏报（因为只要某个值的hash映射的数组的位置的值是0，说明此值不存在） 以太坊中如何使用bloom filter 包含在块头里面，可以快速过滤某些节点不包含指定交易；然后再在可能包含的节点中检索。 transaction-driven state machine（交易驱动的状态机） 18-ETH-GHOST协议 如果只有和父节点平级的才是uncle block 存在问题： 1、uncle block的个数只能是两个，如果分叉超过3个就无法全部包含进来。 2、故意不包含某个叔父区块 只要与当前节点有共同的主链就认为是uncle block 存在问题： 某个矿工在挖矿难度低的时候产生多个分叉（即以后节点的叔父）区块，期待以后被包含进去以获取初块奖励 GHOST协议：与当前区块在7代以内，才被认为是uncle block 距离当前区块越远的uncle block，得到的奖励越少；为了防止分叉过多，有利于鼓励出现分叉尽快合并。叔父区块得不到gas fee（汽油费） 19-ETH-挖矿算法（ethash） Block chain is secured by mining。 bug bounty：bug赏金 one cpu， one vote（一个cpu，一张投票） 设计puzzle的原则：difficult to solve， but easy to verify 以太坊的挖矿算法的目标是做到：AISC resistance memory hard mining puzzle 20-ETH-难度调整 自适应难度调整 子公式解释 难度炸弹（difficulty bomb） 以太坊发展的四个阶段 21-权益证明（Proof of stake） TWH：Terawatt hours 问题：为什么需要权益证明？ 工作量证明太费电了 初块奖励是为了激励矿工参与比特币系统的维护。 virtual mining 权益证明： 每个人按照持有币的数量来投票，省去了挖矿的过程；持有的币越多，权益越大。 持有的币只能从加密货币的系统中获取，如果有人大量购买这个币以获取权益然后搞垮他，会导致币价大涨；涨价会让搞垮这个币所付出的代价很大。 AltCoin Infanticide：把新币扼杀在摇篮里 Proof of Deposit 如果出现分叉的时候，一个人两边都挖，并不会影响他的币的数量。 Casper the Friendly Finality Gadget（FFG） 验证者有任期，验证者在任期外有等待期，如果没有人检举则给验证者保证金和奖励。 EOS币的权益证明： DPOS：Delegated Proof of Stake 22-ETH-智能合约 外部账户如何调用智能合约？ SENDER ADDRESS：调用者的地址 TO CONTRACT ADDRESS：智能合约的地址 VALUE：调用时转多少ETH GAS USED：汽油费 GAS PRICE：汽油费的价格 CAS LIMIT：此调用愿意支付的汽油费上限 TX DATA：调用的函数及其参数的编码值 一个合约如何调用另一个合约中的函数 1、直接调用 2、使用adress类型的call()函数 3、代理调用delegatecall() 错误处理 assert：一般用来判断内部条件 required：一般用于判断外部条件 revert：无条件的抛出异常 嵌套调用 先执行交易再挖矿,因为挖矿之后发布的账户状态需要先执行交易。 就算账户的代码执行错误，也会被发布；然后收取汽油费，为了防止有恶意节点发送大量的不能验证通过的交易。 问题：智能合约的代码支持多线程执行吗？ 不支持多线程,多线程可能造成执行结果的不一致。 智能合约可以获得的区块信息 智能合约可以获得的调用信息 地址类型 地址类型中的不同方法转账时的特点： transfer：会导致连锁性回滚 send：不会导致连锁性回滚 call：不会导致连锁式回滚，call的方式转账会把剩余的汽油全部发送过去 一个例子：简单拍卖 构造方法 出价和结束拍卖的方法 如果黑客的智能合约中没有callback方法怎么办？ 没有办法。。。 Code is low： 优点：没有人能够修改规则 缺点：如果规则有问题，也无法修正，导致上面的问题成为所有人的钱都取不出来 优化后的拍卖代码 无法防止重入攻击（Re-entrancy Attack） 解决的方法是，先把金额修改为0，再发起转账。 转账交易时需要使用这个步骤：先判断条件，再改变条件，再发生交互 better safe by sorry 不要使用call方法转账，因为call支付的汽油费太多 23-ETH-TheDAO DAO：Decentralized Autonomous Organization（去中心化的自治的组织） DAC：Decentralized Autonomous Corporation（去中心化的自治的公司） 因为先转账再更改余额导致被发起了重入攻击： too big to fail 升级后产生两个分叉：通过在链上增加ChainID（为了防止回放），以区分ETC(Ethereum Classic)和ETH 为什么不能只针对黑客的账户？ 因为智能合约有bug，所以就算只针对黑客的账户其他人也可以针对这个bug进行攻击。 24-ETH-思考 Is smart contract really smart？（智能合约真的智能吗） smart contract is anything but smart Nothing is irrevocable（没有什么是不可篡改的） 如TheDAO的例子；所以不能迷信“不可篡改” Is solidity the right programming language？ solidity存在一些问题，但是没有什么东西是没有问题的。所以随着时间的检验可能会出现 智能合约模板 编写智能合约的公司 虽然智能合约的内容是开源的，但是Many eyeball fallacy；在涉及到自己的利益时还是需要自己检查代码。 What does decentralization（权利下放） mean？ 分叉是去中心化和民主的体现 decentralized != distributed(去中心化不等于分布式) state machine的应用场景： mission critical application（关键任务应用程序） air traffic control（空中交通管制） stock exchange（证券交易） space shuttle（航天飞机） 智能合约是用来编写控制程序的，只有在互不信任的实体之间建立共识的操作才需要写在智能合约里 25-ETH-Beauty Chain（美链） IPO：Initial Public Offering ICO：Initial Coin Offering 美链背景介绍 下图中出现的ERC为Ethereum Request for Comments（以太坊征求意见） 因为下面的代码在计算时出现了溢出，从而导致被攻击，凭空出现了很多的代币BEC 如何预防此类（计算溢出）问题？ 26-总结 加密货币应该用在法币支持的不太好的地方，而不是用在法币已经支持的很好的地方。 下一代的的互联网是价值交换网络 Democracy is the worst from of Government except for all those other forms that have bean tried from time to time Is decentralized aways right thing?","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"肖臻老师《区块链技术与应用》","slug":"区块链/肖臻老师《区块链技术与应用》","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E8%82%96%E8%87%BB%E8%80%81%E5%B8%88%E3%80%8A%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8%E3%80%8B/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"bitcoin","slug":"bitcoin","permalink":"https://guozhe001.github.io/tags/bitcoin/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"}]},{"title":"如何开发一个CorDapp","slug":"blockchain/corda/3如何开发一个CorDapp","date":"2024-11-22T06:32:06.491Z","updated":"2024-11-22T06:32:06.491Z","comments":true,"path":"2024/11/22/blockchain/corda/3如何开发一个CorDapp/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/corda/3%E5%A6%82%E4%BD%95%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AACorDapp/","excerpt":"","text":"环境准备 JDK（8u131以上） corda训练营 代码地址： https://github.com/corda/bootcamp-cordapp 个人gitee项目：https://gitee.com/zheshiyigegexingwangzhan/bootcamp-cordapp.git 添加国内镜像 当前项目修改 下载代码之后为了更快的下载依赖，添加国内的镜像： 1maven &#123; url &#39;http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&#x2F;&#39;&#125; 直接修改全局的gradle配置 在**~/.gradle目录下新建init.gradle**文件，写入以下内容： 1234567891011121314151617181920212223allprojects&#123; repositories &#123; def ALIYUN_REPOSITORY_URL &#x3D; &#39;http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&#39; def ALIYUN_JCENTER_URL &#x3D; &#39;http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;repositories&#x2F;jcenter&#39; all &#123; ArtifactRepository repo -&gt; if(repo instanceof MavenArtifactRepository)&#123; def url &#x3D; repo.url.toString() if (url.startsWith(&#39;https:&#x2F;&#x2F;repo1.maven.org&#x2F;maven2&#39;)) &#123; project.logger.lifecycle &quot;Repository $&#123;repo.url&#125; replaced by $ALIYUN_REPOSITORY_URL.&quot; remove repo &#125; if (url.startsWith(&#39;https:&#x2F;&#x2F;jcenter.bintray.com&#x2F;&#39;)) &#123; project.logger.lifecycle &quot;Repository $&#123;repo.url&#125; replaced by $ALIYUN_JCENTER_URL.&quot; remove repo &#125; &#125; &#125; maven &#123; url ALIYUN_REPOSITORY_URL url ALIYUN_JCENTER_URL &#125; &#125;&#125; 测试代码 运行ProjectImportedOKTest单测，如果通过说明环境没有问题 我的运行结果如下： 123456789&gt; Configure project :Repository https:&#x2F;&#x2F;jcenter.bintray.com&#x2F; replaced by http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;repositories&#x2F;jcenter.&gt; Task :compileJava&gt; Task :processResources NO-SOURCE&gt; Task :classes&gt; Task :compileTestJava&gt; Task :processTestResources NO-SOURCE&gt; Task :testClasses&gt; Task :test 代码开发 State开发 一个state需要实现ContractState，ContractState中有一个方法getParticipants()，返回的是List&lt;AbstractParty&gt;,表示在这个state发生了交易时需要通知谁，让谁知道。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package bootcamp;import com.google.common.collect.ImmutableList;import net.corda.core.contracts.ContractState;import net.corda.core.identity.AbstractParty;import net.corda.core.identity.Party;import org.jetbrains.annotations.NotNull;import java.util.List;public class IouState implements ContractState &#123; /** * 发行人 */ private Party issuer; /** * 拥有者 */ private Party owner; /** * 金额 */ private int amount; public IouState(Party issuer, Party owner, int amount) &#123; this.issuer = issuer; this.owner = owner; this.amount = amount; &#125; @NotNull @Override public List&lt;AbstractParty&gt; getParticipants() &#123; return ImmutableList.of(issuer, owner); &#125; public Party getIssuer() &#123; return issuer; &#125; public Party getOwner() &#123; return owner; &#125; public int getAmount() &#123; return amount; &#125;&#125; Contract开发 一个contract简单的理解就是一些校验的规则，需要实现Contract类，Contract类如下，只有一个verify方法，验证LedgerTransaction是否正确，如果不正确就抛IllegalArgumentException异常。 12345678910interface Contract &#123; /** * Takes an object that represents a state transition, and ensures the inputs/outputs/commands make sense. * Must throw an exception if there&#x27;s a problem that should prevent state transition. Takes a single object * rather than an argument so that additional data can be added without breaking binary compatibility with * existing contract code. */ @Throws(IllegalArgumentException::class) fun verify(tx: LedgerTransaction)&#125; 在开发一个contract时，Corda提议的三个验证的类型： 输入与输出个数的校验（Shape Constraint，No. input states, No. output states, command） 输入与输出的内容的校验（Context Constraint），业务校验 需要的签名的校验（Required Singer Constraint） 按照上图的规则IouContract的实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package bootcamp;import net.corda.core.contracts.Command;import net.corda.core.contracts.CommandData;import net.corda.core.contracts.Contract;import net.corda.core.contracts.ContractState;import net.corda.core.transactions.LedgerTransaction;import org.apache.commons.collections4.CollectionUtils;public class IouContract implements Contract &#123; public static String ID = &quot;bootcamp.IouContract&quot;; @Override public void verify(LedgerTransaction tx) &#123; // 1、Shape Constraint，No. input states, No. output states, command if (tx.getCommands().size() != 1) &#123; throw new IllegalArgumentException(&quot;command size must be one&quot;); &#125; Command&lt;CommandData&gt; command = tx.getCommand(0); if (!(command.getValue() instanceof Commands.Issue)) &#123; throw new IllegalArgumentException(&quot;command must be Issue&quot;); &#125; if (CollectionUtils.isNotEmpty(tx.getInputs())) &#123; throw new IllegalArgumentException(&quot;Issue must be not inputs&quot;); &#125; if (tx.getOutputs().size() != 1) &#123; throw new IllegalArgumentException(&quot;Issue outputs must be one&quot;); &#125; ContractState output = tx.getOutput(0); // 2、Context Constraint if (!(output instanceof IouState)) &#123; throw new IllegalArgumentException(&quot;state must be IouState&quot;); &#125; IouState iouState = (IouState) output; if (iouState.getAmount() &lt;= 0) &#123; throw new IllegalArgumentException(&quot;issue amount must big than zero&quot;); &#125; // 3、Required Singer Constraint if (!command.getSigners().contains(iouState.getIssuer().getOwningKey())) &#123; throw new IllegalArgumentException(&quot;issue business must be sing by issuer&quot;); &#125; &#125; public interface Commands extends CommandData &#123; class Issue implements Commands &#123; &#125; &#125;&#125; Flow开发 flow有两种 可以在本地主动启动的flow 只能通过其他的flow启动的flow 发起一个交易的flow都是可以在本地主动启动的flow，有以下特点 需要添加注解@InitiatingFlow来表示他是一个可以初始化的flow 需要添加注@StartableByRPC或者@StartableByService来说明启动的方式 flow需要继承自FlowLogic，业务逻辑在call方法中实现 call方法需要添加@Suspendable注解 指定notary，校验是否双花 创建交易，交易中必须包含command，如果有output必须指定contract来进行验证；可以没有input 然后就是通用的流程，验证交易、收集签名、交易入库 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package bootcamp;import co.paralleluniverse.fibers.Suspendable;import com.google.common.collect.ImmutableList;import net.corda.core.contracts.StateAndRef;import net.corda.core.flows.*;import net.corda.core.identity.Party;import net.corda.core.transactions.SignedTransaction;import net.corda.core.transactions.TransactionBuilder;import net.corda.core.utilities.ProgressTracker;import static java.util.Collections.singletonList;/** * * @author nicai */@InitiatingFlow@StartableByRPCpublic class IouIssueFlowInitiator extends FlowLogic&lt;SignedTransaction&gt; &#123; private final Party owner; private final int amount; public IouIssueFlowInitiator(Party owner, int amount) &#123; this.owner = owner; this.amount = amount; &#125; private final ProgressTracker progressTracker = new ProgressTracker(); @Override public ProgressTracker getProgressTracker() &#123; return progressTracker; &#125; @Suspendable @Override public SignedTransaction call() throws FlowException &#123; // We choose our transaction&#x27;s notary (the notary prevents double-spends). Party notary = getServiceHub().getNetworkMapCache().getNotaryIdentities().get(0); // We get a reference to our own identity. Party issuer = getOurIdentity(); // We create our new IouState. IouState iouState = new IouState(issuer, owner, amount); // We build our transaction. TransactionBuilder transactionBuilder = new TransactionBuilder(notary)// .addInputState() .addOutputState(iouState, IouContract.ID) .addCommand(new IouContract.Commands.Issue(), ImmutableList.of(issuer.getOwningKey(), owner.getOwningKey())); // We check our transaction is valid based on its contracts. transactionBuilder.verify(getServiceHub()); FlowSession session = initiateFlow(owner); // We sign the transaction with our private key, making it immutable. SignedTransaction signedTransaction = getServiceHub().signInitialTransaction(transactionBuilder); // The counterparty signs the transaction SignedTransaction fullySignedTransaction = subFlow(new CollectSignaturesFlow(signedTransaction, singletonList(session))); // We get the transaction notarised and recorded automatically by the platform. return subFlow(new FinalityFlow(fullySignedTransaction, singletonList(session))); &#125;&#125; 被动启动的flow有以下特点： 需要注解@InitiatedBy(IouIssueFlowInitiator.class)指定谁能启动这个flow flow需要继承自FlowLogic，业务逻辑在call方法中实现 call方法需要添加@Suspendable注解 需要有实例变量FlowSession，保存调用者的FlowSession call方法需要验证交易，然后执行接收交易的标准流程ReceiveFinalityFlow 1234567891011121314151617181920212223242526272829package bootcamp;import co.paralleluniverse.fibers.Suspendable;import net.corda.core.flows.*;import net.corda.core.transactions.SignedTransaction;@InitiatedBy(IouIssueFlowInitiator.class)public class IouIssueFlowResponder extends FlowLogic&lt;Void&gt; &#123; private final FlowSession otherSide; public IouIssueFlowResponder(FlowSession otherSide) &#123; this.otherSide = otherSide; &#125; @Override @Suspendable public Void call() throws FlowException &#123; SignedTransaction signedTransaction = subFlow(new SignTransactionFlow(otherSide) &#123; @Suspendable @Override protected void checkTransaction(SignedTransaction stx) throws FlowException &#123; // Implement responder flow transaction checks here &#125; &#125;); subFlow(new ReceiveFinalityFlow(otherSide, signedTransaction.getId())); return null; &#125;&#125; 运行 打包 1./gradlew deployNodes 运行所有的节点 1sudo ./build/nodes/runnodes 启动一个流程 1flow start IouIssueFlow owner: PartyB, amount: 99 我本地日志如下： 1234567 ✅ Starting Requesting signature by notary service Requesting signature by Notary service Validating response from Notary service ✅ Broadcasting transaction to participants➡️ DoneFlow completed with result: SignedTransaction(id=14D268667D208D26BF92ADC1F58003DFC9EAF7E036ACB2C2CABC153E627500C0) 查询生成的数据 1run vaultQuery contractStateType: bootcamp.IouState 我本地的结果如下 123456789101112131415161718192021222324252627282930313233states:- state: data: !&lt;bootcamp.IouState&gt; issuer: &quot;O=PartyA, L=London, C=GB&quot; owner: &quot;O=PartyB, L=New York, C=US&quot; amount: 99 contract: &quot;bootcamp.IouContract&quot; notary: &quot;O=Notary, L=London, C=GB&quot; encumbrance: null constraint: !&lt;net.corda.core.contracts.SignatureAttachmentConstraint&gt; key: &quot;aSq9DsNNvGhYxYyqA9wd2eduEAZ5AXWgJTbTEw3G5d2maAq8vtLE4kZHgCs5jcB1N31cx1hpsLeqG2ngSysVHqcXhbNts6SkRWDaV7xNcr6MtcbufGUchxredBb6&quot; ref: txhash: &quot;14D268667D208D26BF92ADC1F58003DFC9EAF7E036ACB2C2CABC153E627500C0&quot; index: 0statesMetadata:- ref: txhash: &quot;14D268667D208D26BF92ADC1F58003DFC9EAF7E036ACB2C2CABC153E627500C0&quot; index: 0 contractStateClassName: &quot;bootcamp.IouState&quot; recordedTime: &quot;2020-12-03T09:49:48.373Z&quot; consumedTime: null status: &quot;UNCONSUMED&quot; notary: &quot;O=Notary, L=London, C=GB&quot; lockId: null lockUpdateTime: null relevancyStatus: &quot;RELEVANT&quot; constraintInfo: constraint: key: &quot;aSq9DsNNvGhYxYyqA9wd2eduEAZ5AXWgJTbTEw3G5d2maAq8vtLE4kZHgCs5jcB1N31cx1hpsLeqG2ngSysVHqcXhbNts6SkRWDaV7xNcr6MtcbufGUchxredBb6&quot;totalStatesAvailable: -1stateTypes: &quot;UNCONSUMED&quot;otherResults: [] 节点可视化工具 参考网站：https://docs.corda.net/docs/corda-os/4.6/node-explorer.html 可以下载node-explorer来查看节点信息。 第一次打开界面 Node Hostname：localhost Node Port：RPC connection address可以在启动的窗口查看，或者配置文件查看 RPC Username：在配置文件 RPC Password:在配置文件查看 使用spring开发corda： https://manosbatsis.github.io/corbeans/","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Corda","slug":"区块链/Corda","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Corda/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Corda","slug":"Corda","permalink":"https://guozhe001.github.io/tags/Corda/"},{"name":"CorDapp","slug":"CorDapp","permalink":"https://guozhe001.github.io/tags/CorDapp/"}]},{"title":"如何搭建一个Corda网络","slug":"blockchain/corda/4如何搭建一个Corda网络","date":"2024-11-22T06:32:06.491Z","updated":"2024-11-22T06:32:06.491Z","comments":true,"path":"2024/11/22/blockchain/corda/4如何搭建一个Corda网络/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/corda/4%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AACorda%E7%BD%91%E7%BB%9C/","excerpt":"","text":"在查看此文档之前，先查看如何开发一个CorDapp 参考文档：NMS的FAQ.md文件 1、网络服务启动，docker版的网络服务启动： 1docker run --name=network-map -e NMS_ROOT_CA_FILE_PATH=&quot;&quot; -p 8080:8080 cordite/network-map:latest 2、启动后打开接口文档用于验证启动是否成功 http://localhost:8080/swagger/#/ 3、build和配置CorDapp build之前修改build.gradle的配置，修改cordapp节点不给cordapp签名 123456cordapp &#123; signing &#123; enabled false &#125; // 其他配置&#125; 运行build命令 1./gradlew clean deployNodes 修改配置删除自动生成的key等文件 123456789pushd build/nodesfor N in */; do echo &#x27;compatibilityZoneURL=&quot;http://localhost:8080&quot;&#x27; &gt;&gt; $N/node.conf echo &#x27;devModeOptions.allowCompatibilityZone=true&#x27; &gt;&gt; $N/node.conf pushd $N rm -rf network-parameters nodeInfo-* persistence.mv.db certificates additional-node-infos popddonepopd 4、把节点注册到网络 下载网络的truststore 1curl http://localhost:8080/network-map/truststore -o ~/tmp/network-truststore.jks 每个节点都初始化注册 1234567pushd build/nodesfor N in */; do pushd $N java -jar corda.jar --initial-registration --network-root-truststore ~/tmp/network-truststore.jks --network-root-truststore-password trustpass popddonepopd 5、指定Notary节点 启动Notary节点 进到Notary节点的目录下执行,如果没有权限 1java -jar corda.jar 注意：如果报错：Unable to create logging directory /Users/apple/code/open-source/blockchain/my-corda/logs. Node will now shutdown.说明没有权限，在命令前加sudo即可 指定Notary节点 1、登陆NMS（network-map-service）并获取token信息 1TOKEN=`curl -X POST &quot;http://localhost:8080//admin/api/login&quot; -H &quot;accept: text/plain&quot; -H &quot;Content-Type: application/json&quot; -d &quot;&#123; \\&quot;user\\&quot;: \\&quot;sa\\&quot;, \\&quot;password\\&quot;: \\&quot;admin\\&quot;&#125;&quot;` 2、上传notary 1234pushd build/nodes/NotaryNODEINFO=`ls nodeInfo*`curl -X POST -H &quot;Authorization: Bearer $TOKEN&quot; -H &quot;accept: text/plain&quot; -H &quot;Content-Type: application/octet-stream&quot; --data-binary @$NODEINFO http://localhost:8080//admin/api/notaries/validatingpopd 在执行上面的命令时，注意自己当前的所在的目录，如果已经在build/nodes/Notary目录下需要退出到bootcamp-cordapp目录 6、停止Notary节点 在notary节点的shell命令行执行 bye 7、修改notary节点的validating 因为在第5步指定Notary的时候调用的是validating接口，所以确认一下notary的配置是的validating是否为true，如下 123notary &#123; validating&#x3D;true&#125; 如果配置的是validating=false则会报异常： [ERROR] 16:25:22+0800 [main] internal.NodeStartupLogging. - Exception during node startup: There is a discrepancy in the configured notary type and the one advertised in the network parameters - shutting down. Configured as validating: false. Advertised as validating: true [errorCode=r8le54, moreInformationAt=https://errors.corda.net/OS/4.3/r8le54] 8、删除Notary节点的network-parameters文件 进入到notary节点的目录，删除network-parameters文件 9、启动notary节点和其他节点 进入到各个节点的目录，启动： 1java -jar corda.jar 10、发起交易测试 可以下载node-explorer来查看节点信息并发起交易，我的测试结果如下： 扩展 因为上面的文档是按照","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Corda","slug":"区块链/Corda","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Corda/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Corda","slug":"Corda","permalink":"https://guozhe001.github.io/tags/Corda/"}]},{"title":"Corda资料整理","slug":"blockchain/corda/2区块链开发框架-Corda学习总结","date":"2024-11-22T06:32:06.491Z","updated":"2024-11-22T06:32:06.491Z","comments":true,"path":"2024/11/22/blockchain/corda/2区块链开发框架-Corda学习总结/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/corda/2%E5%8C%BA%E5%9D%97%E9%93%BE%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6-Corda%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/","excerpt":"","text":"0. Corda资料整理 官网 油管频道 Corda中文文档 开发文档 Corda中文社区 Stack Overflow讨论区, corda标签 Corda Training 1. Corda是什么？ Corda是为企业构建的开源区块链/分布式账本帐平台；Corda使企业可以使用智能合约在严格的隐私下直接进行交易，从而降低交易和记录保存成本，并简化业务运营。 Corda不会定期将需要确认的交易分批处理再分成块之后一次性确认。相反，Corda会实时确认每笔交易。 1.0 Corda有哪些概念 1.0.1 网络 一个Corda网络由运行着Corda和CorDapps的节点构成的 不同的节点间的沟通是点对点的，不依赖于全局广播 每个节点都可以使用一个数字证书来将真实世界中的法律身份和网络身份相关联 这个网络是一个需要许可的网络，需要从网络维护者那里申请一个数字证书来获得访问权限 1.0.2 账本 每个账本是针对于每一个节点的 对于账本上的共享事实，共享的两方（或多方）总是能够保证存在他们自己的账本中的事实是完全一致的 在 Corda 中是 没有唯一的中心化存储的数据 的。每个节点维护着一个独立的数据库，其中包含了所知道的事实。所以每个 peer 只能够看到账本中的事实中的一部分，没有节点能够知道所有的内容。 1.0.3 States State 代表的是存在账本上的事实 State 通过将原来的 State 变为历史记录然后添加一条新版本的 state 的方式来对 state 进行更新 每个节点都有一个 vault 来存储该节点所有相关的 States 1.0.3.0 State 顺序 个共享的事实的生命周期是可以通过 state 顺序 来体现。当一个 state 需要更新的时候，我们会创建一个代表新的 state 的新版本的 state，然后将原来的那个 state 标注为历史版本。 1.0.3.1 Vault Corda 网络中的每一个节点都维护着一个 vault - 它是一个数据库，其中跟踪了所有 states 的当前以及历史的 states 数据，以及跟它有关的数据： 1.0.3.2 参考 states 并不是所有的 states 都需要被使用他们的节点来更新的。对于参数数据的情况，有一种常见的模式，一方创建了参考数据，这些数据会被其他方使用（但是不会被更新）。对于这种情况，states 中包含的参考数据被称为 “参考 states”。 1.0.4 Transactions Transaction 是关于更新账本的提议；（个人理解：更准确的说应该是更新账本上的某些states的提议） 一个 transaction 提议只能在满足以下条件的时候才会被提交： 它不包含“双花” 它是合约有效的 它需要被所有相关方提供签名 Corda 使用 UTXO (未消费的 transaction output) 模型来使账本上的每条 state 都不可更改。对于账本上数据的变更都是通过使用 transaction 的方式来做的，就是将 0 条或多条已经存在的账本 states 变为历史记录（inputs），然后再新增0条或多条新的账本 states （outputs）。交易代表了 state 顺序中的一个单独的链接。 **个人理解：**这一点和比特币很像，不同点是比特币的交易只需要支付的人的签名，而这里的transaction需要所有人相关人的签名 一个 transaction 中可以包含任何数量任何类型的 inputs 和 outputs： 可以包含多种类型的 state（cash, bonds） 可以是 issuances 类型（有0个input）或者 exists 类型（有0个 output） 可以合并或拆分可替换的资产（比如把一个 $2 的 state 和 $5 的 state 合并为 $7 的 cash state） Transaction 是 原子性操作，一个 transaction 里边的所有 changes 必须要全部执行，或者一个也不会执行。 有两种基本类型的 transactions： Notary-change transactions（用来变更 state 的 notary - 查看 Notaries） General transactions（其他任何类型的 transaction） 1.0.4.1 交易链 一个新的 transaction 的 output state 在账本中应该是还不存在的，所以需要提出 transaction 的一方来创建。但是 transaction 中包含的 input 应该是在账本中已经存在的，应该是前一个 transaction 添加进去的 output。所以我们需要在新的 transaction 中引用这些已经存在的记录。 这些 Input state 的引用包含两部分(个人理解：与比特币的交易链一样)： 创建这个 input 的 transaction 的 hash 这个 input 所指的前一个 transaction 带来的 output state 在 output list 中的位置或者索引值 1.0.4.2 提交交易 初始的时候，一个 transaction 仅仅是一个更新账本的 提议。它表示了经过这次更新后账本的新的状态： 为了成为真正的一笔交易，transaction 必须要获得所有 要求的签名*（查看下边的 *command）。每一个要求的签名者会将签名附加在 transaction 上来表示他们已经同意了这次更新： 如果得到了所有需要的签名，这个 transaction 就会被提交了： 一旦提交就意味着： Transaction 的 input 被标注为历史记录，并且不能再被之后的 transactions 使用了 Transaction 的 output 变为账本上的当前状态的一部分 1.0.4.3 交易的有效性 每一个被要求的签名方应该只有在满足以下两个条件的时候才应该提供签名： Transaction 是有效的：对于当前的 transaction 提案以及产生当前提案的 Input 相关的所有以前的所有 transactions 的链条中： Transaction 应该获得所有相关方的数字签名 Transaction 是 合约有效 的 Transaction 唯一性：本次 transaction 提案要消费的 inputs 没有被任何已经存在的其他的已提交的 transaction 消费过 1.0.4.4 参考 states 正如 States 所描述的，一些 states 需要被其他的 input 或者 output states 的合约代码所引用，但是不需要被修改/消费。这就需要参考 states。当一个 state 被添加到一笔交易的参考 states 列表中，而不是 inputs 或者 outputs 列表的时候，那么它就被作为 参考 state。在常规的 states 和参考 states 间有两点区别： 交易的节点指定的 notary 会检查参考 state 是不是当前的。然而，当包含他们的交易被提交到账本的时候，参考 states 是不会被消费的。 对于参考 states 的合约代码也不会被包含他们的交易所执行。 1.0.4.5 其他的交易组件 就像 input states 和 output states 一样，transactions 还可能会包含下边的组件： Commands Attachments Timestamps Notary 比如一个交易中，Alice 使用 £5 的现金向 Bob 支付了一个 IOU 的 £5。该笔交易包含了两个附件，并且只能够在 notary pool 在指定的时间窗内收到该笔交易的时候被 NotaryClusterA 进行公证，看起来像下边这样： 1.0.4.5.1 Commands 翻译视频讲解Corda 核心概念 - Commands Commands是什么？ Commands 是一些动词（verbs） Commands 将 transaction 进行参数化（parameterise），这样除了从 State 中能够获取的信息外，commands 又能提供了更多的一些信息 Commands 也提示（hint）了 transaction 的意图（intent） Commands 也可能包含通过 Oracle Service 提供的数据（off-ledger data） 一些 Commands 典型的例子： 发布（issue）新的 State 到账本上 交换（transfer）资产到账本中的另一方 付钱（pay）给账本中的另一方 偿还（redeem）一笔资产并结束/清除代表该资产的state 尝试（exercise）一个选项 option 履行（settle）一个义务来递交一个资产 如何知道一个 transaction 都需要谁来提供签名呢？我们会把一个公钥列表关联至一个 command，来说明都谁需要对这个 command 提供签名。 一个 command中会包含一个公钥列表（public key list），通过这个列表就知道了都会涉及哪些人来确认/签名该 state transaction 在 transaction中，input 和 output states 经常会被按照类别分组（还可能根据其他的条件进行分组） 每一组 state 都需要有一个 command 1.0.4.5.2 Attachments 有些时候，我们会有一些数据可以在不同的 transactions 中被重用。比如： 一个公共假期的 calendar 支持的法律文档 一个货币代码的表格 针对这些情况，我们使用附件。一个 transaction 可以通过 hash 引用 0 个或者多个附件。这些附件是 ZIP/JAR 文件，可以包含任何内容。这些附件中信息可以用来验证 transaction 的有效性。 1.0.4.5.3 Time-window 一些时候，我们希望一个交易仅仅在一个指定的时间点被批准执行。例如： 在一个指定的日期之后执行一个选项 一个债券只能在它的过期日期前被赎回 在这些情况下，我们给 transaction 添加一个 time-window。time-windows 制定了交易会在哪个时间点被提交。 1.0.4.5.4 Notary **个人理解：**为了在issuance/genesis 交易中提供公证证明的，证明此交易的合法性。 1.0.5 Contracts **个人理解：**与以太坊的智能合约类似 一个有效的 transaction 必须要被它的所有 input 和 output states中的 contract 接受 Contracts 需要使用 JVM 编程语言编写（java 或者 kotlin） Contract 的执行是一定要有一个确定性结果的，并且它对于一个 transaction 的接受是仅仅基于 transaction 的内容 1.0.5.1 Transaction 验证 一个 transaction 仅仅当被所有要求的签名方提供了签名之后才会被认为是有效的。但是，除了获得到所有人的签名之后，还必须要满足 合约有效 才会被最终认为有效。 合约有效 的定义包含以下几点： 每个 state 都指定了一个 合约 类别 合约将交易(transaction)作为输入，并根据合约规则说明该交易是否有效 仅当every input state和** every output state **的合约都认为其有效时，交易(transaction)才有效 我们可以用下图来描述这个关系： 合约代码可以用任何JVM语言编写，并可以使用该语言的全部功能，包括： 检查 inputs，outputs，commands 的数量，时间，附件 检查这些组件中的任何一个的内容 循环构造，变量分配，函数调用，辅助方法等 将一些类似的 states 分组来验证（比如对于所有的现金 state 的组合定义一个规则） 一个 transaction 如果不是合约有效的话，是不会被视为一个对账本的有效更新，也就不可能被提交至账本。通过这种方式，合同对state随时间的变化施加了规则，这些规则与所需签名者签署给定交易的意愿无关。 1.0.5.2 The contract sandbox **个人理解：**为了保证验证的结果不根据外部的条件而改变，Corda提供了一个沙箱，以防止代码引入可能会造成不确定性结果的外部库 Deterministic Corda Modules Transaction 验证必须是 一个确定性的结果： 在一个确定的transaction提议中，一个 contract 必须总是接受 或者 总是拒绝。比如 transaction 是否有效不能够取决于你在什么时间做的 verify 或者是基于某一方具有的信息量的多少来决定是有效的还是无效的。这是一个很重要的条件来确保网络上的相关节点能够在这个对账本的更新的操作达成共识。 1.0.5.3 Contract 的局限性 因为 contract 没有办法访问到外部的信息，它只能检查 transaction 内部的有效性，比如它不能够检查确认当前这个 transaction 是不是已经同其他相关方达成了共识取得了其他方的确认。 所以在各方提供最终的签名确认之前，各方应该对transaction 的内容进行检查来确定他们是否同意这个对账本的更新，即使这个 transaction 是合约有效的。任何一方都没有义务因为transaction是是合约有效而提供签名。比如他们可能不愿意去提供一个巨额的借款，或者可能不会同意购买一个资产花费的钱的金额。 1.0.5.4 Oracles 有时，交易有效性将取决于某些外部信息，例如汇率。在这些情况下，需要一个oracle。有关更多详细信息，请参见Oracle。 1.0.5.5 Legal prose 每一个合约也会引用一个 legal prose 文档，这个文档中定义了合约中规定的内容，legal prose 也会被传统的法律系统所接受。这个文档会在发生法律纠纷的时候被用来进行判定依据。 1.0.6 Flows Flows 使同意更新账本的流程变得自动化 节点之间的沟通只能够在这些 Flows 的上下文中发生，并且是点对点的 内置的 flows 提供了常用的一些任务 Corda 网络使用点对点的消息传输而不是全局广播。也就是说协调一个关于账本的更新需要网络上的参与者明确的指定需要发送什么信息，发送给谁，按照什么顺序发送。 1.0.6.1 Flow 框架 一个 flow 是一系列有顺序的步骤来告诉一个节点应该如何实现一个指定的账本更新，比如发行一个资产或者结算一笔交易。 下边是一个上边图片所描述的简单账本更新所涉及到的顺序的流程： 1.0.6.2 运行 flows 一旦一个业务流程被封装在了一个 flow 中并且在节点中作为 CorDapp 的一部分被安装好之后，节点的所有者可以在任何时间通过使用一个 RPC call 来告诉节点开始这个业务流程。Flow 将所有的网络，I/O 和并发问题都抽象了出来，这个节点 owner 就不需要关注这些了。 节点上所有的动作都是发生在这些 flows 的上下文上的。与 contract 不同，flows 不是在 sandbox 里执行的，也就是说节点可以在执行一个 flow 的过程中来进行一些动作比如 networking，I/O 或者随机地使用一些资源。 1.0.6.3 节点内部通信 节点间是通过在不同的 flows间传递消息来进行沟通的。每个节点有0个或者多个注册的 flow classes 来回复另外个一个单独的 flow 的消息。 假设 Alice 是网络中的一个节点，并且她希望同 Bob（网络中的另一个节点） 一起同意一次账本的更新。为了跟 Bob 进行沟通， Alice 必须： 开始一个 Bob 已经注册过的 flow Alice 在这个 flow 的上下文中给 Bob 发送一个消息 Bob 会启动它注册的这个 conterparty flow 连接已经建立起来了，Alice 和 Bob 就可以像 flow 步骤中描述的那样来回地沟通关于一个更新账本的改动并且最终达成一致。 1.0.6.4 Subflows Flows 可以通过在另外一个 flow 的上下文中开始一个新的 flow 作为一个子流程的方式被组成。作为子流程被启动的 Flow 被称为 subflow。父 flow 需要等待所有的 subflow 完成后才会继续运行。 1.0.6.5 Flow 类库 Corda 对于一些常规的任务都提供了一套代码库（API: Flows），所以开发者就不需要自己去定义这些常见流程背后的逻辑了，比如： 公正和记录一个 transaction 从相关节点搜集签名 验证交易链 1.0.6.6 并发 Flow 框架允许节点可以同时运行多个 flows。这些 flows 可能由于节点的重启甚至升级会持续几天。 这个可以通过在 flow 变成阻塞的状态的时候，将 flows 序列化到硬盘中的方式来实现（比如他们在等待 I/O 或者是网络的调用）。出现这种情况的时候，节点不会等待这个阻塞状态的 flow变成非阻塞的状态，而会立即运行其他的 flow，只会在稍后返回到原来这个阻塞的flow。 1.0.7 consensus(共识) 为了交易能够被提交，transaction 必须要同时满足有效性和 唯一性的共识 有效性共识需要 transaction 和 它的所有依赖都是合约有效的 唯一性共识可以避免“双花” 1.0.7.1 两种类型的共识 判断一个交易的提案是否是一次有效的账本更新要达到两种类型的共识： 有效性共识：这给是交易所要求的签名者在提供他们签名之前去校验的 唯一性共识：这个只会被 notary service 去验证 1.0.7.1.1 有效性共识 有效性共识是关于验证下边所描述的条件对于提交的 transaction 和生成该该 transaction 的 inputs 的交易链中的每次 transaction 都必须要满足： Transaction 中的每个 input 和 output 的 contracts 所接受 Transaction 得到了所有要求的签名 仅仅检查交易提案本身信息是不够的。我们还需要检查跟产生当前这个 transaction 的 inputs 有关的所有以前的 transaction 链。 这个被称作 walking the chain。假设，例如网络中的一个节点提交了一个交换债券的一笔交易。我们只有了解下边的情况才能确保这个债券的交换是有效的： 这个债券应该是由中心银行发行的，而且应该是在一次有效的发行交易中 关于这个债券的后续交易记录也应该都是有效的 确保两点都满足的唯一方式就是查看整个交易链。我们可以用下图表示： 当确认一个交易提案的时候，给定的一方可能没有它需要验证的交易链上的所有交易信息。这种情况下，他可以向交易的提出方索要缺少的那部分交易。交易的提出方应该永远会有整个的交易链信息，因为他们应该在验证之前的交易中已经获取了相关的交易链信息。 1.0.7.1.2 唯一性共识 设想一下 Bob 持有有效的由中央银行发行的 $1,000,000 现金 state。Bob 可以创建两个交易提案： 一笔交易要跟 Charlie 用这 $1,000,000 交换 £800,000 一笔交易要跟 Dan 用这 $1,000,000 交换 €900,000 这会是一个问题，因为尽管这两笔交易都可以通过有效性共识，但是 Bob 确实现了一次“双花 double spend” 他的美元来获得了两倍价值的 GBP 和 EUR。我们可以用下图表示这个流程： 为了避免这样的问题发生，一个有效的交易提案同时也要满足唯一性共识。唯一性共识要求一个 transaction 的 input 不能被任何其他的 transaction 消费掉过。 当一个交易中的一个或多个 inputs 已经被其他的交易消费掉的情况，通常被称为 双花，那么相关的交易应该被视为无效的交易。 唯一性共识是由 notaries 提供的。查看 Notaries 了解更多详细信息。 1.0.8 Notaries Notary 集群避免 “双花” Notary 集群也可以是时间戳授权。如果一笔交易包含一个 time-window，那么它只能在这个 time-window 内被公证 Notary 集群也可以可选地用来验证交易，在这种情况下他们被称为 “用于验证” 的 notaries，相对于 “非验证” 的 notaries 一个网络中可以有多个 notaries，每一个 notary 运行一个不同的共识算法 1.0.8.1 概览 一个 notary 集群 是一个网络服务，通过证明一个给定的交易的 input 是没有被其他的交易消费过的方式提供了 唯一性共识。 当被要求为一笔交易进行公证的时候，一个 notary 集群会进行下边两种操作中的一种： 如果对于给定的交易中的 input，没有任何其他的交易已经消费该 input 的时候，会提供签名 拒绝这笔交易并且标明产生了双花的情况 通过这样做，notary 集群就在系统中提供了一个终结点。在最终获得 notary 集群的签名之前，交易各方并不能确定交易的有效性。但是当收到了 notary 集群的签名之后，我们可以确认的是，交易中的 Input 是没有被其他任何的交易所消费过的。因此公证（notarisation）在系统里是最后的一步。 每个 state 都会有一个指定的 notary 集群，而且一个 notary 集群也只会去公正那些 input 指定它为 notary 集群的 transaction。 1.0.8.2 共识算法 Corda 拥有一套 “可插拔” 的共识，允许 notary 集群根据不同的需求（私有化、扩展性、法律系统的兼容性和算法的便捷性）来选择一种共识算法。 特别的，notary 集群可能含有下边的不同： 结构： 一个 notary 集群可能是一个单独的网络节点，或者是互相信任的节点集群，或者是互不信任的节点集群 共识算法： 一个 notary 集群可能会选择运行一个高速，高信任的算法（比如 RAFT），或者一个低速低信任的算法（比如 BFT），又或者是任何其他的选择的共识算法 1.0.8.3 验证 一个 notary 集群还需要选择是否在提交之前通过验证每个 transaction 的有效性来提供这种 有效性共识 服务。为了做出这个选择，他们需要面对下边的取舍问题： 如果一个 transaction 没有 被验证了正确与否（非验证 notary），那么这就增加了 “denial of state” 袭击的风险，指的就是某个节点知道这是一个不正确的 transaction 会消费到一些 states，然后该节点还是把这个 transaction 发送给 notary 集群，但是 notary 如果不进行正确性验证的话，会把这个 state 变为历史记录被消费掉，这显然是不正确的 如果 transaction 已经 被验证了正确与否（验证 notary），notary 需要查看该 transaction 的全部内容以及它的所有依赖。这就向 notary 暴露了一些潜在的隐私数据。 当我们考量这些取舍的时候，有一个后续观点需要始终要考虑的。对于非验证模式，Corda 的控制的数据分布模型意味着未被消费的 states 不会被大面积的共享。另外， Corda 的 permissioned network 也意味着 notary 能够存储造成 “denial of state” transaction 的一方的身份信息，这就允许能够在账本外去解决掉这个袭击。 对于验证模式，对于匿名的使用，使用新生成的公钥而不是使用法律的标识来标记一笔交易的各方也限制了 notary 集群能够看到的信息。 1.0.8.4 数据的可视性 下边是关于哪些特殊的交易组件必须要暴露给每种类型的 notary 的一个总结： Transaction components Validating Non-validating Input states Fully visible References only [1] Output states Fully visible Hidden Commands (with signer identities) Fully visible Hidden Attachments Fully visible Hidden Time window Fully visible Fully visible Notary identity Fully visible Fully visible Signatures Fully visible Hidden 两种类型的 notaries 都会记录调用方的身份信息：公钥以及 X.500 唯一的名字。 1.0.8.5 多个 Notaries 每个 Corda 网络可以存在多个 notary 集群，每个 notary 集群可能会运行一套不同的共识算法。这会带来以下的好处： 隐私性 - 我们可以在同一个网络中同时拥有验证和非验证的 notary 集群，每个集群运行着不同的算法。这就允许节点针对每个 transaction 来选择更喜欢的不同的 notary。 负载平衡 - 将 transaction 的工作分发给多个 notary 集群可以提高平台整体的交易吞吐量 低延迟 - 通过选择物理上离交易方最近的 notary 集群来获得最小化的延迟 1.0.8.6 更换 notaries 一个 notary 集群只有当它是这个 transaction 里的所有 input states 指定的 notary 的情况下才可以提供签名。然而下边的情况可能需要换一个 state 的指定的 notary 集群，包括： 当一个 transaction 需要消费的 states 中指定了不同的 notary 集群 当一个节点因为隐私和效率的考虑希望选择一个不同的 notary 集群 当这样的 transactions 被创建之前，states 必须首先被指定到同一个 notary 集群。这可以通过一个改变 notary 的 transaction 来实现: 一个 input state output state与input state相同，但指定的notary群集已更改 如果该 transaction 不会造成“双花”，这个 input state 指定的 notary 会为该 transaction 提供签名，这种情况下，一个新的 state 会产生，它的所有属性和旧的 state相同，但是会指向一个不同的 notary 集群。 1.0.9 Vault Vault 中存储的是跟节点的所有者相关的从账本上得到的数据，以关系模型存储以方便查询和使用。 Vault 同时会追踪未消费掉的和已消费掉的 states： Unconsumed：未消费掉的 （或者未使用的） states 代表了可以用来花费的 fungible states （包括 spend-to-self 交易）以及可以用来更新的 linear states （比如对于一笔交易的生命周期）或者从一方转换给另一方。 Consumed：已消费掉的 （或者已使用的） states 代表了为了交易报表、审计和归档的目的而在账本上存储的不可更改的 state，包括进行同 app-private 数据进行关联的能力（比如客户的 notes）。 一个称为 soft locking 的功能提供了自动或者显式地预定 states 而避免同一个节点尝试同时在多笔交易中使用相同的 output 的能力。这种情况最终会被一个 notary 发现，soft locking 提供了一种能够在早期就发现这种无根据和不正确的情况的机制。Soft Locking 提供了更详细的的关于这个功能的描述。 Vault 支持管理需授权的（“on-ledger”）的数据，也可以管理 shadow（“off-ledger”）形式的数据： “On-ledger” 数据指的是指公司参与的分布式账本的state （现金、交易、）。 “Off-ledger” 数据指的是公司内部的参考数据、静态或者系统数据。 下边的图表展示了将 vault 拆分为子系统组件： 注意以下几点： Vault “On Ledger” 存储并追踪未消费掉的 state，并且在将一笔交易记录到账本的时候由节点内部进行更新（会按照成功执行了智能合约验证以及受到所有参与方的签名） Vault “Off Ledger” 存储了交易记录以外节点的所有者添加的额外的数据 Vault 对 fungible state 进行了花费（并且在将来，fungible state 的优化管理包括合并、拆分以及再发行）。 Vault 扩展代表了开发者可以编写的额外的自定义 plugin 代码，用来查询指定的自定义 contract state 属性。 客户的 “Off Ledger”（私有的存储）代表了内部的组织型数据，可能被用来跟 vault 数据进行关联来进行额外的报表或者处理。 Vault Query API 可以使用标准的 Corda RPC 和 CorDapp plugin 机制暴露给开发者。 Vault 更新 API 可以被交易记录的 flows 内部使用。 Vault 数据库 schemas 可以通过 JDBC 和自定义的 joins 和查询进行直接地访问。 1.0.10 Time-windows 如果一个 transaction 包含了一个 time-window，那么这个 transaction 只能在这个 time-window 里被提交 Notary 具有控制发生的时间的权利，当在 time-window 之外的时候，notary 可以拒绝提交 transaction Time-window 可以有开始和结束时间，或者只有两者之中的一个 1.0.10.1 分布式系统中的时间 Notary 也可以作为 时间戳的验证者，在它确认一笔交易前，需要确保这笔交易是发生在指定的时间窗里。 为了让一个时间窗有意义，它必须要在一方请求它的时候被绑定。一方可以获得一个 time-window 的签名，以此来证明有些事件是在特定时间点 之前、当时 或者 之后 发生的。然而，如果交易参与者不能够在指定的 time-window 内提交到相关的交易，它可以选择是否在未来的某个时间点将这个事实暴露出去。因此，我们需要确保 notary 或者能够在一些可容错的时间范围内对交易进行签名，或者同时进行打时间戳 和 对交易进行公证。后边的这种方式是这个模型中使用的方式。 在创建交易的一方和 notary 之间是无法实现时间的同步的。这并不仅仅是因为物理或者网络的延迟，还会因为在插入命令和获得 notary 签名之间可能会发生很多其他的步骤（比如发送交易到涉及到的其他节点，请求人工的审批等）。所以交易被发送到 notary 的时间和交易创建的时间可能会不同。 1.0.10.2 Time-windows 因为上面的原因，交易中涉及到的时间会被制定为一个时间窗，而不是一个绝对的时间。在一个分布式系统中是永远不会有 “真实的时间” 的，只有一个大概的时间。时间窗可以是开放的（比如在某个时间点后，或者某个时间点之前）或者是一个闭合的范围。 通过这种方式，我们表达了我们的想法，就是 “当前的时间” 永远都是未知的。甚至当在某个时间之前和之后都被包含的时候，交易也可能会在那个时间窗中的任何时间发生。 通过在一端创建一个关闭或者开放的范围，我们允许用以下的方式生成时间窗模型： 一笔交易在指定时间之后的某个时间发生（比如在一个终止事件之后） 一笔交易在指定时间之前的任何时间发生（比如破产事件之前） 一笔交易在指定时间区间的某个时间发生（比如在指定的某一天） 1.0.11 Oracles 一个事实（fact）可以作为 command 的一部分被添加到一个 transaction 中 一个 oracle 是一个服务，它只会为那些包含正确事实的 transaction 提供签名 很多时候 transaction 的合约有效性需要依赖一些外部的数据，比如当前的汇率是多少。如果让每个参与方给予他们对于汇率的观点来验证 transaction 的有效性的话，合约的执行就会变得没有确定性了：一些参与者可能会认为 transaction 是有效的，而其他的参与者可能认为无效。因此，在真正账本中的 state 之上就会提出一些不同的意见。 Corda 通过使用 Oracle 来解决这个问题。Oracle 是一个网络服务，可以根据要求提供包含某一事实的命令（比如在某个时间的汇率）并且将 Oracle 列为要求签名的一方。 如果一个节点希望在一个 transaction 中使用某一个事实，那么它可以提出从 Oracle 来获取该事实的一个命令。如果 Orale 认为这个事实是正确的，它会返回这个要求的命令。然后这个节点就可以把这个命令添加到 transaction 中了，然后 oracle 会为这个事实是真的提供签名。 为了隐私性的目的，Oracle 不需要能够访问交易的每个部分，他们唯一需要的信息就是看到他们内置的、跟这个 Oracle 相关的 command(s)。我们也应该提供让这些需要提供签名的 Oracle 实体能够看到这些 commands 的保证，但是不包括其他的部分。为了实现这个，我们使用过滤过的交易，是指交易的提案方使用一个内嵌的默克尔树的方式来将一些非相关的交易的部分隐藏掉。查看 Transaction tear-offs 了解关于交易如何拿掉工作的详细信息。 如果他们想为他们的服务定价，Oracles 可以选择只为那些包含服务费的交易提供签名并证明它包含的事实的有效性。 1.0.12 node（节点） Corda 中的节点指的是在网络中具有唯一标识的运行着 Corda 服务和 CorDapps 的 JVM 运行时环境。 节点对于外部世界包含两个接口： 网络层，用来同其他的节点通信 RPC，为了跟节点的所有者通信 节点的功能是通过在 plugin registry 里安装 CorDapps 方式来扩展的 1.0.12.1 节点架构 下边是节点的内部架构图： 架构中的核心元素包括： 存储数据的持久化层 同其他节点沟通的网络接口 同节点的所有者进行沟通的 RPC 接口 允许节点的 flows 来调用节点其他服务的 service hub plugin registry 用来通过安装 CorDapps 来扩展节点 1.0.12.2 持久层 持久层包含两部分： Vault，节点用来存储相关的当前和历史的 states 数据 存储服务，用来存储 transaction, attachment 和 flow checkpoints 节点的所有者可以通过使用 RPC 接口来查询节点的 storage。 1.0.12.3 网络接口 同网络中的其他节点进行沟通是节点自己来处理的，作为运行一个 flow 的一部分。节点的所有者不会直接地同网络中其他的节点进行交互。 1.0.12.4 RPC 接口 节点的所有者是通过使用 Remote Procedure Calls(RPC) 来跟节点进行交互的。关键的节点暴露的 RPC 操作可以查看 API: RPC 操作。 1.0.12.4 The service hub 在节点内部，节点可以在 flow 的执行过程中访问丰富的服务来协助更新账本。主要的服务包括： 有关网络上其他节点及其提供的服务的信息 访问 vault 和存储服务的内容 访问和生成节点的公钥私钥对 节点本身的信息 节点跟踪的当前时间 1.0.12.5 CorDapp 提供者 CorDapp 提供者是新的 CorDapps 被安装的地方，来扩展节点的行为。 节点默认会安装一些 CorDapps 来处理一些常见的任务，比如： 从合作方那边获得交易和附件信息 更新合约 向交易其他方广播同意的账本更新信息 1.0.12.6 排空节点模式 为了执行一次干净的关闭节点操作，没有正在执行的 flows 非常重要，也就是说应该没有任何的 checkpoints 被持久化。节点能够被设置为排空状态，在这个状态中： 通过 RPC 要求的启动新的 flows 的命令会被拒绝 预约的 flows 会被忽略 初始化 P2P 的会话消息将不会被处理，意味着 peers 将不能够初始化新的 flows 其他所有的活动还会照常进行，来确保正在执行的 flows 的数量在不断减少。 对于他们的数量 - 可以通过 RPC 来进行监控 - 达到0，那么就是安全的了，可以进行关闭节点的操作了。这个属性是持久的，也就是说重新启动这个节点也不会重置这个值到默认和值，并且需要一个 RPC 命令。 节点可以使用 shell 来被排空然后安全地关闭。 1.0.13 Transaction tear-offs（交易剥离） 隐藏交易组件出于隐私目的 Oracle和非验证公证人只能看到其“相关”交易组件，而不能看到完整的交易详细信息 1.0.13.1 总览 在某些情况下，交易中涉及的某些实体可能只对交易部分具有部分可见性。例如，当一个甲骨文应该签署一个交易时，它唯一需要查看的信息就是与该甲骨文命令相关的嵌入式信息。同样，非验证公证人只需要查看交易的输入状态即可。向Oracle提供任何其他交易数据将构成隐私泄漏。 为了解决这个问题，我们使用过滤交易的概念，其中交易提议者使用嵌套的默克尔树方法“剥离”Oracles/Notraries不需要的交易任何部分，然后再提交给他们进行签名。默克尔树是一种众所周知的加密方案，通常用于提供包含和数据完整性的证明。 Merkle树被广泛用于对等网络，区块链系统和git。 默克尔树的优点是，在向Oracle提交交易时被剥离的交易部分以后就无法更改，而又不会使Oracle的数字签名无效。 1.0.13.2 Transaction Merkle trees 通过将transaction拆分为叶子，从transaction中构造Merkle树，其中每个叶子包含输入，输出，命令或附件。最终的嵌套树结构还包含事务的其他字段，例如时间窗口，公证人和必需的签名者。 如下图所示，唯一需要两棵树而不是一棵树的组件类型是command，为了可视性目的，该命令分为命令数据和必需的签名者。 Corda使用每种组件类型的嵌套Merkle树。简而言之，针对每种组件类型（即输入，输出，附件）生成一个组件子树。然后，这些子树的根形成顶部的Merkle树的叶子，最后，该树的根代表交易ID。 另一个重要特征是，以每个随机数独立的方式为每个组件确定性地生成一个随机数。然后，我们使用随机数及其对应的组件来计算组件哈希，即实际的Merkle树叶。需要使用随机数来防止暴力攻击，否则可能会泄露低熵散列值（即单个单词的文本附件）的内容。 计算完叶子后，通过散列当前节点下面的哈希值的连接，以正常方式构建每棵Merkle树。 上图中的交易有三个input，两个output，两个command，一个attachment，一个notary和一个 time-window。请注意，如果树不是完整的二叉树，则将叶子填充为具有零哈希值的最接近的2的幂（因为找到sha256（x）== 0的原像是困难的计算任务）-上面标记为浅绿色。最后，根的哈希是交易的标识符，它也用于签名和验证数据完整性。叶子级别上的每次交易更改都会更改其标识符。 1.0.13.3 Hiding data 隐藏数据并提供证明它构成事务一部分的证据是通过构造部分Merkle树（或Merkle分支）来完成的。 Merkle分支是一组散列，根据叶的数据，这些散列用于计算根的散列。然后，将该哈希与整个交易的哈希进行比较，如果它们匹配，则意味着我们获得的数据属于该特定交易。 假设只有第一个命令对Oracle是可见的。我们还应该保证所有需要该Oracle签名的命令对于Oracle实体都应该是可见的，而其余部分则不可见。这是此过滤后的交易将如何在Merkle树结构中表示的方式。 向Oracle服务提供了蓝色节点和H(c2)，而省略了黑色节点。 HH(c2)是必需的，这样Oracle可以计算H(commandData)而不必看到第二条命令，但同时确保CommandData1是事务的一部分。突出显示所有签名者都是可见的，以证明没有恶意删除任何相关命令（Oracle应该看到）。此外，当前的Corda协议中还提供了子树的哈希（紫色节点）。在特殊情况下需要知道他们下面的数据，例如需要知道组件组是否为空时。 同样，如果我们想将同一交易发送给非验证notary，则应隐藏除输入状态，时间窗口和公证人信息之外的所有组件。该数据足以使公证人知道应检查哪些input statues进行双花，时间窗口是否有效以及此事务是否应由该notary公证。 1.0.14 权衡 许可的网络会更好的适合金融的 user-cases 点对点的通信允许信息是基于需要知道的原则被共享 UTXO model 允许每秒钟能够处理更多的 transactions 1.0.14.1 需要许可 vs 和不需要许可的 传统的 blockchain 是 不需要许可 的。网络中的各方都是匿名的，而且可以随时加入或离开。 不同的是， Corda 网络是 需要许可 的。网络中的每一方都有一个大家都知道的标识，这个会在同其他节点进行沟通的时候使用，并且访问网络是由一个 doorman 来控制的。这有一下的好处： 匿名的用户对于大多数跟金融有关的情况都是不适用的 知道你的合作方的身份可以允许当出现冲突的时候，可以使用已经存在的法律系统在账本外进行解决 可以不通过使用昂贵的机制（比如工作量证明 proof-of-work）来避免女巫攻击（Sybil attacks） 1.0.14.2 点对点 vs 全局广播 传统的 blockchain networks 将每一条信息广播给网络上的所有参与者。原因是： 合作方的身份是不知道的，所以一条消息需要发给网络上的所有人来确保原本需要收到这条消息的接受者能够接收到 让所有参与者知道每一个 transaction 能够允许网络防止“双花” 不好的地方是所有的参与者都能看到所有其他人的数据。这在很多的 use-cases 是无法接受的。 在 Corda 中，每条消息都会指定一个具体的合作方，而且是不会被任何其他无关方看到的。开发者能够完全掌控什么消息被发送了，发送给了谁，应该按照什么顺序发送。所以 数据是根据需要知道的原则来共享的。为了避免“双花”，我们引入了 notaries 来替换掉工作量证明（proof-of-work）。 Corda 也是用了其他的一些技术来最大化的包括网络上的隐私： Transaction 隐藏：Transactions 被结构化成不暴露 transaction 的内容就可以被数字化地签名。这个是通过使用一种叫默克尔树的数据结构来实现的。 随机化秘钥：一个 transaction 的所有参与方是通过他们的公钥进行识别的，并且针对每一个 transaction 都会生成 一个新的 keypairs。所以一个监视者无法识别出来对于一个给定 transaction 都哪些方参与了。 1.0.14.3 UTXO vs. 账户模型 Corda 使用 UTXO（Unspent Transaction Output）model。每个 transaction 都会消费一系列的已经存在的 states 然后再生成一些新的 states。 相反的一种方式是 账户 模型。在账户模型中，stateful 对象被存在账本上，transaction 会通过请求的方式来对这些对象的当前的 state 进行更新。 UTXO 模型的主要优点在于含有不同的 inputs 的 transactions 能够并行地被执行，很大程度上地增加了网络中每秒能够处理的 transactions。在账户模型中，每秒钟能够处理的 transactions 数量有限，因为对于一个给定的 object 的更新需要按照给定的顺序来执行。 1.0.14.4 代码即法律 vs. 既有的法律系统 金融体系需要在需要的时候使用传统的法律体系来解决冲突的能力。Corda 被设计用来使这个成为可能： 拥有需要准入的网络，意味着所有参与方都能够知道在每一个 transaction 中他们都在跟谁打交道 所有代码合约背后都存在有描述着合约意图行为的法律文档，这个文档可以在解决冲突的时候使用 1.0.14.5 构建 vs. 重用 任何可能的情况，Corda 会使用 已经存在的技术来让这个平台更加的健壮。比如 Corda 重用了： 用于开发CorDapps的标准JVM编程语言 已经存在的 SQL database 已经存在的 消息队列实现 1.0.15 Deterministic JVM 个人理解：为了达成共识，Corda要求所有的节点运行相同的JVM沙箱，叫做DJVM；DJVM为了让智能合约的代码每次执行的结果都相同而做了一些限制。 1.1 开发语言语言是什么？ 开发语言与智能合约的语言都是使用 JVM 编程语言编写（java 或者 kotlin） 源码使用kotlin语言编写 1.2 网络是什么样的？ 可以选择加入corda.network，Corda Network由总部位于荷兰的非营利基金会管理。 Corda Network参与者有资格投票并代表基金会董事会做出重要决定，包括网络标准，参数和政策。 或者搭建自己的私有网络，下载corda网络管理软件，需要填写信息 1.3 Corda是如何达成共识的？ 假如A发起一个交易给B转账500元，那么A需要提交一个交易（transaction）并签名；然后把交易发送给B（如果需要Notary和Oracle参与也会把need-to-know的部分发送给他们）；B验证交易没有问题（包括整个交易链、智能合约是否验证通过、是否同意当前的交易、Notary和Oracle是否签名等）就会提供签名然后提交这次交易。并把签名后的交易发送给A，A也执行相同的提交交易动作。 1.4 CorDapps是什么？ CorDapps是以plugin的形式运行在node上的“应用”；一个node可以有多个CorDapps，比如一个银行的node可以既有贷款的CorDapp，也有存款的CorDapp。 CorDapp包含state, transaction, contract和flow类。 1.5 Corda的隐私保护是怎么做的？ 1.5.1 在网络中的各节点之间的隐私保护 Corda的网络需要申请加入并且对应了现实世界中的一个合法身份，所以不可以把交易信息公开。 Corda的交易是通过一个节点发起的，除了交易涉及的其他节点知道全部的交易内容；和Oracle以及Notary知道交易的部分需要验证的内容之外，对其他节点来说是不知道这个交易的。所以在隐私性方面是比较好的。 比特币和以太坊中的身份信息与现实世界的身份是没有对应关系的，所以把所有的账户和交易信息放在互联网上也是安全的。 1.5.2 在验证双花和依赖Oracle签名时的隐私保护 Corda通过Transaction tear-offs的方式在需要Notary做唯一性校验或需要Oracle提供签名时，提供的只有need-to-know的部分，并不包含交易的所有内容，所以隐私得到了保护。 1.6 Corda交易的实时性怎么样？ Corda交易相较于比特币和以太坊来说比较实时，因为Corda不必等待挖矿只要交易被校验通过，所有人都签了名就写在了区块链上了。（以太坊和比特币需要在挖到矿之后打包很多个交易，所以实时性会差一些） 1.7 Corda中是否有以太坊中的账本的概念？ 个人理解：Corda也有账本的概念，但是Corda账本所包含的内容远比以太坊的账本（只有余额）要多；Corda的账本有很多不同类型的state，Corda只保管了当前的state和历史state，但是Corda没有一个汇总的显示余额的“账本”；应该可以在账本外记录。 1.8 Corda中账户（Accounts）是什么？ Corda中的Accounts是一个虚拟的概念，值得是一个节点的Vault的states打上标签来表示归属的账户；这个账户和节点的账户不一样，Account就像个人在银行（节点）开的账户（Account）。 1.9 Corda可以发布币吗？可以挖矿吗？ 没有数字货币，因此也不能挖矿。因为共识协议也并不是通过工作量证明完成，而是通过交易的涉及方和一些公证人和Oracle来达成共识的，所以也不需要挖矿。 1.10 Corda的Contract和以太坊中的智能合约有什么区别？ 不同点： Corda的Contract主要是为了来做验证交易是否正确的，不可以做以太坊智能合约的转账的操作。 以太坊中的智能合约是一个特殊的账户，里面有余额、交易次数、代码、存储等；但是Corda的Contract只有代码，只用来验证交易是否正确。 相同点： 只要执行中遇到异常就表示验证不通过；能够证明交易非法（不符合合约内容）。 3、如何基于Corda构建应用 详情查看： 如何开发一个CorDapp 如何搭建一个Corda网络 4、Corda汇总 Corda优点 隐私保护做的很好，交易只有涉及到的节点才知道 提供了一些通用的State类，如现金、商品、商业票据、利率交换、债务等 开发CorDapp简单，可以直接使用Java开发并且有模板和套路可循","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Corda","slug":"区块链/Corda","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/Corda/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Corda","slug":"Corda","permalink":"https://guozhe001.github.io/tags/Corda/"}]},{"title":"Uniswap学习","slug":"blockchain/ethereum/DeFi/Uniswap学习","date":"2024-11-22T06:32:06.491Z","updated":"2024-11-22T06:32:06.491Z","comments":true,"path":"2024/11/22/blockchain/ethereum/DeFi/Uniswap学习/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/DeFi/Uniswap%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"uniswap v2 源码下载 源码学习 安全审查是谁做的，怎么做的，评判标准有哪些 uniswap 的交互流程 比如Alice想要把tokenA兑换成tokenB，与合约的交互流程大体如下： Approve：Alice批准uniswap使用tokenA合约的金额 Swap：Alice调用uniswap进行兑换 把Alice的tokenA转给LP 把LP的tokenB转给Alice 还有一种情况是Bob使用ETH兑换SHIB（用eth兑换token），流程如下： Bob调用uniswap进行swap，并把ETH转给Uniswap合约 uniswap把收到的ETH转给WETH合约，并且uniswap获得了相同金额的WETH（这一步是把ETH兑换成符合ERC20标准的WETH） uniswap调用WETH合约把相同金额的WETH转给ETH-SHIB-LP（流动池） ETH-SHIB-LP调用SHIB合约把相应金额的SHIB转给Bob ![image-20210514162529644](/Users/apple/Library/Application Support/typora-user-images/image-20210514162529644.png) uniswap v2的的LP是如何赚钱的？年化多少？是否稳定？ 收益来自于交易，如果没有交易则LP无法赚钱，不稳定 他们标得APY是如何计算的？ uniswap v2的一些资源 info.uniswap可以根据合约搜索token的数据 一些细节问题 路径上的每次计算都要收取手续费 如果我想要用tokenA换tokenC，但是LP中只有tokenA-tokenB和tokenB-tokenC，因此在兑换路径会变成tokenA-&gt;tokenB-&gt;tokenC。在使用这样的路径兑换时tokenA-&gt;tokenB和tokenB-&gt;tokenC都会收取手续费（千分之3） 手续费每次都是收取前面的token的千分之3，如上面例子的兑换路径会收取tokenA和tokenB的千分之3 新建流动性是有最小流动性限制的 如果当前LP池中没有tokenA-tokenZ交易对，那么在第一次创建这个交易对时是需要满足tokenA Liquidity Providers在提供了流动性之后得到的是什么 会得到交易对对应的ERC20的份额 无常损失: 因为价格变动导致添加到LP中的资产的价格少于不提供流动性的价格。 部分代码理解 swap时，根据输入tokenA的值获取应该兑换的tokenB的值： 12345678910111213141516171819202122&#x2F;&#x2F; given an input amount of an asset and pair reserves, returns the maximum output amount of the other assetfunction getAmountOut(uint amountIn, uint reserveIn, uint reserveOut) internal pure returns (uint amountOut) &#123; require(amountIn &gt; 0, &#39;UniswapV2Library: INSUFFICIENT_INPUT_AMOUNT&#39;); require(reserveIn &gt; 0 &amp;&amp; reserveOut &gt; 0, &#39;UniswapV2Library: INSUFFICIENT_LIQUIDITY&#39;); &#x2F;&#x2F; x * y &#x3D; x&#39; * y&#39; &#x3D; k; x &#x3D; reserveIn， y &#x3D; reserveOut &#x2F;&#x2F; x‘ &#x3D; amountIn的千分之997 uint amountInWithFee &#x3D; amountIn.mul(997); &#x2F;&#x2F; numerator &#x3D; x&#39; * y uint numerator &#x3D; amountInWithFee.mul(reserveOut); &#x2F;&#x2F; denominator &#x3D; x + x&#39; uint denominator &#x3D; reserveIn.mul(1000).add(amountInWithFee); &#x2F;&#x2F; amountOut &#x3D; (x&#39; * y) &#x2F; (x + x&#39;)；推导公式如下： &#x2F;&#x2F; (x + x&#39;) * (y - y&#39;) &#x3D; x * y &#x2F;&#x2F; y - y&#39; &#x3D; x * y &#x2F; (x + x&#39;) &#x2F;&#x2F; y&#39; &#x3D; y - x * y &#x2F; (x + x&#39;) &#x2F;&#x2F; y&#39; &#x3D; (y(x + x&#39;) - x * y) &#x2F; (x + x&#39;) &#x2F;&#x2F; y&#39; &#x3D; (y * x + y * x&#39; - x * y) &#x2F; x + x&#39; &#x2F;&#x2F; y&#39; &#x3D; (y * x&#39;) &#x2F; (x + x&#39;) &#x2F;&#x2F; amountOut &#x3D; (x&#39; * y) &#x2F; (x + x&#39;) amountOut &#x3D; numerator &#x2F; denominator;&#125; uniswap中的其他技术学习 Canonical WETH 什么是WETH，原文内容总结如下： ETH是以太坊上的本地代币，而不是ERC20标准代币 因此在DApp操作符合ERC20规范的代币时，如果涉及到了ETH操作起来会比较麻烦 为了方便，DApp的开发者做了符合ERC20标准的代币来代替ETH WETH是目前比较安全和社区支持较高的ERC20标准的ETH代币 mainnet合约地址 Uniswap V3 存入资金池的数量和兑换的价格是不一样的 如下图，当前ETH的价格是3942.1，如果加入资金池的比例是1个ETH对应1953.42个USDT。 审核 trailofbits在审核uniswap时考虑了什么方面： 代码是否遵循最佳实践 单元测试覆盖率 白皮书的完成程度，以及白皮书中的内容是否有错误 访问控制 算数运算 代码结构 可升级性 验证和测试 审核时提到的一些技术或工具 https://github.com/crytic/slither UniswapV2和V3版本比较 V3版本增加了“集中流动性”概念，LP可以只在一定的价格范围内提供流动性 这样可以避免太多的无常损失 可以提高资金利用率 V3版本的交易费用不再重新复投到LP池中，需要LP提供者手动“收割” V3版本支持单一资产存入LP池，条件是设置的价格范围不在当前的市场价格范围内；（这样可以允许你设置一个期望的价格来达成交易，如下图的限价单，你可以在价格为3987.2时指定在4498～4460之间提供流动性，这样在价格到达这个范围时就会把ETH兑换成DAI） 这是一个好用的功能，但是你必须密切注意价格，如果你想要DAI则需要在到达这个区间时手动退出，即不再提供流动性","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"DeFi","slug":"区块链/ethereum/DeFi","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/DeFi/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"1INCH","slug":"1INCH","permalink":"https://guozhe001.github.io/tags/1INCH/"}]},{"title":"结合交易页面与源码看1INCH的兑换逻辑","slug":"blockchain/ethereum/DeFi/结合源码看1inch的兑换逻辑","date":"2024-11-22T06:32:06.491Z","updated":"2024-11-22T06:32:06.491Z","comments":true,"path":"2024/11/22/blockchain/ethereum/DeFi/结合源码看1inch的兑换逻辑/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/DeFi/%E7%BB%93%E5%90%88%E6%BA%90%E7%A0%81%E7%9C%8B1inch%E7%9A%84%E5%85%91%E6%8D%A2%E9%80%BB%E8%BE%91/","excerpt":"","text":"1INCH的主要优缺点 优点 支持主流的DEX，计算的兑换路径比较 支持用户自定义允许的最大划点、交易速度（gas费价格） 缺点 在计算好兑换路径之后，可能会因为兑换链路过长而导致价格已经变化；此时会回滚交易，浪费了gas费又没有成交 在交易时如果gas费没有用完，会归1INCH合约所有而不是返还给调用者。 1INCH的主要逻辑 总结成一句话是在以太坊网络上查询其他的去中心化交易所的兑换汇率，然后通过拆分或者过渡令牌交换的方式选择最佳的兑换方式。 两种兑换方式 过渡令牌 如下图ETH/USDT的交易对，1inch算出的最佳方案是先兑换成sUSD，再用sUSD兑换WETH，再用WETH兑换ETH。 拆分 下面的SNX/USDT交易对的图显示先用过渡令牌，最后一步时拆分到两个交易所兑换SNX。 目前支持的DEX Uniswap Uniswap V2 Kyber Bancor Oasis Curve Mooniswap Dforce XSwap Shell mStable CHAI BDAI Aave Fulcrum Compound Iearn Idle WETH 背后的逻辑 代币源码：1INCH 是一个ERC20代币 总共发行15亿枚 可以被销毁（必须由持有者允许） 合约代码如下，没有其他的特殊性 1234567891011contract OneInch is ERC20Permit, ERC20Burnable, Ownable &#123; constructor(address _owner) public ERC20(&quot;1INCH Token&quot;, &quot;1INCH&quot;) EIP712(&quot;1INCH Token&quot;, &quot;1&quot;) &#123; _mint(_owner, 1.5e9 ether); transferOwnership(_owner); &#125; function mint(address to, uint256 amount) external onlyOwner &#123; _mint(to, amount); &#125;&#125; 协议源码：1inchProtocol 此协议描述了1INCH的工作原理（此协议的代码比较多，只看了一下主要的流程忽略了具体的交易所实现），在兑换时的步骤具体如下： 使用getExpectedReturn方法试算本次的最佳兑换方式 使用getExpectedReturnWithGas方法试算在考虑gas费的情况下的最佳兑换方式 使用前面的方法返回的值（兑换多少，和兑换渠道）作为参数调用swap方法进行兑换 试算兑换金额和路径的getExpectedReturn 1234567891011121314151617181920212223242526272829303132&#x2F;&#x2F;&#x2F; @notice Calculate expected returning amount of &#96;destToken&#96;&#x2F;&#x2F;&#x2F; @param fromToken (IERC20) Address of token or &#96;address(0)&#96; for Ether&#x2F;&#x2F;&#x2F; @param destToken (IERC20) Address of token or &#96;address(0)&#96; for Ether&#x2F;&#x2F;&#x2F; @param amount (uint256) Amount for &#96;fromToken&#96;&#x2F;&#x2F;&#x2F; @param parts (uint256) Number of pieces source volume could be splitted,&#x2F;&#x2F;&#x2F; works like granularity, higly affects gas usage. Should be called offchain,&#x2F;&#x2F;&#x2F; but could be called onchain if user swaps not his own funds, but this is still considered as not safe.&#x2F;&#x2F;&#x2F; @param flags (uint256) Flags for enabling and disabling some features, default 0function getExpectedReturn( IERC20 fromToken, &#x2F;&#x2F; 从A币 IERC20 destToken, &#x2F;&#x2F; 兑换成B币 uint256 amount, &#x2F;&#x2F; 出多少A币 uint256 parts, &#x2F;&#x2F; 允许拆分成多少份 uint256 flags &#x2F;&#x2F; See contants in IOneSplit.sol &#x2F;&#x2F; gas费) public view returns( uint256 returnAmount, &#x2F;&#x2F; 可以兑换多少B币 uint256[] memory distribution &#x2F;&#x2F; 拆分权重数组，描述的是在哪个交易所兑换多少 )&#123; (returnAmount, , distribution) &#x3D; getExpectedReturnWithGas( fromToken, destToken, amount, parts, flags, 0 );&#125; 交换方法swap 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485&#x2F;&#x2F;&#x2F; @notice Swap &#96;amount&#96; of first element of &#96;tokens&#96; to the latest element of &#96;destToken&#96;&#x2F;&#x2F;&#x2F; @param tokens (IERC20[]) Addresses of token or &#96;address(0)&#96; for Ether&#x2F;&#x2F;&#x2F; @param amount (uint256) Amount for &#96;fromToken&#96;&#x2F;&#x2F;&#x2F; @param minReturn (uint256) Minimum expected return, else revert&#x2F;&#x2F;&#x2F; @param distribution (uint256[]) Array of weights for volume distribution returned by &#96;getExpectedReturn&#96;&#x2F;&#x2F;&#x2F; @param flags (uint256[]) Flags for enabling and disabling some features, default 0&#x2F;&#x2F;&#x2F; @param referral (address) Address of referral&#x2F;&#x2F;&#x2F; @param feePercent (uint256) Fees percents normalized to 1e18, limited to 0.03e18 (3%)function swapWithReferralMulti( IERC20[] memory tokens, uint256 amount, uint256 minReturn, uint256[] memory distribution, uint256[] memory flags, address referral, uint256 feePercent) public payable returns(uint256 returnAmount) &#123; require(tokens.length &gt;&#x3D; 2 &amp;&amp; amount &gt; 0, &quot;OneSplit: swap makes no sense&quot;); require(flags.length &#x3D;&#x3D; tokens.length - 1, &quot;OneSplit: flags array length is invalid&quot;); require((msg.value !&#x3D; 0) &#x3D;&#x3D; tokens.first().isETH(), &quot;OneSplit: msg.value should be used only for ETH swap&quot;); require(feePercent &lt;&#x3D; 0.03e18, &quot;OneSplit: feePercent out of range&quot;); uint256 gasStart &#x3D; gasleft(); Balances memory beforeBalances &#x3D; _getFirstAndLastBalances(tokens, true); &#x2F;&#x2F; Transfer From if (amount &#x3D;&#x3D; uint256(-1)) &#123; amount &#x3D; Math.min( tokens.first().balanceOf(msg.sender), tokens.first().allowance(msg.sender, address(this)) ); &#125; tokens.first().universalTransferFromSenderToThis(amount); uint256 confirmed &#x3D; tokens.first().universalBalanceOf(address(this)).sub(beforeBalances.ofFromToken); &#x2F;&#x2F; Swap tokens.first().universalApprove(address(oneSplitImpl), confirmed); oneSplitImpl.swapMulti.value(tokens.first().isETH() ? confirmed : 0)( tokens, confirmed, minReturn, distribution, flags ); Balances memory afterBalances &#x3D; _getFirstAndLastBalances(tokens, false); &#x2F;&#x2F; Return returnAmount &#x3D; afterBalances.ofDestToken.sub(beforeBalances.ofDestToken); require(returnAmount &gt;&#x3D; minReturn, &quot;OneSplit: actual return amount is less than minReturn&quot;); tokens.last().universalTransfer(referral, returnAmount.mul(feePercent).div(1e18)); tokens.last().universalTransfer(msg.sender, returnAmount.sub(returnAmount.mul(feePercent).div(1e18))); emit Swapped( tokens.first(), tokens.last(), amount, returnAmount, minReturn, distribution, flags, referral, feePercent ); &#x2F;&#x2F; Return remainder if (afterBalances.ofFromToken &gt; beforeBalances.ofFromToken) &#123; tokens.first().universalTransfer(msg.sender, afterBalances.ofFromToken.sub(beforeBalances.ofFromToken)); &#125; if ((flags[0] &amp; (FLAG_ENABLE_CHI_BURN | FLAG_ENABLE_CHI_BURN_BY_ORIGIN)) &gt; 0) &#123; uint256 gasSpent &#x3D; 21000 + gasStart - gasleft() + 16 * msg.data.length; _chiBurnOrSell( ((flags[0] &amp; FLAG_ENABLE_CHI_BURN_BY_ORIGIN) &gt; 0) ? tx.origin : msg.sender, (gasSpent + 14154) &#x2F; 41947 ); &#125; else if ((flags[0] &amp; FLAG_ENABLE_REFERRAL_GAS_SPONSORSHIP) &gt; 0) &#123; uint256 gasSpent &#x3D; 21000 + gasStart - gasleft() + 16 * msg.data.length; IReferralGasSponsor(referral).makeGasDiscount(gasSpent, returnAmount, msg.data); &#125;&#125;","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"DeFi","slug":"区块链/ethereum/DeFi","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/DeFi/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"1INCH","slug":"1INCH","permalink":"https://guozhe001.github.io/tags/1INCH/"}]},{"title":"AutoShark Finance被套利分析","slug":"blockchain/ethereum/Exploit&Attack/AutoShark-Finance被套利分析","date":"2024-11-22T06:32:06.491Z","updated":"2024-11-22T06:32:06.491Z","comments":true,"path":"2024/11/22/blockchain/ethereum/Exploit&Attack/AutoShark-Finance被套利分析/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/Exploit&Attack/AutoShark-Finance%E8%A2%AB%E5%A5%97%E5%88%A9%E5%88%86%E6%9E%90/","excerpt":"","text":"事件总结与影响 此次事件“攻击者”通过闪电贷借出大量BNB再利用SHARK合约逻辑漏洞操纵BNB-SHARK池来获得大量SHARK，最后把获得的SHARK兑换成BNB获利 用户质押的SHARK数量没有损失 因为生成了大量的SHARK然后将其抛售导致SHARK价格下跌，官方给的数据是从1.2跌倒0.01，目前的价格如下图： 事件信息 AutoShark官方提供：AutoShark如何被经济利用 慢雾：AutoShark Finance 被黑分析 PeckShield分析 交易信息 pantherswap autoshark.finance pancakeswap 当前项目正在审计中，由WatchPug公司 事件分析 这里直接复用慢雾安全团队的分析步骤，我会结合token的流转和源码和具体的合约地址等再进一步解释。 为了方便分析，我给涉及到的地址打上了对应的功能标签： address对应的tag 解释 AS-Exploiter AutoShark-Exploiter的地址 Pancake-WBNB-BUSD-LP Pancake的WBNB-BUSD流动池，是本次事件的入口，在这个LP闪电贷的BNB AS-Exploiter-Contract AutoShark-Exploiter创建的合约地址 Panther-SHARK-BNB-LP Panther的SHARK-BNB流动池 攻击步骤如下： 1. 攻击者从 Pancake 的 WBNB/BUSD 交易对中借出大量 WBNB； 对应的交易中的token转移如下： 此处是通过调用Pancake-WBNB-BUSD-LP合约的swap方法来实现的，具体代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&#x2F;&#x2F; this low-level function should be called from a contract which performs important safety checksfunction swap(uint amount0Out, uint amount1Out, address to, bytes calldata data) external lock &#123; &#x2F;&#x2F; 至少有一个token兑换出的金额大于0 require(amount0Out &gt; 0 || amount1Out &gt; 0, &#39;Pancake: INSUFFICIENT_OUTPUT_AMOUNT&#39;); &#x2F;&#x2F; 获取当前lp池中的两个token的储备数量 (uint112 _reserve0, uint112 _reserve1,) &#x3D; getReserves(); &#x2F;&#x2F; gas savings &#x2F;&#x2F; 兑换出的token数量必须小于当前池中的token数量 require(amount0Out &lt; _reserve0 &amp;&amp; amount1Out &lt; _reserve1, &#39;Pancake: INSUFFICIENT_LIQUIDITY&#39;); uint balance0; uint balance1; &#123; &#x2F;&#x2F; scope for _token&#123;0,1&#125;, avoids stack too deep errors address _token0 &#x3D; token0; address _token1 &#x3D; token1; &#x2F;&#x2F; 接收兑换token的地址不能是当前lp池中的token中的任意一个 require(to !&#x3D; _token0 &amp;&amp; to !&#x3D; _token1, &#39;Pancake: INVALID_TO&#39;); &#x2F;&#x2F; 如果token0兑换出的金额大于0，则把amount0Out转账给指定的地址to if (amount0Out &gt; 0) _safeTransfer(_token0, to, amount0Out); &#x2F;&#x2F; optimistically transfer tokens if (amount1Out &gt; 0) _safeTransfer(_token1, to, amount1Out); &#x2F;&#x2F; optimistically transfer tokens &#x2F;&#x2F; 如果参数data不为空，则调用合约to的pancakeCall方法；接下来就是合约to的表演了 if (data.length &gt; 0) IPancakeCallee(to).pancakeCall(msg.sender, amount0Out, amount1Out, data); &#x2F;&#x2F; 当合约to表演完之后，分别获取当前lp在两个token中的余额 balance0 &#x3D; IERC20(_token0).balanceOf(address(this)); balance1 &#x3D; IERC20(_token1).balanceOf(address(this)); &#125; &#x2F;&#x2F; 如果新的余额大于（当前存储量-兑换出的数量），则amount0In等于新的余额 - （当前存储量-兑换出的数量） &#x2F;&#x2F; amount0In和amount1In是在计算实际进来了多少 uint amount0In &#x3D; balance0 &gt; _reserve0 - amount0Out ? balance0 - (_reserve0 - amount0Out) : 0; uint amount1In &#x3D; balance1 &gt; _reserve1 - amount1Out ? balance1 - (_reserve1 - amount1Out) : 0; &#x2F;&#x2F; 如果两个都是0，说明新的balance都不大于（存储量-兑换出的金额）；这说明没有进来，那么就报错； &#x2F;&#x2F; 其实这个校验是在说打给当前lp池的token数量必须大于兑换出去的数量 require(amount0In &gt; 0 || amount1In &gt; 0, &#39;Pancake: INSUFFICIENT_INPUT_AMOUNT&#39;); &#123; &#x2F;&#x2F; scope for reserve&#123;0,1&#125;Adjusted, avoids stack too deep errors &#x2F;&#x2F; 计算调整后的balance，此处会收取千分之二的费用 uint balance0Adjusted &#x3D; balance0.mul(1000).sub(amount0In.mul(2)); uint balance1Adjusted &#x3D; balance1.mul(1000).sub(amount1In.mul(2)); &#x2F;&#x2F; 调用此方法后的两个token的积必须大于等于原始储备的两个token的积；即还回来的token在收完手续费之后必须大于借出去的 require(balance0Adjusted.mul(balance1Adjusted) &gt;&#x3D; uint(_reserve0).mul(_reserve1).mul(1000**2), &#39;Pancake: K&#39;); &#125; _update(balance0, balance1, _reserve0, _reserve1); emit Swap(msg.sender, amount0In, amount1In, amount0Out, amount1Out, to);&#125; 本地事件的第一步就是调用swap，入参如下： 123456789Function: swap(uint256 amount0Out, uint256 amount1Out, address to, bytes data) ***MethodID: 0x022c0d9f[0]: 00000000000000000000000000000000000000000000152d02c7e14af6800000[1]: 0000000000000000000000000000000000000000000000000000000000000000[2]: 00000000000000000000000022de6648685e4e47fd944e68b264e0e0667e2e00[3]: 0000000000000000000000000000000000000000000000000000000000000080[4]: 0000000000000000000000000000000000000000000000000000000000000001[5]: 0100000000000000000000000000000000000000000000000000000000000000 前面的三个参数是在描述“兑换100000个BNB和0个BUSD给AS-Exploiter-Contract”，然后因为data参数不为空，所以会调用AS-Exploiter-Contract合于的pancakeCall方法。 2. 将第 1 步借出的全部 WBNB 中的一半通过 Panther 的 SHARK/WBNB 交易对兑换出大量的 SHARK，同时池中 WBNB 的数量增多； 对应的交易中的token转移如下： 此处是一个兑换动作，调用合约的话其实有多种方式实现，下面是一种实现方式，调用PantherPair.sol的swapExactTokensForTokens方法。 1234567891011121314function swapExactTokensForTokens( uint amountIn, uint amountOutMin, address[] calldata path, address to, uint deadline) external virtual override ensure(deadline) returns (uint[] memory amounts) &#123; amounts &#x3D; PantherLibrary.getAmountsOut(factory, amountIn, path); require(amounts[amounts.length - 1] &gt;&#x3D; amountOutMin, &#39;PantherRouter: INSUFFICIENT_OUTPUT_AMOUNT&#39;); TransferHelper.safeTransferFrom( path[0], msg.sender, PantherLibrary.pairFor(factory, path[0], path[1]), amounts[0] ); _swap(amounts, path, to);&#125; 3. 将第 1 步和第 2 步的 WBNB 和 SHARK 打入到 SharkMinter 中，为后续攻击做准备； 4. 调用 AutoShark 项目中的 WBNB/SHARK 策略池中的 getReward 函数，该函数会根据用户获利的资金从中抽出一部分手续费，作为贡献值给用户奖励 SHARK 代币，这部分操作在 SharkMinter 合约中进行操作； 5. SharkMinter 合约在收到用户收益的 LP 手续费之后，会将 LP 重新拆成对应的 WBNB 和 SHARK，重新加入到 Panther 的 WBNB/SHARK 交易池中； 6. 由于第 3 步攻击者已经事先将对应的代币打入到 SharkMinter 合约中，SharkMinter 合约在移除流动性后再添加流动性的时候，使用的是 SharkMinter 合约本身的 WBNB 和 SHARK 余额进行添加，这部分余额包含攻击者在第 3 步打入 SharkMinter 的余额，导致最后合约获取的添加流动性的余额是错误的，也就是说 SharkMinter 合约误以为攻击者打入了巨量的手续费到合约中； 7. SharkMinter 合约在获取到手续费的数量后，会通过 tvlInWBNB 函数计算这部分手续费的价值，然后根据手续费的价值铸币 SHARK 代币给用户。但是在计算 LP 价值的时候，使用的是 Panther WBNB/SHARK 池的 WBNB 实时数量除以 LP 总量来计算 LP 能兑换多少 WBNB。但是由于在第 2 步中，Panther 池中 WBNB 的数量已经非常多，导致计算出来的 LP 的价值非常高； 对应的SharkMinter方法: 123456789101112131415161718192021function mintFor(address flip, uint _withdrawalFee, uint _performanceFee, address to, uint, uint boostRate) override external onlyMinter returns(uint mintAmount) &#123; uint feeSum &#x3D; _performanceFee.add(_withdrawalFee); uint tax &#x3D; 0; if (flip &#x3D;&#x3D; address(PANTHER)) &#123; tax &#x3D; feeSum.mul(PANTHER.transferTaxRate()).div(10000); &#125; IBEP20(flip).safeTransferFrom(msg.sender, address(this), feeSum.sub(tax).sub(1)); uint sharkBNBAmount &#x3D; tokenToSharkBNB(flip, IBEP20(flip).balanceOf(address(this))); address flipToken &#x3D; sharkBNBFlipToken(); IBEP20(flipToken).safeTransfer(sharkPool, sharkBNBAmount); IStakingRewards(sharkPool).notifyRewardAmount(sharkBNBAmount); &#x2F;&#x2F; 这里计算的贡献变大了 uint contribution &#x3D; helper.tvlInBNB(flipToken, sharkBNBAmount).mul(_performanceFee).div(feeSum); &#x2F;&#x2F; 所以计算出的要铸造的shark的数量也变大了 uint mintShark &#x3D; amountSharkToMint(contribution).mul(boostRate).div(10000); mint(mintShark, to); mintAmount &#x3D; mintShark;&#125; 合约StrategyHelperV1的tvlInBNB方法: 12345678910111213141516171819function tvlInBNB(address _flip, uint amount) override public view returns (uint) &#123; if (_flip &#x3D;&#x3D; address(PANTHER)) &#123; return pantherPriceInBNB().mul(amount).div(1e18); &#125; address _token0 &#x3D; IPantherPair(_flip).token0(); address _token1 &#x3D; IPantherPair(_flip).token1(); if (_token0 &#x3D;&#x3D; address(WBNB) || _token1 &#x3D;&#x3D; address(WBNB)) &#123; &#x2F;&#x2F; _flip是lp，因为此交易对的bnb很多，所以在得到的bnb就很大 uint bnb &#x3D; WBNB.balanceOf(address(_flip)).mul(amount).div(IBEP20(_flip).totalSupply()); return bnb.mul(2); &#125; uint balanceToken0 &#x3D; IBEP20(_token0).balanceOf(_flip); &#x2F;&#x2F; 因为之前使用大量的bnb兑换token，导致price变大了 uint price &#x3D; tokenPriceInBNB(_token0); &#x2F;&#x2F; (((balanceToken0 * price) &#x2F; 1e18) * 2 * amount) &#x2F; totalSupply return balanceToken0.mul(price).div(1e18).mul(2).mul(amount).div(IBEP20(_flip).totalSupply());&#125; 8. 在 LP 价值错误和手续费获取数量错误的情况下，SharkMinter 合约最后在计算攻击者的贡献的时候计算出了一个非常大的值，导致 SharkMinter 合约给攻击者铸出了大量的 SHARK 代币； 对应的交易中的token转移如下：图中从0地址到SharkMinter就是在铸造大量的SHARK。 9. 攻击者后续通过卖出 SHARK 代币来换出 WBNB，偿还闪电贷。然后获利离开。 对应的交易中的token转移如下： 此步骤的操作逻辑比较简单，主要是调用Panther-SHARK-BNB-LP合约的swapTokensForExactTokens方法；然后再把WBNB转给Pancake 的 WBNB/BUSD 交易对（调用WBNB的transfer方法）来偿还闪电贷。 事件处理结果 AutoShark官方给的补偿计划： 使用新的代币$JAW代替原来的$SHARK 以被攻击前一个区块作为快照将$JAW分配给此时的$SHARK持有人 在180天里将所有金库的盈利的30%给$JAW的持有者 之前每铸造100个$SHARK，然后再额外铸造15个$SHARK给研发人员；接下来的60天里每铸造100个$JAW将其中的15个$JAW给$JAW的持有者。 将在PantherSwap平台发起IPO所得的部分BNB分配给$JAW持有者（金额没说） 将自己平台持有的所有$SHARK全部销毁 集成ChainLink的资产报价 PantherSwap关停所有$SHARK的LP池","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"Exploit&Attack","slug":"区块链/ethereum/Exploit-Attack","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/Exploit-Attack/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"solidity","slug":"solidity","permalink":"https://guozhe001.github.io/tags/solidity/"},{"name":"智能合约","slug":"智能合约","permalink":"https://guozhe001.github.io/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"},{"name":"Exploit&Attack","slug":"Exploit-Attack","permalink":"https://guozhe001.github.io/tags/Exploit-Attack/"}]},{"title":"Belt Finance事件分析","slug":"blockchain/ethereum/Exploit&Attack/Belt Finance事件分析","date":"2024-11-22T06:32:06.491Z","updated":"2024-11-22T06:32:06.491Z","comments":true,"path":"2024/11/22/blockchain/ethereum/Exploit&Attack/Belt Finance事件分析/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/Exploit&Attack/Belt%20Finance%E4%BA%8B%E4%BB%B6%E5%88%86%E6%9E%90/","excerpt":"","text":"事件总结与影响 本次一共通过8次交易，每次交易循环同样的流程7次 导致beltBUSD的价格从1.018262跌到0.800687，beltBUSD金库损失了21.36%的存款 导致4Belt LP 的价格从1.017904跌到0.961767，4Belt LP 的持有者损失了5.51% 事件信息 Belt Finance的审计由SOOHO和HAECHI AUDIT提供 涉及到的合约 TAG 解释 BF-Attacker Belt Finance事件交易发起人地址 BF-A-Contract Belt Finance事件交易发起人使用的合约地址 PCS-USDC/BUSD Pancake Swap的USDC/BUSD交易对 PCS-BUSDT/BUSD Pancake Swap的BUSDT/BUSD交易对 PCS-DAI/BUSD Pancake Swap的DAI/BUSD交易对 PCS-UST/BUSD Pancake Swap的UST/BUSD交易对 PCS-VAI/BUSD Pancake Swap的VAI/BUSD交易对 PCS-ALPACA/BUSD Pancake Swap的ALPACA/BUSD交易对 BF-Attacker-2 Belt Finance事件最终收款地址 beltBUSD bVenusBUSD vBUSD Token Venus BUSD 交易： 本次事件Attacker使用相同的方式进行了8次交易： https://bscscan.com/tx/0x50b0c05dd326022cae774623e5db17d8edbc41b4f064a3bcae105f69492ceadc https://bscscan.com/tx/0xc4d4156aab1fca85c99e85352b836274d3c53bafe98a2c9867b68950e1eafde9 https://bscscan.com/tx/0xb57acfeab13d52664416aa2ada9b490e340292731fced049fc8c4a730b7af700 https://bscscan.com/tx/0xcca1ebf01e694bb4c447f6018eebb34a3b829cff9ea1ec5fce236eb3cc2ef99c https://bscscan.com/tx/0x7719e1bae25dbe80539edea37c962e941ec4141145e6eabe63540b7178ffd0d0 https://bscscan.com/tx/0xd790026feda9a16646647e9df0779dc4a7b173053369847691b8f3f678da1f66 https://bscscan.com/tx/0xf598e092ab82ce08798f9dab7ea6ade64f152aa91db897f3449b23ab591baa1d https://bscscan.com/tx/0x7b3b727a56d1649ee325c42416a1199f4a9b4f4eb024a60b5848a7b1485953b1 事件分析 与AutoShark和BurgerSwap一样，本次攻击也是始于从PancakeSwap的闪电贷。0xf598…91baa1d交易的攻击过程如下： 从PancakeSwap的多个流动池借出大量（390,379,325）BNB 将200,379,325个BUSD铸造成235,391,847个beltBUSD 使用190,000,000个BUSD兑换168,535,055个BUSDT 这次兑换导致Ellipsis.fi的3pool增值了3% burn掉235,391,847个beltBUSD，然后获得了201,383,385个BUSD 注意此步骤使用的beltBUSD是第二部铸造的，铸造时使用了200,379,325个BUSD，此时burn之后却获得了201,383,385个BUSD，多了1,004,060 BUSD 使用第三步兑换出的168,535,055个BUSDT兑换出189,339,377个BUSD 这一步兑换出了189,339,377个BUSD比第三步使用的190,000,000个BUSD少了660,623个BUSD 但是第四步额外获得的1,004,060个BUSD比660,623个BUSD多了343,437个BUSD（即通过2-5步获利了343,437个BUSD） 继续重复2-5步骤的交易（数字不完全一样，但是逻辑一样），最终额外获得7,132,461个BUSD 还闪电贷（闪电贷因为还有手续费还的必须比借的多） 获利离场，最终转移了1,320,605个BUSD 涉及到的代码 第二步是调用beltBUSD合约的deposit方法： 1234567891011121314151617181920212223function deposit(uint256 _amount)externalnonReentrant&#123; require(_amount &gt; 0, &quot;deposit must be greater than 0&quot;); pool &#x3D; calcPoolValueInToken(); &#x2F;&#x2F; 把token（即BUSD）转给当前的合约 IERC20(token).safeTransferFrom(msg.sender, address(this), _amount); &#x2F;&#x2F; 计算所占的份数 uint256 shares &#x3D; 0; if (pool &#x3D;&#x3D; 0) &#123; shares &#x3D; _amount; pool &#x3D; _amount; &#125; else &#123; &#x2F;&#x2F;0.1%(999&#x2F;1000) enterance fee shares &#x3D; (_amount.mul(totalSupply())).div(pool).mul(999).div(1000); &#125; pool &#x3D; calcPoolValueInToken(); &#x2F;&#x2F; 铸造bBUSD给发送者 _mint(msg.sender, shares); rebalance();&#125; 第四步是调用beltBUSD合约的withdraw方法： 1234567891011121314151617181920212223242526function withdraw(uint256 _shares)externalnonReentrant&#123; require(_shares &gt; 0, &quot;withdraw must be greater than 0&quot;); &#x2F;&#x2F; 用户的余额 uint256 ibalance &#x3D; balanceOf(msg.sender); &#x2F;&#x2F; 取出的份额不能超过余额 require(_shares &lt;&#x3D; ibalance, &quot;insufficient balance&quot;); &#x2F;&#x2F; 计算当前合约和venus合约的BUSD之和 pool &#x3D; calcPoolValueInToken(); &#x2F;&#x2F; 根据份额和总发行量计算本次应该取出的BUSD金额 uint256 r &#x3D; (pool.mul(_shares)).div(totalSupply()); &#x2F;&#x2F; 销毁当前的token，即beltBUSD _burn(msg.sender, _shares); &#x2F;&#x2F; 获取当前地址的BUSD余额 uint256 b &#x3D; IERC20(token).balanceOf(address(this)); &#x2F;&#x2F; 如果当前合约的BUSD余额不够，则先从venus中提现出不够的那一部分 if (b &lt; r) &#123; _withdrawSome(r.sub(b)); &#125; &#x2F;&#x2F; 把所有的需要提现的BUSD转移给用户 IERC20(token).safeTransfer(msg.sender, r); pool &#x3D; calcPoolValueInToken();&#125; 提现时计算Eps3pool的稳定币数量的方法 此方法是导致攻击成功的关键因素，在计算各个稳定币的数量时，直接使用了稳定币合约的balanceOf方法会使计算的值变大，因此再burn掉bBUSD时才能获得较多的BUSD。 12345678910111213141516171819202122function eps3ToWant() public view returns (uint256) &#123; &#x2F;&#x2F; 获取ellipsisSwap的busd、usdc和usdt余额； &#x2F;&#x2F; 在第三步时因为进行了一次兑换（BUSD-&gt;BUSDT）所以ellipsisSwapAddress地址的BUSD便多了，BUSDT变少了 &#x2F;&#x2F; 但是因为增加的BUSD比减少的BUSDT要更多，因此整体来说这三个稳定币只和变大了 uint256 busdBal &#x3D; IERC20(busdAddress).balanceOf(ellipsisSwapAddress); uint256 usdcBal &#x3D; IERC20(usdcAddress).balanceOf(ellipsisSwapAddress); uint256 usdtBal &#x3D; IERC20(usdtAddress).balanceOf(ellipsisSwapAddress); &#x2F;&#x2F; 当前地址在ellipsisStake的有多少的Eps3 (uint256 curEps3Bal, )&#x3D; LpTokenStaker(ellipsisStakeAddress).userInfo(poolId, address(this)); &#x2F;&#x2F; Eps3一共有少个 uint256 totEps3Bal &#x3D; IERC20(eps3Address).totalSupply(); &#x2F;&#x2F; 根据当前地址的占比和busd、usdc和usdt余额，计算当前地址的busd、usdc、usdt之和 return busdBal.mul(curEps3Bal).div(totEps3Bal) .add( usdcBal.mul(curEps3Bal).div(totEps3Bal) ) .add( usdtBal.mul(curEps3Bal).div(totEps3Bal) );&#125; 事件处理结果 修改获取Eps3Pool中稳定币的方法，使用池中的方法获取而不是使用外部的ERC20代币的balanceOf方法 2、 在计算Eps3Pool对应的稳定币数量的方法中增加校验，校验的具体实现如上图，主要是校验“三个稳定币的最大的数量和最小的数量相差不能太多”。校验不成功就不允许提现","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"Exploit&Attack","slug":"区块链/ethereum/Exploit-Attack","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/Exploit-Attack/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"solidity","slug":"solidity","permalink":"https://guozhe001.github.io/tags/solidity/"},{"name":"智能合约","slug":"智能合约","permalink":"https://guozhe001.github.io/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"},{"name":"Exploit&Attack","slug":"Exploit-Attack","permalink":"https://guozhe001.github.io/tags/Exploit-Attack/"}]},{"title":"BurgerSwap被攻击分析","slug":"blockchain/ethereum/Exploit&Attack/BurgerSwap被攻击分析","date":"2024-11-22T06:32:06.491Z","updated":"2024-11-22T06:32:06.491Z","comments":true,"path":"2024/11/22/blockchain/ethereum/Exploit&Attack/BurgerSwap被攻击分析/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/Exploit&Attack/BurgerSwap%E8%A2%AB%E6%94%BB%E5%87%BB%E5%88%86%E6%9E%90/","excerpt":"","text":"事件影响 本次攻击主要是因为burgerswap的智能合约分层时的验证不足，导致被重入攻击成功 BURGER-BNB流动池中的BNB和BURGER都被大量拿走，导致流动性不足 因为黑客手里有大量BURGER，后续就算官方补充流动性也会因为黑客抛售BURGER而导致BURGER的价格变低 事件信息 此项目由成都链安进行审计 慢雾安全团队BurgerSwap 被黑分析 地址对应的tag与解释： TAG 解释 Pancake-BUSDT-BNB-LP Pancake的BUSDT-BNB流动池 BS-A-Contract BuegerSwap攻击者使用的合约地址 BS-Attacker BuegerSwap攻击者的地址 BS-A-Fake-Token BuegerSwap攻击者的“假币” BURGER BURGER Token Demax-BURGER-BNB-LP Demax的BURGER-BNB流动池 BLP-Fake-BURGER Burger的假币-BURGER流动池 Demax-Fake-BURGER-LP Demax的假币-BURGER流动池 攻击交易 https://bscscan.com/tx/0xac8a739c1f668b13d065d56a03c37a686e0aa1c9339e79fcbc5a2d0a6311e333 事件分析 本次攻击共分成六个步骤： 攻击者在Pancake的BUSDT-BNB流动池使用闪电贷贷出6,047个BNB 攻击者用兑换出的6,028个BNB在burgerswap的BURGER-BNB池兑换出92,677（直到目前为止没有任何问题） 攻击者使用兑换出的近一半（45,452）的BURGER和自己的token创建一个交易对 攻击者使用100个自己的token兑换BNB，兑换路径为FakeToken-&gt;BURGER-&gt;BNB 在兑换之前，会调用_getAmountsOut先计算出来路径上的金额是多少 在兑换时会调用&quot;FakeToken&quot;的transfer方法，此时发起重入攻击，使用剩余的45,316个BURGER兑换4,478个BNB 在攻击完成之后继续兑换路径上的其他transfer方法，原本因为4.2步已经使用45,316个BURGER兑换了4,478个BNB，无法再使用45,452个BURGER兑换出4,478个BNB（因为此时的BNB的价格已经升高，应该兑换的BNB更少才对）；但是因为此处依然使用4.1步骤计算好的兑换金额，并且最底层的兑换逻辑并没有根据x*y=k的公式进行校验，因此导致又以相同的价格兑换了BNB，即兑换出的BNB变多了 在完成第四步的攻击之后，BURGER-BNB池中的BNB数量变少，BURGER的价格变低，因此攻击者又使用491个的BNB兑换出了108,791个BURGER。（注意第一步使用6,028个BNB才换了92,677个BURGER！） 归还闪电贷6,062个BNB（闪电贷归还的金额必须大于借出的BNB） 事件涉及的源码 步骤4的调用DemaxPlatform合约的swapExactTokensForTokens方法如下: 从合约代码中可以看出，在这里已经计算好了所有兑换路径的所有的兑换出的金额是多少，然后调用_swap方法。 1234567891011121314151617181920212223242526272829function swapExactTokensForTokens( uint256 amountIn, uint256 amountOutMin, address[] calldata path, address to, uint256 deadline) external ensure(deadline) returns (uint256[] memory amounts) &#123; uint256 percent &#x3D; _getSwapFeePercent(); &#x2F;&#x2F; 计算路径上的token的out amounts &#x3D; _getAmountsOut(amountIn, path, percent); &#x2F;&#x2F; 最后一个目标token的数量必须大于等于期待的最小兑换数量 require(amounts[amounts.length - 1] &gt;&#x3D; amountOutMin, &#39;DEMAX PLATFORM : INSUFFICIENT_OUTPUT_AMOUNT&#39;); address pair &#x3D; DemaxSwapLibrary.pairFor(FACTORY, path[0], path[1]); &#x2F;&#x2F; 先收取交易费 _innerTransferFrom( path[0], msg.sender, pair, SafeMath.mul(amountIn, SafeMath.sub(PERCENT_DENOMINATOR, percent)) &#x2F; PERCENT_DENOMINATOR ); &#x2F;&#x2F; 兑换已经计算好的金额和path _swap(amounts, path, to); &#x2F;&#x2F; 把收取交易费后的金额转给pair _innerTransferFrom(path[0], msg.sender, pair, SafeMath.mul(amounts[0], percent) &#x2F; PERCENT_DENOMINATOR); _swapFee(amounts, path, percent);&#125; 步骤4中调用的DemaxPlatform合约的_swap方法如下： 下面的代码展示了在计算好金额之后，如果满足兑换之前的校验就按照计算好的金额在指定的路径进行兑换；最终兑换的逻辑会调用IDemaxPair的swap方法 1234567891011121314151617181920212223242526272829function _swap( uint256[] memory amounts, address[] memory path, address _to) internal &#123; require(!isPause, &quot;DEMAX PAUSED&quot;); &#x2F;&#x2F; 做一些swap之前的校验 require(swapPrecondition(path[path.length - 1]), &#39;DEMAX PLATFORM : CHECK DGAS&#x2F;TOKEN TO VALUE FAIL&#39;); for (uint256 i; i &lt; path.length - 1; i++) &#123; (address input, address output) &#x3D; (path[i], path[i + 1]); require(swapPrecondition(input), &#39;DEMAX PLATFORM : CHECK DGAS&#x2F;TOKEN VALUE FROM FAIL&#39;); require(IDemaxConfig(CONFIG).checkPair(input, output), &#39;DEMAX PLATFORM : SWAP PAIR CONFIG CHECK FAIL&#39;); (address token0, address token1) &#x3D; DemaxSwapLibrary.sortTokens(input, output); uint256 amountOut &#x3D; amounts[i + 1]; (uint256 amount0Out, uint256 amount1Out) &#x3D; input &#x3D;&#x3D; token0 ? (uint256(0), amountOut) : (amountOut, uint256(0)); address to &#x3D; i &lt; path.length - 2 ? DemaxSwapLibrary.pairFor(FACTORY, output, path[i + 2]) : _to; &#x2F;&#x2F; 调用DemaxPair的swap方法，这里直接传递了amount0Out和amount1Out两个金额 IDemaxPair(DemaxSwapLibrary.pairFor(FACTORY, input, output)).swap(amount0Out, amount1Out, to, new bytes(0)); if (amount0Out &gt; 0) _transferNotify(DemaxSwapLibrary.pairFor(FACTORY, input, output), to, token0, amount0Out); if (amount1Out &gt; 0) _transferNotify(DemaxSwapLibrary.pairFor(FACTORY, input, output), to, token1, amount1Out); &#125; emit SwapToken(_to, path[0], path[path.length - 1], amounts[0], amounts[path.length - 1]);&#125; 合约DemaxPair的swap方法如下： 此合约直接根据传入的金额进行代币的_safeTransfer，最终只是校验了一下amount0In &gt; 0 || amount1In &gt; 0。 123456789101112131415161718192021222324252627282930313233&#x2F;&#x2F; this low-level function should be called from a contract which performs important safety checksfunction swap( uint256 amount0Out, uint256 amount1Out, address to, bytes calldata data) external onlyPlatform lock &#123; require(amount0Out &gt; 0 || amount1Out &gt; 0, &#39;DEMAX PAIR : INSUFFICIENT_OUTPUT_AMOUNT&#39;); (uint112 _reserve0, uint112 _reserve1, ) &#x3D; getReserves(); &#x2F;&#x2F; gas savings require(amount0Out &lt; _reserve0 &amp;&amp; amount1Out &lt; _reserve1, &#39;DEMAX PAIR : INSUFFICIENT_LIQUIDITY&#39;); uint256 balance0; uint256 balance1; &#123; address _token0 &#x3D; token0; address _token1 &#x3D; token1; require(to !&#x3D; _token0 &amp;&amp; to !&#x3D; _token1, &#39;DEMAX PAIR : INVALID_TO&#39;); if (amount0Out &gt; 0) _safeTransfer(_token0, to, amount0Out); if (amount1Out &gt; 0) _safeTransfer(_token1, to, amount1Out); &#x2F;&#x2F; 因为在demaxPlatform调用此方法时data传入的是空，因此这个地方不会被调用 if (data.length &gt; 0) IDemaxCallee(to).demaxCall(msg.sender, amount0Out, amount1Out, data); balance0 &#x3D; _balanceOf(_token0, address(this)); balance1 &#x3D; _balanceOf(_token1, address(this)); &#125; uint256 amount0In &#x3D; balance0 &gt; _reserve0 - amount0Out ? balance0 - (_reserve0 - amount0Out) : 0; uint256 amount1In &#x3D; balance1 &gt; _reserve1 - amount1Out ? balance1 - (_reserve1 - amount1Out) : 0; uint256 _amount0Out &#x3D; amount0Out; uint256 _amount1Out &#x3D; amount1Out; require(amount0In &gt; 0 || amount1In &gt; 0, &#39;DEMAX PAIR : INSUFFICIENT_INPUT_AMOUNT&#39;); _update(balance0, balance1, _reserve0, _reserve1); emit Swap(msg.sender, amount0In, amount1In, _amount0Out, _amount1Out, to);&#125; 作为对比uniswapV2的UniswapV2Pair的swap方法如下： 在最后验证了新的x’和y‘的乘积必须大于等于原来的x和y的乘积：x‘ * y‘ &gt;= x * y 123456789101112131415161718192021222324252627282930313233&#x2F;&#x2F; this low-level function should be called from a contract which performs important safety checksfunction swap(uint amount0Out, uint amount1Out, address to, bytes calldata data) external lock &#123; require(amount0Out &gt; 0 || amount1Out &gt; 0, &#39;UniswapV2: INSUFFICIENT_OUTPUT_AMOUNT&#39;); (uint112 _reserve0, uint112 _reserve1,) &#x3D; getReserves(); &#x2F;&#x2F; gas savings require(amount0Out &lt; _reserve0 &amp;&amp; amount1Out &lt; _reserve1, &#39;UniswapV2: INSUFFICIENT_LIQUIDITY&#39;); uint balance0; uint balance1; &#123; &#x2F;&#x2F; scope for _token&#123;0,1&#125;, avoids stack too deep errors address _token0 &#x3D; token0; address _token1 &#x3D; token1; require(to !&#x3D; _token0 &amp;&amp; to !&#x3D; _token1, &#39;UniswapV2: INVALID_TO&#39;); if (amount0Out &gt; 0) _safeTransfer(_token0, to, amount0Out); &#x2F;&#x2F; optimistically transfer tokens if (amount1Out &gt; 0) _safeTransfer(_token1, to, amount1Out); &#x2F;&#x2F; optimistically transfer tokens if (data.length &gt; 0) IUniswapV2Callee(to).uniswapV2Call(msg.sender, amount0Out, amount1Out, data); balance0 &#x3D; IERC20(_token0).balanceOf(address(this)); balance1 &#x3D; IERC20(_token1).balanceOf(address(this)); &#125; uint amount0In &#x3D; balance0 &gt; _reserve0 - amount0Out ? balance0 - (_reserve0 - amount0Out) : 0; uint amount1In &#x3D; balance1 &gt; _reserve1 - amount1Out ? balance1 - (_reserve1 - amount1Out) : 0; require(amount0In &gt; 0 || amount1In &gt; 0, &#39;UniswapV2: INSUFFICIENT_INPUT_AMOUNT&#39;); &#123; &#x2F;&#x2F; scope for reserve&#123;0,1&#125;Adjusted, avoids stack too deep errors uint balance0Adjusted &#x3D; balance0.mul(1000).sub(amount0In.mul(3)); uint balance1Adjusted &#x3D; balance1.mul(1000).sub(amount1In.mul(3)); &#x2F;&#x2F; x‘ * y‘ &#x3D; x * y require(balance0Adjusted.mul(balance1Adjusted) &gt;&#x3D; uint(_reserve0).mul(_reserve1).mul(1000**2), &#39;UniswapV2: K&#39;); &#125; _update(balance0, balance1, _reserve0, _reserve1); emit Swap(msg.sender, amount0In, amount1In, amount0Out, amount1Out, to);&#125; 作为对比pancakeswap的PancakePair的swap方法代码如下： 在最后不仅有校验进入的金额大于出去的金额，也有乘积的校验。 123456789101112131415161718192021222324252627282930313233343536373839404142434445&#x2F;&#x2F; this low-level function should be called from a contract which performs important safety checksfunction swap(uint amount0Out, uint amount1Out, address to, bytes calldata data) external lock &#123; &#x2F;&#x2F; 至少有一个token兑换出的金额大于0 require(amount0Out &gt; 0 || amount1Out &gt; 0, &#39;Pancake: INSUFFICIENT_OUTPUT_AMOUNT&#39;); &#x2F;&#x2F; 获取当前lp池中的两个token的储备数量 (uint112 _reserve0, uint112 _reserve1,) &#x3D; getReserves(); &#x2F;&#x2F; gas savings &#x2F;&#x2F; 兑换出的token数量必须小于当前池中的token数量 require(amount0Out &lt; _reserve0 &amp;&amp; amount1Out &lt; _reserve1, &#39;Pancake: INSUFFICIENT_LIQUIDITY&#39;); uint balance0; uint balance1; &#123; &#x2F;&#x2F; scope for _token&#123;0,1&#125;, avoids stack too deep errors address _token0 &#x3D; token0; address _token1 &#x3D; token1; &#x2F;&#x2F; 接收兑换token的地址不能是当前lp池中的token中的任意一个 require(to !&#x3D; _token0 &amp;&amp; to !&#x3D; _token1, &#39;Pancake: INVALID_TO&#39;); &#x2F;&#x2F; 如果token0兑换出的金额大于0，则把amount0Out转账给指定的地址to if (amount0Out &gt; 0) _safeTransfer(_token0, to, amount0Out); &#x2F;&#x2F; optimistically transfer tokens if (amount1Out &gt; 0) _safeTransfer(_token1, to, amount1Out); &#x2F;&#x2F; optimistically transfer tokens &#x2F;&#x2F; 如果参数data不为空，则调用合约to的pancakeCall方法；接下来就是合约to的表演了 if (data.length &gt; 0) IPancakeCallee(to).pancakeCall(msg.sender, amount0Out, amount1Out, data); &#x2F;&#x2F; 当合约to表演完之后，分别获取当前lp在两个token中的余额 balance0 &#x3D; IERC20(_token0).balanceOf(address(this)); balance1 &#x3D; IERC20(_token1).balanceOf(address(this)); &#125; &#x2F;&#x2F; 如果新的余额大于（当前存储量-兑换出的数量），则amount0In等于新的余额 - （当前存储量-兑换出的数量） &#x2F;&#x2F; amount0In和amount1In是在计算实际进来了多少 uint amount0In &#x3D; balance0 &gt; _reserve0 - amount0Out ? balance0 - (_reserve0 - amount0Out) : 0; uint amount1In &#x3D; balance1 &gt; _reserve1 - amount1Out ? balance1 - (_reserve1 - amount1Out) : 0; &#x2F;&#x2F; 如果两个都是0，说明新的balance都不大于（存储量-兑换出的金额）；这说明没有进来，那么就报错； &#x2F;&#x2F; 其实这个校验是在说打给当前lp池的token数量必须大于兑换出去的数量 require(amount0In &gt; 0 || amount1In &gt; 0, &#39;Pancake: INSUFFICIENT_INPUT_AMOUNT&#39;); &#123; &#x2F;&#x2F; scope for reserve&#123;0,1&#125;Adjusted, avoids stack too deep errors &#x2F;&#x2F; 计算调整后的balance，此处会收取千分之二的费用 uint balance0Adjusted &#x3D; balance0.mul(1000).sub(amount0In.mul(2)); uint balance1Adjusted &#x3D; balance1.mul(1000).sub(amount1In.mul(2)); &#x2F;&#x2F; 调用此方法后的两个token的积必须大于等于原始储备的两个token的积；即还回来的token在收完手续费之后必须大于借出去的 require(balance0Adjusted.mul(balance1Adjusted) &gt;&#x3D; uint(_reserve0).mul(_reserve1).mul(1000**2), &#39;Pancake: K&#39;); &#125; _update(balance0, balance1, _reserve0, _reserve1); emit Swap(msg.sender, amount0In, amount1In, amount0Out, amount1Out, to);&#125; 合约DemaxPair的_safeTransfer方法如下： 此方法会调用token的transfer方法，而本次的攻击就是攻击者自己的token的transfer方法又调用了DemaxPlatform合约的swapExactTokensForTokens方法。 1234567891011function _safeTransfer( address token, address to, uint256 value) private &#123; &#x2F;&#x2F; 调用token的transfer方法 (bool success, bytes memory data) &#x3D; token.call(abi.encodeWithSelector(SELECTOR, to, value)); require(success &amp;&amp; (data.length &#x3D;&#x3D; 0 || abi.decode(data, (bool))), &#39;DEMAX PAIR : TRANSFER_FAILED&#39;);&#125; 官方后续处理 创建新的**$cBURGER**并空头给满足条件的原$BURGER的持有者 使用burgerswap的收入以及原本要奖励给团队的burger建造一个价值700万美元的奖励池","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"Exploit&Attack","slug":"区块链/ethereum/Exploit-Attack","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/Exploit-Attack/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"solidity","slug":"solidity","permalink":"https://guozhe001.github.io/tags/solidity/"},{"name":"智能合约","slug":"智能合约","permalink":"https://guozhe001.github.io/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"},{"name":"Exploit&Attack","slug":"Exploit-Attack","permalink":"https://guozhe001.github.io/tags/Exploit-Attack/"}]},{"title":"XVS清算事件","slug":"blockchain/ethereum/Exploit&Attack/XVS清算事件","date":"2024-11-22T06:32:06.491Z","updated":"2024-11-22T06:32:06.491Z","comments":true,"path":"2024/11/22/blockchain/ethereum/Exploit&Attack/XVS清算事件/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/blockchain/ethereum/Exploit&Attack/XVS%E6%B8%85%E7%AE%97%E4%BA%8B%E4%BB%B6/","excerpt":"","text":"事件影响 本次事件不是因为代码漏洞被利用，而是由于抵押资产XVS的价格波动导致清算 本次事件没有代币被偷，但是由于清算时会收取10%的清算费用，使抵押XVS进行贷款的地址损失至少10% 抵押XVS进行贷款的地址被大量清算 清算会导致损失至少10%的清算费用 由于抵押率借出的资产是抵押资产最多的80%，因此总损失至少30% 如果抵押的是稳定币，借出的也是稳定币，并且不是定格借出的资产的话，是不会被清算的 事件分析 此项目由certik审计 Venus是一个去中心化的借贷市场。通过抵押数字资产可以借出其他数字资产。 抵押借贷业务了解 超额抵押 根据白皮书的描述，可以借出的资产最多是抵押资产的75%。比如抵押一个BTC，当前价格为$40000，那么用户最多可以借出价值$30000（40000*75%）的其他资产。 抵押不足 如上例，如果用户借出了价值$30000（抵押物价值的75%）的USDT，那么当BTC的价格降低时就会造成抵押不足。 清算 如果BTC的价格降低到$25000，那么客户是没有意愿去还款$30000来赎回1个BTC的。 因此系统设计为任何人都可以对抵押不足的借贷进行清算，进行这个动作的人称为清算人，清算人在进行清算时需要偿还借款人的债务，然后以一定的折价获得抵押物。 假如现在BTC的价格跌到了$35000，那么清算人就可以以($35000*(1-5%) =$33250)的价格获得BTC，即清算人支付了债务$30000之后就能够得到0.902256个BTC，然后清算人以当前$35000的真实价格卖出BTC就能够获利$1578.96；剩余的0.097744个BTC再还给借款人，借款人还剩余$33421.04（0.097744 * 35000+30000）。 Venus事件分析 有人怀疑Venus团队监守自盗，具体操作如下 具体分析逻辑：Venus.IO Exploit— An Inside Job 总结如下： 地址0xef0…c7bf （该地址与Venus团队有关）在价格低的时候累积了130万XVS 地址0xef0…c7bf抵押XVS，借出BTC和ETH 地址0xef0…c7bf把借出的BTC和ETH发送到币安交易所 从币安交易所提取XVS到地址0xef0…c7bf（怀疑是用借出的BTC和ETH又重新购买了XVS） 然后重复2～5步骤，因为地址0xef0…c7bf的XVS量非常大，导致在循环操作几次之后XVS的价格快速上涨 然后当地址0xef0…c7bf不在操作时，XVS价格下降，从而导致此地址的XVS被清算，清算又导致XVS的价格继续快速下跌；从而发生连锁反应导致其他抵押XVS的地址也被清算 虽然最后地址0xef0…c7bf的抵押资产XVS全部被清算，但是却有4000个ETH和2000个BTC未偿还（即地址0xef0…c7bf把便宜的XVS换成了ETH和BTC） Venus团队的分析 官方发布的事故分析:Venus Protocol | 事故报告 总结如下： 没有内部人在操纵XVS价格而从中获利 本次事件是由于市场价格波动导致的大规模清算，这种清算是Venus作为借贷服务的提供者的生态逻辑问题 地址0xef0…c7bf 因为被清算，损失了$6600万","raw":null,"content":null,"categories":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"区块链/ethereum","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/"},{"name":"Exploit&Attack","slug":"区块链/ethereum/Exploit-Attack","permalink":"https://guozhe001.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ethereum/Exploit-Attack/"}],"tags":[{"name":"blockchain","slug":"区块链","permalink":"https://guozhe001.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"ethereum","slug":"ethereum","permalink":"https://guozhe001.github.io/tags/ethereum/"},{"name":"solidity","slug":"solidity","permalink":"https://guozhe001.github.io/tags/solidity/"},{"name":"智能合约","slug":"智能合约","permalink":"https://guozhe001.github.io/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"},{"name":"Exploit&Attack","slug":"Exploit-Attack","permalink":"https://guozhe001.github.io/tags/Exploit-Attack/"}]},{"title":"IDEA安装leetcode插件","slug":"algorithms/IDEA安装leetcode插件","date":"2024-11-22T06:32:06.490Z","updated":"2024-11-22T06:32:06.490Z","comments":true,"path":"2024/11/22/algorithms/IDEA安装leetcode插件/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/algorithms/IDEA%E5%AE%89%E8%A3%85leetcode%E6%8F%92%E4%BB%B6/","excerpt":"","text":"为什么安装leetcode插件 当然是刷题了，程序员都懂的。官方地址： 力扣 (leetcode) 官网 - 全球极客挚爱的技术成长平台 如何安装leetcode插件 安装IDEA插件 插件地址：leetcode editor；插件如何安装略。 配置插件 打开IDEA的Preferences，找到Tools-leetcode plugin；页面如下： 上图的序号配置依次如下： 配置leecode网站的用户名密码 配置生成代码的地址，此处我选择的是一个专门的项目的$&#123;base_dir&#125;/src/main/java/com目录，此插件会自动在此路径下创建leetcode/editor/cn,所以最终代码会在$&#123;base_dir&#125;/src/main/java/com/leetcode/editor/cn路径下 配置类名和文件名，必须配置默认是中文类名(需要勾选Costom Template) 贴出本人配置供参考： CodeFileName: 1P$&#123;question.frontendQuestionId&#125;$!velocityTool.camelCaseName($&#123;question.titleSlug&#125;) CodeTemplate: 12345package com.leetcode.editor.cn;$&#123;question.content&#125;public class P$&#123;question.frontendQuestionId&#125;$!velocityTool.camelCaseName($&#123;question.titleSlug&#125;)&#123; $&#123;question.code&#125;&#125; 如何使用leetcode插件 生成模板代码 1、按照下图标的顺序依次点击插件会加载各种算法 2、随便双击列表中的一个算法，会在配置的$&#123;base_dir&#125;/src/main/java/com/leetcode/editor/cn路径下生成模板代码，效果如下： 结果验证 码完代码之后选中相应的算法点Submit来进行验证正确性 注意事项 1、下面的两个注释不能删除或修改 123// leetcode submit region begin(Prohibit modification and deletion)// leetcode submit region end(Prohibit modification and deletion) 2、提交的所有代码必须在自动生成的Solution类之内 非常感谢！！！","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://guozhe001.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"工具","slug":"工具","permalink":"https://guozhe001.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"name":"leetcode","slug":"leetcode","permalink":"https://guozhe001.github.io/tags/leetcode/"},{"name":"IntelliJ","slug":"IntelliJ","permalink":"https://guozhe001.github.io/tags/IntelliJ/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://guozhe001.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}]},{"title":"动态规划学习","slug":"algorithms/动态规划","date":"2024-11-22T06:32:06.490Z","updated":"2024-11-22T06:32:06.490Z","comments":true,"path":"2024/11/22/algorithms/动态规划/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/algorithms/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","excerpt":"","text":"动态规划 本来想用5W2H分析法来解释此问题，但是发现比较困难，还是先看例子吧。动态规划的原理：动态规划先解决子问题，再逐步解决大问题。先有这个简单的概念即可，我会通过例子来说明。 举例：做个小偷顾问 例1，打家劫舍（无限背包问题） 问题描述 在万恶的资本主义社会美国，有一个小偷（罗伯特），有一天晚上罗伯特与他的同伙开了一辆卡车（假如可以装无限的现金）来到了一排主人都出门旅游去了的房屋面前，每间房内都藏有一定的现金，影响罗伯特偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。 请帮他设计程序以偷取最多的现金。 问题分析 1、简化问题 如果只有一个房子罗伯特最多能偷多少钱？ 如果有两个房子罗伯特最多能偷多少钱？ 如果有三个房子罗伯特最多能偷多少钱？ 。。。。。。 为了方便分析，我们把房子的数量和能够偷的钱数记录下来，我们画一个表格如下： 第一列表示如果只偷前面的n个房子 第二列表示如果只偷前面的n个房子最多能偷多少钱 括号里面的是偷哪些房子 2、各个击破简化后的问题 如果只有前面一个房子罗伯特最多能偷多少钱？ 房子数量 最多能偷多少钱？ 1 $100(1) 如果只有前面两个房子罗伯特最多能偷多少钱？当只有前面两个房子时，因为限制条件是不能偷相邻的房子不然会触发报警，所以偷其中金额大的那个即可。 房子数量 最多能偷多少钱？ 1 $100(1) 2 $200(2) 如果只有前面三个房子罗伯特最多能偷多少钱？当只有前面三个房子时，我们有两种选择，第1种：偷第三个和第一个；第2种：偷第二个。从两种选择中挑一个能偷的金额较大的方法。 房子数量 最多能偷多少钱？ 1 $100(1) 2 $200(2) 3 $200(2) 如果只有前面四个房子罗伯特最多能偷多少钱？ 当只有前面四个房子时，我们有两种选择： 第1种：偷第四个，再加上偷前两个房子的最大值 第2种：不偷第四个，只偷前面三个房子的最大值 从两种选择中挑一个能偷的金额较大的方法。 房子数量 最多能偷多少钱？ 1 $100(1) 2 $200(2) 3 $200(2) 4 $500 = $300(4) + $200(2) 如果只有前面五个房子罗伯特最多能偷多少钱？当只有前面五个房子时，我们有两种选择： 第1种：偷第五个，再加上偷前三个房子的最大值 第2种：不偷第五个，只偷前面四个房子的最大值 从两种选择中挑一个能偷的金额较大的方法。 房子数量 最多能偷多少钱？ 1 $100(1) 2 $200(2) 3 $200(2) 4 $500 = $300(4) + $200(2) 5 $500 = $300(4) + $200(2) 3、总结归纳 我们通过上面的表格可以总结出来什么吗？我们在此约定一个数学公式：total(n)表示最大能偷的金额；使用amount(n)表示第n个房子有多少金额根据以上的表格我们可以知道total(1) = 100 = amount(1) = max(amount(1), 0)total(2) = 200 = max(amount(2), amount(1))total(3) = 200 = max(amount(3) + amount(1), amount(2)) = max(amount(3) + total(3-2), total(2))total(4) = 500 = max(amount(4) + total(4-2), amount(3)) = max(amount(4) + total(4-2), total(3)) total(n) = max(amount(n) + total(n-2), total(n-1)) 4、代码实现 经过上面的分析我们竟然总结出了一个公式：total(n) = max(amount(n) + total(n-2), total(n-1))大家应该对斐波那契数列比较熟悉，他的公式是：f(n) = f(n-1) + f(n-2)，然后可能第一反应就想到了递归的实现，那么我们也可以使用递归的方式解决罗伯特的问题把？show you the code： 123456789101112131415161718// 递归方式public int robRecursion(int[] nums) &#123; // 当没有房子时 if (Objects.isNull(nums) || nums.length == 0) &#123; return 0; &#125; else if (nums.length == 1) &#123; // 当只有一个房子时 return nums[0]; &#125; else if (nums.length == 2) &#123; // 当只有两个房子时 return Math.max(nums[0], nums[1]); &#125; else &#123; // 其他情况 // total(n) = max(amount(n) + total(n-2), total(n-1)) return Math.max(nums[nums.length - 1] + robRecursion(Arrays.copyOf(nums, nums.length - 2)), robRecursion(Arrays.copyOf(nums, nums.length - 1))); &#125;&#125; OK，大功告成，上面的代码经过测试是没有问题的，解决了罗伯特的问题，回家睡觉。等等！！！我们是不是忘了什么，这篇文章的标题不是动态规划吗，动态规划呢？**让我们再回头看一下递归的方式实现，每当要计算total(n)时，就先计算total(n-1)和total(n-2)，如果说我们先计算出来total(n-1)和total(n-2)是不是计算total(n)的时候就不用重新计算total(n-1)和total(n-2)了？按照这个思路我们就需要把每次计算出的total(n-1)和total(n-2)的结果记录下来，等计算total(n)的时候就可以直接用了。show you the code： 12345678910111213141516171819202122232425// 动态规划方式public int rob(int[] nums) &#123; /* * 初始化动态规划的数组，此时的数组中的值都是0 * 此数组的下标为偷取的前n个房屋的数量 * 此数组的值为偷取的前n个房屋可以偷取的金钱最大值 * 如果dp[5] = 100；表示偷取前面的5家房屋，最多可以偷取100刀 */ int[] dp = new int[nums.length + 1]; for (int i = 1; i &lt;= nums.length; i++) &#123; int amountOfNumberI = nums[i - 1]; // 如果只偷第一个房子 if (i == 1) &#123; dp[i] = amountOfNumberI; &#125; else &#123; /* * 此时有两种选择:1、偷当前的房屋；2、不偷当前的房屋，两种选择取最大值 * 如果选择1，则要计算当前房屋的金钱与当前房屋前一个不相邻的所有房屋的金钱价值 * 如果选择2，则直接取当前房屋之前的所有房屋能够偷的金钱最大值 */ dp[i] = Math.max(amountOfNumberI + dp[i - 2], dp[i - 1]); &#125; &#125; return dp[nums.length];&#125; 恭喜你，上面的代码就是动态规划的方式；与递归的方式不同，每次的计算结果都保存在了dp数组中，计算下一个值时直接从数组中获取以前计算过的值即可。罗伯特偷一排房子的源码 例2，背包问题 问题描述 有一天罗伯特带着一个可以装4kg的背包，去了一家小商店，小商店里面有下面至少三个商品；请帮助他决定应该偷哪些商品。 商品名称 商品价格（单位$） 商品重量（单位kg） 吉他 1500 1 音箱 3000 4 电脑 2000 3 … … … 问题分析 首先拿到这个问题可能一眼就看出来了答案，就是偷吉他和电脑；那么如果说商品数量是100个的话是无法一眼看出答案的，那么我们应该怎么去帮罗伯特决策呢？ 我们再来看一下问题的关键： 容量4kg的背包 至少三个不同价格和不同重量的商品 一个商品要嘛全偷要嘛不偷，不能只偷一部分 偷的商品列表背包必须能装的下，并且价格最大 1、简化问题 简化问题的过程： 最简单的是什么？只有一个商品，只能装1kg的背包 增加点难度，只有一个商品，背包的重量逐渐增加到罗伯特的背包重量 继续增加难度，只有两个商品，1kg的背包能偷什么？2kg的背包能偷什么？3kg、4kg呢？ 有三个商品，1kg的背包能偷什么？2kg的背包能偷什么？3kg、4kg呢？ 有n个商品和能装mkg的背包 2、简化后的问题各个击破 把问题最小化：只有一个商品，只能装1kg的背包 到这里其实我们还是无法知道到底应该怎么帮罗伯特决策，那么我们可不可以把问题简化一下，假如背包容量是1，商品个数也是1只有一把吉他；如下： 容量1kg的背包 1把重量是1kg价格是$1500的吉他 如果是上面简化后的问题，我们是可以计算的，计算方法是：判断吉他能否装入背包，如果可以则1kg容量的背包可以偷吉他，最大价格是$1500，我们继续使用一个表格把它记录下来：我们先约定好表格的内容： 行表示背包的容量 列表示有哪些商品 单元格的数字表示可以偷的最大值 括号里面是偷哪些商品 | 商品\\容量 | 1 | | — | — | | 吉他 | 1500（吉他） | 我们是如何得到上面的表格的呢？判断吉他是否能装进容量为1kg的背包中，如果可以则偷吉他，吉他的价格也就是偷取的最大的价格。 增加难度，增加背包的容量：只有一个商品，背包的重量逐渐增加到罗伯特的背包重量 我们在上面的基础上再把背包的容量增加，直到增加到与罗伯特的背包相同的容量为止，但是依然只可以偷取一把吉他；我们把这些信息记录下来如下，其中第一列为商品，第一行为背包容量，表格记录的是偷取商品的最大价格，括号里面的是偷取的商品。如下表的红色部分就代表，背包容量为4只有一把吉他可偷时，可以偷取的商品最大价格是1500，偷取的商品是吉他。 商品\\容量 1 2 3 4 吉他 1500（吉他） 1500（吉他） 1500（吉他） 1500（吉他） 继续增加难度，增加一个商品 我们再在上面的基础上，增加可以偷取的商品，再加一个音箱，然后使用相同的方法绘制上面的表格； 商品\\容量 1 2 3 4 吉他 1500（吉他） 1500（吉他） 1500（吉他） 1500（吉他） 音箱 1500（吉他） 上面可以看到**table[音箱][容量1]**的单元格的值如上表是1500,因为容量是1的背包无法装下音箱，所以依然只能偷吉他，所以可以偷取的商品的最大的价格为1500。让我们完成这个表格的填写： 商品\\容量 1 2 3 4 吉他 1500（吉他） 1500（吉他） 1500（吉他） 1500（吉他） 音箱 1500（吉他） 1500（吉他） 1500（吉他） 3000（音箱） 如上表所示，当背包容量为4时，可以装下音箱，并且音箱的价格3000大于**table[吉他][容量4]的1500，所以此时我们设置table[音箱][容量4]的单元格的最大价格为3000。table[音箱][容量4] = Max(当前行计算的值, table[吉他][容量4]) 继续增加难度，再增加一个商品再增加一个商品 我们继续把电脑增加到可以偷取的商品列表中，然后继续使用相同的方法画出电脑行的前三个容量的单元格如下：此时我们可以看到**table[电脑][容量3]**的值应该是2000，因为容量是3时可以装下电脑，而且电脑的价格比吉他的价格高，所以此时罗伯特应该偷电脑而不是吉他。 商品\\容量 1 2 3 4 吉他 1500（吉他） 1500（吉他） 1500（吉他） 1500（吉他） 音箱 1500（吉他） 1500（吉他） 1500（吉他） 3000（音箱） 电脑 1500（吉他） 1500（吉他） 2000（电脑） table[电脑][容量3] = Max(当前行计算的值, table[音箱][容量3])我们继续看最后一个单元格（**table[电脑][容量4]）**应该填什么，如果罗伯特偷电脑，则背包容量还剩下1，而容量为1的背包可以偷取的商品价格最大值是1500，偷取的商品是吉他，所以此时可以选择偷取电脑+吉他，价格是2000+1500=3500；这比之前记录的背包容量是4时的商品最大值（3000）大，所以这个单元格的价格应该是3500，偷取的商品是电脑+吉他 商品\\容量 1 2 3 4 吉他 1500（吉他） 1500（吉他） 1500（吉他） 1500（吉他） 音箱 1500（吉他） 1500（吉他） 1500（吉他） 3000（音箱） 电脑 1500（吉他） 1500（吉他） 2000（电脑） 3500（电脑+吉他） table[电脑][容量4] = Max(当前行计算的值 + 剩余容量可以偷取的最大值, table[音箱][容量3])OK，完成上面的表格之后我们就可以确定，罗伯特应该偷电脑+吉他，商品的价格为3500。随着我们不断的填写表格，我们可以知道结果最终保存在表格的右下角，即**table[电脑][容量4]**的单元格内。 2、总结归纳 让我们总结一下每个单元格填写的规律：假设背包总容量为V，商品的数量是M，第i个商品的重量是Wi，价格是Pi，容量是v（1&lt;v&lt;=V）时我们可以使用下面的公式：f(i,v) = Wi &lt;= v ? max(Pi + f(i-1, v-Wi), f(i-1, v)) : f(i-1, v)分解上面的公式： 情形 值 Wi &lt;= v max(Pi + f(i-1, v-Wi), f(i-1, v)) Wi &gt; v f(i-1, v) 3、代码实现我们继续用上面罗伯特打家劫舍的思路，把已经计算过的值保存下来，然后在用到的时候直接取用。因为当前问题有多个商品和多种背包容量两个限制纬度，所以在记录时需要用到二维数组。show you the code： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 /** * 给出商品列表和背包的容量，请计算偷取哪些商品可以达到价格最大化，最大的价格是多少？ * * @param products 商品列表 * @param bagCapacity 背包容量 * @return 能够偷取的商品最大的价格之和 */ public int stealMaxPrice(Product[] products, int bagCapacity) &#123; /* * 二维数组，记录已经计算过的最大价格 * 二维数组比商品的个数多1，比背包的大小多1，原因是为了方便使用相同的公式，第0行和第0列的值都是0 */ int[][] table = new int[products.length + 1][bagCapacity + 1]; for (int j = 1; j &lt;= products.length; j++) &#123; Product product = products[j - 1]; for (int currentBagCapacity = 1; currentBagCapacity &lt;= bagCapacity; currentBagCapacity++) &#123; table[j][currentBagCapacity] = product.weight &lt;= currentBagCapacity ? Math.max(product.price + table[j - 1][currentBagCapacity - product.weight], table[j - 1][currentBagCapacity]) : table[j - 1][currentBagCapacity]; &#125; &#125; return table[products.length][bagCapacity]; &#125; /** * 商品信息 */ static class Product &#123; public Product(String name, int price, int weight) &#123; this.name = name; this.price = price; this.weight = weight; &#125; /** * 商品名称 */ String name; /** * 商品价格(单位$) */ int price; /** * 商品重量(单位磅) */ int weight; &#125;&#125; 代码中的table最终是这样的： 0 0 0 0 0 0 0 1500 1500 1500 1500 1500 0 1500 1500 1500 1500 3000 0 1500 1500 1500 2000 3500 其实上面的代码我简化了一下，返回的是最大能偷的价格，而罗伯特当然是要价格最大的商品列表了，这个实现比较麻烦不贴在这里了可以看源码 什么是动态规划（英语：Dynamic programming，简称DP） 概念： 动态规划是一种在数学、管理科学、计算机科学、经济学和生物信息学中使用的，通过把原问题分解为相对简单的子问题的方式求解复杂问题的方法。 用途： 动态规划常常适用于有重叠子问题和最优子结构性质的问题，动态规划方法所耗时间往往远少于朴素解法。动态规划背后的基本思想非常简单。大致上，若要解一个给定问题，我们需要解其不同部分（即子问题），再根据子问题的解以得出原问题的解。 适用情况 最优子结构性质。 如果问题的最优解所包含的子问题的解也是最优的，我们就称该问题具有最优子结构性质（即满足最优化原理）。 最优子结构性质为动态规划算法解决问题提供了重要线索。 无后效性。 即子问题的解一旦确定，就不再改变，不受在这之后、包含它的更大的问题的求解决策影响。 子问题重叠性质。 子问题重叠性质是指在用递归算法自顶向下对问题进行求解时，每次产生的子问题并不总是新问题，有些子问题会被重复计算多次。 动态规划算法正是利用了这种子问题的重叠性质，对每一个子问题只计算一次，然后将其计算结果保存在一个表格中，当再次需要计算已经计算过的子问题时，只是在表格中简单地查看一下结果，从而获得较高的效率，降低了时间复杂度。 ### 重叠子问题：如何理解这个概念呢？Fibnacci数列 1234567public int fib(int n)&#123; assert n &gt;=0; if(n&lt;2)&#123; return n; &#125; return fib(n-2) + fib(n-1);&#125; 在上面的斐波那契数列的递归的实现方法中，我们传入的参数n等于8或者等于10的时候，第m（m&lt;n）个数字是变化的吗？ 123456789101112public int fib(int n) &#123; assert n &gt;= 0; int[] c = new int[n + 1]; for (int i = 0; i &lt;= n; i++) &#123; if (i &lt; 2) &#123; c[i] = i; &#125; else &#123; c[i] = c[i - 2] + c[i - 1]; &#125; &#125; return c[n];&#125; 动态规划是递归算法的优化方案，一般来说能用递归的都可以思考一下能不能使用动态规划的方式优化。 最优子结构性质 上面两个罗伯特的例子就是最“优自结构性质”的问题，不好解释大家可以自己体会。 总结：判断是否可以用动态规划解决问题的核心是：大规模的问题是否能够通过较小规模的问题来解决。 效率： 通常许多子问题非常相似，为此动态规划法试图仅仅解决每个子问题一次，从而减少计算量：一旦某个给定子问题的解已经算出，则将其记忆化存储，以便下次需要同一个子问题解之时直接查表。这种做法在重复子问题的数目关于输入的规模呈指数增长时特别有用。 一些可以使用动态规划解决的常见题目 爬楼梯问题 最长子串（子串需要连续） 最长子序列（子序列不需要连续） 最长子串的变种：最长回文子串（回文：“上海自来水来自海上”） DNA序列比对 动态规划不可以解决什么问题 可以拆分的商品（如罗伯特拿着4kg的背包偷四袋不同价格的豆子（这些商品可以拆分））","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://guozhe001.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://guozhe001.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"动态规划","slug":"动态规划","permalink":"https://guozhe001.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"}]},{"title":"读书笔记-《我的第一本算法书》","slug":"algorithms/读书笔记-《我的第一本算法书》","date":"2024-11-22T06:32:06.490Z","updated":"2024-11-22T06:32:06.490Z","comments":true,"path":"2024/11/22/algorithms/读书笔记-《我的第一本算法书》/","link":"","permalink":"https://guozhe001.github.io/2024/11/22/algorithms/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E7%AE%97%E6%B3%95%E4%B9%A6%E3%80%8B/","excerpt":"","text":"第一章：数据结构 链表 特性 呈线性排列的数据结构，元素中有字段指向下一个元素 内存 内存空间不连续 时间复杂度 删除： 直接在最后把指向被删除的元素改为指向被删除的下一个元素修改即可 时间复杂度：O(1) 添加： 直接在当前列表的最后的元素的指向另一个元素即可 时间复杂度：O(1) 查询： 需要从最开始的元素查询 时间复杂度：O(n) 扩展 循环链表，最后一个元素的下一个元素指向开头的元素 每个元素有两个指向，分别指向前一个元素和后一个元素 数组 特性 呈线性排列的数据结构，元素有下标 内存 元素在内存中是连续的 时间复杂度 添加： 首先需要在末尾增加需要的存储空间，把需要添加的位置以及以后的元素的下标全部+1，把需要添加的位置放进新的元素 时间复杂度：O(n) 删除： 依此把需要删除的位置的以后的元素的下标-1 时间复杂度：O(n) 查询： 根据下标直接随机访问 时间复杂度：O(1) 栈 特性 呈线性排列的数据结构；后进先出Last In First Out，简称 LIFO push（入栈），pop（出栈） 时间复杂度 入栈和出栈，时间复杂度都是：O(1) 队列 特性 呈线性排列的数据结构；先进先出First In First Out，简称FIFO 入队，出队 时间复杂度 入队和出队的时间复杂度都是：O(1) 哈希表 特性 哈希表存储的是由键（key）和值（value）组 成的数据 如果在hash值不冲突时，哈希表的每个桶都只保存一个key；如果hash值冲突了，则会变成链表存储 先用key计算hash值，将得到的哈希值除以数组的长度，求得其余数、就找到了存储位置。这样的求余运算叫作“mod 运算” 如果两个key的hash值求余后找到的存储位置已经有值，这种存储位置重复了的情况便叫作“冲突”。遇到这种情况，可使用链表在已有数据的后面 继续存储新的数据 时间复杂度 哈希表的时间复杂度与hash算法有关 如果hash值不会冲突（理想情况），则新增、修改、删除、查询的时间复杂度都是：O(1) 如果hash值全部一致，则hash表其实就是一个链表，时间复杂度也与链表一致 补充说明 在存储数据的过程中，如果发生冲突，可以利用链表在已有数据的后面插入新数据 来解决冲突；这种方法被称为“链地址法”。 除了链地址法以外，还有几种解决冲突的方法。 其中，应用较为广泛的是“开放地址法”。这种方法是指当冲突发生时，立刻计算出一个候补地址（数组上的位置）并将数 据存进去。如果仍然有冲突，便继续计算下一个候补地址，直到有空地址为止。可以通过多次使用哈希函数或“线性探测法”等方法计算候补地址。 堆 特性 堆是一种图的树形结构，被用于实现“优先队列”（priority queues）。 优先队列是一种数据结构，可以自由添加数据，但取出数据时要从最小值开始按顺 序取出。 在堆的树形结构中，各个顶点被称为“结点”（node），数据就存储在这些结点中。 堆中的节点最多有两个子节点，节点的排序为从上到下，同一行则从左到右。 堆中存储数据的规则：子节点必须大于父节点 时间复杂度 添加数据 增加节点时在最下面一行的最左边增加，如果最下面的一行没有位置则增加新的一行 如果增加的数据比父节点的数字小，则与父节点交换位置，重复此步骤直到比父节点大或者没有父节点为止 时间复杂度：O(logn) 取出数据 取出数据永远是取最上面节点的数据 最上面节点的数据被取走之后，需要重新调整 重新调整时，需要把最后的数据（即最下面一行最右边的节点）移动到最上面 然后与最上面的两个子节点做比较，如果数字小于两个子节点，则调整完成 如果最上面的数据大于子节点的数据，则与较小的子节点的位置进行交换，重复此操作直到所有父节点小于子节点为止 时间复杂度:O(logn) 二叉查找树 特性 二叉查找树（又叫作二叉搜索树或二叉排序树）是一种采用了图的树形结构的数据结构 每个节点最多有两个子节点 每个节点的值大于其左子树的任意节点的值 每个节点的值小于其右子树的任意节点的值 根据上面的特性，我们可以知道如果想要查找最小值，则在左边的最末端 时间复杂度 添加数据 从顶端开始查找添加位置 如果添加的值大于顶端的值，则往右移；小于它则往左移 时间复杂度：O(logn) 删除数据 如果删除的节点没有子节点，则直接删除此节点 如果删除的节点有一个子节点，则删除此节点后把子节点移到当前的节点 如果删除的节点有两个子节点，则删除此节点后把左边子节点的最右端移到当前节点（也可以把右边子节点的最左端移到当前节点） 上面的一句可以理解为：把小于被删除的节点的最大值移到删除的节点；或者把大于被删除节点的最小值移到删除节点 如果移动的节点还有子节点，也按照同样的方式移动 时间复杂度：O(logn) 查找数据 从顶端开始查找 如果大于查找节点的值，则向右移；如果小于查找节点的值，则向左移；循环此操作 时间复杂度：O(logn) 扩展 关于时间复杂度 如果数的形状比较均衡，查找的时间复杂度是O(logn) 如果不均衡极端情况下是一个链表，查找的时间复杂度是O(n) 以二叉查找树为基础扩展的数据结构 “平衡二叉查找树”：这种数据结构可以修正形状不均衡的树，让其始终保持均衡形态，以提高查找效率 “B 树”：二叉查找树中一个结点最多有两个子结点，如果我们把子结点数扩展为 m（m 为预先设定好的常数）。像这种子结点数可以自由设定，并且形状均衡的树便是 B 树 第二章：排序 冒泡排序 算法释义 冒泡排序就是重复“从序列右边开始比较相邻两个数字的大小，再根据结果交换两个数字 的位置”这一操作的算法。 在这个过程中，数字会像泡泡一样，慢慢从右往左“浮”到序列的 顶端，所以这个算法才被称为“冒泡排序”。 时间复杂度：O(n²) 在冒泡排序中： 第 1 轮需要比较 n -1 次 第 2 轮需要比较 n -2 次 第 n -1 轮需 要比较 1 次 因此，总的比较次数为 (n -1) +(n -2) +…+1 ≈ n² /2。这个比较次数恒定为 该数值，和输入数据的排列顺序无关。 Java代码实现 冒泡排序 选择排序 算法释义 选择排序就是重复“从待排序的数据中寻找最小值，将其与序列最左边的数字进行交换” 这一操作的算法。 在序列中寻找最小值时使用的是线性查找。 时间复杂度：O(n²) 选择排序使用了线性查找来寻找最小值，因此在 第 1 轮中需要比较 n - 1 个数字 第 2 轮需要比较 n - 2 个数字 到第 n - 1 轮的时候就只需比较 1 个数字 因此，总的比较次数与冒泡排序的相同，都是(n-1)+(n-2)+…+1 ≈ n2/2 次。 Java代码实现 选择排序 插入排序 算法释义 插入排序是一种从序列左端开始依次对数据进行排序的算法。 在排序过程中，左侧的数据陆续归位，而右侧留下的就是还未被排序的数据。 插入排序的思路就是从右侧的未排序区域内取出一个数据，然后将它插入到已排序区域内合适的位置上。 时间复杂度：O(n²) Java代码实现 插入排序 堆排序 算法释义 堆排序的特点是利用了数据结构中的堆 首先，在堆中存储所有的数据，并按降序来构建堆 然后从堆中取出数据，并把取出的数据放在最右边的空位置 时间复杂度：O(nlogn) 堆排序一开始需要将 n 个数据存进堆里，所需时间为 O(nlogn) 每轮取出最大的数据并重构堆所需要的时间为 O(logn) 由于总共有 n 轮，所以重构后排序的时间也是 O(nlogn) 因此，整体来看堆排序的时间复杂度为 O(nlogn) Java代码实现 暂无 归并排序 算法释义 归并排序算法会把序列分成长度相同的两个子序列，当无法继续往下分时(也就是每个子序列中只有一个数据时)，就对子序列进行归并。 归并指的是把两个排好序的子序列合并成一个有序序列。 该操作会一直重复执行，直到所有子序列都归并为一个整体为止。 时间复杂度:O(nlogn) 把数组拆分成不可分割的最小单元的数组，时间复杂度O(n) 依次把所有数组进行合并排序，每一轮的比较次数为O(n)；需要进行logn轮 最终的时间复杂度是O(nlogn) Java代码实现 归并排序 快速排序 算法释义 快速排序算法首先会在序列中随机选择一个基准值（pivot） 然后将除了基准值以外的数分为“比基准值小的数”和“比基准值大的数”这两个类别，再将其排列成以下形式。 [ 比基准值小的数 ] 基准值 [ 比基准值大的数 ] 接着，对两个“[ ]”中的数据进行排序之后，整体的排序便完成了。对“[ ]”里面的数据进行排序时同样也会使用快速排序。 时间复杂度：O(nlogn) 每一轮比较的次数为n次，时间复杂度O(n) 需要进行logn轮的比较 最终的时间复杂度是O(nlogn) Java代码实现 快速排序 扩展 基准值约接近数组的平均值，排序的速度越快；基准值一般都使用第一个数字 第三章：数组的查找 线性查找 特性 遍历整个数组，逐个进行比较，直到找到为止 时间复杂度：O(n) Java代码实现 线性查找 二分查找 特性 只能查找已经排好序的数组 每次查找取中间位置的值与需要查找的数字比较，如果中间值大于待查找数据，则继续在中间值左边的数组进行查找；反之亦然 时间复杂度 O(logn) 每一次查找都会把待查找的范围缩小一半，直到结束为止 查找需要logn轮，每一轮比较1次；所以时间复杂度为O(logn) Java代码实现 二分查找 第四章：图的搜索 图的定义 计算机科学或离散数学中说的“图”是下面这样的： 上图中的圆圈叫作“顶点”(也叫“结点”)，连接顶点的线叫作“边”。也就是说，由顶点和连接每对顶点的边所构成的图形就是图。图可以表示各种关系 加权图 我们可以给边加上一个值，这个值叫作边的“权重”或者“权”，加了权的图被称为“加权图”。 没有权的边只能表示两个 顶点的连接状态，而有权的边就可以表示顶点之间的“连接程度”。 所谓“程度”在不同的场景意思也不一样： 地铁线路图两站之间的权是两站之间的距离 同样是地铁线路图，两站之前的权也可以是两站之间的时间 如果是高铁站线路图，两站之间的权也可以表示两站之间的乘车费 有向图 当我们想在路线图中表示该路线只能单向行驶时，就可以给边加上箭头，而这样的图就叫 作“有向图”。 和无向图一样，有向图也可以在边上添加权重，而且根据方向的不同，权重也不一样。 如下图中，如果权重表示花费时间，则B点到C点是下坡路，反过来C到B就是上坡路。 图能给我们带来哪些便利 假设图中有两个顶点 s 和 t，而我们设计出了一种算法， 可以找到“从 s 到 t 的权重之和最小”的那条路径，如： 寻找计算机网络中通信时间最短的路径 寻找路线图中耗时最短的路径 寻找路线图中最省乘车费的路径 图在代码中如何实现 图是用来表示节点与节点的关系的，所以可以使用Map来实现图 有向图，如上面图两个节点A和B、map中key为A的值有B，而key为B的值没有A，就可以表示方向 加权图，同样适用Map实现，区别是在value中既包含下一个节点的信息，又包含权重信息加权图Java实现 图的搜索 广度优先搜索 假设我们一开始位于某个顶点(即起点)，此时并不知道图的整体结构，而我们的目的是从起点开始顺着边搜索，直到到达指定顶点(即终点)。 在此过程中每走到一个顶点，就会判断一次它是否为终点。广度优先搜索会优先从离起点近的顶点开始搜索。 Java代码实现 广度优先搜索 深度优先搜索 深度优先搜索会沿着一条路径不断往下搜索直到不能再继续为止，然后再折返，开始搜索下一条候补路径。 Java代码实现 深度优先搜索 广度优先搜索和深度优先搜索对比 广度优先搜索选择的是最早成为候补的顶点，因为顶点离起点越近就越早成为候补，所以会从离起点近的地方开始按顺序搜索; 而深度优先搜索选择的则是最新成为候补的顶点，所以会一路往下，沿着新发现的路径不断深入搜索。 贝尔曼 - 福特算法 解决的问题 贝尔曼 - 福特(Bellman-Ford)算法是一种在图中求解最短路径问题的算法。 最短路径问题就是在加权图指定了起点和终点的前提下，寻找从起点到终点的路径中权重总和最小的那条路径。 求解的步骤 首先设置各个顶点的初始权重 :起点为 0，其他顶点为无穷大(∞)；这个权重的意思是从起点到当前节点的最短路径暂定值。 从起点（A）开始遍历，找到子节点（B），更新子节点的权重：min(A的权重+A到B边的权重,B节点权重) 循环上面的步骤一直更新所有节点 时间复杂度O(nm) 将图的顶点数设为 n、边数设为 m。 该算法经过 n 轮更新操作后就会停止，而在每轮更新操作中都需要对各个边进行 1 次确认 因此 1 轮更新所花费的时间就是 O(m)，整体的时间复杂度就是 O(nm) Java代码实现 贝尔曼-福特算法 狄克斯特拉算法 解决的问题 狄克斯特拉(Dijkstra)算法也是求解最短路径问题 的算法，使用它可以求得从起点到终点的路径中权重总和最小的那条路径。 求解的步骤 首先设置各个顶点的初始权重 :起点为 0，其他顶点为无穷大(∞)；这个权重的意思是从起点到当前节点的最短路径暂定值。 从起点出发，寻找可以从目前所在的顶点直达且尚未被搜索过的顶点。 计算各个候补顶点的权重。计算方法是“目前所在顶点的权重+目前所在顶点到候补顶点的权重”。 如果计算结果小于候补顶点的值，就更新这个值。 从候补顶点中选出权重最小的顶点，作为下一个被搜索的点，这一点与贝尔曼-福特算法不一样 时间复杂度 将图的顶点数设为 n、边数设为 m，那么如果事先不进行任何处理，该算法的时 间复杂度就是 O(n2)。 不过，如果对数据结构进行优化，那么时间复杂度就会变为 O(m + nlogn)。 Java代码实现 狄克斯特拉(Dijkstra)算法 贝尔曼福特算法和迪克斯特拉算法对比 说明 如果在一个闭环中边的权重总和是负数，那么只要不断遍历这个闭环，路径的权重就能不断减小，也就是说根本不存在最短路径。 贝尔曼 - 福特算法可以直接认定不存在最短路径，但在狄克斯特拉算法中，即便不存在最短路径，它也会 算出一个错误的最短路径出来。因此，有负数权重时不能使用狄克斯特拉算法。 总的来说，就是不存在负数权重时，更适合使用效率较高的狄克斯特拉算法，而存 在负数权重时，即便较为耗时，也应该使用可以得到正确答案的贝尔曼 - 福特算法。 A*（A-Star）算法 解决的问题 A-Start算法也是解决在图中求解最短路径问题的算法，由狄克斯特拉算法发展而来。 狄克斯特拉算法会从离起点近的顶点开始，按顺序求出起点到各个顶点的最短路径。 也就是说，一些离终点较远的顶点的最短路径也会被计算出来，但这部分其实是无用的。 与之不同，A* 就 会预先估算一个值，并利用这个值来省去一些无用的计算 第五章 安全算法 安全和算法 传输数据时的四个问题 窃听 A 向 B 发送的消息可能会在传输途中被 X 偷看(如下图)。这就是“窃听”。 假冒 A 以为向 B 发送了消息，然而 B 有可能是 X 冒充的(如下图);反过来，B 以为从 A 那里收到了消息，然而 A 也有可能是 X 冒充的。 篡改 即便 B 确实收到了 A 发送的消息，但也有可能像右图 这样，该消息的内容在途中就被 X 更改了。 除了被第三者篡改外，通 信故障导致的数据损坏也可能会使消息内容发生变化。 事后否认 B 从 A 那里收到了消息，但作为消息发送者的 A 可 能对 B 抱有恶意，并在事后声称“这不是我发送的消息”。 解决这些问题的安全技术 为了应对“窃听”，我们会使用“加密” 技术。 为了应对“假冒”，我们会使用“消息认证码”(下图左)或“数字签名”(下图右)技术。 为了应对“篡改”，我们同样会使用 “消息认证码”或“数字签名”技术。 其中“数字签名”技术还可以用于预防“事后否认”。 哈希函数 哈希函数可以把给定的数据转换成固定长度的无规律数值。 转换后的无规律数值可以作为数据摘要应用于各种各样的场景。 希函数的特征： 第一个特征是输出的哈希值数据长度不变。（不论输入的参数长短，得到的哈希值是定长的） 第二个特征是如果输入的数据相同，那么输出 的哈希值也必定相同。 第三个特征是即使输入的数据相似，但哪怕它们只有一比特的差别，那么输出的哈希值也会有很大的差异。 第四个特征是即使输入的两个数据完全不同，输 出的哈希值也有可能是相同的；这种情况叫作“哈希冲突”。 第五个特征是不可能从哈希值反向推算出原本的数据。（输入和输出不可逆） 哈希函数的算法中具有代表性的是 MD5 1、SHA-1 2和 SHA-2 等。其中 SHA-2 是现 在应用较为广泛的一个，而 MD5 和 SHA-1 存在安全隐患，不推荐使用。 应用示例 将用户输入的密码保存到服务器时也需要用到哈希函数。 如果把密码直接保存到服务器，可能会被第三者窃听，因此需要算出密码的哈希值，并只存储哈希值。 当用户输入密码时，先算出该输入密码的哈希值，再把它和服务 器中的哈希值进行比对。 共享密钥加密（对称加密） 共享密钥加密是加密和解密都使用相同密钥的一种加密方式。 实现共享密钥加密的算法有凯撒密码、AES 1、DES 2、动态口令等，其中 AES 的应用最 为广泛。 存在密钥分配问题 如上图，如果在A给B发送密钥时，被X监听了，则X就能用相同的密钥解密截获的密文。 公开密钥加密（非对称加密） 公开密钥加密是加密和解密使用不同密钥的一种加密方法。 由于使用的密钥不同，所以这种算法也被称为“非对称加密”。 加密用的密钥叫作“公开密钥”，解密用的叫作“私有密钥”。 实现公开密钥加密的算法有 RAS 算法、椭圆曲线加密算法等，其中使用最为广泛的是 RSA 算法。 不存在密钥分配问题 公开密钥和密文都是通过互联网传输的，因此可能会被 X 窃听。 但是，使用公开密钥无法解密密文，因此 X 也无法得到原本的数据。 密钥数量不会过多 只需要生成一对公私钥，就可以把公钥共享给n个人使用。 对称加密就的密钥数量会随着人的增多而增多。 公开密钥加密存在公开密钥可靠性的问题 如下图，加入B在把公钥Pb共享给A的时候，被X截获了；X把自己的公钥Px发送给了A。 这时A在不知情的情况下使用Px对数据进行加密发送给B时，X截获密文就可以通过私钥Sx进行解密。 然后X可以截获的通过公钥Pb加密恶意数据发送给B，B能够使用自己的密钥Sb进行解密，以为数据是A发送的。 如下图所示： 非对称加密算法的条件 可以使用某个数值对数据进行加密(计算)。 使用另一个数值对加密数据进行计算就可以让数据恢复原样。 无法从一种密钥推算出另一种密钥。 混合加密 共享密钥加密存在无法安全传输密钥的密钥分配问题，公开密钥加密又存在加密解密速度较慢的问题。 在混合加密中，要用处理速度较快的共享密钥加密对数据进行加密。不过，加密时使用的密钥，则需要用没有密钥分配问题的公开密钥加密进行处理。混合加密可以拆分成下面两步操作： 1、A在给B发送数据之前，先使用非对称的公钥对”对称加密的密钥“进行加密，然后把加密后的密文发送给A，A解密后就得到了”对称加密的密钥“。如下图： 2、发送数据时，A使用”对称加密的密钥“对数据进行加密，然后发送给B，这样B就能使用之前收到的”对称加密的密钥“对数据进行解密。如下图： 迪菲 - 赫尔曼密钥交换 迪菲 - 赫尔曼(Diffie-Hellman)密钥交换是一种可以在通信双方之间安全交换密钥的方法。 这种方法通过将双方共有的秘密数值隐藏在公开数值相关的运算中，来实现双方之间密钥的安全交换。 算法的概念 假设有一种方法可以合成两个密钥。使用这种方法来合成密钥P和密钥S，就会得到由这两个密钥的成分所构成的密钥 P-S。 这种合成方法有三个特征。 第一，即使持有密钥 P 和合成的密钥 P-S，也无法把密钥 S 单独取出来。 第二，不管是怎样合成而来的密钥，都可以把它作为新的元素，继续与别的密钥进行合成。如下图，使用密钥 P 和密钥 P-S，还能合成出新的密钥 P-P-S。 第三，密钥的合成结果与合成顺序无关，只与用了哪些密钥有关。比如合成密钥 B 和密钥 C 后，得到的是密 钥 B-C，再将其与密钥 A 合成，得到的就是密钥 A-B-C。而合成密钥 A 和密钥 C 后，得到的是密钥 A-C， 再将其与密钥 B 合成，得到的就是密钥 B-A-C。此处的密钥 A-B-C 和密钥 B-A-C 是一样的。 密钥的交换 消息认证码，MAC（Message Authentication Code） 消息认证码可以实现“认证”和“检测篡改”这两个功能。 举个例子，如下图，假设 A 发送给 B 的密文（abc）在通信过程中被 X 恶意篡改了，而 B 收到密文后没有意识到这个问题。 B对密文进行解密可能无法解密或者解密后的数据是xyz。如果A在向B进行商品订购，如果B解密出的密文是xyz，就会给A发送xyz商品从而导致问题。 如何使用消息认证码解决篡改问题呢？ A在发送数据之前，先生成一个用于制作消息验证码的密钥（key），然后用安全的方法（如混合加密）发送给B A对数据进行加密，并且使用第一步生成的key和密文生成一个数值，此值就是MAC A把MAC和密文一起发送给B B接收到密文和MAC后，先使用第一步A发送过来的key和密文使用同样的方法生成一个数值；并且使用此数值和收到的MAC进行比对 如果比对一致，则说明数据未被篡改 如果比对不一致，则说明数据被篡改了，直接丢弃数据；然后通知A重发 如果MAC和密文都被X截获了怎么办？ X可以修改密文，此时B使用被篡改后的密文和key生成的数值不等于MAC，就能确认通信过程中发生了篡改 X如果篡改了MAC，也与上一步一样，B也能确认通信过程中发生了篡改 X既篡改了密文也篡改了MAC，因为X没有生成MAC的key，所以B收到被篡改后的数据时同样能确认发生了篡改 我们可以把 MAC 想象成是由密钥和密文组成的字符串的“哈希值”。 计算 MAC 的算法有 HMAC 1、OMAC 2、CMAC 3等。目前，HMAC 的应用最为广泛。 消息验证码无法防止“事后否认” 然而，这种方法也有缺点。在使用消息认证码的过程中，AB 双方都可以对消息进行加密并且算出 MAC。 也就是说，我们无法证明原本的消息是 A 生成的还是 B 生成的。 因此，假如 A 是坏人，他就可以在自己发出消息后声称“这条消息是 B 捏造的”，而否认自己的行为。如果 B 是坏人，他也可以自己准备一条消息，然后声称“这是 A 发 给我的消息”。 数字签名 数字签名不仅可以实现消息认证码的认证和检测篡改功能，还可以预防事后否认问题的发生。 由于在消息认证码中使用的是共享密钥加密，所以持有密钥的收信人也有可能是消息的发 送者，这样是无法预防事后否认行为的。 而数字签名是只有发信人才能生成的，因此使用它就可以确定谁是消息的发送者了。 数字签名的特征 比如A给B发送消息，那么数字签名必须满足下面两个条件： 只要发送的消息上有 A 的数字签名，就能确定消息的发送者就是 A。 B 可以验证数字签名的正确性，但无法生成数字签名。 如何实现数字签名 先回想一下非对称加密的流程，A给B发送消息时使用B提供的公钥进行加密，B使用自己的私钥进行解密。如下图： 那么我们把这个过程反过来，就可以做到数字签名，如下图： A 使用自己的私有密钥加密消息。加密后的消息就是数字签名。 A把数字签名和原始的数据都发送给B B接收到数字签名和数据后，使用A提供的公钥进行解密，并把解密后的数据和发送来的数据做比对 如果一致，则说明此消息是由A发送的，因为A的公钥只能解密经有A的私钥加密的数据 能够用 A 的公开密钥解密的密文，必定是由 A 生成的。因此，我们可以利用这个结论来确认消息的发送者是否为 A，消息是否被人篡改。 由于 B 只有公开密钥，无法生成 A 的签名，所以也预防了“事后否认”这一问题的 发生。 在使用此方式进行加密时，A使用自己的私钥加密的数据最好没有任何意义，只是用来验证发送着是否是A，并且没有被篡改。 数字证书 “公开密钥加密”和“数字签名”无法保证公开密钥确实来自信息的发送者。因此，就算公 开密钥被第三者恶意替换，接收方也不会注意到。 而数字证书，就能保证公开密钥的正确性。 如何使用数据证书发送公钥 A持有公开密钥Pa 和 A私有密钥 Sa ，现在想要将公开密钥PA发送给B，如何做呢？ A首先需要向认证中心 (Certification Authority， CA)申请发行证书，证明公开密钥PA 确实由自己生成 认证中心里保管着他们自己准备的公开密钥Pc和私有密钥 Sc A将公开密钥Pa 和包含邮箱信息的个人资料发送给认证中心 认证中心对收到的资料进行确认，判断其是否为A本人的资料。确认完毕后，认证中心使用自己的私有密钥 Sc，根据 A 的资料生成数字签名。 认证中心将生成的数字签名和资料放进同一个文件中，并把这个文件发送给 A。（这个文件就是 A 的数字证书） A 将作为公开密钥的数字证书发送给了 B。 B 收到数字证书后，确认证书里的邮件地址确实是 A 的地址。接着，B 获取了认证中心的公开密钥。 B 对证书内的签名进行验证，判断它是否为认证中心给出的签名。证书中的签名只能用认证中心的公开密钥 Pc 进行验证。如果验证结果没有异常，就能说明这份证书的确由认证中心发行。 确认了证书是由认证中心发行的，且邮件地址就是 A的之后，B从证书中取出A的公开密钥PA。这样，公开密钥便从 A 传到 了B。 经过以上步骤信息的接收者B可以确认公开密钥的制作者是A。 循环质疑，我们从认证中心获取的公钥Pc真的来自认证中心吗 由于公开密钥自身不能表示其制作者，所以有可能是冒充认证中心的 X 所生成的。也就是说，这里同样存在公开密钥问题(请参考下图)。 实际上，认证中心的公开密钥 PC 是以数字证书的形式交付的，会有更高级别的认证 中心对这个认证中心署名(请参考下图)。 所以我们有所怀疑可以一直验证下去。 最顶端的认证中心被称为“根认证中心”(root CA)，其自身的正当性由自己证明。 第六章 聚类 什么是聚类 将相似的对象分为一组 聚类就是在输入为多个数据时，将“相似”的数据分为一组的操作。1个组就叫作1个 “簇”。 下面的示例中每个点都代表 1 个数据，在平面上位置较为相近、被圈起来的点就代表一类相似的数据。 也就是说，这些数据被分为了 3 个簇。 如何定义“相似” 定义数据间的差距 根据数据类型不同，定义该数据是否“相似”的标准也不同。具体来说，就是要对两个数 据之间的“差距”进行定义。 如：假设某所高中的某个年级中共有 400 名学生，现在我们想要将这些学生在考试中取得的语 文、数学、英语成绩数据化，并将他们按照“擅长或不擅长的科目相似”进行聚类。 把每个学生都转换成“(语文成绩 , 数学成绩 , 英语成绩)”形式的数据后，就可以将两个数据(c1, m1, e1)和(c2, m2, e2)之间的差距定义为 (c1-c2) + (m1-m2) + (e1-e2) ，其中差距小的数据 就互为“相似的数据”。 符合条件的算法 即使定义好了数据间的差距，聚类的方法也会有很多种。我们可以设定各种各样的条件， 比如想把数据分为 10 个簇，或者想把 1 个簇内的数据定在 30~50 人之间，再或者想把簇内数据 间的最大距离设为 10，等等。而设定什么样的条件取决于进行聚类的目的。 k-means 算法 k-means 算法是聚类算法中的一种，它可以根据事先给定的簇的数量进行聚类。 k-means算法步骤 首先准备好需要聚类的数据，然后决定簇的数量（比如下面图示簇的数量为3）。 随机选择 3 个点作为簇的中心点。 计算各个数据分别和 3 个中心点中的哪一个点距离最近。 将数据分到相应的簇中。这样，3 个簇的聚类就完成了。 计算各个簇中数据的重心，然后将簇的中心点移动到这个位置。 重新计算距离最近的簇的中心点，并将数据分到相应的簇中。 重复执行“将数据分到相应的簇中”和“将中心点移到重心的位置”这两个操作，直到中心点不 再发生变化为止。 解说： k-means 算法中，随着操作的不断重复，中心点的位置必定会在某处收敛，这一点 已经在数学层面上得到证明。 前面的例子中我们将簇的数量定为 3，若现在使用同样的数据，将簇的数量定为 2， 那么聚类将如下图所示。 位于左边和下边的两个数据块被分到了一个簇中。就像这样，由于 k-means 算法需 要事先确定好簇的数量，所以设定的数量如果不合理，运行的结果就可能会不符合我们的需求。 如果对簇的数量没有明确要求，那么我们可以事先对数据进行分析，推算出一个合适的数量，或者不断改变簇的数量来试验 k-means 算法。 另外，如果簇的数量同样为 2，但中心点最初的位置不同，那么也可能会出现下图 这样的聚类结果。 与之前的情况不同，这次右上和右下的两个数据块被分到了一个簇中。也就是说， 即使簇的数量相同，只要随机设置的中心点最初的位置不同，聚类的结果也会产生变化。 因此，我们可以通过改变随机设定的中心点位置来不断尝试 k-means 算法，再从中选择 最合适的聚类结果。 补充说明 除了 k-means 算法以外，聚类算法还有很多，其中“层次聚类算法”较为有名。与 k-means 算法不同，层次聚类算法不需要事先设定簇的数量。 在层次聚类算法中，一开始每个数据都自成一类。也就是说，有 n 个数据就会形成 n 个簇。然后重复执行“将距离最近的两个簇合并为一个”的操作 n-1 次。每执行 1 次， 簇就会减少 1 个。执行 n - 1 次后，所有数据就都被分到了一个簇中。在这个过程中，每个阶段的簇的数量都不同，对应的聚类结果也不同。只要选择其中最为合理的 1 个结果 就好。 合并簇的时候，为了找出“距离最近的两个簇”，需要先对簇之间的距离进行定义。 根据定义方法不同，会有“最短距离法”“最长距离法”“中间距离法”等多种算法。 第七章 其他算法 欧几里得算法 欧几里得算法(又称辗转相除法)用于计算两个数的最大公约数**(GCD:greatest common divisor)**，被称为世界上最古老的算法。 使用欧几里得算法求1112和695的最大公约数 首先用较小的数字去除较大的数字，求出余数。也就是对两个数字进行 mod 运算，除完后的余数为417。 mod运算即取余运算，A mod B 就是算出A除以B后的余数C。 接下来再用除数695和余数417进行mod运 算。结果为 278。 继续重复同样的操作，对 417 和 278 进行 mod 运算，结果为139。 对 278 和 139 进行 mod 运算，结果为 0。也就 是说，278 可以被 139 整除。 余数为 0 时，最后一次运算中的除数 139 就是 1112 和 695 的最大公约数。 Java实现 欧几里得最大公约数算法 素性测试 素性测试是判断一个自然数是否为素数的测试。素数(prime number)就是只能被 1 和其自身整除，且大于 1 的自然数。 素数从小到大有 2、3、5、7、11、13…目前在加密技术中被广泛应用的 RSA 算法就会用到大素数，因此“素性测试”在该算法中起到了重要的作用。","raw":null,"content":null,"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://guozhe001.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://guozhe001.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://guozhe001.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]}]}